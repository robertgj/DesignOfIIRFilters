\pdfminorversion=7 % Suppress warning messages with pdf files produced by dia
\documentclass[a4paper,twoside,10pt,english]{report}
%\usepackage{showframe} % Helps debug vbox and hbox warnings
\usepackage{geometry}
\geometry{verbose,nomarginpar,tmargin=1.5cm,bmargin=1.5cm,lmargin=1.5cm,
rmargin=1.5cm,headheight=1cm,headsep=1cm,footskip=1cm}

\usepackage[chapter]{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{amsthm}
\usepackage[toc,page]{appendix}
\usepackage{array}
\usepackage{babel}
\usepackage{booktabs}
\usepackage{chngcntr} \counterwithin*{footnote}{chapter}
\usepackage{color} % For monochrome printing
\usepackage{enumitem}
\usepackage{esint}
\usepackage{float}
\usepackage[T1]{fontenc}
\usepackage{framed}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{mathtools}
\usepackage{mflogo}
\usepackage{multirow}
\usepackage{nag}
\usepackage{needspace}
\usepackage{subcaption}
\usepackage{threeparttable}
\usepackage{times}
\usepackage[nottoc,notbib]{tocbibind}
\usepackage{upquote}
\usepackage{verbatim}

\ifdefined\pdfsuppresswarningpagegroup{}
  % Does this version of TeX allow suppression of some PDF figure warnings
  \pdfsuppresswarningpagegroup=1
\fi
  
\ifdefined\DesignOfIIRFiltersMono{}
  \begin{comment}
  To build a monochrome version:
  1. Set OCTAVE_ENABLE_MONOCHROME=1 in the shell to enable the following
     line in src/test_common.m:
    if getenv("OCTAVE_ENABLE_MONOCHROME")
      set(0,"defaultaxescolororder",zeros(size(get(0,"defaultaxescolororder"))));
    endif
  2. Use the command:
    pdflatex '\newcommand\DesignOfIIRFiltersMono{}\input{DesignOfIIRFilters}'
  \end{comment}
  \usepackage[hidelinks,colorlinks=false]{hyperref}
\else
  \usepackage[unicode=true,pdfusetitle,bookmarks=true,backref=page,
              bookmarksnumbered=false,bookmarksopen=false,breaklinks=false,
              pdfborder={1 0 0},colorlinks=true]{hyperref}
  \usepackage[all]{hypcap} % Needed to help hyperlinks direct correctly
\fi

\setlength{\parindent}{0em}
\setlength{\parskip}{\bigskipamount}

\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\floatname{algorithm}{Algorithm}

\newcommand{\DesignOfIIRFiltersPdfScale}{1}
\newcommand{\DesignOfIIRFiltersIncludeScale}{0.33}

\newcommand{\coloneq}{\mathrel{\resizebox{\widthof{$\mathord{=}$}}
    {\height}{ $\!\!\resizebox{1.2\width}{0.8\height}
      {\raisebox{0.23ex}{$\mathop{:}$}}\!\!=\!\!$ }}}

\DeclareMathOperator{\sinc}{sinc}
\DeclareMathOperator{\jsn}{sn}
\DeclareMathOperator{\jns}{ns}
\DeclareMathOperator{\jcn}{cn}
\DeclareMathOperator{\jnc}{nc}
\DeclareMathOperator{\jdn}{dn}
\DeclareMathOperator{\jnd}{nd}
\DeclareMathOperator{\jsd}{sd}
\DeclareMathOperator{\jds}{ds}
\DeclareMathOperator{\jcd}{cd}
\DeclareMathOperator{\jdc}{dc}
\DeclareMathOperator{\jsc}{sc}
\DeclareMathOperator{\jcs}{cs}
\DeclareMathOperator{\jam}{am}
\DeclareMathOperator{\jarcsn}{arcsn}
\DeclareMathOperator{\jarcsc}{arcsc}
\DeclareMathOperator{\jarccn}{arccn}
\DeclareMathOperator{\jarcdn}{arcdn}
\DeclareMathOperator{\jarccd}{arccd}
\DeclareMathOperator{\jarccs}{arccs}
\DeclareMathOperator{\cosec}{cosec}
\DeclareMathOperator{\cotan}{cotan}
\DeclareMathOperator{\sech}{sech}
\DeclareMathOperator{\arctanh}{arctanh}
\DeclareMathOperator{\arccosh}{arccosh}
\DeclareMathOperator{\sign}{sign}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
\DeclarePairedDelimiter{\nint}{\lfloor}{\rceil}
\DeclarePairedDelimiter{\mathabs}{\lvert}{\rvert}
\DeclarePairedDelimiter{\mathnorm}{\lVert}{\rVert}
\DeclareMathOperator{\mathnull}{null}
\DeclareMathOperator{\mathspan}{span}
\DeclareMathOperator{\mathrank}{rank}
\DeclareMathOperator{\mathrange}{range}
\DeclareMathOperator{\mathtrace}{trace}
\DeclareMathOperator{\mathadj}{adj}
\DeclareMathOperator{\mathdiag}{diag}
\DeclareMathOperator{\mathtpltz}{Toeplitz}
\DeclareMathOperator{\mathcohull}{cohull}
\DeclareMathOperator{\mathcone}{cone}
\DeclareMathOperator{\mathri}{ri}
\DeclareMathOperator{\mathaff}{aff}
\DeclareMathOperator{\mathconv}{conv}
\DeclareMathOperator{\mathhe}{He}
\DeclareMathOperator{\mathsq}{Sq}
\DeclareMathOperator{\mathvec}{vec}
\DeclareMathOperator{\mathconj}{\ast} % {\textsf{\tiny{H}}}
\DeclareMathOperator{\mathreverse}{\textsf{\tiny{F}}}

\allowdisplaybreaks{} % For page breaks in long \begin{align} equations

% Use numerals or letters for footnotes
%\renewcommand{\thefootnote}{\arabic{footnote}}
\renewcommand{\thefootnote}{\alph{footnote}}
                                                  
\title{On the design of IIR filters}
\author{Robert G. Jenssen}

\begin{document}
\begin{titlepage}
\maketitle
\end{titlepage}
\clearpage

\vspace*{7cm}
\begin{align*}
&\scalebox{2}{$\left(1+9^{-4^{6\times{}7}}\right)^{3^{2^{85}}}$}
\end{align*}
\vspace*{1cm}
\begin{center}
  See \url{https://erich-friedman.github.io/mathmagic/0804.html}
\end{center}

\vspace*{11cm}
Copyright \copyright\; 2017--2025 Robert G. Jenssen

This work is licensed under the Creative Commons Attribution 4.0 International
License.\\ View a copy of the license at 
\url{https://creativecommons.org/licenses/by/4.0/legalcode}
\tableofcontents
\listofalgorithms{}
\cleardoublepage
\chapter*{\hypertarget{sec:Introduction}{Introduction}}
An IIR filter can approximate a desired amplitude response with fewer
coefficients than an FIR
filter\footnote{Section~\ref{sec:Comparison-FIR-IIR-low-pass-filter-gain-zero-pole-with-SeDuMi}
compares the frequency responses of FIR and IIR implementations of a low-pass
filter with approximately flat pass-band group delay.}.
The design of IIR filters is more difficult
than the design of FIR filters. FIR filters are inherently stable. An FIR
filter design problem can be formulated as a convex optimisation problem with
a global solution (see, for example, \emph{Wu et
  al.}~\cite{WuBoydVandenberghe_FIRFilterDesignSDP}). The coefficient-response
surface of an IIR filter rational polynomial transfer function is more
complicated than that of an FIR polynomial transfer function. An IIR filter
design procedure must find a locally optimal solution that satisfies the
specifications and the coefficients of the IIR transfer function must be
constrained to ensure that the IIR filter is stable. This report describes my
experiments in the design of IIR digital filters with constraints on the
amplitude, phase and group delay responses. I intended to show that it is
possible to design an ``acceptable'' or ``good-enough'' IIR digital filter
with coefficients that use a limited number of shift-and-add operations and so
do not require software or hardware multiplications.

My experiments are programmed in the \emph{Octave}
language~\cite{Eaton_Octave}\footnote{The~\hyperlink{sec:Colophon}{Colophon}
  describes my local Octave build.}. Octave is an ``almost'' compatible
open-source-software clone of the commercial \emph{MATLAB}
package~\cite{Mathworks_MATLAB}. The minimum-mean-squared-error (MMSE)
approximation to the required response is found by either a
sequential-quadratic-programming (SQP) solver or by the \emph{SeDuMi}
second-order-cone-programming (SOCP) solver originally written by
\emph{Sturm}~\cite{Sturm_SeDuMi_GitHub}. The stability of the filter is
ensured by constraining the pole locations of the filter transfer function
when expressed in gain-pole-zero
form~\cite{Deczky_MinPSynthesisIIRDigitalFilters,
  Richards_DeczkyRecursiveDecimator} or by constraining the reflection
coefficients of a tapped all-pass lattice filter
implementation~\cite{GrayMarkel_DigitalLatticeAndLadderFilterSynthesis,
  Parhi_VLSIDigitalSignalProcessingSystems}. A valid initial solution for the
MMSE solver is found by ``eye'' or by using the WISE method of
\emph{Tarczynski et
  al.}~\cite{TarczynskiCainHermanowiczRojewski_WISEMethodDesignIIRFilters}. A
peak-constrained-least-squares (PCLS) solution is found by the exchange
algorithm of \emph{Selesnick et
  al.}~\cite{SelesnickLangBurrus_ConstrainedLeastSquareMultiBandFIRFilters}.
The lattice filter implementation with integer coefficients has good round-off
noise and coefficient sensitivity performance. For coefficient word lengths
greater than 10-bits the coefficients are allocated signed-digits by the
algorithm of \emph{Lim et
  al.}~\cite{Lim_SignedPowerOfTwoAllocationDigitalFilters} or that of
\emph{Ito et al.}~\cite{Ito_PowersOfTwoAllocationFIR} and branch-and-bound or
relaxation search is used to find an acceptable response. For lesser
coefficient word-lengths simulated-annealing of the signed-digit rounded
coefficients gives the best results.

\paragraph{The state variable description of digital filters}
Part~\ref{part:State-Variable-digital-filters} is a review of the \emph{state
  variable} description of digital filters. The state variable description
models the internal structure and round-off noise performance of the digital
filter. Chapter~\ref{sec:Schur-decomposition} shows the state variable
description of the tapped all-pass lattice filter. This part summarises
chapters $8$ to $10$ of the book \emph{``Digital Signal Processing''} by
\emph{Roberts} and \emph{Mullis}~\cite{RobertsMullis_DigitalSignalProcessing}
and chapter $12$ of \emph{``VLSI Digital Signal Processing Systems:Design
  and Implementation''} by
\emph{Parhi}~\cite{Parhi_VLSIDigitalSignalProcessingSystems}.

\paragraph{Optimising the IIR filter frequency response}
Part~\ref{sec:Constrained-Optimisation-of-IIR-frequency-response} reviews
constrained optimisation of the IIR filter transfer function.

One formulation of the filter optimisation problem is to
minimise the \emph{weighted squared error} of the frequency response:
\begin{align}
\begin{split}
  \textbf{minimise}\quad &\mathcal{E}_{H}\left(x\right) =
  \int W\left(\omega\right)\left|H\left(x,\omega\right)
    -H_{d}\left(\omega\right)\right|^{2}d\omega \\
\textbf{subject to}\quad &H\text{ is stable} 
\end{split}
\label{eqn:Definition-of-squared-response-error}
\end{align}
where $x$ is the coefficient vector of the filter, $\mathcal{E}_{H}$ is
the weighted sum of the squared error, $W\left(\omega\right)$ is the frequency
weighting, $H\left(x,\omega\right)$ is the filter frequency response and 
$H_{d}\left(\omega\right)$ is the desired filter frequency response.
The solution proceeds by choosing an initial coefficient vector
 and calling the SQP solver to find the coefficient vector that
optimises a second-order approximation to $\mathcal{E}_{H}$. The solution is
repeated until the difference between successive errors or
successive coefficient vectors is sufficiently small.

Alternatively, the optimisation problem can be expressed as a \emph{weighted
mini-max} problem:
\begin{align}\label{eqn:Definition-of-minimax-response-error}
\begin{split}
\textbf{minimise}\quad &\max\;W\left(\omega\right)\left|H\left(x,\omega\right)
  -H_{d}\left(\omega\right)\right|\\
\textbf{subject to}\quad &H\text{ is stable} 
\end{split}
\end{align}
Similarly, in this case, given an initial coefficient vector, the
solution proceeds by calling the SOCP solver to find the coefficient vector
that minimises the maximum error of a first-order approximation to $H$.

Constraints on the IIR filter response are applied by the
\emph{Peak-Constrained-Least-Squares} (PCLS) exchange algorithm of
\emph{Selesnick}, \emph{Lang} and
\emph{Burrus}~\cite{SelesnickLangBurrus_ConstrainedLeastSquareMultiBandFIRFilters}.
Appendix~\ref{app:PCLS-design-non-symmetric-FIR-filters-SOCP}
describes the use of the PCLS method of \emph{Selesnick et al.} to design 
symmetric FIR filters with constraints on the filter amplitude response.

Chapter~\ref{sec:Constrained-Optimisation-of-IIR-by-Quadratic-Programming-Pole-Zero-Location}
applies the \emph{Sequential Quadratic Programming} (SQP) method to the
optimisation of the frequency of an IIR filter. The SQP method is reviewed in
Appendix~\ref{app:Constrained-Non-linear-Optimisation}. That review makes
extensive use of the books by \emph{Nocedal} and 
\emph{Wright}~\cite{NocedalWright_NumericalOptimization},
\emph{Ruszczynski}~\cite{Ruszczynski_NonlinearOptimization} and
\emph{Bertsekas}~\cite{Bertsekas_NonlinearProgramming}.  I chose to write my
own SQP solver in Octave.  In
Chapter~\ref{sec:Constrained-Optimisation-of-IIR-by-Quadratic-Programming-Pole-Zero-Location},
I follow \emph{Deczky}~\cite{Deczky_MinPSynthesisIIRDigitalFilters} and
\emph{Richards}~\cite{Richards_DeczkyRecursiveDecimator} and optimise the
filter response with respect to the gain and pole and zero locations of the
filter rather than the coefficients of the transfer function polynomial. When
the transfer function is expressed in \emph{gain-pole-zero} form the stability
of the filter is ensured by constraining the radius of the poles of the
filter.  Calculation of the response and gradient from the coefficients of the
transfer function polynomials is simpler but the stability constraint on the
transfer function denominator is more complex and may exclude valid
alternative designs. Appendix~\ref{app:IIR-filter-response}, derives
expressions for the amplitude, phase and delay responses and gradients of an
IIR filter in terms of the gain-pole-zero coefficients. The SQP method
requires that at each step the optimisation problem is initialised with the
second-order derivatives (ie: the Hessian matrix) of the response with respect
to the coefficients.

Chapter~\ref{sec:IIR-Design-Using-SOCP} is based on the description of IIR
filter design using \emph{Second-Order-Cone-Programming} (SOCP) by \emph{Lu} and 
\emph{Hinamoto}~\cite{LuHinamoto_IIRFrequencyMaskingFiltersConeProgramming}. 
SOCP is a subclass of 
\emph{convex programming}~\cite{BoydVandenberghe_ConvexOptimization}. See the 
review articles by \emph{Alizadeh} and 
\emph{Goldfarb}~\cite{AlizadehGoldfarb_SecondOrderCone} and 
\emph{Lobo et al.}~\cite{LoboVandenbergheBoydLebret_ApplicationsSecondOrderConeProgramming} 
for a description of applications of SOCP.\@ Unlike SQP, SOCP optimisation does not
require the the Hessian of the response. In this report I use the public domain
\emph{SeDuMi} SOCP solver originally written by 
\emph{Jos Sturm}~\cite{Sturm_SeDuMi_GitHub}. 

Chapter~\ref{sec:IIR-Filter-Design-With-Predefined-Structure} considers 
optimisation of the filter transfer function of several filter structures.
The simplest IIR filter structure is the \emph{``direct form''} implementation
of the filter transfer function. This filter structure rarely has good
round-off noise and coefficient sensitivity when the coefficients are truncated.
\emph{Regalia et al.}~\cite{RegaliaMitraVaidyanathan_DigitalAllPassFilterVersatileSignalProcessing}
and 
\emph{Vaidyanathan et al.}~\cite{VaidyanathanMitraNuevo_LowSensitivityIIRDigitalFilters} 
show that an IIR digital filter composed of two all-pass filters connected in 
parallel has desirable coefficient sensitivity and round-off noise performance. 
\emph{Renfors} and 
\emph{Saram\"{a}ki}~\cite{RenforsSaramaki_RecursiveNthBandDigitalFiltersPart1,RenforsSaramaki_RecursiveNthBandDigitalFiltersPart2}, 
describe IIR digital filterbanks as a ``polyphase'' combination of all-pass
digital filters.
\emph{Gray} and
\emph{Markel}~\cite{GrayMarkel_DigitalLatticeAndLadderFilterSynthesis} and
\emph{Parhi}~\cite[Chapter 12]{Parhi_VLSIDigitalSignalProcessingSystems} describe
the synthesis of digital filters as tapped lattice structures. The lattice 
filter is stable if the lattice coefficients, $k_{l}$, have 
$\left|k_{l}\right|<1$. 
\emph{Johansson} and 
\emph{Wanhammar}~\cite{JohanssonWanhammar_RecursiveDigitalFiltersFrequencyMasking}, 
\emph{Mili\'{c}} and 
\emph{\'{C}erti\'{c}}~\cite{MilicCertic_IIRFilterBanksFrequencyResponseMasking} 
and 
\emph{Lu and Hinamoto}~\cite{LuHinamoto_IIRFrequencyMaskingFiltersConeProgramming} 
describe efficient, sharp transition-band IIR filter designs using the
\emph{frequency masking} approach described for FIR filters by 
\emph{Lim}~\cite{Lim_FrequencyResponseMaskingSharpDigitalFilters}.

\paragraph{Truncating the IIR filter coefficients}
Part~\ref{part:IIR-filters-fixed-point-coefficients} considers algorithms for
optimising the frequency response of the IIR filter with truncated or
quantised rather than exact or floating-point coefficients. The truncated
coefficients are represented as \emph{N-bit 2's complement} or
\emph{M-signed-digit} numbers. The signed-digit representation reduces the
complexity and power requirements of the filter. \emph{Lim et
  al.}~\cite{Lim_SignedPowerOfTwoAllocationDigitalFilters} and \emph{Ito et
  al.}~\cite{Ito_PowersOfTwoAllocationFIR} describe methods of allocating the
number of signed-digits used by each coefficient. This part considers methods
of searching the space of truncated coefficients for the best filter
response. A brute force, exhaustive, search is likely to take too much
time. Part~\ref{part:IIR-filters-fixed-point-coefficients}
considers methods of searching for the best filter response with truncated filter
coefficients.
Figure~\ref{fig:sqp-relax-schurOneMlattice-bandpass-10-nbits-intro-response}
shows the response of a $20$'th order tapped Schur lattice bandpass filter
with denominator coefficients only in $z^{-2}$ and $31$ non-zero
coefficients. The figure compares the filter responses for the floating-point
coefficients and $10$-bit signed-digit coefficients with an average of $3$
signed-digits allocated to each coefficient by the method of
\emph{Ito et al.}~\cite{Ito_PowersOfTwoAllocationFIR}. After successive
SQP-relaxation optimisations of the signed-digit coefficient values, 
\input{sqp_relaxation_schurOneMlattice_bandpass_10_nbits_test_signed_digits.tab}
signed-digits and
\input{sqp_relaxation_schurOneMlattice_bandpass_10_nbits_test_adders.tab}
shift-and-add operations are required to implement the coefficient
multiplications.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sqp_relaxation_schurOneMlattice_bandpass_10_nbits_test_intro}}
\caption{Comparison of the pass-band and stop-band amplitude responses and 
  group delay responses for a Schur one-multiplier lattice bandpass filter
  with floating-point coefficients and with 10 bit integer coefficients found by
  allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Ito et al.} and performing SQP-relaxation optimisation.}
\label{fig:sqp-relax-schurOneMlattice-bandpass-10-nbits-intro-response}
\end{figure}
Chapter~\ref{sec:Comparison-filter-search-fifth-order-elliptic-filter}, 
shows the results of searching for the truncated coefficients of a $5$th order 
elliptic filter having various structures and $6$-bit coefficients with the
\emph{bitflipping} algorithm of \emph{Krukowski} and
\emph{Kale}~\cite{KrukowskiKale_FixedPointFilterDesignBitFlippingSimplex}, and
the \emph{simplex}, \emph{differential evolution} and \emph{simulated annealing}
routines from the Octave-Forge \emph{optim} 
package~\cite{OctaveForge_OptimPackage}.

\paragraph{\label{sec:Introduction-reproducing-results}Reproducing my results}
The Octave scripts referred to in this report generate long sequences of
floating point operations. I recommend reading \emph{``What Every 
  Computer Scientist Should Know About Floating-point Arithmetic''} by
\emph{Goldberg}~\cite{Goldberg_FloatingPoint} and \emph{``The perfidious
  polynomial''} by \emph{Wilkinson}~\cite{Wilkinson_PerfidiousPolynomial}. In
the latter, Wilkinson reminisces about programming polynomial root finding on
early computers. He comments that \emph{``explicit polynomial equations with
  ill-conditioned roots are remarkably common''} but that if \emph{``one
  already knows the roots, then the polynomial can be evaluated without any
  loss of accuracy.''} As an example, Figure~\ref{fig:bincoeff-test-roots}
shows the results of calling the Octave \emph{roots} function to find the
roots of the binomial polynomial of order $20$ with the expression
\texttt{roots (bincoeff (20,0:20))}. In fact the roots are all $-1$.
Figure~\ref{fig:bincoeff-test-qzsolve} repeats the example with the oct-file
\emph{qzsolve}, an implementation using 128-bit floating-point numbers based
on \emph{gsl\_poly\_complex\_solve} from the GNU GSL
library\cite{GNU_GSL}\footnote{The \emph{MPSolve} multi-precision polynomial
  solver~\cite{BiniFiorentinoRobol_mpsolve} finds the expected roots. The package
  includes an Octave interface. The Matlab \emph{multroot}
  solver~\cite{Zeng_multroot} finds the expected roots.}.

\textbf{\textsc{The results shown in this report were obtained on my system
    running with a particular combination of CPU architecture, operating system,
    library versions, compiler version and Octave version. Your system will
    almost certainly be different. You may need to modify a script to run on
    your system.}}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bincoeff_test_roots}}
\caption{Plot of the roots of the binomial polynomial of order $20$ calculated
  by the Octave \emph{roots} function.}
\label{fig:bincoeff-test-roots}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bincoeff_test_qzsolve}}
\caption{Plot of the roots of the binomial polynomial of order $20$ calculated
  by the \emph{qzsolve} oct-file function using 128-bit floating point numbers.}
\label{fig:bincoeff-test-qzsolve}
\end{figure}

\cleardoublepage
\part{\label{part:State-Variable-digital-filters}State Variable description of digital filters}
\cleardoublepage
\chapter{\label{chap:Review-State-Variable-digital-filters}A review of the State Variable description of digital filters}
This chapter briefly summarises parts of the text 
\emph{Digital Signal Processing} by \emph{Roberts} and 
\emph{Mullis}~\cite{RobertsMullis_DigitalSignalProcessing}.
Appendix~\ref{app:Review-of-complex-variables} reviews the necessary complex
variables theory.
\section{The z-transform}
The bi-lateral \emph{z-transform} of a sequence $\boldsymbol{f}$ is
\begin{align*}
F\left(z\right) &= Z\left\{\boldsymbol{f}\right\} = 
\sum_{k=-\infty}^{\infty} f\left(k\right)z^{-k}
\end{align*}
where $z$ is a complex variable. The region of convergence (ROC) of the series
is that part of the $z$-plane for which
\begin{align*}
\sum_{k} \left|f\left(k\right)z^{-k}\right| < \infty
\end{align*}
If $\boldsymbol{f}$ is causal then the z-transform is one-sided:
\begin{align*}
F\left(z\right) &= \sum_{k=0}^{\infty} f\left(k\right)z^{-k}
\end{align*}

The \emph{Cauchy integral theorem}, shown in 
Appendix~\ref{app:Cauchys-Integral-Theorem}, can be used to invert the 
z-transform. Start by selecting a circular contour, $C$, centred at the origin
and lying in the ROC.\@ Multiply each side of the z-transform by $z^{n-1}$ and
integrate along $C$:
\begin{align*}
\ointctrclockwise_{C}z^{n-1}F\left(z\right)dz &= 
\sum_{k=-\infty}^{\infty} \ointctrclockwise_{C}f\left(k\right)z^{n-1-k}dz
\end{align*}
Cauchy's \emph{integral lemma} states
\begin{align*}
\ointctrclockwise_{C}z^{n}dz &=\begin{cases}
2\pi\imath & n=-1 \\
0 & n \ne -1, \text{integral}
\end{cases}
\end{align*}
so the terms in the sum vanish except for $k=n$ and
\begin{align*}
f\left(n\right) &= 
\frac{1}{2\pi\imath}\ointctrclockwise_{C}z^{n-1}F\left(z\right)dz 
\end{align*}
For rational z-transforms the contour integrals are usually evaluated by
finding the residues of the integrand. See 
Appendix~\ref{app:Review-of-complex-variables}.

The inversion integral can be used to derive Parseval's theorem for the 
z-transform of two sequences. Following \emph{Roberts} and
\emph{Mullis}~\cite[Section 3.4]{RobertsMullis_DigitalSignalProcessing}, let 
$\boldsymbol{f}$ and $\boldsymbol{g}$ be causal sequences with z-transforms
$F\left(z\right)$ and $G\left(z\right)$, respectively. Define the z-transform
of the product as
\begin{align*}
Z\left\{\boldsymbol{f}  \centerdot \boldsymbol{g}\right\} &=
\sum_{k=0}^{\infty} f\left(k\right)g\left(k\right)z^{-k}
\end{align*}
Substituting the inversion integral for $\boldsymbol{f}$
\begin{align*}
Z\left\{\boldsymbol{f}  \centerdot \boldsymbol{g}\right\} &=
\frac{1}{2\pi\imath}\sum_{k=0}^{\infty} 
\ointctrclockwise_{C}g\left(k\right)s^{k-1}F\left(s\right)z^{-k}ds \\
&=\frac{1}{2\pi\imath}\ointctrclockwise_{C}s^{-1}F\left(s\right)
\sum_{k=0}^{\infty} g\left(k\right){\left[zs^{-1}\right]}^{-k}ds \\
&= \frac{1}{2\pi\imath}\ointctrclockwise_{C}
s^{-1}F\left(s\right)G\left(\frac{z}{s}\right)ds
\end{align*}
If $\left|z\right|=1$ lies in the ROC of the integrand then
\begin{align*}
Z\left\{\boldsymbol{f}  \centerdot \boldsymbol{g}\right\} &=
\frac{1}{2\pi\imath}\ointctrclockwise_{C}
s^{-1}F\left(s\right)G\left(\frac{1}{s}\right)ds
\end{align*}
If $\boldsymbol{f}=\boldsymbol{g}$ then we have the discrete form of 
Parseval's theorem:
\begin{align*}
Z\left\{\boldsymbol{f}  \centerdot \boldsymbol{f}\right\} &=
\sum_{k=0}^{\infty} f^{2}\left(k\right)z^{-k} \\
&= \frac{1}{2\pi\imath}\ointctrclockwise_{C}
z^{-1}F\left(z\right)F\left(z^{-1}\right)dz
\end{align*}
If $C$ is the contour $\left|z\right|=1$ then, after expanding terms in
$e^{\imath\theta}$:
\begin{align*}
\sum_{k=0}^{\infty} f^{2}\left(k\right) &=
 \frac{1}{2\pi}\int_{-\pi}^{\pi}\left|F\left(e^{\imath\theta}\right)\right|d\theta
\end{align*}
\section{Filter difference equation}
The standard difference equation (SDE) of a digital filter is
\begin{align}
\sum^{n}_{l=0}a_{l}y\left(k-l\right) &= \sum^{m}_{l=0}b_{l}u\left(k-l\right),
\quad a_{0}=1\text{ and }k\ge 0
\label{eqn:Standard-difference-equation}
\end{align}

If $\star$ represents the convolution operation and $u\left(k\right)$ and
$y\left(k\right)$ are the input and output sequences, respectively, then the
difference equation is: 
\begin{align*}
\boldsymbol{a}\star\boldsymbol{y} &= 
\boldsymbol{b}\star\boldsymbol{u}
\end{align*}

If $\boldsymbol{y^{0}}$ is a solution of the 
homogenous equation (HE), $\boldsymbol{y}\star\boldsymbol{a} = 0$, then
\begin{align*}
\boldsymbol{a}\star\left(\boldsymbol{y}+\boldsymbol{y^{0}}\right) &=
 \boldsymbol{b}\star\boldsymbol{u}
\end{align*}
The polynomial $a\left(z\right)$ is known as the \emph{characteristic}
polynomial of the HE.\@ The $n$ roots $\lambda_{1},\hdots,\lambda_{n}$ of 
$\boldsymbol{a}$ define the solutions of the HE since
\begin{align*}
\sum^{n}_{l=0}a_{l}z^{k-l}&=z^{k}a\left(z\right)
\end{align*}
and if $\lambda$ is a root of $a\left(z\right)$ then
\begin{align}
\sum^{n}_{l=0}a_{l}\lambda^{k-l}&=\lambda^{k}a\left(\lambda\right)=0
\label{eqn:Characteristic-equation-identity}
\end{align}
If the roots are distinct then there are $n$ solutions of the form 
$y_{l}\left(k\right)=\lambda_{l}^{k}$, $1\le l \le n$ and solutions of the 
HE are of the form
\begin{align*}
y^{0}\left(k\right) &=\sum^{n}_{l=1}c_{l}\lambda_{l}^{k-l}
\end{align*}
The case of repeated roots can be treated by differentiating 
Equation~\ref{eqn:Characteristic-equation-identity}. Roots of multiplicity $m$
generate $m$ solutions $y_{l}\left(k\right)=k^{l-1}\lambda^{k-l+1}$, 
$1\le l \le m$. 

Every solution of the HE is a linear combination of these solutions
\begin{align*}
y^{0}\left(k\right) &=\sum^{n}_{l=1}c_{l}y_{l}\left(k\right)
\end{align*}
The constants $c_{l}$ are usually chosen so that the filter is stable and 
causal. 

The unit-pulse response sequence of the filter, $\boldsymbol{h}$, is found by
setting the input $\boldsymbol{u}=\boldsymbol{\delta}$
\begin{align}
\sum^{n}_{l=0}a_{l}h\left(k-l\right) &= \sum^{n}_{l=0}b_{l}\delta\left(k-l\right),
\quad a_{0}=1\text{ and }k\ge 0
\label{eqn:Impulse-response}
\end{align}
Further, if $\boldsymbol{h}$ is causal, then it is of the form
\begin{align*}
h\left(k\right) &=
\begin{cases}
0, & k<0\\
b_{0}, & k=0\\
\sum^{n}_{l=1}c_{l}y_{l}\left(k\right), & k>0
\end{cases}
\end{align*}
The initial conditions $h\left(1\right),\hdots,h\left(n\right)$ that
determine the $c_{l}$ are obtained by direct evaluation of 
Equation~\ref{eqn:Impulse-response}. 

Finally, if the filter is Bounded-Input-Bounded-Output (BIBO) stable then
\begin{align*}
\sum^{\infty}_{l=-\infty}\left|h\left(k\right)\right| < \infty
\end{align*}
For the case of distinct roots, $\boldsymbol{h}$ has the form
\begin{align*}
h\left(k\right)=\sum^{n}_{l=1}c_{l}\lambda_{l}^{k}, \quad k > 0
\end{align*}
If the unit-pulse response is causal, then BIBO stability requires that
$\left|\lambda_{l}\right|<1$, $l=1,\hdots,n$.

\section{Filter transfer function}
The filter transfer function is related to the z-transform of the filter
difference equation, Equation~\ref{eqn:Standard-difference-equation}, by
\begin{align*}
H\left(z\right) &= \frac{b\left(z\right)}{a\left(z\right)}
                = \frac{\sum^{m}_{l=0}b_{l}z^{-l}}{\sum^{n}_{l=0}a_{l}z^{-l}}
\end{align*}
     
The transfer function, $H\left(z\right)$, can also be written
\begin{align*}
H\left(z\right)&= g\frac{\prod^{n}_{l=1}\left(z-z_{l}\right)}
                        {\prod^{n}_{l=1}\left(z-p_{l}\right)}
\end{align*}
The $p_{l}$ are the roots of $a\left(z\right)$ and are called the poles
of $H\left(z\right)$. The $z_{l}$ are the roots of $b\left(z\right)$
and are called the zeros of $H\left(z\right)$. $g=H\left(0\right)$ is a gain
factor.

\section{\label{sec:Filter-signal-flow-graph}Filter signal flow graph}
Signal flow graphs are \emph{primitive} if: 
\begin{enumerate}
\begin{minipage}{0.8\columnwidth}
  \item All branch gains are either constant or a unit delay ($z^{-1}$)
  \item There are no delay free loops in the graph
  \item There are a finite number of nodes and branches
\end{minipage}
\end{enumerate}

The implementation of primitive signal flow graphs requires \emph{node
reordering}, shown in Algorithm~\ref{alg:Primitive-signal-flow}.
\begin{algorithm}[!ht]
\begin{enumerate}
\item \noindent Examine each unit delay. If there is an incoming branch
at the output then isolate the output of the unit delay by inserting
a unit gain branch as shown in Figure~\ref{fig:Isolating-a-unit}
\item \noindent Label all input nodes and all unit delay output nodes with 0
\item \noindent All nodes that can be calculated from nodes labelled 0 are
labelled 1
\item \noindent If any nodes are unlabelled increment the label and repeat
until all nodes are labelled
\end{enumerate}
\caption{Procedure for reordering the nodes of a primitive signal flow graph.}
\label{alg:Primitive-signal-flow}
\end{algorithm}
\begin{figure}[!ht]
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{reorder}
\caption{Isolating a unit delay from an incoming branch.}
\label{fig:Isolating-a-unit}
\end{figure}

For example, Figure~\ref{fig:Second-order-direct} shows the signal flow graph of
a second order \emph{direct form }filter. 
\begin{figure}[!ht]
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{direct2}
\caption{Second order direct form filter.}
\label{fig:Second-order-direct}
\end{figure}
The nodes are labelled according to Algorithm~\ref{alg:Primitive-signal-flow}:
\begin{itemize}
  \item $S_{0}$: $u,v_{2},v_{3}$
  \item $S_{1}$: $v_{1}=u-a_{1}v_{2}-a_{2}v_{3}$
  \item $S_{2}$: $y=b_{0}v_{1}+b_{1}v_{2}+b_{2}v_{3}$
\end{itemize}
with updates:
\begin{itemize}
\item $v_{2}\leftarrow v_{1}$
\item $v_{3}\leftarrow v_{2}$
\end{itemize}
In the $z$-domain:
\begin{align*}
y\left(z\right) &= b_{0}z^{2}+b_{1}z^{1}+b_{2}\\
u\left(z\right) &= z^{2}+a_{1}z+a_{0}
\end{align*}
The transfer function is:
\begin{align*}
H\left(z\right) &= \frac{b_{0}z^{2}+b_{1}z+b_{2}}{z^{2}+a_{1}z+a_{0}}
\end{align*}
$n^{'}$th order direct form filters can be generated recursively by:
\begin{align*}
A_{k}\left(z\right) &= z^{-1}\left[a_{k}+A_{k+1}\left(z\right)\right]\\
B_{k}\left(z\right) &= z^{-1}\left[b_{k}+B_{k+1}\left(z\right)\right]
\end{align*}
where $A_{n+1}\left(z\right) = B_{n+1}\left(z\right)=0$. The filter
structure recursion is initialised with:
\begin{align*}
y\left(z\right) &= b_{0}v+B_{1}\left(z\right)v\\
u\left(z\right) &= v+a_{0}A_{1}\left(z\right)v
\end{align*}
so that:
\begin{align*}
H\left(z\right) &= \frac{b_{0}+B_{1}\left(z\right)}{1+a_{0}A_{1}\left(z\right)}
\end{align*}
See Figure~\ref{fig:Recursive-generation-of}.
\begin{figure}[!ht]
\begin{subfigure}[b]{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{directL}
\caption{Left hand side termination.}
\vspace{1cm}
\end{subfigure}
\begin{subfigure}[b]{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{directR}
\caption{$k_{th}$ internal section.}
\end{subfigure}
\caption{Recursive generation of direct form filters.} 
\label{fig:Recursive-generation-of}
\end{figure}
\section{State variable description of a signal flow graph\label{sec:State-variable-description-of-a-signal-flow-graph}}
The state variable description of a signal flow graph is derived by
Algorithm~\ref{alg:state-variable-signal-flow}.
\begin{algorithm}
\begin{enumerate}
\item Replace each unit delay with the equivalent path shown in 
Figure~\ref{fig:Unit-delay-equivalent}
\item Remove the unit delays thereby creating new outputs $x_{i}^{\prime}$
and inputs $x_{i}$. Note that 
$x_{i}^{\prime}\left(k\right)\triangleq x_{i}\left(k+1\right)$
\item Eliminate all nodes that are not inputs or outputs
\item Replace the unit delays
\end{enumerate}
\caption{Derivation of the state variable description of a signal flow graph.}
\label{alg:state-variable-signal-flow}
\end{algorithm}

\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{delay}
\caption{Unit delay equivalent.}
\label{fig:Unit-delay-equivalent}
\end{figure}

Figure~\ref{fig:Second-order-direct} shows the signal flow graph
for a second order direct form filter. 

The time domain state variable equations for this filter are:
\begin{align} \label{eq:StateVarTime}
\left[\begin{array}{c}
x\left(k+1\right)\\
y\left(k\right)
\end{array}\right] &= \left[\begin{array}{cc}
A & B\\
C & D
\end{array}\right]\left[\begin{array}{c}
x\left(k\right)\\
u\left(k\right)
\end{array}\right]
\end{align}
where:
\begin{align*}
A &= \left[\begin{array}{cc}
0 & 1\\
-a_{2} & -a_{1}
\end{array}\right]\\
B &= \left[\begin{array}{c}
0\\
1
\end{array}\right] \\
C &= \left[\begin{array}{cc}
b_{2}-a_{2}b_{0}, & b_{1}-a_{1}b_{0}\end{array}\right]\\
D &= b_{0}
\end{align*} 

The $z$-domain state variable equations for this filter are:
\begin{align} \label{eq:StateVarZdom}
\left[\begin{array}{c}
zX\\
Y
\end{array}\right] 
= 
 \left[\begin{array}{cc}
A & B\\
C & D
\end{array}\right] 
\left[\begin{array}{c}
X\\
U
\end{array}\right]
\end{align}

Figure~\ref{fig:SVFG-PSFG} shows the signal flow graph for the state variable
filter of Equation~\ref{eq:StateVarZdom}. The matrix $A$ is called the
\emph{state transition matrix}.
\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{svfg}
\caption{Signal flow graph of a state variable filter.}
\label{fig:SVFG-PSFG}
\end{figure}

If the arrows in Figure~\ref{fig:SVFG-PSFG} are reversed and the inputs to each
node become the outputs then the state-variable description of the
\emph{transposed} signal flow graph is:
\begin{align}
\left[\begin{array}{cc}
A & B\\
C & D\end{array}\right]^{\top}&=\left[\begin{array}{cc}
A^{\top} & C^{\top}\\
B^{\top} & D\end{array}\right]^{\top}
\end{align}
\section{Controllability}
The matrix pair $\left(A,B\right)$ is said to be \emph{controllable}
if-and-only-if $\det\left[\begin{array}{cccc} B & AB & \cdots & A^{n-1}B\end{array}\right]\neq0$.

The n-by-n matrix
$\left[\begin{array}{cccc} B & AB & \cdots & A^{n-1}B\end{array}\right]$ is
called the \emph{controllability} matrix.

If the matrix pair $ (A,B) $ is controllable then the system
\begin{align*}
x\left(0\right) &= 0\\
x\left(k+1\right) &= Ax\left(k\right)+Bu\left(k\right)
\end{align*}
can be driven to any specified vector $x\left(n\right)$.

\emph{Proof:}~ From above
\begin{align*}
x\left(n\right) &= \sum_{l=1}^{n}A^{l-1}Bu\left(n-l\right)\\
 &= \left[\begin{array}{cccc}
B & AB & \cdots & A^{n-1}B\end{array}\right]\left[\begin{array}{c}
u\left(n-1\right)\\
u\left(n-2\right)\\
\vdots\\
u\left(0\right)
\end{array}\right]
\end{align*}
The input $u\left(k\right)$, $0\leq k<n$, producing $x\left(n\right)$
can be found by inverting the controllability matrix.

\section{Observability}
The matrix pair $\left(A,C\right)$ is said to be \emph{observable}
if the matrix $\left[\begin{array}{cccc}
C & CA & \cdots & CA^{n-1}\end{array}\right]$ is invertible (for a single output
variable).

If the matrix pair $\left(A,C\right)$ is observable then the state
$x\left(0\right)$ can be uniquely determined from
$\left(u\left(k\right),y\left(k\right)\right)$ for $0\leq{} k<n$.

\emph{Proof} : From the matrix equations for $x\left(k\right)$and
$y (k)$
\begin{align*}
\left[\begin{array}{c}
y\left(0\right)\\
y\left(1\right)\\
\vdots\\
y\left(n-1\right)
\end{array}\right] &= \left[\begin{array}{c}
C\\
CA\\
\vdots\\
CA^{n-1}
\end{array}\right]x\left(0\right)+\left[\begin{array}{cccc}
D & 0 & \cdots & 0\\
CB & D & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
CA^{n-2}B & CA^{n-3}B & \cdots & D
\end{array}\right]\left[\begin{array}{c}
u\left(0\right)\\
u\left(1\right)\\
\vdots\\
u\left(n-1\right)
\end{array}\right]
\end{align*}
The right-hand term reduces to an n-by-1 column vector. $x\left(0\right)$
is found by inverting the observability matrix.

\section{\label{sec:coordinate-transformations}Coordinate Transformations}
Let $T$ be an n-by-n non-singular matrix and 
$q\left(k\right)=T^{-1}x\left(k\right)$
then the state variable equations have the same form except that
$\left\{A,B,C,D\right\} \leftarrow \left\{T^{-1}AT,T^{-1}B,CT,D\right\}$. In
matrix form:
\begin{align*}
\left[\begin{array}{cc}
A^{\prime} & B^{\prime}\\
C^{\prime} & D^{\prime}
\end{array}\right] =
\left[\begin{array}{cc}
T^{-1}AT          & T^{-1}B\\
\phantom{T^{-1}}CT & \phantom{T^{-1}}D
\end{array}\right] =
\left[\begin{array}{cc}
T & 0\\
0 & 1
\end{array}\right]^{-1}
\left[\begin{array}{cc}
A & B\\
C & D
\end{array}\right]
\left[\begin{array}{cc}
T & 0\\
0 & 1
\end{array}\right]
\end{align*}

\section{State variable descriptions and the transfer function\label{sec:Transfer-function}}
From the $z$-domain state variable matrix shown in Equation~\ref{eq:StateVarZdom}
\begin{align*}
X\left(z\right) &= \left(zI-A\right)^{-1}BU
\end{align*}
so
\begin{align*}
Y\left(z\right) &= C\left(zI-A\right)^{-1}BU+DU
\end{align*}
and the transfer function is
\begin{align}
H\left(z\right) &= D+C\left(zI-A\right)^{-1}B
\label{eqn:State-variable-transfer-function}
\end{align}

The transfer function of the \emph{transpose} of the signal flow diagram shown
in~\ref{fig:SVFG-PSFG} is the same as that of the original diagram.

The similarity transformation,
 $\left\{A,B,C,D\right\} \leftarrow \left\{T^{-1}AT,T^{-1}B,CT,D\right\}$,
leaves the transfer function, $H\left(z\right)$, unchanged\footnote{Recall that
$\left(AB\right)^{-1}=B^{-1}A^{-1}$}:
\begin{align}
H\left(z\right) &= D+C\left(zI-A\right)^{-1}B \\
                &= D+CTT^{-1}\left(zI-A\right)^{-1}\left(T^{-1}\right)^{-1}T^{-1}B \\
                &= D+CT\left[T^{-1}\left(zI-A\right)T\right]^{-1}T^{-1}B \\
                &= D+CT\left(zI-T^{-1}AT\right)^{-1}T^{-1}B
\end{align}

The poles of $H\left(z\right)$ are the eigenvalues of $A$. The zeros of 
$H\left(z\right)$ are related to the $n+1$ components in $C$ and $D$ via a 
system of linear equations. This system of equations is invertible if the 
controllability matrix 
$\left[\begin{array}{cccc}B & AB & \cdots & A^{n-1}B\end{array}\right]$ 
is non-singular. The term $\left(zI-A\right)^{-1}$ is called the
\emph{matrix resolvent}. The determinant
$p\left(z\right)=\det\left(zI-A\right)$  is called the \emph{characteristic
 polynomial} of $A$.  

The transfer function can be written
\begin{align}
H\left(z\right) &= \frac{b_{0}z^{n}+b_{1}z^{n-1}+\cdots+b_{n-1}z+b_{n}}
                        {z^{n}+a_{1}z^{n-1}+\ldots a_{n-1}z+a_{n}}
\label{eqn:rational-transfer-function}
\end{align}
The denominator of $H\left(z\right)$ is the characteristic polynomial of $A$.
The unit impulse response is related to the coefficients of the
numerator and denominator polynomials of $H\left(z\right)$ by
\begin{align*}
\left[\begin{array}{cccc}
1 & 0 & \cdots & 0\\
a_{1} & 1 & \cdots & \vdots\\
\vdots & \vdots & \ddots & 0\\
a_{n} & a_{n-1} & \cdots & 1
\end{array}\right]\left[\begin{array}{c}
h_{0}\\
h_{1}\\
\vdots\\
h_{n}
\end{array}\right] &=  \left[\begin{array}{c}
b_{0}\\
b_{1}\\
\vdots\\
b_{n}
\end{array}\right]
\end{align*}
\subsection{\label{sec:transform-transform-function-to-state-variable}Transformation of a transfer function to a state variable description}
Algorithm~\ref{alg:Transformation-transfer-to-SV} converts a rational transfer
function to the equivalent direct form state variable
description\footnote{Appendix~\ref{app:Continued-fraction-expansion} shows the
  continued fraction expansion of a rational transfer function into state
  variable form.}. An \emph{Octave} implementation is shown in the file
\emph{tf2Abcd.m}. 

\begin{algorithm}[!ht]
Given a transfer function
\begin{align*}
H\left(z\right) &= \frac{\hat{b}\left(z\right)}{\hat{a}\left(z\right)}\\
&= \frac{b_{0}z^{n}+b_{1}z^{n-1}+\cdots+b_{n}}{z^{n}+a_{1}z^{n-1}+\cdots+a_{n}}
\end{align*}
the direct form state variable description is
\begin{align*}
H\left(z\right) &= D+C(zI-A)^{-1}B
\end{align*}
where
\begin{align*}
A &= \left[\begin{array}{cccc}
0 & 1 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 1\\
-a_{n} & -a_{n-1} & \cdots & -a_{1}
\end{array}\right]\\
B &= \left[\begin{array}{ccccc}
0 & 0 & \cdots & 0 & 1\end{array}\right]^{\top}\\
C &= \left[\begin{array}{ccc}
b_{n}-b_{0}a_{n} & \cdots & b_{1}-b_{0}a_{1}\end{array}\right]\\
D &= b_{0}
\end{align*}
\caption{Transformation of a transfer function to a state variable description.}
\label{alg:Transformation-transfer-to-SV}
\end{algorithm}

\emph{Proof} of Algorithm~\ref{alg:Transformation-transfer-to-SV}:
Firstly, show the identity
\begin{align*}
\left(zI-A\right)\Psi\left(z\right) &= \hat{a}\left(z\right)B
\end{align*}
with $\Psi\left(z\right)=\left[\begin{array}{cccc} 1 & z & \cdots & z^{n-1}\end{array}\right]^{\top}$ uniquely defines the matrix:
\begin{align*}
  A&=\left[\begin{array}{cccc}
\alpha_{1,1} & \alpha_{1,2} & \cdots & \alpha_{1,n}\\
\alpha_{2,1} & \alpha_{22} & \cdots & \alpha_{2,n}\\
\vdots & \vdots & \ddots & \vdots\\
\alpha_{n,1} & \alpha_{n,2} & \cdots & \alpha_{n,n}
           \end{array}\right]
\end{align*}
and the column vector:
$B=\left[\begin{array}{ccc}\beta_{1} & \cdots &\beta_{n}\end{array}\right]^{\top}$.
For row $i$:
\begin{align*}
  z^{i}-\beta_{i}\left(z^{n}+\sum_{j=1}^{n}a_{i}z^{n-j}\right)
  &= \sum_{j=1}^{n}\alpha_{i,j}z^{j-1}
\end{align*}
If $i\neq n$, then, equating coefficients, $\beta_{i}=0$, so $\alpha_{i,i+1}=1$
and $\alpha_{i,j}=0$ if $i\neq j+1$. If $i=n$ then $\beta_{i}=1$
and
\begin{align*}
-\sum_{j=1}^{n}a_{j}z^{n-j} &= \sum_{j=1}^{n}\alpha_{n,j}z^{j-1}
\end{align*}
so
\begin{align*}
\alpha_{n,1} &= -a_{n}\\
 & \vdots\\
\alpha_{n,n} &= -a_{1}
\end{align*}
Now find vector $C=\left[\begin{array}{cccc}
c_{1} & c_{2} & \cdots & c_{n}\end{array}\right]$ and scalar $D=\delta$ that satisfy
\begin{align*}
D\hat{a}\left(z\right)+C\Psi &= \hat{b}\left(z\right)
\end{align*}
Expanding
\begin{align*}
\delta\left(z^{n}+\sum_{j=1}^{n}a_{j}z^{n-j}\right)+\sum_{j=1}^{n}c_{j}z^{j-1} &= \sum_{j=0}^{n}b_{j}z^{n-j}
\end{align*}
Equating coefficients
\begin{align*}
\delta &= b_{0}\\
c_{j} &= b_{n-j+1}-b_{0}a_{n-j+1}\quad1\leq j\leq n
\end{align*}
\subsection{\label{app:Continued-fraction-expansion}Transformation of a transfer function to a state variable description by continued fraction expansion}
See \emph{Roberts} and
\emph{Mullis}~\cite[Problems 8.16, 10.13 to 10.16]{RobertsMullis_DigitalSignalProcessing} 
and \emph{Mitra} and 
\emph{Sherwood}~\cite{MitraSherwood_DigitalFiltersContinuedFraction}.
Algorithm~\ref{alg:continued-fraction-expansion} calculates the continued
fraction expansion of a rational transfer function. 

\begin{algorithm}[!ht]
Given a rational transfer function
$H\left(z\right) = \frac{\hat{b}\left(z\right)}{\hat{a}\left(z\right)} =
\frac{\sum^{N}_{j=0}b_{j}z^{N-j}}{z^{N}+\sum^{N}_{j=1}a_{j}z^{N-j}}$ find the
continued fraction expansion:
\begin{algorithmic}
\State{} $\hat{a}_{1}\left(z\right) = \hat{a}\left(z\right)$
\State{} $\hat{b}_{1}\left(z\right) = \hat{b}\left(z\right) - b_{0}\hat{a}_{1}\left(z\right)$
\For{} {$k=1,\hdots,N$}
  \State{} Find $q_{k}\left(z\right)$ and $\hat{b}_{k+1}\left(z\right)$ so that
     $\hat{a}_{k}\left(z\right) = 
       q_{k}\left(z\right)\hat{b}_{k}\left(z\right)-\hat{b}_{k+1}\left(z\right)$
  \State{} $\hat{a}_{k+1}\left(z\right) = \hat{b}_{k}\left(z\right)$
\EndFor{}
\end{algorithmic}
\caption{Continued fraction expansion of a rational transfer function.}
\label{alg:continued-fraction-expansion}
\end{algorithm}

\begin{figure}
\centering
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{sv_cfA}
\caption{Signal flow graph of a first order approximation to a state variable
  filter.}
\label{subfig:SV-CF-A}
\vspace{1cm}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{sv_cfB}
\caption{Signal flow graph of a second order approximation to a state variable
  filter.}
\label{subfig:SV-CF-B}
\vspace{1cm}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{sv_cfC}
\caption{Signal flow graph of a continued fraction expansion of a state variable
  filter.}
\label{subfig:SV-CF-C}
\end{subfigure}
\caption{Continued fraction expansion of a state variable filter.}
\label{fig:continued-fraction-state-variable-filter}
\end{figure}

The continued fraction expansion of a state variable filter is shown in 
Figure~\ref{fig:continued-fraction-state-variable-filter}. 
Figure~\ref{subfig:SV-CF-A} shows the signal flow graph for a first order 
approximation to a state variable filter. The state variable equations for 
Figure~\ref{subfig:SV-CF-A} are:
\begin{align*}
zX_{1}&=\alpha_{0}X_{1}+bU + G_{1}X_{1}\\
Y&=cX_{1}+dU
\end{align*}
The corresponding transfer function, $G\left(z\right)$, is:
\begin{align*}
G\left(z\right)&=d + \frac{bc}{z-\alpha_{0}-G_{1}\left(z\right)}
\end{align*}
Figure~\ref{subfig:SV-CF-B} shows the addition of a second section for
$G_{1}\left(z\right)$ with:
\begin{align*}
zX_{2}&=\alpha_{1}X_{2}+\gamma_{1}X_{1}+bU + G_{2}X_{2}\\
Y_{1}&=\beta_{1}X_{2}\\
G_{1}\left(z\right)&=\frac{\beta_{1}\gamma_{1}}{z-\alpha_{1}-G_{2}\left(z\right)}
\end{align*}
Finally, in Figure~\ref{subfig:SV-CF-C}, for a filter of order $N$:
\begin{align*}
G_{N-1}\left(z\right)&=\frac{\beta_{N-1}\gamma_{N-1}}{z-\alpha_{N-1}}
\end{align*}
The state variable equations for Figure~\ref{subfig:SV-CF-C} are:
\begin{align*}
x_{1}\left(k+1\right)&=\alpha_{0}x_{1} + \beta_{1}x_{2} + bu\\
x_{2}\left(k+1\right)&=\gamma_{1}x_{1} + \alpha_{1}x_{2} + \beta_{2}x_{3}\\
&\vdots\\
x_{N-1}\left(k+1\right)&=\gamma_{N-2}x_{N-2}+\alpha_{N-2}x_{N-1} + \beta_{N-1}x_{N}\\
x_{N}\left(k+1\right)&=\gamma_{N-1}x_{N-1} + \alpha_{N-1}x_{N}\\
y\left(k\right)&=cx_{1} + du
\end{align*}
or:
\begin{align*}
\left[\begin{array}{cc}
\mathcal{A} & \mathcal{B} \\
\mathcal{C} & \mathcal{D}
\end{array}\right] 
&=
\left[\begin{array}{ccccccc|c}
\alpha_{0} & \beta_{1}  & 0          & 0          & 0        & \cdots & 0 & b \\
\gamma_{1} & \alpha_{1} & \beta_{2}   & 0          & 0        & \cdots & 0 & 0 \\
0         & \gamma_{2}  & \alpha_{2} & \beta_{3}   & 0        & \cdots & 0 & 0 \\
0         & 0          & \gamma_{3}  & \alpha_{3}  & 0       & \cdots & 0 & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
0        & 0 & \cdots  & 0 & \gamma_{N-2} & \alpha_{N-2} & \beta_{N-1} & 0 \\
0         & 0  & \cdots & 0 & 0 & \gamma_{N-1} & \alpha_{N-1} & 0 \\ \hline 
c & 0 & \cdots & 0 & 0 & 0 & 0 & d
\end{array}\right] 
\end{align*}

The tridiagonal state transition matrix means that the state variable 
description is ``pipelined''. The continued fraction expansion apparently has
$N$ additional parameters compared to the direct form but, by construction, 
the ratios $\frac{\alpha_{i}}{\gamma_{i}}$ and $\frac{\beta_{i}}{\gamma_{i}}$ 
are fixed. Furthermore, only a diagonal similarity transform maintains the 
tridiagonal filter structure so only state rescaling is possible.
\emph{Golub and Van Loan}~\cite[Section 9.4.3]{GolubVanLoan_MatrixComputations}
describe \emph{unsymmetric Lanczos tridiagonalisation} of an arbitrary matrix,
summarised in Appendix~\ref{app:Unsymmetric-Lanczos-tridiagonalisation}. The
Octave function \emph{lanczos\_tridiag} implements \emph{Lanczos}
tridiagonalisation.

The Octave function \emph{contfrac} implements 
Algorithm~\ref{alg:continued-fraction-expansion} and returns the equivalent 
state variable description. The Octave script \emph{contfrac\_test.m} implements
the continued fraction expansion of a $5$th order elliptic low-pass filter with
cutoff frequency $0.05f_{S}$. The noise gains of the continued fraction filter
and the corresponding minimum noise and direct-form state variable filter
implementations are $127$, $0.928$ and $583e3$ respectively\footnote{See
  Chapter~\ref{sec:Round-off-noise-in-state-variable-filters}.}.

\subsection{\label{sub:Transformation-state-variable-to-transfer-function}Transformation of a state variable description to a transfer function}
This section describes three methods for finding the transfer function of a
state variable description.
\subsubsection{Using the controllability matrix}
Algorithm~\ref{alg:Transformation-SV-to-Direct-Form} uses the controllability
matrix to find the characteristic polynomial of the state transition matrix, 
$A$. The transfer function follows from 
Equation~\ref{eqn:State-variable-transfer-function}.

\begin{algorithm}[!tbph]
If
\begin{enumerate}
\item the matrix pair $\left(A,B\right)$ is controllable so that $\det\left[\begin{array}{ccccc}
B & AB & A^{2}B & \cdots & A^{n-1}B\end{array}\right]\neq0$.
\item the characteristic function of the state transition matrix, $A$,
  is $\det\left(zI-A\right)=a_{0}z^{n}+a_{1}z^{n-1}+\ldots+a_{n}$ with $a_{0}=1$.
\item the state vectors are: $\begin{cases}
x\left(0\right)=0\\
x\left(k+1\right)=Ax\left(k\right)+Ba_{k}
\end{cases}$
\end{enumerate}
then
\begin{enumerate}
\item $x\left(n+1\right)=0$
\item If $T=\left[\begin{array}{cccc}
x\left(n\right) & x\left(n-1\right) & \cdots & x\left(1\right)\end{array}\right]$
then
\begin{align*}
T^{-1}AT &= \left[\begin{array}{cccc}
0 & 1 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 1\\
-a_{n} & -a_{n-1} & \cdots & -a_{1}
\end{array}\right]\\
T^{-1}B &= \left[\begin{array}{c}
0\\
\vdots\\
0\\
1
\end{array}\right]
\end{align*}
\end{enumerate}
\caption{Transformation of state variable description to direct form.}
\label{alg:Transformation-SV-to-Direct-Form}
\end{algorithm}

\emph{Proof} of Algorithm~\ref{alg:Transformation-SV-to-Direct-Form}: 
By repeated application, the state vectors, $x$, at time $k+1$ are:
\begin{align*}
x\left(k+1\right) &= \sum_{i=0}^{k}A^{k-i}Ba_{i}
\end{align*}
and
\begin{align*}
x\left(n+1\right) &= \left(\sum_{i=0}^{n}A^{n-i}a_{i}\right)B
\end{align*}
The Cayley-Hamilton theorem states that a matrix is a solution of
its own characteristic polynomial so the expression in the parentheses
is zero. Factorising
\begin{align*}
T &= \left[\begin{array}{cccc}
x\left(n\right) & x\left(n-1\right) & \cdots & x\left(1\right)\end{array}\right]\\
 &= \left[\begin{array}{cccc}
A^{n-1}B & A^{n-2}B & \cdots & B\end{array}\right]\left[\begin{array}{cccc}
1 & 0 & \cdots & 0\\
a_{1} & 1 & \ddots & \vdots\\
\vdots & \vdots & \ddots & 0\\
a_{n-1} & a_{n-2} & \cdots & 1
\end{array}\right]
\end{align*}
If the matrix pair $\left(A,B\right)$ is controllable then $T$ is
invertible. Now consider the state variables $q\left(k\right)$ of
the direct form filter with the transfer function denominator polynomial
$z^{n}+a_{1}z^{n-1}+\cdots+a_{n}$ and make the input to the filter be
the coefficients of this denominator polynomial (recall that by definition
$q\left(k\right)=T^{-1}x\left(k\right)$):
\begin{align*}
q\left(0\right) &= 0\\
q\left(1\right) &= \left[\begin{array}{cccc}
0 & 1 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 1\\
-a_{n} & -a_{n-1} & \cdots & -a_{1}
\end{array}\right]\left[\begin{array}{c}
0\\
\vdots\\
0\\
0
\end{array}\right]+\left[\begin{array}{c}
0\\
\vdots\\
0\\
1
\end{array}\right]=\left[\begin{array}{c}
0\\
\vdots\\
0\\
1
\end{array}\right]\\
q\left(2\right) &= \left[\begin{array}{cccc}
0 & 1 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 1\\
-a_{n} & -a_{n-1} & \cdots & -a_{1}
\end{array}\right]\left[\begin{array}{c}
0\\
\vdots\\
0\\
1
\end{array}\right]+\left[\begin{array}{c}
0\\
\vdots\\
0\\
1
\end{array}\right]a_{1}=\left[\begin{array}{c}
0\\
\vdots\\
1\\
0
\end{array}\right]\\
 & \vdots\\
q\left(n\right) &= \left[\begin{array}{cccc}
0 & 1 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 1\\
-a_{n} & -a_{n-1} & \cdots & -a_{1}
\end{array}\right]\left[\begin{array}{c}
0\\
\vdots\\
0\\
1
\end{array}\right]+\left[\begin{array}{c}
0\\
\vdots\\
0\\
1
\end{array}\right]a_{n}=\left[\begin{array}{c}
1\\
0\\
\vdots\\
0
\end{array}\right]\\
q\left(n+1\right) &= 0
\end{align*}
Form the matrix with columns consisting of the states 
$\left\{ q \left(n+1\right),\ldots,q\left(2\right) \right\}$:
\begin{align*}
\left[\begin{array}{cccc}
q\left(n+1\right) & q\left(n\right) & \cdots & q\left(2\right)\end{array}\right] &= \left[\begin{array}{cccc}
0 & 1 & \cdots & 0\\
\vdots & \cdots & \ddots & \vdots\\
0 & \cdots & 0 & 1\\
0 & \cdots & 0 & 0
\end{array}\right]\\
 &= T^{-1}AT\left[\begin{array}{cccc}
1 & 0 & \cdots & 0\\
0 & 1 & \cdots & \vdots\\
\vdots & \vdots & \ddots & 0\\
0 & \cdots & 0 & 1
\end{array}\right]+\left[\begin{array}{cccc}
0 & 0 & \cdots & 0\\
0 & 0 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
a_{n} & a_{n-1} & \cdots & a_{1}
\end{array}\right]
\end{align*}
The result follows.
\subsubsection{\emph{Le Verrier}'s algorithm}
In practice, I have found that the simplest method of finding $(zI-A)^{-1}$ 
(sometimes referred to as the matrix \emph{resolvent}) is by
matrix inversion. An alternative, slower, but more accurate method for finding
the resolvent of a matrix is \emph{Le Verrier}'s algorithm~\cite[Algorithm
8A.12]{RobertsMullis_DigitalSignalProcessing} shown in
Algorithm~\ref{alg:LeVerriers-algorithm-characteristic-polynomial}.
\begin{algorithm}[!ht]
To find $p\left(z\right)=\sum_{k=0}^{n}z^{n-k}a_{k}$ and
$\left(zI-A\right)^{-1}=\frac{1}{p\left(z\right)}\sum_{k=0}^{n-1}z^{n-1-k}\bar{A}_{k}$
perform the following recursion:
\begin{algorithmic}
\State $a_{0}=1$ , $\bar{A}_{0}=I$
\For{$k=1,\hdots,n$}
  \State $a_{k}= -\frac{1}{k}\mathtrace\left(A\bar{A}_{k-1}\right)$
  \vspace{1.5mm}
  \State $\bar{A}_{k}=A\bar{A}_{k-1}+a_{k}I$
\EndFor
\end{algorithmic}
\caption{\emph{Le Verrier}'s algorithm for finding the resolvent of the state
  transition matrix, A~\cite[Algorithm
  8A.12]{RobertsMullis_DigitalSignalProcessing}.}
\label{alg:LeVerriers-algorithm-characteristic-polynomial}
\end{algorithm}
Note that \emph{Le Verrier}'s algorithm calculates the characteristic
polynomial of $A$ as a by-product. In this case the characteristic polynomial
of the state-transition matrix is the denominator polynomial of the transfer
function, which is known. The recursion in $\bar{A}_{k}$ is justified by
rearranging the expansion of the resolvent shown in 
Algorithm~\ref{alg:LeVerriers-algorithm-characteristic-polynomial} and then 
equating coefficients of $z$:
\begin{align*}
\sum_{k=0}^{n}z^{n-k}a_{k}I&=\left(zI-A\right)\sum_{k=0}^{n-1}z^{n-1-k}\bar{A}_{k}\\
&=z^{n}\bar{A}_{0}
+\sum_{k=1}^{n-1}z^{n-k}\left(\bar{A}_{k}-A\bar{A}_{k-1}\right) 
-A\bar{A}_{n-1}
\end{align*}

When the characteristic polynomial is known, the resolvent and the transfer
function can be calculated with the matrix recursion of \emph{Le
Verrier}'s algorithm~\cite[pp.332--333]{RobertsMullis_DigitalSignalProcessing}.
The m-file \emph{Abcd2tf.m} implements \emph{Le Verrier}'s algorithm. The
oct-file \emph{Abcd2tf.cc} implements \emph{Le Verrier}'s algorithm with
extended precision using the MPFR library~\cite{Fousse_MPFR}.

\subsubsection{\emph{La Budde}'s algorithm for finding the 
characteristic polynomial of an upper Hessenberg matrix}
\emph{La Budde}~\cite{LaBudde_ReductionSquareMatrix} describes ``a new algorithm
for reducing an arbitrary real square matrix to tri-diagonal form using real
similarity transformations''. \emph{Parlett}~\cite{Parlett1964ANO} commented
that `` ... this procedure is identical to the more familiar reduction by
elimination methods. Therefore the same care is needed with the new technique as
with elimination in treating the instabilities which can occur ...''.
\emph{Wilkinson}~\cite[Section 57, Chapter
6]{Wilkinson_AlgebraicEigenvalueProblem}, 
\emph{Rehman}~\cite[Chapter 6]{Rehman_ComputationCharacteristicPolynomial},
and \emph{Rehman} and \emph{Ipsen}~\cite{RehmanIpsen_BuddeCharacteristicPoly}
describe a \emph{La Budde}'s style algorithm for the calculation of the
characteristic polynomial of an \emph{upper Hessenberg} matrix, reproduced here
as  Algorithm~\ref{alg:La-Budde-characteristic-polynomial}~\cite[Algorithm
2]{RehmanIpsen_BuddeCharacteristicPoly}. 
\emph{Rehman}~\cite[Appendix B]{Rehman_ComputationCharacteristicPolynomial} 
provides a \emph{MATLAB} implementation, \emph{labudde.m}, that I have edited
for compatiblity with Octave. \emph{Rehman} shows that the numerical performance
of \emph{La Budde}'s algorithm compares favourably with the eigenvalue method, 
$p\left(z\right)=\prod_{k=1}^{n}\left(z-\lambda_{k}\right)$, where the 
$\lambda_{k}$ are the (possibly repeated) eigenvalues of $A$.

\begin{algorithm}[!ht]
Given:
$H = \left[\begin{array}{ccccc}
\alpha_{1} & h_{1,2} & \cdots & \cdots & h_{1,n}\\
\beta_{2} & \alpha_{2} & h_{2,3} & & \vdots \\
 & \ddots & \ddots & \ddots & \vdots \\
 & & \ddots & \ddots & h_{n-1,n} \\
0 & & & \beta_{n} & \alpha_{n}
\end{array}\right]$, the $n\times{}n$ \emph{upper Hessenberg} reduction of $A$,
find $a_{1}\hdots{}a_{n}$:
\begin{algorithmic}
\State $a_{1}^{\left(1\right)}=-\alpha_{1}$
\State $a_{1}^{\left(2\right)}=a_{1}^{\left(1\right)}-\alpha_{2}$
\State $a_{2}^{\left(2\right)}=\alpha_{1}\alpha_{2}-h_{1,2}\beta_{2}$
\For{$k=3,\hdots,n$} 
\State $a_{1}^{\left(k\right)}=a_{1}^{\left(k-1\right)}-\alpha_{k}$
\For{$l=2,\hdots,k-1$}
\State $a_{l}^{\left(k\right)}=a_{l}^{\left(k-1\right)}
-\alpha_{k}a_{l-1}^{\left(k-1\right)}
-\sum_{m=1}^{l-2}h_{k-m,k}\beta_{k}\cdots\beta_{k-m+1}a_{l-m-1}^{\left(k-m-1\right)}
-h_{k-l+1,k}\beta_{k}\cdots\beta_{k-l+2}$
\EndFor
\State $a_{k}^{\left(k\right)}=-\alpha_{k}a_{k-1}^{\left(k-1\right)}
-\sum_{m=1}^{k-2}h_{k-m,k}\beta_{k}\cdots\beta_{k-m+1}a_{k-m-1}^{\left(k-m-1\right)}
-h_{1,k}\beta_{k}\cdots\beta_{2}$
\EndFor\
\State $a_{k}=a_{k}^{\left(n\right)},\;1\le{}k\le{}n$
\end{algorithmic}
\caption{\emph{La Budde}'s algorithm for finding the characteristic polynomial
  of A~\cite[Algorithm 2]{RehmanIpsen_BuddeCharacteristicPoly}.}
\label{alg:La-Budde-characteristic-polynomial}
\end{algorithm}

The first stage of \emph{La Budde}'s algorithm reduces the non-symmetric 
matrix, $A$, to \emph{upper Hessenberg} form, $H$ (see \emph{Golub} and 
\emph{van Loan}~\cite[Section 7.4]{GolubVanLoan_MatrixComputations}).
The determinant of a matrix is unchanged by replacing a row of the matrix by
linear combinations with other rows, so $H$ and $A$ have the same characteristic
polynomial. \emph{Rehman} and 
\emph{Ipsen}~\cite[pp.10-11]{RehmanIpsen_BuddeCharacteristicPoly} justify 
\emph{La Budde}'s algorithm as follows (lightly edited for consistency with my
notation):
\begin{quotation}
\emph{La Budde}'s method computes the characteristic polynomial of 
an upper Hessenberg matrix, $H$, by successively computing the characteristic 
polynomials of leading principal submatrices $H_{k}$ of order $k$. Denote the
characteristic polynomial of $H_{k}$ by 
$p_{k}\left(z\right)=\det\left(zI-H_{k}\right),\;1\le{}k\le{n}$, 
where $p\left(z\right)=p_{n}\left(z\right)$. The recursion for computing 
$p\left(z\right)$ is~\cite[Section 6.57.1]{Wilkinson_AlgebraicEigenvalueProblem}
\begin{align}
p_{0}\left(z\right)&=1\nonumber\\
p_{1}\left(z\right)&=z-\alpha_{1}\nonumber\\
p_{k}\left(z\right)&=(z-\alpha_{1})p_{k-1}\left(z\right)
-\sum_{m=1}^{k-1}h_{k-m,k}\beta_{k}\cdots\beta_{k-m+1}p_{k-m-1}\left(z\right)
\label{eqn:characteristic-poly-recursion}
\end{align}
where $2\le{}k\le{}n$. The recursion for 
$p_{k}\left(z\right)=\sum_{m=0}^{k}z^{k-m}a_{m}^{\left(k\right)}$ is obtained by 
developing the determinant of $zI-H_{k}$ along the last row of $H_{k}$. Each
term in the sum contains an element in the last column of $H_{k}$ and a product
of subdiagonal elements. Equating like powers of $z$ in 
Equation~\ref{eqn:characteristic-poly-recursion} gives recursions for 
individual coefficients $a_{k}$.
\end{quotation}
\subsection{\label{sec:Sensitivity-analysis-state-variable-transfer-function}Sensitivity of the state variable description of a transfer function}
\emph{Thiele}~\cite{Theile_SensitivityLinearStateSpaceSystems} analyses the
sensitivity of the frequency response of linear state variable digital filters 
with respect to the coefficients. Differentiation of the resolvent,
$R=\left(zI-A\right)^{-1}$, is simplified
by the matrix identities:
\begin{subequations}
\label{eqn:Sensitivity-analysis-state-variable-transfer-function}
\begin{align}
  RR^{-1} &= I
     \label{eqn:Sensitivity-analysis-state-variable-transfer-function-a}\\
\frac{\partial{}R}{\partial{}x}R^{-1}
  +R\frac{\partial{}R^{-1}}{\partial{}x} &= 0
 \label{eqn:Sensitivity-analysis-state-variable-transfer-function-b}\\
\frac{\partial{}R}{\partial{}x} &=-R\frac{\partial{}R^{-1}}{\partial{}x}R
 \label{eqn:Sensitivity-analysis-state-variable-transfer-function-c}
\end{align}
\end{subequations}
where $x$ represents the components of the matrix $R$.
With this identity, the gradients of $H\left(z\right)$ are found by
differentiating Equation~\ref{eqn:State-variable-transfer-function}:
\begin{align*}
\frac{\partial{}H\left(z\right)}{\partial{}z} &= 
-C\left(zI-A\right)^{-2}B \\
\frac{\partial{}H\left(z\right)}{\partial\alpha} &= 
C\left(zI-A\right)^{-1}\frac{\partial{}A}{\partial\alpha}
\left(zI-A\right)^{-1}B \\
\frac{\partial{}H\left(z\right)}{\partial\beta} &= 
C\left(zI-A\right)^{-1}\\
\frac{\partial{}H\left(z\right)}{\partial\gamma} &= 
\left(zI-A\right)^{-1}B\\
\frac{\partial{}H\left(z\right)}{\partial\delta} &= I
\end{align*}
where $\alpha$, $\beta$, $\gamma$ and $\delta$ represent the
components of $A$, $B$, $C$ and $D$ respectively.
\section{Time domain description}
If the input sequence is zero then in the time-domain, given 
$x\left(k_{0}\right)$
\begin{align*}
x\left(k+1\right) = Ax\left(k\right)\, , \; k>k_{0}
\end{align*}
The matrix powers of $A$ tend to $0$ as $k$ approaches infinity
if-and-only-if the eigenvalues $\lambda_{k}$ of $A$ satisfy
\begin{align*}
\left|\lambda_{k}\right|<1\,{},\;k=1,\ldots{},n
\end{align*}
This is equivalent to the stability condition that the poles of $H\left(z\right)$
lie inside the unit circle in the $z$-plane since the eigenvalues of $A$ are 
the roots of the polynomial $\hat{a}\left(z\right)=\det\left(zI-A\right)$
which is the denominator polynomial of the transfer function $H\left(z\right)$.
If the matrix $A$ is stable then
\begin{align*}
x\left(k\right) = \sum_{l=1}^{\infty}A^{l-1}Bu\left(k-l\right)
\end{align*}
\section{Unit Pulse Response\label{sec:Unit-pulse-response}}
The input and output sequences are related by the convolution,
$y = h\star u$. The state variable form is:
\begin{align*}
y\left(k\right) &= Cx\left(k\right)+Du\left(k\right)\\
 &= \sum_{l=1}^{\infty}CA^{l-1}Bu\left(k-l\right)+Du\left(k\right)\\
 &= \sum_{l=-\infty}^{\infty}h\left(l\right)u\left(k-l\right)
\end{align*}
For these to agree
\begin{align*}
h\left(k\right) &= \begin{cases}
0 & k<0\\
D & k=0\\
CA^{k-1}B & k>0
\end{cases}
\end{align*}
\section{\label{sec:Factored-state-variable-descriptions}Factored state variable descriptions}
See \emph{Roberts} and
\emph{Mullis}~\cite[Section 8.4]{RobertsMullis_DigitalSignalProcessing}.
Equation~\ref{eq:StateVarTime} assumes that the left-hand side
is calculated concurrently. If that is not the case, then the \emph{factored} 
state variable description is more appropriate. This models individual
computations that are done separately but in a fixed cyclic order. The number
of factors is the number of delay free paths in the PSFG description. For $L$
factors:
\begin{align*}
q_{0}\left(k\right) &= \left[\begin{array}{c}
x\left(k\right)\\
u\left(k\right)
\end{array}\right]\\
q_{i}\left(k\right) &= F_{i}q_{i-1}\left(k\right)\,,\,1\leq{}i\leq{}L\\
\left[\begin{array}{c}
x\left(k+1\right)\\
y\left(k\right)
\end{array}\right] &= q_{L}\left(k\right)
\end{align*}

The corresponding state variable description is
\begin{align*}
\left[\begin{array}{cc}
A & B\\
C & D
\end{array}\right] &= F_{L}F_{L-1}\ldots F_{1}
\end{align*}

\subsection{\label{sec:Factored-state-variable-filters-with-fractional-delays}Factored state variable filters with fractional delays}
Figure~\ref{subfig:Factored-SVFG} shows the signal flow graph of a factored
state variable filter with $L$ factors. The longest delay free path
has length $L$. The factors $F_{1}$ and $F_{L}$ are:
\begin{align*}
F_{1} &= 
\left[\begin{array}{cc}
F_{11} & F_{12}
\end{array}\right]\\
F_{L} &= 
\left[\begin{array}{c}
F_{L1} \\
F_{L2}
\end{array}\right]
\end{align*}

Figure~\ref{subfig:Retimed-Factored-SVFG} shows the result of 
retiming the filter with a delay of $z^{-1/L}$ after each factor. The 
loop gain and therefore the transfer function $H\left(z\right)$ are unchanged.
The longest delay free path is now $1$.

\begin{figure}
\centering
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{factoredsvfg}
\caption{Signal flow graph of a factored state variable filter.} 
\label{subfig:Factored-SVFG}
\vspace{1cm}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{retimedfactoredsvfg}
\caption{Signal flow graph of a retimed factored state variable filter.}
\label{subfig:Retimed-Factored-SVFG}
\end{subfigure}
\caption{Factored state variable filters. (See~\cite[Figure
  8.4.6]{RobertsMullis_DigitalSignalProcessing}.)}
\label{fig:Factored-state-variable-filters}
\end{figure}

The factored and retimed filter has a reduced delay free path at the
expense of a higher sub-sampling clock rate.

\subsection{\label{Sec:Construction-factored-state-variable-description}Construction of the factored state variable description}
To construct a FSVD from a PSFG, first find the sets 
$\{S_{0},S_{1},\ldots,S_{L}\}$ of node variables and let $v_{k}$ be a vector
representing the nodes in $S_{k}$. In particular:
\begin{align*}
v_{0} = 
\left[\begin{array}{c}
x_{1}\\
x_{2}\\ 
\vdots\\
x_{n}\\ 
u
\end{array}\right]
\end{align*}
where the $x_{k}$ are the outputs of the unit delays. Each variable in $S_{k}$ 
is a linear combination of the variables in 
\begin{align*}
\left\{S_{0} \cup S_{1} \cup \hdots \cup S_{k-1}\right\}
\end{align*}
so there is a coefficient matrix $G_{k}$ for which:
\begin{align*}
v_{k} = 
G_{k}\left[\begin{array}{c}
v_{k-1}\\
v_{k-2}\\ 
\vdots\\
v_{0}
\end{array}\right]\;1\le{}k\le{}L
\end{align*}

Finally let $G_{0}$ be a matrix that picks out the next-state and outputs:
\begin{align*}
\left[\begin{array}{c}
x^{\prime}_{1}\\
x^{\prime}_{2}\\ 
\vdots\\
x^{\prime}_{n}\\
y
\end{array}\right] = G_{0}
\left[\begin{array}{c}
v_{L}\\
v_{L-1}\\ 
\vdots\\
v_{0}
\end{array}\right]
\end{align*}

and the FSVD is:
\begin{align*}
\left[\begin{array}{c}
x^{\prime}\\
y
\end{array}\right] = G_{0}
\left[\begin{array}{c}
G_{L}\\
I
\end{array}\right]
\left[\begin{array}{c}
G_{L-1}\\
I 
\end{array}\right]
\cdots
\left[\begin{array}{c}
G_{1}\\
I
\end{array}\right]
\left[\begin{array}{c}
x\\
u
\end{array}\right] 
\end{align*}

\subsubsection{Factoring cascaded state variable filters}
As an example, Figure~\ref{fig:Cascaded-SVFG} shows two state variable filters
connected in cascade.

\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{svfgcascade}
\caption{Signal flow graph of two cascaded state variable filters.}
\label{fig:Cascaded-SVFG}
\end{figure}

The node variable sets are:
\begin{align*}
S_{0} &= \left\{ x_{1} , x_{2} , u \right\}\\ 
S_{1} &= \left\{ w, x^{\prime}_{1} \right\}\\
S_{2} &= \left\{ y, x^{\prime}_{2} \right\}
\end{align*}

where:

\begin{align*}
\left[\begin{array}{c}
w\\
x^{\prime}_{1}\\
x_{1}\\ 
x_{2}\\
u
\end{array}\right] 
&= 
\left[\begin{array}{ccc}
C_{1} & 0 & D_{1}\\
A_{1} & 0 & B_{1}\\
I & 0 & 0\\
0 & I & 0\\
0 & 0 & I\\
\end{array}\right]
\left[\begin{array}{c}
x_{1}\\
x_{2}\\
u
\end{array}\right] 
\end{align*}

\begin{align*}
\left[\begin{array}{c}
y\\
x^{\prime}_{2}\\
w\\
x^{\prime}_{1}\\
x_{1}\\ 
x_{2}\\
u
\end{array}\right]
&= 
\left[\begin{array}{ccccc}
D_{2} & 0 & 0 & C_{2} & 0 \\
B_{2} & 0 & 0 & A_{2} & 0 \\
I & 0 & 0 & 0 & 0\\
0 & I & 0 & 0 & 0\\
0 & 0 & I & 0 & 0\\
0 & 0 & 0 & I & 0\\
0 & 0 & 0 & 0 & I\\
\end{array}\right]
\left[\begin{array}{c}
w\\
x^{\prime}_{1}\\
x_{1}\\ 
x_{2}\\
u
\end{array}\right] 
\end{align*}

\begin{align*}
\left[\begin{array}{c}
x^{\prime}_{1}\\
x^{\prime}_{2}\\
y
\end{array}\right]
&= 
\left[\begin{array}{ccccccc}
0 & 0 & 0 & I & 0 & 0 & 0\\
0 & I & 0 & 0 & 0 & 0 & 0\\
I & 0 & 0 & 0 & 0 & 0 & 0\\
\end{array}\right]
\left[\begin{array}{c}
y\\
x^{\prime}_{2}\\
w\\
x^{\prime}_{1}\\
x_{1}\\ 
x_{2}\\
u
\end{array}\right] 
\end{align*}

The factored state variable equations are:
\begin{align*}
\left[\begin{array}{c}
x^{\prime}_{1}\\
x^{\prime}_{2}\\
y
\end{array}\right] 
&= 
\left[\begin{array}{ccc}
0 & I & 0\\
B_{2} & 0 & A_{2}\\
D_{2} & 0 & C_{2}\\
\end{array}\right]
\left[\begin{array}{ccc}
C_{1} & 0 & D_{1}\\
A_{1} & 0 & B_{1}\\
0 & I & 0\\
\end{array}\right] 
\left[\begin{array}{c}
x_{1}\\
x_{2}\\
u
\end{array}\right]\\
&= 
\left[\begin{array}{ccc}
A_{1}     & 0     & B_{1}\\
B_{2}C_{1} & A_{2} & B_{2}D_{1}\\
D_{2}C_{1} & C_{2} & D_{2}D_{1}\\        
\end{array}\right] 
\left[\begin{array}{c}
x_{1}\\
x_{2}\\
u
\end{array}\right]
\end{align*}

\subsubsection{Factoring a feedback connection of state variable filters}
\emph{Roberts} and \emph{Mullis}~\cite[Problem 8.9]
{RobertsMullis_DigitalSignalProcessing} show a feedback connection
of two MIMO state-variable systems:
\begin{align*}
  x^{\prime}_{1}&=A_{1}x_{1}+\left[\begin{array}{cc}
         B_{1} & B_{2}\end{array}\right]\left[\begin{array}{c}
                                                u_{1} \\
                                                u_{2}\end{array}\right] \\
\left[\begin{array}{c}
        y_{1} \\
        y_{2}\end{array}\right]  &= \left[\begin{array}{c}
        C_{1} \\
        C_{2}\end{array}\right]x_{1}+\left[\begin{array}{cc}
        D_{11} & D_{12}\\
        D_{21} & D_{22}\end{array}\right]\left[\begin{array}{c}
        u_{1} \\
        u_{2}\end{array}\right]
\end{align*}
and
\begin{align*}
  x^{\prime}_{2}&=A_{2}x_{2}+\left[\begin{array}{cc}
         b_{1} & b_{2}\end{array}\right]\left[\begin{array}{c}
                                                w_{1} \\
                                                w_{2}\end{array}\right] \\
\left[\begin{array}{c}
        v_{1} \\
        v_{2}\end{array}\right]  &= \left[\begin{array}{c}
        c_{1} \\
        c_{2}\end{array}\right]x_{2}+\left[\begin{array}{cc}
        d_{11} & d_{12}\\
        d_{21} & d_{22}\end{array}\right]\left[\begin{array}{c}
        w_{1} \\
        w_{2}\end{array}\right]
\end{align*}
The feedback connections are $u_{2}=v_{1}$ and $w_{1}=y_{2}$. A delay-free loop
is avoided by setting $D_{22}=0$ or $d_{11}=0$. Choosing the latter, the state
equations are, after substitution: 
\begin{align*}
  x^{\prime}_{1}&=A_{1}x_{1}+ B_{1} u_{1} +B_{2}v_{1}\\
  y_{1} &= C_{1}x_{1} +D_{11}u_{1} + D_{12}v_{1}\\
  y_{2} &= C_{2}x_{1} +D_{21}u_{1} +D_{22}v_{1}\\
  x^{\prime}_{2}&=A_{2}x_{2}+b_{1}y_{2}+b_{2}w_{2}\\
  v_{1} &= c_{1}x_{2}+d_{12}w_{2}\\
  v_{2} &= c_{2}x_{2}+d_{21}y_{2}+d_{22}w_{2}
\end{align*}

The node variable sets are:
\begin{align*}
S_{0} &= \left\{ x_{1} , x_{2} , u_{1} , w_{2}  \right\}\\ 
S_{1} &= \left\{ v_{1} \right\} \\
S_{2} &= \left\{ x^{\prime}_{1} , y_{1} , y_{2} \right\}\\
S_{3} &= \left\{ x^{\prime}_{2} , v_{2} \right\}
\end{align*}
where:
\begin{align*}
\left[\begin{array}{c}
v_{1}\\
x_{1}\\ 
x_{2}\\
u_{1}\\
w_{2}\\
\end{array}\right] 
&= 
\left[\begin{array}{cccc}
0 & c_{1} & 0 & d_{12}\\
I & 0 & 0 & 0\\
0 & I & 0 & 0\\
0 & 0 & I & 0\\
0 & 0 & 0 & I\\
\end{array}\right]
\left[\begin{array}{c}
x_{1}\\
x_{2}\\
u_{1}\\
w_{2}\\        
\end{array}\right] 
\end{align*}

\begin{align*}
\left[\begin{array}{c}
x^{\prime}_{1}\\
y_{1}\\
y_{2}\\
v_{1}\\
x_{1}\\ 
x_{2}\\
u_{1}\\
w_{2}\\
\end{array}\right] 
&= 
\left[\begin{array}{ccccc}
B_{2}  & A_{1} & 0 & B_{1} & 0 \\
D_{12} & C_{1} & 0 & D_{11} & 0 \\
D_{22} & C_{2} & 0 & D_{21} & 0 \\                                   
I & 0 & 0 & 0 & 0\\
0 & I & 0 & 0 & 0\\
0 & 0 & I & 0 & 0\\
0 & 0 & 0 & I & 0\\
0 & 0 & 0 & 0 & I\\
\end{array}\right]
\left[\begin{array}{c}
v_{1}\\
x_{1}\\
x_{2}\\
u_{1}\\
w_{2}\\        
\end{array}\right] 
\end{align*}

\begin{align*}
\left[\begin{array}{c}
x^{\prime}_{2}\\
v_{2}\\
x^{\prime}_{1}\\
y_{1}\\
y_{2}\\
v_{1}\\
x_{1}\\ 
x_{2}\\
u_{1}\\
w_{2}\\
\end{array}\right] 
&= 
\left[\begin{array}{cccccccc}
0 & 0 & b_{1}  & 0 & 0 & A_{2} & 0 & b_{2}\\
0 & 0 & d_{21} & 0 & 0 & c_{2} & 0 & d_{22}\\
I & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & I & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & I & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & I & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & I & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & I & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & I & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0 & I\\
\end{array}\right] 
\left[\begin{array}{c}
x^{\prime}_{1}\\
y_{1}\\
y_{2}\\
v_{1}\\
x_{1}\\ 
x_{2}\\
u_{1}\\
w_{2}\\
\end{array}\right] 
\end{align*}

\begin{align*}
\left[\begin{array}{c}
x^{\prime}_{1}\\
x^{\prime}_{2}\\
y_{1}\\ 
v_{2}\\ 
\end{array}\right] 
&=\left[\begin{array}{cccccccccc}
  0 & 0 & I & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
  I & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
  0 & 0 & 0 & I & 0 & 0 & 0 & 0 & 0 & 0 \\
  0 & I & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
\end{array}\right] 
\left[\begin{array}{c}
x^{\prime}_{2}\\
v_{2}\\ 
x^{\prime}_{1}\\
y_{1}\\ 
y_{2}\\
v_{1} \\
x_{1}\\ 
x_{2}\\
u_{1}\\
w_{2}\\
\end{array}\right] 
\end{align*}

The factored state variable description is:
\begin{align*}
\left[\begin{array}{c}
x^{\prime}_{1}\\
x^{\prime}_{2}\\
y_{1}\\ 
v_{2}\\ 
\end{array}\right] 
&=\left[\begin{array}{cccccccccc}
  0 & 0 & I & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
  I & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
  0 & 0 & 0 & I & 0 & 0 & 0 & 0 & 0 & 0 \\
  0 & I & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
\end{array}\right] 
\left[\begin{array}{cccccccc}
0 & 0 & b_{1}  & 0 & 0 & A_{2} & 0 & b_{2}\\
0 & 0 & d_{21} & 0 & 0 & c_{2} & 0 & d_{22}\\
I & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & I & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & I & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & I & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & I & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & I & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & I & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0 & I\\
\end{array}\right]
\left[\begin{array}{c}
x^{\prime}_{1}\\ 
y_{1}\\
y_{2}\\
v_{1}\\
x_{1}\\ 
x_{2}\\
u_{1}\\
w_{2}\\
\end{array}\right] \\
&=\left[\begin{array}{ccccc}
I & 0 & 0    & 0     & 0\\
0 & 0 & b_{1} & A_{2} & b_{2}\\
0 & I & 0    & 0     & 0\\
0 & 0 & d_{21} & c_{2} & d_{22}\\
\end{array}\right] 
\left[\begin{array}{ccccc}
B_{2}  & A_{1} & 0 & B_{1} & 0 \\
D_{12} & C_{1} & 0 & D_{11} & 0 \\
D_{22} & C_{2} & 0 & D_{21} & 0 \\                                   
0 & 0 & I & 0 & 0\\
0 & 0 & 0 & 0 & I\\
\end{array}\right]
\left[\begin{array}{cccc}
0 & c_{1} & 0 & d_{12}\\
I & 0 & 0 & 0\\
0 & I & 0 & 0\\
0 & 0 & I & 0\\
0 & 0 & 0 & I\\
\end{array}\right]
\left[\begin{array}{c}
x_{1}\\
x_{2}\\
u_{1}\\
w_{2}\\        
\end{array}\right] \\
&=\left[\begin{array}{cccc}
      A_{1} & B_{2}c_{1} & B_{1} & B_{2}d_{12} \\
      b_{1}C_{2} & b_{1}D_{22}c_{1}+A_{2} & b_{1}D_{21} & b_{1}D_{22}d_{12}+b_{2}\\
      C_{1} & D_{12}c_{1} & D_{11} & D_{12}d_{12} \\
      d_{21}C_{2} & d_{21}D_{22}c_{1}+c_{2} & d_{21}D_{21} & d_{21}D_{22}d_{12}+d_{22}\\
\end{array}\right]
\left[\begin{array}{c}
x_{1}\\
x_{2}\\
u_{1}\\
w_{2}\\        
\end{array}\right]
\end{align*}

\section{\label{sec:Block-proc-filters}Block processing and decimation filters}
See \emph{Roberts} and 
\emph{Mullis}~\cite[Section 10.2]{RobertsMullis_DigitalSignalProcessing}.
Block processing digital filters are multi-input, multi-output (MIMO) filters 
which are equivalent to a single-input, single-output (SISO) filter. MIMO 
filters have the following advantages:
\begin{itemize}
\item parallel computation increases the output data rate
\item output noise is reduced and other finite register effects are improved when compared to the corresponding SISO filter
\item the number of multiplies per output is reduced when compared to the
corresponding SISO filter. 
\end{itemize}

In general, for a state variable filter with state updates every P samples:
\begin{align*}
\left[ \begin{array}{c} 
x \left( k + P \right) \\
y^{\prime} \left(k\right)
\end{array} \right]
 &= 
\left[ \begin{array}{cc}
A^{\prime} & B^{\prime}\\ 
C^{\prime} & D^{\prime}
\end{array}\right]
\left[ \begin{array}{c}
x \left( k \right)\\
u^{\prime} \left( k \right)
\end{array}\right]
\end{align*}
where:
\begin{align*}
u^{\prime} \left( k \right) &= \left[ 
\begin{array}{c}
u\left(k\right)\\
u\left(k+1\right)\\
\vdots\\
u\left(k+P-1\right)
\end{array} \right]\\
y^{\prime} \left(k\right) &= \left[ 
\begin{array}{c}
y\left(k\right)\\
y\left(k+1\right)\\
\vdots\\
y\left(k+P-1\right)
\end{array}\right]
\end{align*}
and:
\begin{align*}
A^{\prime} &= A^{P}\\ 
B^{\prime} &= \left[
\begin{array}{cccc}
A^{P-1}B & A^{P-2}B & \cdots & B
\end{array}\right]\\
C^{\prime} &= \left[
\begin{array}{c}
C\\
CA\\
\vdots\\
CA^{P-1}
\end{array}\right]\\
D^{\prime} &= \left[
\begin{array}{ccccc}
D & 0 & 0 & \cdots & 0\\
CB & D & 0 & \cdots & 0\\
CAB & CB & D & \cdots & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
CA^{P-2}B & \cdots & \cdots & CB & D
\end{array}\right]
\end{align*}

For example, if the block length is $P=2$:
\begin{align}
\label{eq:block-2-state-variable}
\left[ \begin{array}{c} 
x \left( k + 1 \right) \\
y \left( k \right) \\
u \left( k+1 \right)
\end{array} \right]
 &= 
\left[ \begin{array}{ccc}
A & B & 0\\ 
C & D & 0\\
0 & 0 & I\\
\end{array}\right]
\left[ \begin{array}{c}
x \left( k \right) \\
u \left( k \right) \\
u \left( k+1 \right)
\end{array}\right],\;\text{first update}\\
\left[ \begin{array}{c} 
x \left( k + 2 \right) \\
y \left( k \right) \\
y \left( k+1 \right)
\end{array} \right]
 &= 
\left[ \begin{array}{ccc}
A & 0 & B\\ 
0 & I & 0\\
C & 0 & D\\
\end{array}\right]
\left[ \begin{array}{c}
x \left( k+1 \right)\\
y \left( k \right) \\
u \left( k+1 \right)
\end{array}\right],\;\text{second update}
\end{align}

The factored state variable description of the block-length 2 filter is:
\begin{align*}
\left[ \begin{array}{c} 
x \left( k + 2 \right) \\
y \left( k \right) \\
y \left( k+1 \right)
\end{array} \right]
&=\left[ \begin{array}{ccc}
A & 0 & B\\ 
0 & I & 0\\
C & 0 & D\\
\end{array}\right]
\left[ \begin{array}{ccc}
A & B & 0\\ 
C & D & 0\\
0 & 0 & I\\
\end{array}\right]\left[ \begin{array}{c}
x \left( k \right)\\
u \left( k \right) \\
u \left( k+1 \right)
\end{array}\right]=\left[ \begin{array}{ccc}
A^{2} & AB & B\\ 
C & D & 0\\
CA & CB & D\\
\end{array}\right]\left[ \begin{array}{c}
x \left( k \right)\\
u \left( k \right) \\
u \left( k+1 \right)
\end{array}\right]
\end{align*}

\emph{Roberts} and
\emph{Mullis}~\cite[Table 10.2.1]{RobertsMullis_DigitalSignalProcessing}
list the number of multipliers-per-output for three classes of $N$-th order,
block length $P$ block processing state variable filters, reproduced in
Table~\ref{tab:block-filter-multipliers-per-output}. If the filter is decimating
then 
only a single output, $y(k)$, needs to be calculated in each block and the
number of multipliers-per-output is reduced accordingly.

\begin{table}
\centering
\begin{threeparttable}
\bgroup{}
\begin{tabular}{lll} \\ \toprule
Filter structure & Number of multipliers per output & Optimal block length, P\\
\midrule
  \vspace{1pt} \\
Full state variable filter & $\frac{N^{2}}{P}+2N+\frac{P+1}{2}$ & $N\sqrt{2}$ \\
  \vspace{1pt} \\
  $m$-th order cascaded sections & $\left(\frac{m}{P}+2+\frac{P+1}{2m}\right)N$ & $m\sqrt{2}$ \\
  \vspace{1pt} \\
$m$-th order parallel sections & $\left(\frac{m}{P}+2+\frac{P-1}{2m}\right)N+1$ & $m\sqrt{2}$ \\
  \vspace{1pt} \\
\bottomrule
\end{tabular}
\egroup{}
\end{threeparttable}
\caption[The number of multipliers for three classes of block filters]{The
  number of multipliers for three classes of $N$-th order block processing
  filters. (See~\cite[Table 10.2.1]{RobertsMullis_DigitalSignalProcessing}.)}
\label{tab:block-filter-multipliers-per-output}
\end{table}

The Octave function \emph{sv2block} converts a block length $1$ state variable
filter to a block length $P$ state variable filter. The Octave function
\emph{svf} implements a MIMO state variable filter that can be applied to block
filtering by rearranging the input and output matrixes appropriately.
The Octave function \emph{Abcd2cc} generates an \emph{oct}-file implementation of
a block processing state variable filter. The Octave script
\emph{Abcd2cc\_test.m} tests the \emph{oct}-file implementation of an $8$-th
order elliptic filter with block length $12$ and $8$ bit coefficients.
Figure~\ref{fig:response-of-8th-order-block-length-12-filter} shows the overall
simulated response and
Figure~\ref{fig:passband-response-of-8th-order-block-length-12-filter} compares
the passband responses. The pass-band response of the block length $12$ filter
is more accurate than that of the block length $1$ filter. The noise
gain\footnote{See Chapter~\ref{sec:Round-off-noise-in-state-variable-filters}.}
of the block filter with truncated coefficients is accurately estimated by
dividing the noise gain of the \emph{untruncated} block length $1$ filter by
$P$. Use of the noise gain of the untruncated filter reflects the improvement in
round-off noise performance obtained by block processing. The accuracy of the
estimate of the noise gain of the truncated block length $1$ filter improves
when the number of bits is increased to $10$. From
Table~\ref{tab:block-filter-multipliers-per-output}, the number of
multipliers per output is $81$ for the block length $1$ filter and $27.83$ for
the block length $12$ filter. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{Abcd2cc_test_ellip8ABCD12_response}}
\caption{Simulated response of an $8$-th order elliptic filter with $8$-bit
precision coefficients for block lengths of $1$ and $12$. The block length
$12$ filter is implemented as an \emph{oct}-file.}
\label{fig:response-of-8th-order-block-length-12-filter}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{Abcd2cc_test_ellip8ABCD12_passband_response}}
\caption{Simulated passband response of a $8$-th order elliptic filter with
  $8$-bit precision coefficients for block lengths of $1$ and $12$. The block
  length $12$ filter is implemented as an \emph{oct}-file.}
\label{fig:passband-response-of-8th-order-block-length-12-filter}
\end{figure}

\chapter{Frequency transformations of Digital Filters}
See \emph{Roberts} and
\emph{Mullis}~\cite[Section 6.7]{RobertsMullis_DigitalSignalProcessing}.
A \emph{generalised band-pass} filter has a frequency response function
$H\left(e^{\imath\theta}\right)$ which is zero in each \emph{stop-band}
and one in each \emph{pass-band}. Given a prototype low-pass filter
$H\left(z\right)$ we wish to design a frequency transformation $F\left(z\right)$
such that the composition $G\left(z\right)=H\left(F\left(z\right)\right)$
is a filter with the properties:
\begin{enumerate}
\item $F\left(z\right)$ should map the unit circle into itself, ie:
  $F\left(e^{\imath \phi}\right)=e^{\imath\theta\left(\phi\right)}$,
so that $G\left(e^{\imath\phi}\right)=H\left(e^{\imath\theta\left(\phi\right)}\right)$.
\item If $H\left(z\right)$ is stable and minimum phase, then $G\left(z\right)$
is stable and minimum phase. If $\lambda$ is a pole (or zero) $G\left(z\right)$,
then $F\left(\lambda\right)$ is a pole (or zero) of $H\left(z\right)$.
Thus if $\left|\lambda\right|<1$ implies $\left|F\left(\lambda\right)\right|<1$
then these properties are preserved.
\end{enumerate}
Consequently, the complex function $F\left(z\right)$ is a \emph{frequency
transformation} if
\begin{enumerate}
\item $\left|z\right|>1\Leftrightarrow\left|F\left(z\right)\right|>1$
\item $\left|z\right|=1\Leftrightarrow\left|F\left(z\right)\right|=1$
\item $\left|z\right|<1\Leftrightarrow\left|F\left(z\right)\right|<1$
\end{enumerate}
Products $F_{1}\left(z\right)F_{2}\left(z\right)$ of frequency transformations
are frequency transformations. Compositions
$F_{1}\left(F_{2}\left(z\right)\right)$ of frequency transformations are also
frequency transformations. If $F\left(z\right)$ is a frequency transformation,
then $1/F\left(z\right)$ is a stable all-pass filter. In the composition
$G\left(z\right)=H\left(F\left(z\right)\right)$ the unit delay $z^{-1}$ is
replaced with the all-pass filter $\left[F\left(z\right)\right]^{-1}$. For IIR
filter design $F\left(z\right)$ must be a rational function. A first order
frequency transformation has the form: 
\begin{align*}
F\left(z\right) &= \pm\frac{z-\alpha}{1-\alpha^{\ast}z}\quad\left|\alpha\right|^{2}<1
\end{align*}
This is a frequency transformation since
\begin{align*}
\left|F\left(z\right)\right|^{2} &= \frac{\left(z-\alpha\right)\left(z^{\ast}-\alpha^{\ast}\right)}{\left(1-\alpha^{\ast}z\right)\left(1-\alpha z^{\ast}\right)}\\
 &= 1+\frac{zz^{\ast}-1+\alpha\alpha^{\ast}-\alpha\alpha^{\ast}zz^{\ast}}{1-\alpha z^{\ast}-\alpha^{\ast}z+\alpha\alpha^{\ast}zz^{\ast}}\\
 &= 1+\frac{\left[\left|z\right|^{2}-1\right]\left[1-\left|\alpha\right|^{2}\right]}{\left|1-\alpha^{\ast}z\right|^{2}}
\end{align*}
Order $n$ frequency transformations are known as \emph{Blaschke products}
\begin{align*}
F\left(z\right) &= \pm\prod_{i=1}^{m}\left(\frac{z-\alpha_{i}}{1-\alpha_{i}^{\ast}z}\right)=\pm\frac{p\left(z\right)}{\tilde{p}\left(z\right)}
\end{align*}
where
\begin{align*}
p\left(z\right) &= \sum_{i=o}^{n}p_{i}z^{-i}=p_{0}z^{-n}\prod_{i=1}^{n}\left(z-\alpha_{i}\right)
\end{align*}
has roots $\left|\alpha_{i}\right|<1$ and $\tilde{p}\left(z\right)=z^{-n}p\left(z^{-1}\right)$.

Suppose the prototype $H\left(z\right)$ has cut-off frequency $\theta=\pi/2$
and $G\left(z\right)$ has the pass band edges shown in 
Figure~\ref{fig:Frequency-warping-function}
(where $G\left(z\right)$ is low-stop).

\begin{figure}[!ht]
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{FrequencyTransformation}
% Note that to enter a Unicode character (eg: small omega) in dia 
% type CTRL-SHIFT-u 03c9
\caption{Frequency warping function (after \emph{Roberts} and
  \emph{Mullis}~\cite[Figure 6.7.2]{RobertsMullis_DigitalSignalProcessing}).}
\label{fig:Frequency-warping-function}
\end{figure}

$F\left(z\right)$ must map the band edges as shown by the frequency
warp $\theta\left(\phi\right)$. There are two cases:
\begin{align*}
\text{low-pass:} & \begin{cases}
F\left(1\right)=1\\
\theta\left(0\right)=0\\
\theta_{k}=\theta\left(\phi_{k}\right)=\left(k-\frac{1}{2}\right)\pi
\end{cases}
\end{align*}
\begin{align*}
\text{low-stop:} & \begin{cases}
F\left(1\right)=-1\\
\theta\left(0\right)=\pi\\
\theta_{k}=\theta\left(\phi_{k}\right)=\left(k+\frac{1}{2}\right)\pi
\end{cases}
\end{align*}
\emph{Roberts} and
\emph{Mullis}~\cite[Figure 6.7.3]{RobertsMullis_DigitalSignalProcessing} show
an algorithm for calculating the parameters of the frequency transformation
$F\left(z\right)$. This algorithm is implemented by the
Octave~\cite{Eaton_Octave} function \emph{phi2p}.
\section{Frequency Transformation of the Transfer Function}
See \emph{Roberts} and
\emph{Mullis}~\cite[Problem 6.26]{RobertsMullis_DigitalSignalProcessing}.
Given a low-pass prototype:
\begin{align*}
H\left(z\right) &= \frac{\beta\left(z\right)}{\alpha\left(z\right)}\\
 &= \frac{\sum_{k=0}^{L}\alpha_{k}z^{-k}}{\sum_{k=0}^{L}\beta_{k}z^{-k}}
\end{align*}
and a frequency transformation function
\begin{align*}
F\left(z\right) &= \frac{p\left(z\right)}{\tilde{p}\left(z\right)}
\end{align*}
where $p\left(z\right)=\sum_{k=0}^{M}p_{k}z^{-k}$ and $\tilde{p}\left(z\right)=z^{-M}p\left(z^{-1}\right)$,
find the filter
\begin{align*}
G\left(z\right) &= H\left(\sigma F\left(z\right)\right)=\frac{b\left(z\right)}{a\left(z\right)}
\end{align*}
where $\sigma=1$ for low-pass and $\sigma=-1$ for low-stop.

First expand $a\left(z\right)$ and $b\left(z\right)$ in $\alpha\left(z\right)$,
$\beta\left(z\right)$ and $p\left(z\right)$:
\begin{align*}
\frac{a\left(z\right)}{b\left(z\right)} &= \frac{\sum_{k=0}^{LM}a_{k}z^{-k}}{\sum_{k=0}^{LM}b_{k}z^{-k}}\\
 &= \frac{\sum_{k=0}^{L}\alpha_{k}\left[\sigma p\left(z\right)/\tilde{p}\left(z\right)\right]^{-k}}{\sum_{k=0}^{L}\beta_{k}\left[\sigma p\left(z\right)/\tilde{p}\left(z\right)\right]^{-k}}\\
 &= \frac{\sum_{k=0}^{L}\alpha_{k}\left[\sigma z^{-M}p\left(z^{-1}\right)\right]^{k}\left[p\left(z\right)\right]^{L-k}}{\sum_{k=0}^{L}\beta_{k}\left[\sigma z^{-M}p\left(z^{-1}\right)\right]^{k}\left[p\left(z\right)\right]^{L-k}}
\end{align*}
A common factor of $\left[p\left(z\right)\right]^{L}$ has been introduced.
Next choose $N\geq LM+1$ and define the following 
\emph{Discrete Fourier Transform} pairs:
\begin{align*}
\left[\begin{array}{cccccc}
p_{0} & \cdots & p_{M} & 0 & \cdots & 0\end{array}\right] 
& \overset{DFT}{\longleftrightarrow}  \left[\begin{array}{cccc}
P\left(0\right) & P\left(1\right) & \cdots & P\left(N-1\right)\end{array}\right]\\
\left[\begin{array}{cccccc}
a_{0} & \cdots & a_{LM} & 0 & \cdots & 0\end{array}\right] 
& \overset{DFT}{\longleftrightarrow} \left[\begin{array}{cccc}
A\left(0\right) & A\left(1\right) & \cdots & A\left(N-1\right)\end{array}\right]\\
\left[\begin{array}{cccccc}
b_{0} & \cdots & b_{LM} & 0 & \cdots & 0\end{array}\right] 
& \overset{DFT}{\longleftrightarrow} \left[\begin{array}{cccc}
B\left(0\right) & B\left(1\right) & \cdots & B\left(N-1\right)\end{array}\right]
\end{align*}
where 
\begin{align*}
A\left(n\right) &= \sum_{k=0}^{N-1}a_{k}W_{N}^{-nk}\\
 &= a\left(W_{N}^{n}\right)\\
 &= \sum_{k=0}^{L}\alpha_{k}\sigma^{k}W_{N}^{-knM}e^{-2k\arg\left\{ P\left(n\right)\right\} }\left\{ P\left(n\right)\right\} ^{L}\\
 &= \alpha\left(e^{\imath\theta_{n}}\right)\left\{ P\left(n\right)\right\} ^{L}
\end{align*}
and
\begin{align*}
\theta_{n} &= \frac{2\pi nM}{N}+\left(\frac{1-\sigma}{2}\right)\pi+2\arg\left\{ P\left(n\right)\right\} 
\end{align*}
Here $W_{N}=e^{\imath\frac{2\pi}{N}}$ and $\arg$ means \emph{``angle
  of''}. Similarly:
\begin{align*}
  B\left(n\right)
  &= \beta\left(e^{\imath\theta_{n}}\right)\left\{ P\left(n\right)\right\} ^{L}
\end{align*}
This algorithm is implemented by the Octave function \emph{tfp2g.m}.
\section{\label{sec:Frequency-Transformations-of-State-Variable-Filters}Frequency Transformations of State Variable Filters}
See \emph{Mullis and Roberts}~\cite[Section  III]{MullisRoberts_RoundoffNoiseInDigitalFiltersFrequencyTransformations}.
Given a (usually low-pass) prototype filter $H\left(z\right)$ parameterised
by the state variable description $\left\{ A,b,c,d\right\}$ construct the 
filter $G\left(z\right)=H\left(F\left(z\right)\right)$ where 
\begin{align*}
F\left(z\right) &= \pm\prod_{i=1}^{m}\left(\frac{z-\alpha_{i}^{\ast}}{1-\alpha_{i}z}\right),\quad\left|\alpha_{i}\right|<1
\end{align*}
where $\ast$ means complex conjugate transpose.

If the order of $H\left(z\right)$ is $n$ then the order of $G\left(z\right)$
is $mn$. The map $z\rightarrow F\left(z\right)$ preserves the disk
$\left|z\right|<1$, the circle $\left|z\right|=1$ and the set $\left|z\right|>1$
since
\begin{align*}
1-\left|\frac{z-\alpha^{\ast}}{1-\alpha z}\right|^{2} &= \frac{\left(1-\left|z\right|^{2}\right)\left(1-\left|\alpha\right|^{2}\right)}{\left|1-\alpha z\right|^{2}}
\end{align*}
Therefore if $H\left(z\right)$ is stable (minimum phase) then $G\left(z\right)$
is stable (minimum phase). We want to find the matrices $\mathfrak{A},\mathfrak{B},\mathfrak{C},\mathfrak{D}$
such that 
\begin{align*}
\mathfrak{D}+\mathfrak{C}\left(zI-\mathfrak{A}\right)^{-1}\mathfrak{B} &= 
G\left(z\right) = H\left(F\left(z\right)\right)
\end{align*}
Let matrices $\left\{\alpha,\beta,\gamma,\delta\right\}$ parameterise the filter
$1/F\left(z\right)$ so that 
\begin{align*}
\frac{1}{F\left(z\right)} &= \delta+\gamma\left(zI-\alpha\right)^{-1}\beta
\end{align*}
Note that $1/F\left(z\right)$is a stable, all-pass filter. 

A heuristic construction of $H\left(F\left(z\right)\right)$ follows.
The filter $1/F\left(z\right)$ replaces each delay branch in in the
original filter, $H\left(z\right)$, so for a $m\times n$ matrix
$S\left(k\right)$
\begin{align*}
S\left(k+1\right) &= \alpha S\left(k\right)+\beta\left[Ax\left(k\right)+bu\left(k\right)\right]^{\top}\\
x\left(k\right) &= S^{\top}\left(k\right)\gamma^{\top}+\delta\left[Ax\left(k\right)+bu\left(k\right)\right]\\
y\left(k\right) &= cx\left(k\right)+du\left(k\right)
\end{align*}
Eliminating $x\left(k\right)$ gives
\begin{align*}
S\left(k+1\right) &= \alpha S\left(k\right)+\beta\gamma S\left(k\right)\left[A\left(I-\delta A\right)^{-1}\right]^{\top}+\beta\left[\left(I-\delta A\right)^{-1}b\right]^{\top}u\left(k\right)\\
y\left(k\right) &= \gamma S\left(k\right)\left[c\left(I-\delta A\right)^{-1}\right]^{\top}+\left[d+\delta c\left(I-\delta A\right)^{-1}b\right]u\left(k\right)
\end{align*}

Define $V\left(X\right)$ as the vector formed by stacking the columns
of $X$ and define $G\otimes F$ as the \emph{Kronecker product}\footnote{
Define $V\left(X\right)$ as the vector formed by stacking the columns
of $X$. Suppose the matrix product $FXG^{\top}$is defined. This represents
a linear transformation applied to X. When this transformation is
arranged as a vector
\begin{align*}
V\left(FXG^{\top}\right) &= \left[G\otimes F\right]V\left(X\right)
\end{align*}
where $G\otimes F$ is defined as the \emph{Kronecker product}, 
$\left\{ G_{ij}F\right\} $, of matrices $G$ and $F$. 
The Kronecker product is defined for any two matrices and satisfies the 
following:
\begin{align*}
\left[A\otimes B\right]\left[C\otimes D\right] &= \left(AC\right)\otimes\left(BD\right)\\
\left(A+B\right)\otimes\left(C+D\right) &= A\otimes C+A\otimes D+B\otimes C+B\otimes D\\
\left[A\otimes B\right]^{-1} &= A^{-1}\otimes B^{-1}\\
\left[A\otimes B\right]^{\top} &= A^{\top}\otimes B^{\top}
\end{align*}
By convention Kronecker products are performed \emph{after} ordinary
matrix products and \emph{before} matrix addition.}, 
\emph{$\left\{ G_{ij}F\right\}$}, of the matrixes $G$ and $F$. Then:
\begin{align*}
V\left(S\left(k+1\right)\right) &= \mathfrak{A}V\left(S\left(k\right)\right)+\mathfrak{B}u\left(k\right)\\
y\left(k\right) &= \mathfrak{C}V\left(S\left(k\right)\right)+\mathfrak{D}u\left(k\right)
\end{align*}
where 
\begin{align*}
\mathfrak{A} &= I\otimes\alpha+A\left(I-\delta A\right)^{-1}\otimes\beta\gamma\\
\mathfrak{B} &= \left(I-\delta A\right)^{-1}b\otimes\beta\\
\mathfrak{C} &= c\left(I-\delta A\right)^{-1}\otimes\gamma\\
\mathfrak{D} &= d+\delta c\left(I-\delta A\right)^{-1}b
\end{align*}
 and 
\begin{align}
H\left(F\left(z\right)\right) &= \mathfrak{D}+\mathfrak{C}\left(zI-\mathfrak{A}\right)^{-1}\mathfrak{B}\label{eq:FreqTransHofF}
\end{align}
\emph{Mullis and
  Roberts}~\cite[Appendix A]{MullisRoberts_RoundoffNoiseInDigitalFiltersFrequencyTransformations}
give a direct proof. Start with the identity:
\begin{align*}
\left(fI-A\right)b\otimes\beta &= f\left[b\otimes\beta-Ab\otimes\beta\left(\frac{1}{f}\right)\right]
\end{align*}
Where, for convenience the scalar $F\left(z\right)=f$. So 
\begin{align*}
b\otimes\beta &= f\left[\left(fI-A\right)^{-1}b\otimes\beta-A\left(fI-A\right)^{-1}b\otimes\beta\left(\delta+\gamma\left(zI-\alpha\right)^{-1}\beta\right)\right]\\
 &= f\left[I\otimes\left(zI-\alpha\right)-\delta A\otimes\left(zI-\alpha\right)-A\otimes\beta\gamma\right]\cdot\left[\left(fI-A\right)^{-1}b\otimes\left(zI-\alpha\right)^{-1}\beta\right]\\
 &=  \left[\left(I-\delta A\right)\otimes\left(zI-\alpha\right)-A\otimes\beta\gamma\right]\cdot\left[f\left(fI-A\right)^{-1}b\otimes\left(zI-\alpha\right)^{-1}\beta\right]
\end{align*}
Therefore
\begin{align*}
\mathfrak{B} &= \left(I-\delta A\right)^{-1}b\otimes\beta\\
 &= \left[I\otimes\left(zI-\alpha\right)-\left(I-\delta A\right)^{-1}A\otimes\beta\gamma\right]\cdot\left[f\left(fI-A\right)^{-1}b\otimes\left(zI-\alpha\right)^{-1}\beta\right]\\
 &= \left(zI-\mathfrak{A}\right)\left[f\left(fI-A\right)^{-1}b\otimes\left(zI-\alpha\right)^{-1}\beta\right]
\end{align*}
so, substituting $\left(zI-\mathfrak{A}\right)^{-1}\mathfrak{B}$
\begin{align*}
\mathfrak{D}+\mathfrak{C}\left(zI-\mathfrak{A}\right)^{-1}\mathfrak{B} 
&= \left[ d+\delta c\left(I-\delta A\right)^{-1}b\right] 
 +
   \left[c\left(I-\delta A\right)^{-1}\otimes\gamma\right]
   \cdot
   \left[f\left(fI-A\right)^{-1}b\otimes\left(zI-\alpha\right)^{-1}\beta\right]\\
 &= d+\delta c\left(I-\delta A\right)^{-1}b
    + f\left[c\left(I-\delta A\right)^{-1}\left(fI-A\right)^{-1}b \right]
      \cdot
      \left[ \gamma\left(zI-\alpha\right)^{-1}\beta \right] \\
 &= d+c\left(I-\delta A\right)^{-1}
      \left[ \delta\left(fI-A\right)+f\left(\frac{1}{f}-\delta\right)I\right]
      \left(fI-A\right)^{-1}b\\
 &= d+c\left(fI-A\right)^{-1}b\\
 &= H\left(f\right)\\
 &= H\left(F\left(z\right)\right)
\end{align*}
This algorithm is implemented by the Octave function \emph{tfp2Abcd}.
\section{\label{sec:example-frequency-transformations-of-5-th-order-elliptic-filter}An example: frequency transformations of a 5-th order elliptic filter}
The Octave script \emph{tfp2g\_test.m}
shows examples of frequency transformations of a 5th order
elliptic low-pass filter. Figure~\ref{fig:tfp2g-lpproto} shows
the prototype filter. Figure~\ref{fig:tfp2g-lp} shows the result of a 
low-pass to low-pass transformation. Figure~\ref{fig:tfp2g-hp} shows the
result of a low-pass to high-pass transformation. Figure~\ref{fig:tfp2g-bp}
shows the result of a low-pass to band-pass
transformation. Figure~\ref{fig:tfp2g-bs} shows the result of a low-pass to
triple band-stop transformation.
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{tfp2g_test_lpproto}}
\caption{Prototype 5-th order elliptic low-pass filter.}
\label{fig:tfp2g-lpproto}\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{tfp2g_test_lp}}
\caption{Low-pass to low-pass transformation of a 5-th order elliptic low-pass
  filter.}
\label{fig:tfp2g-lp}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{tfp2g_test_hp}}
\caption{Low-pass to high-pass transformation of a 5-th order elliptic low-pass
  filter.}
\label{fig:tfp2g-hp}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{tfp2g_test_bp}}
\caption{Low-pass to band-pass transformation of a 5-th order elliptic low-pass
  filter.}
\label{fig:tfp2g-bp}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{tfp2g_test_bs}}
\caption{Low-pass to triple band-stop transformation of a 5-th order elliptic
  low-pass filter.}
\label{fig:tfp2g-bs}
\end{figure}


\chapter{\label{sec:Round-off-noise-in-state-variable-filters}Round-off noise in state variable filters}
This chapter is based on Chapter 9 of \emph{Roberts} and
\emph{Mullis}~\cite{RobertsMullis_DigitalSignalProcessing}. 
\section{\label{Quantisation-noise-in-digital-filters}Quantisation noise in digital filters}
The binary number generated by an ADC is assumed to be a fixed
point number. Most often this number is represented in $2$'s complement
format because that is easily implemented. The $2$'s complement representation
of a real number, $r$, in a finite length register of $B$ bits is:
\begin{align*}
\left[r\right]_{Q}=\Delta \left(-b_{0}+\sum_{m=1}^{B-1}{b_{m}2^{-m}}\right)
\end{align*}
where:
\begin{align*}
\Delta  &\le r <\Delta\\
b_{0}&=1\; for\; r \le 0\\
b_{0}&=0\; for\; r \ge 0
\end{align*}

Here $\Delta$ is the maximum voltage represented and $b_{0}$ is the sign bit. 
The quantisation step size is $q=\Delta 2^{-B+1}$. If the quantiser rounds to 
the nearest integer multiple of $q$ then the error in the representation of
$r$ can be considered to be uncorrelated from sample to sample and uniformly
distributed in the range $\left(-\frac{q}{2},\frac{q}{2}\right)$ with 
variance\footnote{The probability density function of 
the quantisation error of $r$, $e$, is $p_{e}\left(x\right)=q^{-1}$ and the 
mean error is $\mu_{e}=0$. The variance of the error is the \emph{second
central moment} of the pdf:
\begin{align*}
\sigma_{e}=E\{\left[ e-\mu_{e}\right] ^{2}\}
=\int_{-\infty}^{\infty}\left( x-\mu_{e}\right)^{2}p_{e}\left(x\right)\mathit{dx}
=\int_{-q/2}^{q/2}{\frac{x^{2}}{q}}\mathit{dx}=\frac{q^{2}}{12}
\end{align*}} $\sigma_{e}^{2}=\frac{q^{2}}{12}$.
This assumes that the frequency spectrum of the input, $u\left(k\right)$, of 
the quantiser is reasonably broad and that the probability density function of
$u\left(k\right)$ is broad relative to $q$ so that several quantisation levels 
are crossed between samples of $u\left(k\right)$. The signal-to-noise ratio 
obtained depends on the statistics of both the quantisation noise and the 
signal that is quantised, $u\left(k\right)$. If $u\left(k\right)$ is uniformly 
distributed over the range $\left[-\Delta,\Delta\right]$ then the variance of
$u\left(k\right)$ is $\sigma_{u}^{2}=\frac{1}{3}$ and the required number of 
bits, $B$, to obtain a signal to noise ratio of $SN_{Q}$ is 
$b=\frac{\log_{2}SN_{Q}}{2}$.

$2$'s complement arithmetic does rounding-toward-zero rounding,
also called magnitude truncation. The quantisation error is uniformly
distributed in the range $\left(-q,q\right)$ with variance 
$\sigma_{e}^{2}=\frac{q^{2}}{3}$. For positive inputs the error is 
negative and for negative inputs the error is positive. 
This distribution corresponds to a step input of ${\frac{q}{2}}$
at the state round off noise error input to the filter. 
Modern digital signal processing ICs use a few gates to provide a 
rounding-to-nearest arithmetic mode. If this is not present software rounding
may be required to give adequate noise performance. The results presented in 
the following sections assume the rounding-to-nearest quantiser. Note 
that the $2$'s complement overflow characteristic has the useful property 
that immediate overflows in an accumulator cancel whenever the resulting sum
is in range. An example will demonstrate the effect of the 
rounding-to-minus-infinity quantiser. 

\section{\label{sec:Limit-cycle-oscillation-digital-filters}Limit-cycle oscillations in digital filters}
See \emph{Roberts} and
\emph{Mullis}~\cite[Section 9.3]{RobertsMullis_DigitalSignalProcessing}. If
numbers are represented as $2$'s complement integers and there is no provision
for explicitly detecting and correcting overflows then, depending on how the
filter is scaled, there is a possibility that internal registers will overflow.
What happens then depends on:
\begin{itemize}
\item the nature of the input
\item the filter realisation
\item the number representation used in the filter
\item the overflow characteristic used in the filter
\end{itemize}
The direct form filter has the minimum number of multipliers
for a second order filter. However, with a $2$'s complement overflow
characteristic the output of the filter after an overflow can, depending
on the poles of the filter, become independent of the input sequence.
This condition is called overflow oscillation. A second order direct
form filter is free of overflow oscillations provided:
\begin{align*}
\left|\alpha_{1}\right|+\left|\alpha_{2}\right| \le 1
\end{align*}
where $1+\alpha_{1}z^{-1}+\alpha_{2}z^{-2}$ is the denominator of the transfer 
function. Many other realisations are free of overflow oscillations by design.

\section{State variable filters and wide sense stationary inputs}
\subsection{The filter state covariance matrix}
Assume a causal filter $H\left(z\right)$ driven by white, wide-sense stationary
unit variance white noise inputs, $u\left(k\right)$. The covariance matrix of 
the filter state is:
\begin{align*}
K &= E\left\{x\left(k\right)x^{\top}\left(k\right)\right\}\\
 &= E\left\{x\left(k+1\right)x^{\top}\left(k+1\right)\right\}\\
 &= E\left\{\left(Ax\left(k\right)+Bu\left(k\right)\right)\left(Ax\left(k\right)+Bu\left(k\right)\right)^{\top}\right\}\\
 &= E\left\{Ax\left(k\right)x^{\top}\left(k\right)A^{\top}+Bu\left(k\right)u^{\top}\left(k\right)B^{\top}\right\}\\
 &= AKA^{\top}+BB^{\top}
\end{align*}
This is known as a \emph{discrete Lyapunov equation}. Alternatively, since
\begin{align*}
x\left(k\right) = \sum_{l=0}^{\infty}A^{l}Bu\left(k-l-1\right)
\end{align*}
the state covariance matrix is
\begin{align*}
K = \sum_{m=0}^{\infty}\sum_{l=0}^{\infty}A^{l}Br_{uu}\left(l-m\right)\left(A^{m}B\right)^{\top}
\end{align*}
For unit variance white inputs
\begin{align*}
K = \sum_{l=0}^{\infty}\left(A^{l}B\right)\left(A^{l}B\right)^{\top}
\end{align*}
Algorithm~\ref{alg:Recursive-calculation-of-the-covariance-matrix} is a 
simple recursive calculation of the covariance matrix implemented in 
the Octave function \emph{dlyap\_recursive}.
\begin{algorithm}
\begin{algorithmic}
\State $F \leftarrow A$
\State $K \leftarrow BB^{\top}$
\Repeat
  \State $K \leftarrow FKF^{\top}+K$
  \State $F \leftarrow F^{2}$
\Until $F=0$
\end{algorithmic}
\caption{Recursive calculation of the covariance matrix.}
\label{alg:Recursive-calculation-of-the-covariance-matrix}
\end{algorithm}

Alternative methods for calculating the covariance matrix are:
\begin{itemize}
\item find the auto-correlation sequence of the characteristic equation 
of the state transition matrix with the inverse-Levinson recursion. See 
\emph{Roberts} and
\emph{Mullis}~\cite[Section 9.11, p. 393]{RobertsMullis_DigitalSignalProcessing}.
The Octave function \emph{dlyap\_levinson} implements this solution.
\item use \emph{Hammarling}'s solution of the discrete \emph{Lyapunov}
  equation~\cite{Hammarling_SolutionDiscreteLyapunov}. The Octave \emph{Control}
  package contains the \emph{dlyap} function that calls functions from an
  open-source version of the \emph{SLICOT}
  library~\cite{Slicot_ControlSystemsLibrary} to implement \emph{Hammarling}'s
  algorithm.
\end{itemize}

\subsection{The output response to white noise in a state variable}
The unit pulse response is a cross-correlation of the input and output
\begin{align*}
h\left(k\right) = E\left\{y\left(k+l\right)u\left(l\right)\right\}
\end{align*}
The autocorrelation sequence for the output is 
\begin{align*}
r_{yy}\left(k\right) &= E\left\{y\left(k+l\right)y\left(l\right)\right\}\\
 &= \sum_{l=0}^{\infty}h\left(k+l\right)h\left(l\right)
\end{align*}
Using a state variable description
\begin{align*}
h\left(k\right) =
\begin{cases}
0 & k<0\\
D & k=0\\
CA^{k-1}B & k>0
\end{cases} \quad\quad \underset{\Leftrightarrow}{DFT} \quad\quad
H\left(e^{\imath\theta}\right)=D+C\left(e^{\imath\theta}I-A\right)^{-1}B
\end{align*}
Since
\begin{align*}
r_{yy}\left(k\right) \quad\quad \underset{\Leftrightarrow}{DFT} \quad\quad
S_{yy}\left(\theta\right)=\left|H\left(e^{\imath\theta}\right)\right|^{2}
\end{align*}
we can express the output autocorrelation sequence directly from
$\left\{A,B,C,D\right\}$.
The output autocorrelation sequence is
\begin{align*}
r_{yy}\left(k\right) &= E\left\{y\left(k+l\right)y^{\top}\left(l\right)\right\}\\
 &= E\left\{\left(Cx\left(k+l\right)+Du\left(k+l\right)\right)\left(Cx\left(l\right)+Du\left(l\right)\right)^{\top}\right\}\\
 &= E\left\{Cx\left(k+l\right)x^{\top}\left(l\right)C^{\top}+Du\left(k+l\right)x^{\top}\left(l\right)C^{\top}+Cx\left(k+l\right)u^{\top}\left(l\right)D^{\top}+Du\left(k+l\right)u^{\top}\left(l\right)D^{\top}\right\}
\end{align*}
The first term is
\begin{align*}
E\left\{x\left(k+l\right)x^{\top}\left(l\right)\right\} &= 
E\left\{\left(\sum_{m=0}^{\infty}A^{m}Bu\left(k+l-m-1\right)\right)
\left(\sum_{m^{\prime}=0}^{\infty}A^{m^{\prime}}
Bu\left(l-m^{\prime}-1\right)\right)^{\top}\right\}\\
 &= \sum_{m=0}^{\infty}\sum_{m^{\prime}=0}^{\infty}
\left(A^{m}B\right)\left(A^{m^{\prime}}B\right)^{\top}r_{uu}\left(k-m-m^{\prime}\right)\\
 &= \sum_{m=0}^{\infty}A^{k}A^{m}B\left(A^{m}B\right)^{\top}\\
 &= A^{k}K
\end{align*}
where we have used the fact that 
$r_{uu}\left(k-m+m^{\prime}\right)=\delta\left(k-m+m^{\prime}\right)$.
The cross-correlation between the state and a white noise input is
\begin{align*}
E\left\{x\left(k+l\right)u\left(l\right)\right\} 
&= E\left\{\sum_{j=0}^{\infty}A^{j}Bu\left(k+l-j-1\right)u\left(l\right)\right\}\\
&= \sum_{j=0}^{\infty}A^{j}B\delta\left(k-j-1\right)\\
&= \begin{cases}
A^{k-1}B & k>0\\
0 & k\leq0
\end{cases}
\end{align*}
(This is also the unit-pulse response from the input to internal states.)
The present state is uncorrelated with future inputs so the term containing
is $u\left(k+l\right)x^{\top}\left(k\right)$ is zero. Finally,
\begin{align*}
r_{yy}\left(k\right) 
&= CA^{k}KC^{\top}+CA^{k-1}BD^{\top}\\
&= CA^{k}KC^{\top}+h\left(k\right)D^{\top}
\end{align*}
The energy in the unit-pulse response is given by
\begin{align*}
r_{yy}\left(0\right) &= E\left\{y^{2}\left(k\right)\right\}\\
&= \sum_{l=0}^{\infty}h^{2}\left(l\right)\\
&= \frac{1}{2\pi}\int_{-\pi}^{\pi}\left|H\left(e^{\imath\theta}\right)^{2}
\right|d\theta\\
&= D^{2}+CKC^{\top}
\end{align*}
\subsection{Scaling State Variable Filters To Avoid Overflow\label{sec:Scaling-State-Variable-Filters-To-Avoid-Overflow}}
Round off noise is the dominant component of output error
in digital filters only when overflows in internal registers are negligible.
Overflows are avoided by properly scaling the realisation. For a fixed
point number representation the range of internal variables is:
\begin{align*}
\left|v\left(k\right)\right|\le\Delta
\end{align*}
The magnitude of $\Delta$ depends on the quantisation
step size and the number of bits. The unit pulse response from the
input, $u\left(k\right)$ to an internal variable, $v\left(k\right)$, can be 
written:
\begin{align*}
v\left(k\right)=\left(f \star u\right)\left(k\right)
\end{align*}
where $f$ is the unit pulse response from the input to $v\left(k\right)$
and $\star$ is the convolution operator. The range of values of $v$ depends
on the nature of the input and on the sequence $f$.

For sinusoidal inputs:
\begin{align*}
u\left(k\right) &= \cos\left(k\theta\right)\\
\left|v\left(k\right)\right| &\le \max\left|F\left(e^{\imath\theta}\right)\right|
\end{align*}
where $F$ is the transfer function from $u$ to $v$.

For bounded inputs:
\begin{align*}
\left|u\left(k\right)\right| &\le 1\\
\left|v\left(k\right)\right| &\le 
\sum_{l}\left|f\left(l\right)\right|=\|f\|_{1}
\end{align*}
The right side of the expression for the range of $v$ is known as the 
$l_{1}$-norm of $f$. These are called \emph{``bang{}-bang''} controller inputs
in control theory. For filter design the ${l_{1}}$ norm is usually far too 
conservative.

For finite energy inputs:
\begin{align*}
\sum_{l \le k}u^{2}\left(l\right) &\le 1 \\
\left|v\left(k\right)\right| &\le 
\left[\sum_{l}f^{2}\left(l\right)\right]^{\frac{1}{2}} = \|f\| _{2}
\end{align*}
The right side of the expression for the range of $v$ is known as the 
$l_{2}$-norm of $f$.

To reconcile these bounds on the range of $v$ with the constraint on the size 
of $v$ given above we must constrain the \emph{``gain''} of the unit-pulse 
response sequences for the internal variables. The $l_{2}$-norm scaling rule is:
\begin{align*}
\delta\|f\|_{2}=\delta\left[\sum_{l}f^{2}\left(l\right)\right]^{\frac{1}{2}}=1
\end{align*}
The parameter $\delta$ is 
chosen subjectively. It can be interpreted as the number of standard deviations
representable in the register containing $v$ if the input is unit-variance
white noise. A good value for $\delta$ is 4.

The diagonal components of the state variable covariance matrix, $K$, given 
above are related to the $l_{2}$-norm for each state variable, 
$x\left(k\right)$, by:
\begin{align*}
K_{ii}=\overset{\infty}{\underset{k=0}{\sum}}f_{i}^{2}\left(k\right)=\|f_{i}\|_{2}
\end{align*}
so the scaling constraint applied to the $i$-th component of the state vector is:
\begin{align*}
\delta\sqrt{K_{ii}}=1\;,\;i=1,\;2,\;\;\cdots\;\;,\; n
\end{align*}
This can be achieved by applying the coordinate transformation:
\begin{align*}
T^{-1}=\mathdiag\,\left[ \frac{1}{t_{1}}\;,\;\cdots\;\;,\;\frac{1}{t_{n}}\;\right]
\end{align*}
where:
\begin{align*}
t_{i}=\delta\sqrt{K_{ii}} \; , \; i=1\;,\;2\;,\;\;\cdots\;\;,\; n
\end{align*}
A geometric interpretation of scaling is as follows: For unit
variance stationary Gaussian inputs the set of values of the state
variables $\left\{ x\;:\; x^{\top}K^{-1}x\le\;1\;\right\}$ represents
the \emph{``one standard deviation error ellipsoid''} in the filter state
\section{Estimation of output round-off noise in state variable filters\label{sec:Estimation-of-output-round-off-noise-in-state-variable-filters}}
The z-domain state variable equations with round off noise
inputs can be represented by the following signal flow graph shown in
Figure~\ref{fig:SVFG-noise}.

\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{svfg_noise}
\caption{Signal flow graph of round-off noise of the state
  variable.}
\label{fig:SVFG-noise}
\end{figure}

Where $e$ models the round off noise due to calculation of the state vector,
$x$, and $n$ models the round off noise due to calculation of the output, $y$.
The state variable difference equations for the flow graph are:
\begin{align*}
x\left(k+1\right) &= Ax\left(k\right)+Bu\left(k\right)+e\left(k\right)\\
y\left(k\right) &= Cx\left(k\right)+Du\left(k\right)+n\left(k\right)
\end{align*}
The contribution of $e$ to the state vector, $x$, is usually ignored when the
filter realisation is scaled. The round off noise at the output can be modeled 
as shown in Figure~\ref{fig:Output-noise}.

\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{output_noise}
\caption{Signal flow graph of round-off noise at the
  filter output.} 
\label{fig:Output-noise}
\end{figure}

Where:
\begin{align*}
H\left(z\right)&=D+C\left(zI-A\right)^{-1}B\\
G\left(z\right)&=C\left(zI-A\right)^{-1}\\
g\left(k\right)&=\begin{cases}
0 & k\le0\\
CA^{k-1} & k>0
\end{cases}
\end{align*}
$G\left(z\right)$ is a vector of transfer functions from each state to the
output. $g\left(k\right)$ is a vector of unit pulse responses, one for each 
state. If we call $\sigma_{i}^{2}$ the variance of that part of the output
which is the response to $e\left(k\right)$, then:
\begin{align*}
\sigma_{i}^{2}=\sigma_{e}^{2}\sum^{\infty}_{k=1}g_{i}^{2}\left(k\right)
=\sigma_{e}^{2}\|g_{i}\|^{2}
\end{align*}
Recall that $q$ is the quantisation step size and for a rounding-to-nearest
characteristic $\sigma_{e}^{2}=\frac{q^{2}}{12}$.

These estimates assume that the state variables are truncated
after accumulation (ie: a double length accumulator is used).

In a similar fashion to the covariance matrix, $K$, of the state vector, the 
energy in the sequence $g_{i}$ can be characterised by the matrix, $W$:
\begin{align*}
  W &= E\left\{g_{i}\left(k\right)g_{i}\left(k\right)^{\top}\right\}\\
  &= \sum^{\infty}_{k=0}\left(CA^{k}\right)^{\top}\left(CA^{k}\right)\\
  &=A^{\top}WA+C^{\top}C
\end{align*}

This is also a discrete \emph{Lyapunov} equation and can be solved in the
same manner as the equation for the state covariance matrix, $K$. The matrixes
$K$ and $W$ are often called the \emph{controllability Gramian} 
and \emph{observability Gramian}, respectively. The Octave function \emph{KW.m}
returns both $K$ and $W$ given the state variable description 
$\left\{A,B,C,D\right\}$. The user can select the algorithm used to solve the 
corresponding discrete \emph{Lyapunov} equation. The default algorithm uses the 
Octave function \emph{dlyap} if it is found and the \emph{Levinson} recursion
otherwise.

The output noise variance due to round-off noise in calculating the $i$-th
state can be written:
\begin{align*}
  \sigma^{2}_{i} &= \sigma^{2}_{e}W_{ii} \quad i=1,\;\cdots\;,n
\end{align*}

After the filter is scaled, the total output error due to
round off noise in the calculation of the state vector is:
\begin{align*}
  \sigma_{total}^{2}=\sigma_{e}^{2}\delta^{2}\sum^{n}_{i=1}W_{ii}K_{ii}
\end{align*}

$W_{ii}$ and $K_{ii}$ are those for the unscaled filter.
The sum $\sum^{n}_{i=1}W_{ii}K_{ii}$ is known as the \emph{``noise gain''} of 
the filter realisation. It is invariant under a diagonal (or scaling)
coordinate transformation. Under a general coordinate transform, $T$:
\begin{align*}
\left\{A\;,\ B\;,\ C\;,\;D,\;K,\;W\right\}\quad&\leftarrow\quad 
\left\{T^{-1}AT\;,\; T^{-1}B\;,\;CT\;,\;T^{-1}K{T^{-1}}^{\top}\;,\;T^{\top}WT\right\}
\end{align*}

The other sources of output noise variance are those due to the
input quantisation and the round off in calculating the output. Neither
term depends on the filter realisation. Output roundoff contributes
the amount:
\begin{align*}
\sigma_{other}^{2}&=\sigma_{e}^{2} {\sum^{m}_{{j=1}}}\|g_{j}\|_{2}^{2}
\end{align*}

to the output noise. $m$ is the number of non-state variable summation nodes,
$g_{j}$ is the unit pulse response from node $j$ to the output and the 
quantisation step size at the output and at each node is assumed to be the 
same ie: the word lengths used are the same for each state. 

The following result can be used to calculate the $l_{2}$-norm of a transfer 
function, $H\left(z\right)$, with unit pulse response $h\left(k\right)$ and state
variable representation $\left\{A,B,C,D\right\}$:

\begin{align}
\label{eqn:Transfer-function-l2-norm-from-unit-pulse-response}
\|h\|_{2}^{2}=D^{2}+CKC^{\top}
\end{align}

\subsection{Rounding-to-minus-infinity quantisation noise}
As stated in Section~\ref{Quantisation-noise-in-digital-filters}, the results
for round-off noise shown above assume rounding-to-nearest rounding. With
rounding-to-nearest rounding, the quantisation error is assumed to be 
uniformly distributed in the range $\left(-\frac{q}{2},\frac{q}{2}\right)$
with variance $\frac{q^{2}}{12}$, where $q$ is the quantisation step size. For 
rounding-to-minus-infinity, the quantisation error is assumed to be 
uniformly distributed in the range $\left(0,q\right)$ with variance 
$\frac{q^{2}}{3}$. Consequently, rounding-to-minus-infinity rounding of the
state variables is equivalent to adding a step of $\frac{q}{2}$ at the
output of each state. The Octave script \emph{gkstep\_test.m} demonstates the
effect of using rounding-to-minus-infinity rounding in a $3$rd order Butterworth 
filter with cut-off frequency $0.05f_{S}$. The Butterworth filter is globally 
optimised so that the states are equally scaled. The quantisation noise at the 
filter output is due to the filtered state variable quantisation noise in
addition to the quantisation noise of the output calculation. The latter has a
mean value of $\frac{q}{2}$. The state-to-filter-output unit impulse response 
has been given above. The state-to-filter-output step response is the sum 
over time of the impulse response. The expected step response at the filter 
output can be estimated as the sum of the state-to-filter-output step 
responses of each of the state variables. Figure~\ref{fig:gkstep-test-noise} 
shows the simulated filtered state variable quantisation noise at the 
output of the filter superimposed on the summed state-output-to-filter-output
step response to a step of $\frac{q}{2}$ at each state variable.

\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{gkstep_test_noise}}
\caption{Summed state-to-output step response superimposed on the output quantisation noise of a 3rd order Butterworth filter due to rounding-to-minus-infinity at each state.}
\label{fig:gkstep-test-noise}
\end{figure}

The rounding-toward-minus-infinity rounding error is not signal dependent.
On the other hand, with the 2's-complement rounding-toward-zero rounding,
 the offset follows the sign of the input signal. The additional signal
dependent quantisation noise introduced by rounding-toward-zero can
significantly degrade filter noise performance.

\section{\label{sec:Minimisation-of-round-off-noise}Minimisation of round-off noise in the calculation of the state vector}
Minimising the noise gain minimises the round off noise. \emph{Mullis} and
\emph{Roberts}~\cite[Section 9.9]{RobertsMullis_DigitalSignalProcessing}
,~\cite{MullisRoberts_SynthesisMinimumRoundoffNoiseDigitalFilters}
prove Algorithm~\ref{alg:Minimisation-of-the-noise-gain} for equal word-length 
filters.

\begin{algorithm}[!ht]
If $K$ and $W$ are two n-by-n real symmetric positive definite matrices
then:
\begin{align*}
\left[ \frac{1}{n} {\sum^{n}_{i=1}} K_{ii} W_{ii} \right] ^{\frac{1}{2}} \ge \frac{1}{n} {\sum^{n}_{i=1}}\mu_{i}
\end{align*}
where $\mu_{i}^{2}$ are the eigenvalues of the product $KW$. Equality
holds if-and-only-if for some diagonal matrix $D$:
\begin{align*}
K&=DWD
\end{align*}
and $K_{ii}W_{ii}=K_{jj}W_{jj}$ for all $i$ and $j$.
\caption{Minimisation of the noise gain.}
\label{alg:Minimisation-of-the-noise-gain}
\end{algorithm}

Algorithm~\ref{alg:Optimisation-of-the-noise-gain} finds a coordinate 
transformation, $T$, that optimises the round-off noise of fixed point, 
equal wordlength state-variable filters given the $K$ and $W$ matrices. 
Algorithm~\ref{alg:Optimisation-of-the-noise-gain} is implemented in the
Octave function \emph{optKW.m}.

\begin{algorithm}[!ht]
\begin{enumerate}
\item Diagonalise $K$ and $W$:\\
Since $K$ and $W$ are real, symmetric and positive definite, a decomposition
into $W=U_{1}D_{1}U_{1}^{\top}$ exists. Here $U_{1}$ is real and unitary (ie:
$U_{1}^{\ast} U_{1}=U_{1} U_{1}^{\ast}=I$, where $\ast$ means complex
conjugate transpose) and $D_{1}$ is diagonal with real, positive
elements. Recall that for non-singular matrices
$\left(AB\right)^{-1}=B^{-1}A^{-1}$ and  
$\left(AB\right)^{\top}=B^{\top}A^{\top}$.
Let $T_{1}=U_{1}D_{1}^{-\frac{1}{2}}$ then:
\begin{align*}
  W_{1}&=T_{1}^{\top}WT_{1}=I \\
  K_{1}&=T_{1}^{-1}K\left(T_{1}^{-1}\right)^{\top}=U_{2}D_{2}U_{2}^{\top}
\end{align*}
where $U_{2}$ is real and unitary and $D_{2}$ is diagonal
with real, positive elements. Let $T_{2}=T_{1}U_{2}D_{2}^{\frac{1}{4}}$
then
\begin{align*}
W_{2}&=T_{2}^{\top}WT_{2}=D_{2}^{\frac{1}{2}} \\
K_{2}&=T_{2}^{-1}K\left(T_{2}^{-1}\right)^{\top}=D_{2}^{\frac{1}{2}}
\end{align*}
\item Balance $D_{2}^{\frac{1}{2}}$:\\
Now find a unitary transformation, $U_{3}$, for which
the diagonal elements of $U_{3}^{\top}D_{2}^{\frac{1}{2}}U_{3}$
are nearly equal. $U_{3}$ can be found as a sequence of rotations
that replace the largest and smallest diagonal elements of $D_{2}^{\frac{1}{2}}$
with their average. In two dimensions:
\begin{align*}
\left[\begin{array}{cc}
x^{\prime} & y^{\prime}\\
y^{\prime} & z^{\prime}
\end{array}\right]
=
\left[\begin{array}{cc}
\phantom{-}\cos \theta & \sin \theta\\
-\sin \theta & \cos\theta
\end{array}\right]
\left[\begin{array}{cc}
x & y\\
y & z
\end{array}\right]
\left[\begin{array}{cc}
\cos \theta & -\sin \theta\\
\sin \theta & \phantom{-}\cos\theta
\end{array}\right]
\end{align*}
Expand the matrix product and set $x^{\prime}=z^{\prime}$ so that
\begin{align*}
  \tan 2\theta&=\frac{z-x}{2y}
\end{align*}
After eliminating $y$ from $x^{\prime}$ and $z^{\prime}$:
\begin{align*}
x^{\prime}=z^{\prime}&=\frac{x+z}{2}
\end{align*}
\item The optimising transform is:
 \begin{align*}
T&=U_{1}D_{1}^{-\frac{1}{2}}U_{2}D_{2}^{\frac{1}{4}}U_{3}
\end{align*}
\end{enumerate}
\caption{Optimisation of the noise gain.}
\label{alg:Optimisation-of-the-noise-gain}
\end{algorithm}

The globally optimised state variable filter has
$\mathcal{O}\left(n^{2}\right)$ coefficients. An alternative structure such as a
lattice filter or a cascade of lower-order filters has fewer coefficients,
$\mathcal{O}\left(n\right)$, but will have a larger than optimal noise gain. The
noise gain for a non-optimal filter may be improved by distributing bits
unevenly between the states. \emph{Mullis} and \emph{Roberts}~\cite[Section
IV]{MullisRoberts_SynthesisMinimumRoundoffNoiseDigitalFilters} 
show that if the state wordlengths are $B_{i}$ with:
\begin{align*}
\sum^{n}_{i=1}B_{i} &= nB
\end{align*}
and the quantisation step size for each state is:
\begin{align*}
  q &= 2^{-B_{i}+1}
\end{align*}
then the choice of $B_{i}$ is optimised by setting:
\begin{align*}
  \frac{K_{ii}W_{ii}}{2^{2B_{i}}} &= c
\end{align*}
where $c$ is a constant. Each $B_{i}$ is given by:
\begin{align}
  \label{eqn:Optimal-roundoff-noise-bit-distribution}
  B_{i} &= B + \frac{1}{2}\log_{2}K_{ii}W_{ii} -
  \frac{1}{2n}\sum_{j=1}^{n}\log_{2}K_{jj}W_{jj}
\end{align}
The optimal output noise is then:
\begin{align*}
  \sigma_{total}^{2} &=
  \left[ \frac{n}{3}\left(\frac{\delta}{2^{B}}\right)^{2}\right]
  \left[ \prod^{n}_{i=1}W_{ii}K_{ii}\right]^{\frac{1}{n}}
\end{align*}

\section{Coefficient sensitivity}
An additional effect of the use of finite length registers
is the quantisation of the filter parameters. This appears as a deterministic
change in the filter transfer function. In fact, the sensitivities
of the transfer function to the state variable coefficients are bounded
reasonably tightly by the noise-gain. This means that low round off
noise and low coefficient sensitivity generally occur together in
digital filters. In general, finite register effects become more severe
as the poles of the filter cluster together. The ratio of cut-off
frequency, $f_{c}$, to sample rate, $f_{S}$,
is a useful measure of this clustering. For small values the finite
register effects determine the realisation chosen.
\section{Factored state variable filters and wide sense stationary inputs}
The estimate of round-off noise shown in 
Section~\ref{sec:Estimation-of-output-round-off-noise-in-state-variable-filters}
only applies to the state variables and does not include the round-off noise due 
to arithmetic operations at other nodes in the filter. The \emph{factored} 
state variable description can be used to find the variance of any variable 
in the realisation. Let 
\begin{align*}
q_{0}\left(k\right) = \left[\begin{array}{c}
x\left(k\right)\\
u\left(k\right)
\end{array}\right]
\end{align*}
then the covariance matrix for $q_{0}\left(k\right)$ is 
\begin{align*}
E\left\{q_{0}\left(k\right)q_{0}^{\top}\left(k\right)\right\} &= 
\left[\begin{array}{cc}
E\left\{x\left(k\right)x^{\top}\left(k\right)\right\} & E\left\{x\left(k\right)u\left(k\right)\right\}\\
E\left\{u\left(k\right)x^{\top}\left(k\right)\right\} & E\left\{u^{2}\left(k\right)\right\}
\end{array}\right]\\
 &= \left[\begin{array}{cc}
K & 0\\
0 & 1
\end{array}\right]\\
 & \triangleq{} \tilde{K_{0}}
\end{align*}
The factored state variable equations lead to
\begin{align*}
q_{l+1}^{\left(k\right)} = F_{l+1}q_{l}^{\left(k\right)},\,0\leq l\leq L-1
\end{align*}
leading to
\begin{align*}
\tilde{K}_{l+1} &= E\left\{q_{l+1}^{\left(k\right)}\left(k+1\right)
\left(q_{l+1}^{\left(k\right)}\left(k+1\right)\right)^{\top}\right\}\\
 &= F_{l+1}\tilde{K_{l}}F_{l+1}^{\top}
\end{align*}
Since the corresponding state variable description is
\begin{align*}
\left[\begin{array}{cc}
A & B\\
C & D
\end{array}\right] = F_{L}F_{L-1}\ldots F_{1}
\end{align*}
we have
\begin{align*}
\tilde{K}_{L} &= E\left\{q_{L}\left(k\right)q_{L}^{\top}\left(k\right)\right\}\\
 &= E\left\{ \left[\begin{array}{c}
x\left(k+1\right)\\
y\left(k\right)
\end{array}\right]\left[\begin{array}{cc}
x^{\top}\left(k+1\right) & y\left(k\right)\end{array}\right]\right\} \\
 &= \left[\begin{array}{cc}
A & B\\
C & D
\end{array}\right]\tilde{K_{0}}\left[\begin{array}{cc}
A^{\top} & B^{\top}\\
C^{\top} & D^{\top}
\end{array}\right]\\
 &= \left[\begin{array}{cc}
AKA^{\top}+BB^{\top} & AKC^{\top}+BD^{\top}\\
CKA^{\top}+DB^{\top} & CKC^{\top}+D^{2}
\end{array}\right]\\
 &= \left[\begin{array}{cc}
K & AKC^{\top}+BD^{\top}\\
CKA^{\top}+DB^{\top} & r_{yy}\left(0\right)
\end{array}\right]
\end{align*}
\section{\label{sec:Frequency-transformations-and-round-off-noise}Frequency transformations and round-off noise}
Section~\ref{sec:Frequency-Transformations-of-State-Variable-Filters} describes
frequency transformations of state-variable filters. If the prototype filter,
$H\left(z\right)$ of order $n$, is defined by the state-variable filter 
$\left\{A,B,C,D\right\}$ and the all-pass frequency transformation
$1/F\left(z\right)$ of order $m$, is defined by
 $\left\{\alpha,\beta,\gamma,\delta\right\}$, then the transformed filter,
$G\left(z\right)=H\left(F\left(z\right)\right)$, defined by
$\left\{\mathfrak{A}\mathfrak{B}\mathfrak{C}\mathfrak{D}\right\}$ is:
\begin{align*}
\mathfrak{A} &= I\otimes\alpha+A\left(I-\delta A\right)^{-1}\otimes\beta\gamma\\
\mathfrak{B} &= \left(I-\delta A\right)^{-1}B\otimes\beta\\
\mathfrak{C} &= C\left(I-\delta A\right)^{-1}\otimes\gamma\\
\mathfrak{D} &= D+\delta C\left(I-\delta A\right)^{-1}B
\end{align*}
\emph{Mullis} and \emph{Roberts}~\cite[Section III]
{MullisRoberts_RoundoffNoiseInDigitalFiltersFrequencyTransformations},
consider the state and output covariance matrixes, (also called the 
controllability and observability Gramians) $\mathfrak{K}$ and $\mathfrak{W}$ of
the transformed filter:
\begin{align*}
\mathfrak{K}&=\mathfrak{A}\mathfrak{K}\mathfrak{A}^{\top}+
              \mathfrak{B}\mathfrak{B}^{\top}\\
\mathfrak{W}&=\mathfrak{A}\mathfrak{W}\mathfrak{A}^{\top}+
              \mathfrak{C}^{\top}\mathfrak{C}
\end{align*}
They prove that if $1/F\left(z\right)$ is a stable $m$th
degree all-pass filter, then there is a positive-definite $m\times{}m$
symmetric matrix $Q$ for which:
\begin{align*}
Q&=\alpha{}Q\alpha^{\top}+\beta\beta^{\top}\\
Q^{-1}&=\alpha{}Q^{-1}\alpha^{\top}+\gamma^{\top}\gamma\\
\end{align*}
Consequently, if
\begin{align*}
K&=AKA^{\top}+BB^{\top}\\
W&=AWA^{\top}+C^{\top}C
\end{align*}
then
\begin{align}
\mathfrak{K}&=K\otimes{}Q \\
\mathfrak{W}&=W\otimes{}Q^{-1}
\label{eqn:Frequency-transformations-and-round-off-noise-K-W-Q}
\end{align}
and the $nm$ second-order modes of the filter 
$G\left(z\right)=H\left(F\left(z\right)\right)$ are $m$ copies of the $n$
second-order modes of $H\left(z\right)$.

\chapter{State variable filter realisation as a cascade of second order sections\label{sec:Second-order-cascade}}
\section{Second Order State Variable Filters Optimised for 
Overflow and Round-Off Noise}

Section~\ref{sec:Minimisation-of-round-off-noise} shows how to calculate the
minimum noise state variable filter for an $N$-th order rational transfer 
function filter. The minimum noise filter has $\mathcal{O}\left(N^{2}\right)$
coefficients. This chapter describes the implementation of a rational filter
transfer function as a cascade of optimised second order state variable 
sections having a total of $\mathcal{O}\left(N\right)$ coefficients\footnote{
\emph{Roberts} and
\emph{Mullis}~\cite[Table 10.2.1]{RobertsMullis_DigitalSignalProcessing} show
that a block processing
implementation of the original SISO state variable filter may well have fewer
arithmetic operations per output than a realisation by a cascade of second 
order sections.}. The cascade of second order sections can be pipelined for
hardware implementation by inserting a delay between each section. Experience
has shown that the filter realisation as a cascade of second order sections 
can successfully implement higher order filters than are possible with a
single high order filter. The cascade of second order sections can be designed
to have a round-off noise gain approaching the minimum possible. The round-off
noise variance in the output of a cascade of second order sections includes:
\begin{itemize}
\item input quantisation noise filtered by the cascade transfer function
\item quantisation noise at the output $y_{j}(k)$ of each sub-filter filtered
by the remaining sub-filters
\item quantisation noise at the output of the last sub-filter, in
which case ${\|g_{m}\|_{2}^{2}=1}$.
\end{itemize}

\section{Design equations for optimised second order state variable filters}
\emph{Roberts} and
\emph{Mullis}~\cite[Figure 9.14.1 with corrections]{RobertsMullis_DigitalSignalProcessing}
give the construction of the transformation matrix required to optimise a 
second order state variable filter, shown as
Algorithm~\ref{alg:Construction-optimised-second-order-state-variable-filters}.

\begin{algorithm}
Given $K=\left[\begin{array}{cc}
k_{11} & k_{12}\\
k_{21} & k_{22}
\end{array}\right]$ and $W=\left[\begin{array}{cc}
w_{11} & w_{12}\\
w_{21} & w_{22}
\end{array}\right]$:
\begin{enumerate}
\item Transform $K$ and $W$ using a Cholesky transformation:
\begin{align*}
T_{c} & =  \left[\begin{array}{cc}
\sqrt{\frac{k_{11}k_{22}-k_{12}^{2}}{k_{22}}} & \frac{k_{12}}{\sqrt{k_{22}}}\\
0 & \sqrt{k_{22}}
\end{array}\right]
\end{align*}
 so 
\begin{align*}
K^{\prime} & =  T_{c}^{-1}K{T_{c}^{-1}}^{\top}=\left[\begin{array}{cc}
1 & 0\\
0 & 1
\end{array}\right]
\end{align*}
 and 
\begin{align*}
W^{\prime} & =  T_{c}^{\top}WT_{c}=\left[\begin{array}{cc}
w_{11}^{\prime} & w_{12}^{\prime}\\
w_{21}^{\prime} & w_{22}^{\prime}
\end{array}\right]
\end{align*}

\item Apply a rotation transformation to $W^{\prime}$ so that 
$w_{12}^{\prime}=w_{21}^{\prime}=0$.
The eigenvalues of $KW$ are thus the eigenvalues of $W^{\prime}$.
Let 
\begin{align*}
R(\theta) & = \left[\begin{array}{cc}
\cos\theta & -\sin\theta\\
\sin\theta & \cos\theta
\end{array}\right]
\end{align*}
\begin{align*}
\theta & = \begin{cases}
\frac{\pi}{4} & w_{11}^{\prime}=w_{22}^{\prime}\\
\frac{1}{2}\arctan\left(\frac{2w_{12}^{\prime}}{w_{11}^{\prime}-w_{22}^{\prime}}\right) & w_{11}^{\prime}\neq w_{22}^{\prime}
\end{cases}
\end{align*}
 Then
\begin{align*}
K^{\prime\prime} & =  I
\end{align*}
\begin{align*}
W^{\prime\prime} & =  R\left(-\theta\right)W^{\prime}\left(\theta\right)\\
 & =  \left[\begin{array}{cc}
\mu_{1}^{2} & 0\\
0 & \mu_{2}^{2}
\end{array}\right]
\end{align*}

\item Now apply a transformation:
\begin{align*}
\mu & =  \frac{\mu_{2}}{\mu_{1}}\\
T & =  \frac{\delta}{2}\left[\begin{array}{cc}
\sqrt{1+\mu} & -\sqrt{1+\mu}\\
\sqrt{1+\frac{1}{\mu}} & \sqrt{1+\frac{1}{\mu}}
\end{array}\right]\\
\end{align*}
 so that
\begin{align*}
K^{\prime\prime\prime} & = \frac{1}{\delta^{2}}\left[\begin{array}{cc}
1 & \frac{\mu_{2}-\mu_{1}}{\mu_{2}+\mu_{1}}\\
\frac{\mu_{2}-\mu_{1}}{\mu_{2}+\mu_{1}} & 1
\end{array}\right]\\
W^{\prime\prime\prime} & = \delta^{2}\left[\begin{array}{cc}
\frac{\left(\mu_{2}+\mu_{1}\right)^{2}}{4} & \frac{\mu_{2}^{2}-\mu_{1}^{2}}{4}\\
\frac{\mu_{2}^{2}-\mu_{1}^{2}}{4} & \frac{\left(\mu_{2}+\mu_{1}\right)^{2}}{4}
\end{array}\right]
\end{align*}
\item The optimising transform is $T_{c}R\left(\theta\right)T$.
\end{enumerate}
\caption{Construction of optimised second order state variable
  filters\cite[Figure 9.14.1]{RobertsMullis_DigitalSignalProcessing}.}
\label{alg:Construction-optimised-second-order-state-variable-filters}
\end{algorithm}

\emph{Bomar}~\cite{Bomar_NewSecondOrderStateSpaceStructures} gives design 
equations, shown in 
Algorithm~\ref{alg:Bomar-optimised-second-order-state-variable-filter-sections}
for a state variable second order section with scaling $\delta=1$ and optimal
noise performance. (See also \emph{Roberts} and
\emph{Mullis}~\cite[Figure 9.12.1 with corrections]{RobertsMullis_DigitalSignalProcessing}).
\emph{Bomar} assumes that transfer function of each second order section is 
arranged in the form:
\begin{align}
H\left(z\right) &= d + \frac{q_{1}z^{-1}+q_{2}z^{-2}}{1+p_{1}z^{-1}+p_{2}z^{-2}}
\label{eqn:Second-order-section-transfer-function}
\end{align}

\begin{algorithm}
Compute: $A_{11},\;A_{12},\;A_{21},\;A_{22},\;b_{1},\;b_{2},\;c_{1},\;c_{2}$
\begin{align*}
v_{1} &= \frac{q_{2}}{q_{1}}\\
v_{2} &= \sqrt{v_{1}^{2}-p_{1}v_{1}+p_{2}} & \left(\text{Bomar's }\mu\right)\\\\
v_{3} &= v_{1}-v_{2} & \left(\text{Bomar's }\gamma\right)\\
v_{4} &= v_{1}+v_{2} & \left(\text{Bomar's }\xi\right)\\
v_{5} &= p_{2}-1\\
v_{6} &= p_{2}+1\\
v_{7} &= v_{5}\left(v_{6}^{2}-p_{1}^{2}\right)
       & \left(\text{Bomar's }\lambda\right)\\\\
v_{8} &= \left(\frac{p_{1}}{2}\right)^{2}-p_{2}
      & \left(\text{Bomar's }\epsilon\right)\\
A_{11} = A_{22} &= -\frac{p_{1}}{2}\\
b_{1} &= \sqrt{\frac{v_{7}}{2p_{1}v_{3}-v_{6}\left(1+v_{3}^{2}\right)}}\\
b_{2} &= \sqrt{\frac{v_{7}}{2p_{1}v_{4}-v_{6}\left(1+v_{4}^{2}\right)}}\\
A_{21} &= \sqrt{v_{8}\frac{v_{5}+b_{2}^{2}}{v_{5}+b_{1}^{2}}}\\
A_{12} &= \frac{v_{8}}{A_{21}}\\
c_{1} &= \frac{q_{1}}{2b_{1}}\\
c_{2} &= \frac{q_{1}}{2b_{2}}
\end{align*}
\caption{Bomar second order optimised state variable filter
  sections~\cite[Equation 17]{Bomar_NewSecondOrderStateSpaceStructures}.
  (See also~\cite[Figure 9.12.1]{RobertsMullis_DigitalSignalProcessing}.)} 
\label{alg:Bomar-optimised-second-order-state-variable-filter-sections}
\end{algorithm}

\emph{Bomar}~\cite{Bomar_NewSecondOrderStateSpaceStructures} also gives design
equations, shown in
Algorithm~\ref{alg:Bomar-Type-III-optimised-second-order-state-variable-filter-sections},
for a state variable second order section with scaling $\delta=1$ and near 
optimal noise performance with one less multiplication (\emph{Bomar} calls 
this a type III section). He shows experimentally for a $6$th order low-pass
Butterworth filter that the Type III section has a noise gain that is, as for
the minimum-noise realisation, independent of the passband edge frequency.

\begin{algorithm}
Compute: $A_{11},\;A_{12},\;A_{21},\;A_{22},\;b_{1},\;b_{2},\;c_{1},\;c_{2}$
\begin{align*}
A_{11} = A_{22} &= -\frac{p_{1}}{2}\\
A_{12} &= \sqrt{1+\left(\frac{p_{1}}{2}\right)^{2}\left(\frac{p_{2}-3}{p_{2}+1}\right)}\\
A_{21} &= \frac{\left(\frac{p_{1}}{2}\right)^{2}-p_{2}}{A_{12}}\\
b_{1} &= 0\\
b_{2} &= \sqrt{
\frac{\left(1-p_{2}\right)\left[\left(1+p_{2}\right)^{2}-p_{1}^{2}\right]}
{\left(1+p_{2}\right)\left[1+\left(\frac{p_{1}}{2}\right)^{2}\right]-p_{1}^{2}}}\\
c_{1} &= \frac{q_{2}+A_{11}q_{1}}{A_{12}b_{2}}\\
c_{2} &= \frac{q_{1}}{b_{2}}
\end{align*}
\caption{Bomar Type III second order optimised state variable filter
  sections~\cite[Equation 23]{Bomar_NewSecondOrderStateSpaceStructures}.} 
\label{alg:Bomar-Type-III-optimised-second-order-state-variable-filter-sections}
\end{algorithm}
The Octave function \emph{pq2svcasc}
converts the 2nd-order sections from the \emph{d-p-q} format of 
Equation~\ref{eqn:Second-order-section-transfer-function} into 2nd-order
\emph{direct-form}, \emph{Bomar-Type-III} or \emph{minimum-noise} state variable
sections.

\emph{Bomar}~\cite{Bomar_OnDesignSecondOrderStateSpaceDigitalFilterSections}
also describes realisation of second-order state variable sections that are
\emph{``as computationally efficient as possible subject to preserving
low-roundoff noise,low coefficient sensitivity and freedom from limit cycles''}.
In these realisations some matrix elements are replaced by single powers of $2$.

\section{Block optimal second order cascade filter realisations}
A cascade of individually optimised second order sections
is not block optimal. That is, with the constraint that the sectional
structure is maintained, the output round off noise of the cascade
will not be minimised. This is so because for a white noise input
the covariance matrix of the downstream sub-filters must be calculated
for a coloured rather than white noise input. A cascade realisation
can be block optimised by:
\begin{enumerate}
\item Find the state variable description $\left\{A,B,C,D\right\}$ of the cascade
\item Find the $\left\{K,W\right\}$ matrixes of the cascade. For
a cascade of second order sections, the 2$\times$2 blocks on the diagonals
are the covariance and noise gain matrices of the individual sections
$\left\{K_{i},W_{i}\right\}$
\item Find the transformation, $T_{i}$, that optimises 
$\left\{K_{i},W_{i}\right\}$ for each section
\item Apply these $T_{i}$ to each section in the cascade
\end{enumerate}

\section{An example of a second-order state-variable cascade filter}
The Octave script \emph{svcasc2noise\_example\_test.m} designs a $20$th order 
Butterworth filter with cut-off frequency $f_{c}=0.1\,f_{S}$, where $f_{S}$ is the
sample rate, realised as a cascade of direct-form, Bomar Type III, minimum noise 
or block-optimised second-order state variable sections with a state variable 
scaling of $\delta=4$. The Octave function \emph{butter2pq} calculates the
coefficients of a highpass or lowpass Butterworth filter with second order 
sections in the form of the rational transfer function shown in
Equation~\ref{eqn:Second-order-section-transfer-function}. The sections are
ordered with increasing pole angle\footnote{The Octave function \emph{sos2pq} 
converts the output of the Octave-Forge \emph{signal} 
package~\cite{OctaveForge_SignalPackage} \emph{tf2sos} function to \emph{p-q} 
format}. The Octave function \emph{pq2svcasc} converts these coefficients to 
second-order direct-form, Bomar Type III or minimum-noise state variable
sections. The \emph{pq2blockKWopt} function block-optimises the second-order
direct-form cascade realisation. If the transfer function has odd order then 
\emph{pq2blockKWopt} makes the final section a direct-form first-order section 
with an unused state variable. Note that, to avoid numerical problems, the 
\emph{svcasc2Abcd} function will quietly remove an obviously unused state 
variable so that the state variable matrixes have the expected size for the odd
filter order. For an odd order filter realised as a cascade of second-order 
minimum-noise or Bomar Type III sections \emph{svcasc2Abcd} may not be able to 
remove the unused state variable. This may cause numerical problems when 
calculating the $K$ and $W$ covariance matrixes of the complete second-order
cascade. In practice, the block-optimised second-order cascade, as generated by
\emph{pq2blockKWopt}, is the preferred realisation.
  
The example script uses the Octave function \emph{svcasc2noise} to calculate 
the section noise-gain for each realisation generated by \emph{pq2svcasc} and
for the block-optimised realisation generated by \emph{pq2blockKWopt}. 
\emph{svcasc2noise} also calculates an estimate of the contribution of the
output roundoff noise for that section at the overall cascade output. Finally,
\emph{svcas2noise} estimates the optimal state variable bit distribution
according to Equation~\ref{eqn:Optimal-roundoff-noise-bit-distribution}.

The example script compares the overall noise gains for each cascade realisation
with the section pole angles in increasing and decreasing order. That is, in
the latter case the sections are in the reverse order to that calculated by
\emph{butter2pq}.

For comparison, the example script finds the overall state variable matrix with
\emph{svcasc2Abcd} and calculates the noise gain of the globally optimised
filter. Recall that in the worst case, the globally optimised $N$th order
filter requires $\left(N+1\right)^{2}$ multiplies and the second-order cascade
requires $4.5N$ multiplies.

Finally, the example script compares the estimated and simulated output
roundoff noise variance of the block optimised second order cascade lowpass
and highpass filters with the globally optimised state variable versions of
those filters.

\subsection{Comparison of calculated noise gains}
Table~\ref{tab:Section-noise-gain-20-order-Butterworth-low-pass} shows the
section noise gains for each low-pass filter realisation. The
coefficients used for these calculations are floating-point, not rounded, in
order to illustrate the frequency independence of the optimised sections. 
As expected, the second-order minimum-noise, block-optimised and globally
optimised realisations have the same noise gain in the high-pass and low-pass
filters. Table~\ref{tab:Section-noise-gain-20-order-Butterworth-high-pass}
shows the section noise gains for each high-pass filter realisation. 
\input{svcasc2noise_butterworth_20_low_section_noise_gain.tab}
\input{svcasc2noise_butterworth_20_high_section_noise_gain.tab}

Recall that the noise gain for each section estimates the contribution of the
state variable roundoff noise from that section in the overall filter cascade
output. This is \emph{not} the same as the noise gain from the section state
variables to the section output. If you calculate the latter separately for each
section, then the state variable noise gain at each section output of the
minimum-noise filter will be found to be less than that of the corresponding
section from the Bomar Type III filter. This explains the apparent discrepancies
in Table~\ref{tab:Section-noise-gain-20-order-Butterworth-low-pass} and
Table~\ref{tab:Section-noise-gain-20-order-Butterworth-high-pass}. The
noise-gains for each second-order minimum-noise section calculated according to
Bomar's equations, as shown in
Algorithm~\ref{alg:Bomar-optimised-second-order-state-variable-filter-sections},
agree with those calculated following the general method shown in
Algorithm~\ref{alg:Construction-optimised-second-order-state-variable-filters},
although the state variable coefficients found by the two methods are different.

Tables~\ref{tab:Overall-noise-gain-20-order-Butterworth-low-pass} 
and~\ref{tab:Overall-noise-gain-20-order-Butterworth-high-pass} show the
overall noise gains for each filter realisation with sections ranked
in order of increasing and decreasing pole angle for the lowpass and highpass
filters respectively. For the block optimised
cascade the noise gain in parentheses shows that calculated if the cascade is
not re-optimised after the section order is reversed.
\input{svcasc2noise_butterworth_20_low_overall_noise_gain.tab}
\input{svcasc2noise_butterworth_20_high_overall_noise_gain.tab}
\subsection{Simulation results}
Figure~\ref{fig:order-20-low-butterworth-second-order-cascade-output-response}
shows the simulated response of the $20$th order Butterworth lowpass filter
realised as a block optimised cascade of second order sections with
coefficients rounded to $10$ bits and $10$ bit state storage. 
Figure~\ref{fig:order-20-high-butterworth-second-order-cascade-output-response}
shows the simulated response of the corresponding $20$th order Butterworth
highpass filter. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{svcasc2noise_lowpass_response}}
\caption{Simulated amplitude response of the $20$th order lowpass Butterworth
  filter realised as a block optimised cascade of second-order sections with
  $10$-bit coefficients and state storage.} 
\label{fig:order-20-low-butterworth-second-order-cascade-output-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{svcasc2noise_highpass_response}}
\caption{Simulated amplitude response of the $20$th order highpass Butterworth
  filter realised as a block optimised cascade of second-order sections with
  $10$-bit coefficients and state storage.} 
\label{fig:order-20-high-butterworth-second-order-cascade-output-response}
\end{figure}
Tables~\ref{tab:Simulated-noise-20-order-Butterworth-low-pass}
and~\ref{tab:Simulated-noise-20-order-Butterworth-high-pass} show the
simulated and estimated output roundoff noise variance for the $20$th order
Butterworth lowpass and highpass filter respectively.
\input{svcasc2noise_butterworth_20_low_noise_simulation.tab}
\input{svcasc2noise_butterworth_20_high_noise_simulation.tab}

The input signal is a uniformly distributed random noise signal with a nominal
standard deviation of $2^{8}$. The state variables are scaled with $\delta=4$ so
that the nominal standard deviation of the state variables is $2^{6}$. In each 
case the section outputs, state variables and coefficients are rounded to $10$ 
bits. The effect of coefficient truncation on the noise-gain is seen by
 comparison with the calculated values shown in
Table~\ref{tab:Overall-noise-gain-20-order-Butterworth-low-pass} and
Table~\ref{tab:Overall-noise-gain-20-order-Butterworth-high-pass}. The
simulation results suggest that, to avoid overflow, the intermediate section
outputs should be kept in a double-length accumulator. For comparison, the
tables show the simulation results for the globally-optimised filter and the
improvement obtained by adding an extra bit to the state variables in the
first $6$ sections of the block-optimised filter. (See
Equation~\ref{eqn:Optimal-roundoff-noise-bit-distribution}). When
calculating the output noise gain of the block optimised cascade with additional
state variable bits in some sections, the noise gain for the individual section
is scaled in proportion to the number of extra bits for that section. The nominal
standard deviation of these state variables is $2^7$.
\subsection{Comparison with an N=10 example}
The order $20$ Butterworth filter was chosen as an extreme example. 
Table~\ref{tab:Simulated-noise-10-order-Butterworth-low-pass} shows the 
simulation results obtained by setting $N=10$ in 
\emph{svcasc2noise\_example\_test.m}.
\begin{table}
\centering
\begin{threeparttable}
\begin{tabular}{lrrr}  \\ \toprule
& Estimated & Estimated & Simulated \\ 
& noise gain & noise variance & noise variance\\ 
\midrule
 Scaled Direct &  7.36 &  9.93 &  6.93 \\ 
 Block Opt.&  1.92 &  2.69 &  2.62 \\ 
 Block Opt. (extra bits) &  1.10 &  1.59 &  1.59 \\ 
 Global Opt. &  1.01 &  1.43 &  1.43 \\ 
\bottomrule
\end{tabular}
\end{threeparttable}
\caption[Butterworth 10th order lowpass noise simulation]{Estimated noise gain
  and estimated and simulated output roundoff noise variances for the $10$th
  order Butterworth lowpass filter with $10$ bit rounded coefficients.}
\label{tab:Simulated-noise-10-order-Butterworth-low-pass}
\end{table}
\clearpage{}
\section{Coefficient sensitivity and round-off noise of first-order and second-order all-pass filter sections}
Digital filters implemented as the parallel combination of two or more allpass
filters typically have low coefficient
sensitivity~\cite{VaidyanathanMitraNuevo_LowSensitivityIIRDigitalFilters}.
The transfer function of a filter consisting of parallel all-pass filters
$A\left(z\right)$ and $B\left(z\right)$ is:
\begin{align*}
  H\left(z\right)&=\frac{A\left(z\right)+B\left(z\right)}{2}
\end{align*}
The frequency response of this filter is:
\begin{align*}
  H\left(\omega\right)&=\frac{e^{\phi_{A}\left(\omega\right)}+
                        e^{\phi_{B}\left(\omega\right)}}{2}
\end{align*}
where $\phi_{A}\left(\omega\right)$ and $\phi_{B}\left(\omega\right)$ are the
phase responses of the all-pass filters. The corresponding squared-amplitude,
phase and group delay responses are:
\begin{align*}
\left|H\left(\omega\right)\right|^{2} &=
\frac{1+\cos\left(\phi_{A}\left(\omega\right)-
                  \phi_{B}\left(\omega\right)\right)}{2}\\
\phi_{H}\left(\omega\right) &=
\frac{\phi_{A}\left(\omega\right)+\phi_{B}\left(\omega\right)}{2} \\
T\left(\omega\right) &= 
-\frac{1}{2}\left[
\frac{\partial\phi_{A}\left(\omega\right)}{\partial\omega}+
\frac{\partial\phi_{B}\left(\omega\right)}{\partial\omega}
\right]
\end{align*}

When the all-pass branches of a parallel all-pass filter are realised as the
cascaded connection of first and second order all-pass filters then the phase
response of each branch is, without loss of generality,
$\phi_{A}\left(\omega\right)=\sum_{l}\phi_{A_{l}}\left(\omega\right)$ where
$\phi_{A_{l}}$ is the phase response of the $l$'th first or second order
all-pass section. If $x$ represents a multiplier coefficient in the realisation
of section $A_{l}$, then the squared-amplitude and group delay sensitivities with respect to $x$ are:
\begin{align*}
  S^{\left|H\right|^{2}}_{x}\left(\omega\right)
  &=
    -\frac{1}{\left|H\left(\omega\right)\right|^{2}}
    \frac{\sin\left(\phi_{A}\left(\omega\right)-
                    \phi_{B}\left(\omega\right)\right)}{2}
    \frac{\partial\phi_{A_{l}}\left(\omega\right)}{\partial{}x} \\  
  S^{\top}_{x}\left(\omega\right)
  &=-\frac{1}{T\left(\omega\right)}\frac{1}{2}
    \frac{\partial^{2}\phi_{A_{l}}\left(\omega\right)}{\partial\omega\partial{}x}
\end{align*}

The transfer function of a first order all-pass filter section is:
\begin{align*}
  H\left(z\right)&=-\frac{r-z^{-1}}{1-rz^{-1}}
\end{align*}
where $r$ is real. The filter is stable if $\left|r\right|<1$.

The transfer function of a second order all-pass filter section is:
\begin{align*}
  H\left(z\right)&=\frac{a_{2}+a_{1}z^{-1}+z^{-2}}{1+a_{1}z^{-1}+a_{2}z^{-2}}
\end{align*}
The transfer function of a second order all-pass filter section with complex
poles in the $z$-plane at $z=re^{\pm\imath\theta}$ is:
\begin{align*}
  H\left(z\right)
  &=\frac{\left(re^{\imath\theta}-z^{-1}\right) \left(re^{-\imath\theta}-z^{-1}\right)}
    {\left(1-re^{\imath\theta}z^{-1}\right)\left(1-re^{-\imath\theta}z^{-1}\right)}\\
  &=\frac{r^{2}-2r\cos\theta{}z^{-1}+z^{-2}}{1-2r\cos\theta{}z^{-1}+r^2z^{-2}}
\end{align*}
where $r$ is real. The filter is stable if $\left|r\right|<1$.
The transfer function of a second order all-pass filter section with real
poles in the $z$-plane at $z=r_{1},r_{2}$ is:
\begin{align*}
  H\left(z\right)
  &=\frac{\left(r_{1}-z^{-1}\right)\left(r_{2}-z^{-1}\right)}
    {\left(1-r_{1}z^{-1}\right)\left(1-r_{2}z^{-1}\right)}\\
  &=\frac{r_{1}r_{2}-\left(r_{1}+r_{2}\right)z^{-1}+z^{-2}}
    {1-\left(r_{1}+r_{2}\right)z^{-1}+r_{1}r_{2}z^{-2}}
\end{align*}
The filter is stable if $\left|r_{1}\right|<1$ and $\left|r_{2}\right|<1$.

This section surveys the maximum phase response gradient,
$\frac{\partial\phi}{\partial{}x}$, and round-off noise performance of a
selection of first-order and second-order all-pass filter section transfer
functions and realisations. The Maxima script \emph{allpass\_filter.max}
performs the algebra required to find the state variable description of each
realisation and the Octave scripts \emph{Abcd2H.m} and \emph{H2P.m} calculate
the phase response gradient (see
Appendix~\ref{app:Gradients-state-variable-filter-frequency-response}). 

\subsection{Searching for realisations of all-pass filter transfer functions}
\emph{Mitra} and
\emph{Hirano}~\cite{MitraHirano_DigitalAllPassNetworks} show a catalogue of
realisations of minimum multiplier first and second order all-pass filters. They
consider realisations of the \emph{Type 1} first order all-pass transfer
function:
\begin{align}
  H_{1}\left(z\right)&=\frac{z^{-1}-b_{1}}{1-b_{1}z^{-1}}
                       \label{eqn:First-order-allpass-direct-form}
\end{align}
as a \emph{two-port} network with a constraint:  
\begin{align*}
  \left[\begin{array}{c}
          Y_{1}\\
          Y_{2}\end{array}\right] &=
  \left[\begin{array}{cc}
          t_{11} & t_{12}\\
          t_{21} & t_{22}\end{array}\right]
  \left[\begin{array}{c}
          X_{1}\\
          X_{2}\end{array}\right] \\
  X_{2}&=b_{1}Y{2}
\end{align*}
Eliminating variables $X_{2}$ and $Y_{2}$:
\begin{align*}
  \frac{Y_{1}}{X_{1}}&=\frac{t_{11}-b_{1}\left(t_{11}t_{22}-t_{12}t_{21}\right)}
                       {1-t_{22}b_{1}}
\end{align*}
Comparing with Equation~\ref{eqn:First-order-allpass-direct-form}:
\begin{align*}
  t_{11}=t_{22}&=z^{-1}\\
  t_{12}t_{21}&=z^{-2}-1
\end{align*}
There are four possible realisations of $t_{12}$ and $t_{21}$:
$t_{12}=z^{-2}-1,t_{21}=1$ and $t_{12}=z^{-1}-1,t_{21}=z^{-1}+1$ and their transposed
equivalents~\cite[Fig. 2]{MitraHirano_DigitalAllPassNetworks}. 

In a similar fashion, \emph{Mitra} and \emph{Hirano} find 
realisations of the \emph{Type 2} and \emph{Type 3} second order all-pass
transfer functions: 
\begin{subequations}
\begin{align}
  H_{MH2}\left(z\right)&=\frac{z^{-2}-b_{1}z^{-1}+b_{1}b_{2}}
                         {1-b_{1}z^{-1}+b_{1}b_{2}z^{-2}}
                         \label{eqn:MH2-second-order-all-pass-filter-section} \\
  H_{MH3}\left(z\right)&=\frac{z^{-2}-b_{1}z^{-1}+b_{2}}{1-b_{1}z^{-1}+b_{2}z^{-2}}
                         \label{eqn:MH3-second-order-all-pass-filter-section}
\end{align}
\end{subequations}
Their realisations of these transfer functions are constrained to have only $2$
multipliers but may have more than $2$ delays. \emph{Mitra} and \emph{Hirano}
show $4$ Type 2 and $8$ Type 3 realisations\footnote{There are equal numbers of
  transposed realisations.}. \emph{Mitra} and \emph{Hirano } show plots of the
estimated output round-off noise of each
realisation~\cite[Fig.9, Fig.10 and Fig.11]{MitraHirano_DigitalAllPassNetworks}
due to truncation at the multiplier outputs. This estimate does not include the
round-off noise due to truncation at the register inputs.

\emph{Nishihara} and \emph{Sugahara}~\cite{NishiharaSugahara_SynthesisDigitalFiltersMinimumPoleSensitivity}
present a catalogue of general (not just all-pass) second order filter
realisations with low pole sensitivity with respect to each of the two
multipliers in the realisation. They show 37 realisations\footnote{Note the
  complexity of the classification map shown in Figure 2!}.

\emph{Szczupak
  et.\ al}~\cite{SzczupakMitraFardavi_ComputerBasedSynthesisAllpassNetworks}
describe a computer based search for realisations in which the two coefficients
of the second order all-pass filter transfer function are themselves functions
of two multipliers. They find $646$ distinct realisations. 
\clearpage
\subsection{Maximum phase gradient and round-off noise of some first-order all-pass filter sections}

Equation~\ref{eqn:Dir1-first-order-all-pass-filter-section} is the transfer
function of the first order direct form all-pass filter section
shown in Figure~\ref{fig:Dir1-first-order-all-pass-filter-section}. This
realisation has $2$ multipliers.
\begin{align}
\label{eqn:Dir1-first-order-all-pass-filter-section}
  H_{Dir1}\left(z\right)&=\frac{b_{1}+z^{-1}}{1+b_{1}z^{-1}}
\end{align}

The \emph{Gray} and
\emph{Markel}~\cite{GrayMarkel_DigitalLatticeAndLadderFilterSynthesis}
first order all-pass filter section shown in
Figure~\ref{fig:GM1-first-order-all-pass-filter-section} also implements the
transfer function of Equation~\ref{eqn:Dir1-first-order-all-pass-filter-section}.
The $\epsilon_{1}=\pm{}1$ are chosen to scale the state for good numerical
performance in the implementation. The choice of $\epsilon$ does not alter the
transfer function or the noise gain.

Equation~\ref{eqn:LS1-first-order-all-pass-filter-section} is the transfer
function of the first order all-pass filter section of \emph{Stoyanov et
  al.}~\cite{Stoyanov_RealizationEfficientIIRFilterSensitivityMinimizations}
shown in Figure~\ref{fig:LS1-first-order-all-pass-filter-section}. This
realisation has low sensitivity for filter poles near $z=1$.
\begin{align}
\label{eqn:LS1-first-order-all-pass-filter-section}
  H_{LS1}\left(z\right)&=\frac{-\left(1-c_{1}\right)+z^{-1}}
                         {1-\left(1-c_{1}\right)z^{-1}}
\end{align}

\begin{figure}
\centering
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_dir1}
\caption{Direct form first order all-pass filter section.}
\label{fig:Dir1-first-order-all-pass-filter-section}
\vspace{1cm}
\end{subfigure}
 
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_GM1}
\caption{Gray and Markel first order all-pass filter section.}
\label{fig:GM1-first-order-all-pass-filter-section}
\vspace{1cm}
\end{subfigure}
 
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_LS1}
\caption{Stoyanov et al.\ low sensitvity first order all-pass filter section.}
\label{fig:LS1-first-order-all-pass-filter-section}
\vspace{1cm}
\end{subfigure}
\caption{First order all-pass filter sections.}
\label{fig:First-order-all-pass-filter-sections}
\end{figure}

Figure~\ref{fig:dir1-all-pass-filter-phase-gradient} plots the maximum of the
gradient of the first-order all-pass filter phase response with respect to the
section coefficient against the pole radius. It is the same for each
realisation. The noise gain of each scaled realisation was calculated with the
Octave function \emph{Abcd2ng.m}, as shown in
Chapter~\ref{sec:Round-off-noise-in-state-variable-filters}. The noise gain is
found to be $1$ for each realisation regardless of pole radius. For the
direct-form section, a \emph{slowed} and \emph{retimed} realisation, shown in
Figure~\ref{fig:Retimed-dir1-first-order-all-pass-filter-section}, was
analysed. \emph{Slowing} is the replacement of each $z^{-1}$ delay by $z^{-M}$, reducing the sample rate. The realisation is \emph{retimed} by distributing the
delays so that there is a register, or state, at each multiplier output. This
allows calculation  by the state-variable method of the output round-off noise
due to truncation at both the register inputs and the multiplier outputs. See
\emph{Parhi}~\cite[Chapter 4]{Parhi_VLSIDigitalSignalProcessingSystems} for a
description of retiming algorithms. The Maxima script
\emph{allpass\_filter\_retimed.max} performs the algebra required to find the 
state variable description of each retimed filter realisation.

\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_dir1_retimed}
\caption{Retimed first-order direct form all-pass filter section.}
\label{fig:Retimed-dir1-first-order-all-pass-filter-section}
\end{figure}
 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_dir1_pgrad}}
\caption{Maximum phase gradient plotted against pole radius of first order
  all-pass filter sections.}
\label{fig:dir1-all-pass-filter-phase-gradient}
\end{figure}
\clearpage
\subsection{Maximum phase gradient and round-off noise of some second-order all-pass filter sections}
Equation~\ref{eqn:Dir2-second-order-all-pass-filter-section} is the transfer
function of the second-order direct-form all-pass filter section
shown in Figure~\ref{fig:Dir2-second-order-all-pass-filter-section}. This
realisation has $4$ multipliers.
\begin{align}
\label{eqn:Dir2-second-order-all-pass-filter-section}
  H_{Dir2}\left(z\right)&=\frac{b_{2}+b_{1}z^{-1}+z^{-2}}{1+b_{1}z^{-1}+b_{2}z^{-2}}
\end{align}

Equation~\ref{eqn:GM2-second-order-all-pass-filter-section} is the transfer
function of the second order Gray-and-Markel all-pass filter section shown in
Figure~\ref{fig:GM2-second-order-all-pass-filter-section}.
The $\epsilon_{1},\epsilon_{2}=\pm{}1$ are chosen to scale the states.
\begin{align}
\label{eqn:GM2-second-order-all-pass-filter-section}
  H_{GM2}\left(z\right)&=\frac{k_{2}+k_{1}\left(1+k_{2}\right)z^{-1}+z^{-2}}
                         {1+k_{1}\left(1+k_{2}\right)z^{-1}+k_{2}z^{-2}}
\end{align}

Figure~\ref{fig:AL7c-second-order-all-pass-filter-section} shows a realisation
of Equation~\ref{eqn:GM2-second-order-all-pass-filter-section} due to
\emph{Ansari} and
\emph{Liu}~\cite{AnsariLiu_LowNoiseEfficientRecursiveDigitalFilters}. This
realisation has low noise gain for poles near $z=\pm\imath$. 

The three port transfer matrix of the \emph{Mitra} and
\emph{Hirano}~\cite{MitraHirano_DigitalAllPassNetworks} type 2d
realisation of Equation~\ref{eqn:MH2-second-order-all-pass-filter-section} is:
\begin{align}
\left[\begin{array}{ccc}
        z^{-2} & 1 & 0 \\
        z^{-1}\left(z^{-2}-1\right) & z^{-1} & 1 \\
        z^{-4}-1 & z^{-2} & 0 
\end{array}\right]
\end{align}
and that of the type 3d realisation of
Equation~\ref{eqn:MH3-second-order-all-pass-filter-section} is:
\begin{align}
\left[\begin{array}{ccc}
        z^{-2} & 1 & 1 \\
        z^{-1}\left(z^{-2}-1\right) & z^{-1} & z^{-1} \\
        z^{-4}-1 & z^{-2} & z^{-2}        
\end{array}\right]
\end{align}
Figures~\ref{fig:MH2d-second-order-all-pass-filter-section}
and~\ref{fig:MH2dt-second-order-all-pass-filter-section} show the type 2d
and transposed type 2d realisations of
Equation~\ref{eqn:MH2-second-order-all-pass-filter-section}. 
Figures~\ref{fig:MH3d-second-order-all-pass-filter-section}
and~\ref{fig:MH3dt-second-order-all-pass-filter-section} show the type 3d
and transposed type 3d realisations of
Equation~\ref{eqn:MH3-second-order-all-pass-filter-section}. The state variable
implementations of the transposed realisations have duplicated state
updates. In other words, the rows of the state-transition matrix are not
linearly independent.

Equation~\ref{eqn:LS2a-second-order-all-pass-filter-section} is the transfer
function of the second order all-pass filter section of \emph{Stoyanov et
  al.}~\cite{Stoyanov_RealizationEfficientIIRFilterSensitivityMinimizations}
shown in Figure~\ref{fig:LS2a-second-order-all-pass-filter-section}. This
realisation has low sensitivity for filter poles near $z=1$.
\begin{align}
\label{eqn:LS2a-second-order-all-pass-filter-section}
  H_{LS2}\left(z\right)&=
   \frac{\left(1-c_{2}\right)+\left(2c_{1}+c_{2}-2\right)z^{-1}+z^{2}}
        {1+\left(2c_{1}+c_{2}-2\right)z^{-1}+\left(1-c_{2}\right)z^{-2}}
\end{align}

Equation~\ref{eqn:IS-second-order-all-pass-filter-section} is the transfer
function of the second order all-pass filter section of \emph{Ivanova} and
\emph{Stoyanov}~\cite{IvanovaStoyanov_LowSensitivitySecondOrderAllpass}
shown in Figure~\ref{fig:IS-second-order-all-pass-filter-section}. This
realisation has low sensitivity for filter poles near $z=0$.
\begin{align}
\label{eqn:IS-second-order-all-pass-filter-section}
  H_{IS}\left(z\right)&=
   \frac{d_{2}+\left(d_{1}d_{2}-d_{1}-2d_{2}\right)z^{-1}+z^{2}}
        {1+\left(d_{1}d_{2}-d_{1}-2d_{2}\right)z^{-1}+d_{2}z^{-2}}
\end{align}

\begin{figure}
\centering

\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_dir2}
\caption{Direct form second order all-pass filter section.}
\label{fig:Dir2-second-order-all-pass-filter-section}
\vspace{1cm}
\end{subfigure}
 
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_GM2}
\caption{Gray-and-Markel second order all-pass filter section.}
\label{fig:GM2-second-order-all-pass-filter-section}
\vspace{1cm}
\end{subfigure}
 
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_AL7c}
\caption{Ansari-and-Liu second order all-pass filter section.}
\label{fig:AL7c-second-order-all-pass-filter-section}
\vspace{1cm}
\end{subfigure}

\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_MH2d}
\caption{Mitra-and-Hirano Type 2d second order all-pass filter section.}
\label{fig:MH2d-second-order-all-pass-filter-section}
\vspace{1cm}
\end{subfigure}

\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_MH2dt}
\caption{Mitra-and-Hirano transposed type 2d second order all-pass filter
  section.}
\label{fig:MH2dt-second-order-all-pass-filter-section}
\vspace{1cm}
\end{subfigure}

\end{figure}

\begin{figure}\ContinuedFloat
\centering

\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_MH3d}
\caption{Mitra-and-Hirano type 3d second order all-pass filter section.}
\label{fig:MH3d-second-order-all-pass-filter-section}
\vspace{1cm}
\end{subfigure}

\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_MH3dt}
\caption{Mitra-and-Hirano transposed type 3d second order all-pass filter
  section.}
\label{fig:MH3dt-second-order-all-pass-filter-section}
\vspace{1cm}
\end{subfigure}

\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_LS2a}
\caption{Stoyanov et al.\ low sensitvity near $z=1$ second order all-pass filter
  section.}
\label{fig:LS2a-second-order-all-pass-filter-section}
\vspace{1cm}
\end{subfigure}

\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_IS}
\caption{Ivanova-and-Stoyanov low sensitivity near $z=0$ second order all-pass
  filter section.} 
\label{fig:IS-second-order-all-pass-filter-section}
\vspace{1cm}
\end{subfigure}

\caption{Second order all-pass filter sections.}
\label{fig:Second-order-all-pass-filter-sections}
\end{figure}
\clearpage
\subsubsection{Maximum phase gradient of some second-order all-pass filter sections}
Figure~\ref{fig:dir2-all-pass-filter-phase-gradient-real-poles} shows the maximum
of the gradient of the phase plotted against the second-order direct-form
coefficients $b_{1}$ and $b_{2}$ in
Equation~\ref{eqn:Dir2-second-order-all-pass-filter-section} for real poles
plotted against the real pole radius.
Figure~\ref{fig:dir2-all-pass-filter-phase-gradient-complex-poles} shows
the maximum of the gradient of the phase plotted against the same coefficients
for complex conjugate poles plotted against pole angle. 

Figure~\ref{fig:GM2-all-pass-filter-phase-gradient-real-poles} shows the maximum
of the gradient of the phase plotted against the second-order
\emph{Gray} and \emph{Markel} and \emph{Ansari} and \emph{Liu} coefficients
$k_{1}$ and $k_{2}$ in
Equation~\ref{eqn:GM2-second-order-all-pass-filter-section} for real 
poles plotted against pole
radius. Figure~\ref{fig:GM2-all-pass-filter-phase-gradient-complex-poles} shows 
the maximum of the gradient of the phase plotted against the same coefficients 
for complex conjugate poles plotted against pole angle.

Figure~\ref{fig:MH2d-all-pass-filter-phase-gradient-real-poles} shows the maximum
of the gradient of the phase plotted against the \emph{Mitra} and \emph{Hirano}
type 2d second-order all-pass filter section coefficients $b_{1}$ and $b_{2}$ in
Equation~\ref{eqn:MH2-second-order-all-pass-filter-section} for real poles.
Figure~\ref{fig:MH2d-all-pass-filter-phase-gradient-complex-poles} shows
the maximum of the gradient of the phase plotted against the same coefficients
for complex conjugate poles. The phase gradient is not defined at a pole angle
of $\frac{\pi}{2}$. 

Figure~\ref{fig:MH3d-all-pass-filter-phase-gradient-real-poles} shows the maximum
of the gradient of the phase plotted against the \emph{Mitra} and \emph{Hirano}
type 3d second-order all-pass filter section coefficients $b_{1}$ and $b_{2}$ in
Equation~\ref{eqn:MH3-second-order-all-pass-filter-section} for real poles.
Figure~\ref{fig:MH3d-all-pass-filter-phase-gradient-complex-poles} shows
the maximum of the gradient of the phase plotted against the same coefficients
for complex conjugate poles.  

Figure~\ref{fig:LS2a-all-pass-filter-phase-gradient-real-poles} shows the maximum
of the gradient of the phase plotted against the coefficients $c_{1}$ and
$c_{2}$ of the second-order low-sensitivity near $z=1$ section of \emph{Stoyanov
  et al.} having the transfer function shown in
Equation~\ref{eqn:LS2a-second-order-all-pass-filter-section} for real poles.
Figure~\ref{fig:LS2a-all-pass-filter-phase-gradient-complex-poles} shows
the maximum of the gradient of the phase plotted against the same coefficients
for complex conjugate poles.  

Figure~\ref{fig:IS-all-pass-filter-phase-gradient-real-poles} shows the maximum
of the gradient of the phase plotted against the coefficients $d_{1}$ and
$d_{2}$ of the second-order low-sensitivity near $z=0$ section of \emph{Ivanova}
and \emph{Stoyanov} having the transfer function shown in
Equation~\ref{eqn:IS-second-order-all-pass-filter-section} for real poles.
Figure~\ref{fig:IS-all-pass-filter-phase-gradient-complex-poles} shows
the maximum of the gradient of the phase plotted against the same coefficients
for complex conjugate poles.  
\clearpage
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_dir2_real_pgrad}}
\caption{Maximum phase gradient plotted against pole radius of the second-order
  direct-form all-pass filter section with real poles.}
\label{fig:dir2-all-pass-filter-phase-gradient-real-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_dir2_complex_pgrad}}
\caption{Maximum phase gradient plotted against pole angle of the second-order
  direct-form all-pass filter section with complex conjugate poles.}
\label{fig:dir2-all-pass-filter-phase-gradient-complex-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_GM2_real_pgrad}}
\caption{Maximum phase gradient plotted against pole radius of the second-order
  Gray-and-Markel and Ansari-and-Liu all-pass filter section with real poles.}
\label{fig:GM2-all-pass-filter-phase-gradient-real-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_GM2_complex_pgrad}}
\caption{Maximum phase gradient plotted against pole angle of the second-order
  Gray-and-Markel and Ansari-and-Liu all-pass filter section with complex
  conjugate poles.}
\label{fig:GM2-all-pass-filter-phase-gradient-complex-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_MH2d_real_pgrad}}
\caption{Maximum phase gradient plotted against pole radius of the second-order
  Mitra-and-Hirano type 2d all-pass filter section with real poles.}
\label{fig:MH2d-all-pass-filter-phase-gradient-real-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_MH2d_complex_pgrad}}
\caption{Maximum phase gradient plotted against pole angle of the second-order
  Mitra-and-Hirano type 2d all-pass filter section with complex conjugate poles.}
\label{fig:MH2d-all-pass-filter-phase-gradient-complex-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_MH3d_real_pgrad}}
\caption{Maximum phase gradient plotted against pole radius of the second-order
  Mitra-and-Hirano type 3d all-pass filter section with real poles.}
\label{fig:MH3d-all-pass-filter-phase-gradient-real-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_MH3d_complex_pgrad}}
\caption{Maximum phase gradient plotted against pole angle of the second-order
  Mitra-and-Hirano type 3d all-pass filter section with complex conjugate poles.}
\label{fig:MH3d-all-pass-filter-phase-gradient-complex-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_LS2a_real_pgrad}}
\caption{Maximum phase gradient plotted against pole radius of the second-order
  Stoyanov low-sensitivity mear $z=1$ all-pass filter section with real poles.}
\label{fig:LS2a-all-pass-filter-phase-gradient-real-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_LS2a_complex_pgrad}}
\caption{Maximum phase gradient plotted against pole angle of the second-order
  Stoyanov low-sensitivity near $z=1$ all-pass filter section with complex
  conjugate poles.}
\label{fig:LS2a-all-pass-filter-phase-gradient-complex-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_IS_real_pgrad}}
\caption{Maximum phase gradient plotted against pole radius of the second-order
  Ivanova and Stoyanov low-sensitivity near $z=0$ all-pass filter section with
  real poles.}
\label{fig:IS-all-pass-filter-phase-gradient-real-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_IS_complex_pgrad}}
\caption{Maximum phase gradient plotted against pole angle of the second-order
  Ivanova and Stoyanov low-sensitivity near $z=0$ all-pass filter section with
  complex conjugate poles.}
\label{fig:IS-all-pass-filter-phase-gradient-complex-poles}
\end{figure}
\clearpage
\subsubsection{Noise gain of some second-order all-pass filter sections}
As for the first-order direct-form section the noise gain of the scaled
second-order direct-form section can be estimated with a slowed and retimed
realisation. 

Figure~\ref{fig:dir2-all-pass-filter-noise-gain-real-poles} shows the
noise gain of a scaled realisation with real poles of
Equation~\ref{eqn:Dir2-second-order-all-pass-filter-section}. Figure~\ref{fig:dir2-all-pass-filter-noise-gain-complex-poles}
shows  the noise gain of a scaled realisation with complex conjugate poles.  

As for the second-order direct-form section the noise gain of the scaled
second-order \emph{Gray} and \emph{Markel} section can be estimated with a slowed
and retimed realisation. As for the first-order \emph{Gray} and \emph{Markel}
section, the $\epsilon$ coefficients do not alter the transfer function or noise
gain but must be selected for effective internal state scaling in a fixed-point
implementation. Figure~\ref{fig:GM2-all-pass-filter-noise-gain-real-poles} shows
the noise gain of a scaled realisation with real poles.
Figure~\ref{fig:GM2-all-pass-filter-noise-gain-complex-poles} shows 
the noise gain of a scaled realisation with complex conjugate poles.  

The noise gain of the scaled second-order \emph{Ansari} and \emph{Liu} section
can be estimated with a slowed and retimed realisation. 
Figure~\ref{fig:AL7c-all-pass-filter-noise-gain-real-poles} shows the
noise gain of a scaled realisation with real poles.
Figure~\ref{fig:AL7c-all-pass-filter-noise-gain-complex-poles} shows 
the noise gain of a scaled realisation with complex conjugate poles.  

The noise gain of the scaled second-order \emph{Mitra} and \emph{Hirano} type 2d
section can be estimated with the retimed realisation shown in
Figure~\ref{fig:Retimed-MH2d-second-order-all-pass-filter-section}. The section
is retimed by adding a $z^{-1} $delay at the output and then redistributing
the delay ``backwards'' until the output of the $b_{1}$ multiplier is registered.

\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{allpass_MH2d_retimed}
\caption{Retimed Mitra-and-Hirano type 2d second-order direct form all-pass
  filter section.}
\label{fig:Retimed-MH2d-second-order-all-pass-filter-section}
\end{figure}

Figure~\ref{fig:MH2d-all-pass-filter-noise-gain-real-poles} shows the
noise gain of a scaled realisation with real poles.
Figure~\ref{fig:MH2d-all-pass-filter-noise-gain-complex-poles} shows 
the noise gain of a scaled realisation with complex conjugate poles.  

The noise gain of the scaled second-order \emph{Mitra} and \emph{Hirano} type 3d
section can be estimated without slowing or retiming the retimed realisation.
Figure~\ref{fig:MH3d-all-pass-filter-noise-gain-real-poles} shows the
noise gain of a scaled realisation with real poles.
Figure~\ref{fig:MH3d-all-pass-filter-noise-gain-complex-poles} shows 
the noise gain of a scaled realisation with complex conjugate poles.  

The round-off noise of the second-order Stoyanov low-sensitivity section can be
estimated without slowing and retiming the realisation. 
Figure~\ref{fig:LS2a-all-pass-filter-noise-gain-real-poles} shows the
noise gain of a scaled realisation with real poles. 
Figure~\ref{fig:LS2a-all-pass-filter-noise-gain-complex-poles} shows 
the noise gain of a scaled realisation with complex conjugate poles.  

The round-off noise of the second-order \emph{Ivanova} and \emph{Stoyanov}
low-sensitivity near $z=0$ section can be estimated with a slowed and retimed
realisation. Figure~\ref{fig:IS-all-pass-filter-noise-gain-real-poles} shows
the noise gain of a scaled realisation with real poles. 
Figure~\ref{fig:IS-all-pass-filter-noise-gain-complex-poles} shows 
the noise gain of a scaled realisation with complex conjugate poles.  
\clearpage
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_dir2_retimed_real_ng}}
\caption{Noise gain of the scaled and retimed second-order direct-form all-pass
  filter section with real poles.}
\label{fig:dir2-all-pass-filter-noise-gain-real-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_dir2_retimed_complex_ng}}
\caption{Noise gain of the scaled and retimed second-order direct-form
  all-pass filter section with complex conjugate poles.}
\label{fig:dir2-all-pass-filter-noise-gain-complex-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_GM2_retimed_real_ng}}
\caption{Noise gain of the scaled and retimed second-order Gray-and-Markel
  all-pass filter section with real poles.}
\label{fig:GM2-all-pass-filter-noise-gain-real-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_GM2_retimed_complex_ng}}
\caption{Noise gain of the scaled and retimed second-order Gray-and-Markel
  all-pass filter section with complex conjugate poles.}
\label{fig:GM2-all-pass-filter-noise-gain-complex-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_AL7c_retimed_real_ng}}
\caption{Noise gain of the scaled and retimed second-order Ansari-and-Liu
  all-pass filter section with real poles.}
\label{fig:AL7c-all-pass-filter-noise-gain-real-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_AL7c_retimed_complex_ng}}
\caption{Noise gain of the scaled and retimed second-order Ansari-and-Liu
  all-pass filter section with complex conjugate poles.}
\label{fig:AL7c-all-pass-filter-noise-gain-complex-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_MH2d_retimed_real_ng}}
\caption{Noise gain of the scaled and retimed second-order Mitra-and-Hirano
  type 2d all-pass filter section with real poles.}
\label{fig:MH2d-all-pass-filter-noise-gain-real-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_MH2d_retimed_complex_ng}}
\caption{Noise gain of the scaled and retimed second-order Mitra-and-Hirano
  type 2d all-pass filter section with complex conjugate poles.}
\label{fig:MH2d-all-pass-filter-noise-gain-complex-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_MH3d_real_ng}}
\caption{Noise gain of the scaled second-order Mitra-and-Hirano
  type 3d all-pass filter section with real poles.}
\label{fig:MH3d-all-pass-filter-noise-gain-real-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_MH3d_complex_ng}}
\caption{Noise gain of the scaled second-order Mitra-and-Hirano
  type 3d all-pass filter section with complex conjugate poles.}
\label{fig:MH3d-all-pass-filter-noise-gain-complex-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_LS2a_real_ng}}
\caption{Noise gain of the scaled second-order Stoyanov low-sensitivity
  near $z=1$ all-pass filter section with real poles.}
\label{fig:LS2a-all-pass-filter-noise-gain-real-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_LS2a_complex_ng}}
\caption{Noise gain of the scaled second-order Stoyanov low-sensitivity
  near $z=1$ all-pass filter section with complex conjugate poles.}
\label{fig:LS2a-all-pass-filter-noise-gain-complex-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_IS_retimed_real_ng}}
\caption{Noise gain of the scaled and retimed second-order Ivanova-and-Stoyanov
  low-sensitivity near $z=0$ all-pass filter section with real poles.}
\label{fig:IS-all-pass-filter-noise-gain-real-poles}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass_filter_test_IS_retimed_complex_ng}}
\caption{Noise gain of the scaled and retimed second-order Ivanova-and Stoyanov
  low-sensitivity near $z=0$ all-pass filter section with complex conjugate
  poles.}
\label{fig:IS-all-pass-filter-noise-gain-complex-poles}
\end{figure}

\chapter{\label{sec:Schur-decomposition}Filter synthesis by the Schur decomposition}
This chapter follows
\emph{Parhi}~\cite[Chapter 12]{Parhi_VLSIDigitalSignalProcessingSystems}.
\section{The Schur algorithm}
From \emph{Parhi}~\cite[Chapter 12]{Parhi_VLSIDigitalSignalProcessingSystems}:
\begin{quotation}
The Schur algorithm was originally used to test if a power series
is analytic and bounded in the unit disk. If an $N$-th order polynomial
$\Phi_{N}\left(z\right)$ has all zeros inside the unit circle then
$N+1$ polynomials
\begin{align*}
\left\{ \Phi_{i}\left(z\right),i=N,N-1,\ldots,0\right\} 
\end{align*}
can be generated by the Schur algorithm. One of the most important
properties of the Schur algorithm is that these $N+1$ polynomials
form an orthonormal basis that can be used to expand any $N$-th order
polynomial.
\end{quotation}
In this section, the inner product formulation used to demonstrate orthonormality
is based on the calculation of the signal power at an internal node
of a digital filter. Appendix~\ref{app:Cauchys-Integral-Formula}
contains a review of the complex variables theory required in this
section.
\subsection{Computation of Schur polynomials}
The denominator of a stable IIR filter is a Schur polynomial because
it has no zeros on or outside the unit circle. Define the $N$-th order
denominator polynomial as:
\begin{align*}
D_{N}\left(z\right)=\sum_{i=0}^{N}d_{i}z^{i}
\end{align*}
Initialise the $N$-th order Schur polynomial $\Phi_{N}\left(z\right)$
as:
\begin{align*}
\Phi_{N}\left(z\right)=D_{N}\left(z\right)=\sum_{i=0}^{N}\phi_{i}z^{i}
\end{align*}
From $\Phi_{N}\left(z\right)$ form the polynomial $\Phi_{N-1}\left(z\right)$ by:
\begin{align*}
\Phi_{N-1}\left(z\right) & = \frac{z^{-1}\left\{ \phi_{N}\Phi_{N}\left(z\right)-
\phi_{0}\tilde{\Phi}_{N}\left(z\right)\right\}}{\sqrt{\phi_{N}^{2}-
\phi_{0}^{2}}}\\
 & = \frac{z^{-1}\left\{ \Phi_{N}\left(z\right)-
 k_{N}\tilde{\Phi}_{N}\left(z\right)\right\} }{\sqrt{1-k_{N}^{2}}}
\end{align*}
where $k_{N}=\phi_{0}/\phi_{N}$ and $\tilde{\Phi}_{N}\left(z\right)$
is the reverse polynomial of $\Phi_{N}\left(z\right)$ defined by:
\begin{align*}
\tilde{\Phi}_{N}\left(z\right)=z^{N}\Phi_{N}\left(z^{-1}\right)
\end{align*}
The degree of $\Phi_{N-1}\left(z\right)$ is $1$ less than that of
$\Phi_{N}\left(z\right)$ since, by a change of variables the numerator
is:
\begin{align*}
 z^{-1}\left\{ \phi_{N}\Phi_{N}\left(z\right)-\phi_{0}\tilde{\Phi}_{N}\left(z\right)\right\}
& = z^{-1}\sum^{N}_{i=0}\left\{\phi_{N}\phi_{i}z^{i}-\phi_{0}\phi_{N-i}z^{i}\right\}\\
& = \sum^{N}_{i=1}\left\{\phi_{N}\phi_{i}-\phi_{0}\phi_{N-i}\right\}z^{i-1}\\
\end{align*}
For $\Phi_{N}\left(z\right)$ to be a Schur polynomial, $\left|k_{i}\right|<1$
for each polynomial in the set $\left\{ \Phi_{N}\left(z\right),\Phi_{N-1}\left(z\right),\ldots,\Phi_{1}\left(z\right)\right\} $. 
\emph{Parhi}~\cite[Equation 12.6]{Parhi_VLSIDigitalSignalProcessingSystems}
 points out that by inspection of $\Phi_{N-1}\left(z\right)$, the coefficients
of increasing powers of $z$ in $\Phi_{N-1}\left(z\right)$ are 
$\frac{1}{\sqrt{\phi^{2}_{N}-\phi^{2}_{0}}}$ times the $N$ determinants of the
$2\times{}2$ submatrices formed by the first column and each succeeding column
in the matrix:
\begin{align*}
\left[
\begin{array}{ccccccc}
\phi_{N} & \phi_{N-1} & \phi_{N-2} & \hdots & \phi_{2} & \phi_{1} & \phi_{0} \\
\phi_{0} & \phi_{1} & \phi_{2} & \hdots & \phi_{N-2} & \phi_{N-1} & \phi_{N} \\
\end{array}
\right]
\end{align*}
The Schur decomposition of a polynomial is implemented in the Octave function
\emph{schurdecomp}. 
The C++ file \emph{schurdecomp.cc} implements \emph{schurdecomp} as an
\emph{oct}-file using the \emph{MPFR} abitrary precision floating point
library~\cite{Fousse_MPFR, GNU_GMP} written by
\emph{Fousse et al.}~\cite{Fousse:2007:MMB:1236463.1236468}. The mantissa
precision is set to $256$ bits.

\subsection{Orthonormality of Schur Polynomials}
\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_H_filter}
\caption{A filter structure implementing
  $H\left(z\right)=\frac{N_{N}\left(z\right)}{P_{N}\left(z\right)}$ (after 
\emph{Parhi}~\cite[Fig. 12.1]{Parhi_VLSIDigitalSignalProcessingSystems}).}
\label{fig:A-filter-structure}
\end{figure}

The filter structure shown in Figure~\ref{fig:A-filter-structure} implements a
real causal stable transfer function
$H\left(z\right)=N_{N}\left(z\right)/D_{N}\left(z\right)$. The transfer function
from the input node to node \emph{p} is $P\left(z\right)/D_{N}\left(z\right)$. If
the input signal is modeled as random and white with unit power, then the
average power at node \emph{p} is:
\begin{align*}
P_{p} & = \frac{1}{2\pi}\intop_{-\pi}^{\pi}\left|\frac{P\left(e^{\imath\omega}\right)}{D_{N}\left(e^{\imath\omega}\right)}\right|^{2}d\omega\\
 & = \frac{1}{2\pi}\intop_{-\pi}^{\pi}\frac{P\left(e^{\imath\omega}\right)P\left(e^{-\imath\omega}\right)}{D_{N}\left(e^{\imath\omega}\right)D_{N}\left(e^{-\imath\omega}\right)}d\omega
\end{align*}
On the unit circle, $z=e^{\imath\omega}$, so in the z-domain:
\begin{align*}
P_{p} & = \frac{1}{2\pi \imath}\ointctrclockwise_{C}\frac{P\left(z\right)P\left(z^{-1}\right)z^{-1}}{D_{N}\left(z\right)D_{N}\left(z^{-1}\right)}dz
\end{align*}
Where the contour is taken in the anti-clockwise direction about the
origin. Recall that all the zeros of $D_{N}\left(z\right)$ are inside
the unit circle, $C$. Now define the inner product of two internal polynomials
$P\left(z\right)$ and $Q\left(z\right)$ as:
\begin{align*}
\left\langle P\left(z\right),Q\left(z\right)\right\rangle  & = \frac{1}{2\pi \imath}\ointctrclockwise_{C}\frac{P\left(z\right)Q\left(z^{-1}\right)z^{-1}}{D_{N}\left(z\right)D_{N}\left(z^{-1}\right)}dz
\end{align*}
so that $P_{p}=\left\langle P\left(z\right),P\left(z\right)\right\rangle $.
This is a valid inner product definition because it has the following
three properties:
\begin{enumerate}
\item Conjugate symmetry: 
\begin{align*}
\left\langle P\left(z\right),Q\left(z\right)\right\rangle  & = \left\langle Q\left(z\right),P\left(z\right)\right\rangle ^{\ast}
\end{align*}
where $\ast$ represents the complex conjugate transpose. This can
be verified by a change of variables. The coefficients of $P\left(z\right)$
and $Q\left(z\right)$ are usually real.
\item Linearity: for any real constants $\alpha$, $\beta$ and $\gamma$:
\begin{align*}
\left\langle \alpha P\left(z\right),\beta Q\left(z\right) +
             \gamma R\left(z\right)\right\rangle  
& = \alpha\beta\left\langle P\left(z\right),Q\left(z\right)\right\rangle + 
    \alpha\gamma\left\langle P\left(z\right),R\left(z\right)\right\rangle 
\end{align*}

\item Positive norm:
\begin{align*}
\left\langle P\left(z\right),Q\left(z\right)\right\rangle  & \geq 0
\end{align*}
 with equality if-and-only-if $P\left(z\right)=0$.
\end{enumerate}
Some identities:
\begin{align*}
\left\langle \Phi_{N}\left(z\right),z^{i}\right\rangle  & = \begin{cases}
\frac{1}{\phi_{N}} & i=N\\
0 & 0\leq i\leq N-1
\end{cases}
\end{align*}
\emph{Proof:}~ Recall that 
$\tilde{\Phi}_{N}\left(z\right)=z^{N}\Phi_{N}\left(z^{-1}\right)$. Then
\begin{align*}
\left\langle \Phi_{N}\left(z\right),z^{i}\right\rangle  & = \frac{1}{2\pi\imath}
\ointctrclockwise_{C}\frac{\Phi_{N}\left(z\right)z^{-i}}{\Phi_{N}\left(z\right)\Phi_{N}\left(z^{-1}\right)}dz\\
 & = \frac{1}{2\pi \imath}\ointctrclockwise_{C}\frac{z^{N-i-1}}{\tilde{\Phi}_{N}\left(z\right)}dz\\
 & = \begin{cases}
\frac{1}{\Phi_{N}} & i=N\\
0 & otherwise
\end{cases}
\end{align*}
The reverse Schur polynomial has all its roots outside the unit circle
so the integrand is analytic within the unit circle if $0\leq i<N$
and Cauchy's Integral Theorem applies. The result for $i=N$ follows
from Cauchy's Integral Formula.\bigskip{}
Similarly:
\begin{align*}
\left\langle \tilde{\Phi}_{N}\left(z\right),z^{i}\right\rangle  & = \begin{cases}
\frac{1}{\phi_{N}} & i=0\\
0 & i\geq1
\end{cases}
\end{align*}
If 
\begin{align*}
P\left(z\right) & = \sum_{i=0}^{N}p_{i}z^{i}
\end{align*}
then:
\begin{align*}
\left\langle \Phi_{N}\left(z\right),P\left(z\right)\right\rangle  & = \frac{p_{N}}{\phi_{N}}\\
\left\langle \tilde{\Phi}_{N}\left(z\right),P\left(z\right)\right\rangle  & = \frac{p_{0}}{\phi_{N}}
\end{align*}
Also:
\begin{align*}
\left\langle \Phi_{N}\left(z\right),\Phi_{N}\left(z\right)\right\rangle  & = 1\\
\left\langle \tilde{\Phi}_{N}\left(z\right),\tilde{\Phi}_{N}\left(z\right)\right\rangle  & = 1\\
\left\langle \Phi_{N}\left(z\right),\tilde{\Phi}_{N}\left(z\right)\right\rangle  & = \frac{\phi_{0}}{\phi_{N}}\\
\left\langle z^{-j}\Phi_{N}\left(z\right),z^{i}\right\rangle  & = \left\langle \Phi_{N}\left(z\right),z^{i+j}\right\rangle \\
\left\langle z^{-j}\tilde{\Phi}_{N}\left(z\right),z^{i}\right\rangle  & = \left\langle \tilde{\Phi}_{N}\left(z\right),z^{i+j}\right\rangle 
\end{align*}
The Schur polynomials satisfy the following orthonormality condition:
\begin{align*}
\left\langle \Phi_{i}\left(z\right),\Phi_{j}\left(z\right)\right\rangle  & = \begin{cases}
1 & i=j\\
0 & i\neq j
\end{cases}
\end{align*}
where $0\leq i,j\leq N$. See the proof in 
\emph{Parhi}~\cite[Appendix D]{Parhi_VLSIDigitalSignalProcessingSystems}.
The reverse Schur polynomials are not orthonormal. However:
\begin{align*}
\left\langle \tilde{\Phi}_{i}\left(z\right),z^{i-j}\tilde{\Phi}_{j}\left(z\right)\right\rangle  & = \left\langle z^{j-i}\tilde{\Phi}_{j}\left(z^{-1}\right),\tilde{\Phi}_{i}\left(z^{-1}\right)\right\rangle \\
 & = \left\langle z^{j}\tilde{\Phi}_{j}\left(z^{-1}\right),z^{i}\tilde{\Phi}_{i}\left(z^{-1}\right)\right\rangle \\
 & = \left\langle \Phi_{j}\left(z\right),\Phi_{i}\left(z\right)\right\rangle \\
 & = 0
\end{align*}
where $0\leq j\leq i\leq N$. Therefore the polynomials
\begin{align*}
\left\{ \tilde{\Phi}_{N}\left(z\right),z\tilde{\Phi}_{N-1}\left(z\right),z^{2}\tilde{\Phi}_{N-2}\left(z\right),\ldots,z^{N}\tilde{\Phi}_{0}\left(z\right)\right\}
\end{align*}
also form an orthonormal basis. This basis can be used to synthesise
an alternative lattice structure. \emph{Parhi}~\cite[Section
12.7.2]{Parhi_VLSIDigitalSignalProcessingSystems} 
shows that the reverse polynomial structure has inferior round off
noise performance when compared with the forward polynomial structure
described later in this summary.
\subsection{Polynomial Expansion Algorithm}
The Schur polynomials in the set 
$\left\{ \Phi_{N}\left(z\right),\ldots,\Phi_{0}\left(z\right)\right\}$
form an orthonormal basis. Therefore any $N$-th order polynomial
$N_{N}\left(z\right)$ can be expanded as
\begin{align*}
N_{N}\left(z\right) & = \sum_{i=0}^{N}c_{i}\Phi_{i}\left(z\right)
\end{align*}
Algorithm~\ref{alg:Polynomial-Expansion} shows the Schur expansion of an
arbitrary polynomial in a Schur basis.
 
\begin{algorithm}[!ht]
For any polynomial $N_{m}\left(z\right)$ of degree $m,\:(0<m\leq N)$:
\begin{algorithmic}
\State $Q\left(z\right)=N_{m}\left(z\right)$ 
\State $c_{i}=0$, for $m<i\leq N$
\For {$i=m,m-1,\hdots,0$}
  \State $c_{i}=\frac{\tilde{Q}(0)}{\tilde{\Phi}_{i}(0)}$
  \State $Q\left(z\right)=Q\left(z\right)-c_{i}\Phi_{i}\left(z\right)$
\EndFor
\end{algorithmic}
$\tilde{Q}\left(z\right)$ and $\tilde{\Phi}_{i}\left(z\right)$ are
the reverse polynomials of $Q\left(z\right)$ and $\Phi_{i}\left(z\right)$.
\caption{Schur polynomial expansion (see 
\emph{Parhi}~\cite[Section 12.2.3]{Parhi_VLSIDigitalSignalProcessingSystems}).}
\label{alg:Polynomial-Expansion}
\end{algorithm}

For lattice filter implementations of a rational transfer function, the
denominator is synthesised using the Schur algorithm and the numerator is 
synthesised using the polynomial expansion algorithm with the orthonormal
functions obtained from the denominator. The Schur expansion of a polynomial
is implemented in the Octave function \emph{schurexpand}. The C++ 
\emph{oct}-file \emph{schurexpand.cc} implements \emph{schurexpand} with the
\emph{MPFR} abitrary precision floating point
library written by \emph{Fousse et
  al.}~\cite{Fousse:2007:MMB:1236463.1236468}. The mantissa precision is set to
$256$ bits.

\subsection{Power calculation using the Schur algorithm}
For the lattice filter structure in Figure~\ref{fig:A-filter-structure},
when the input signal is random and white with unit power then the
average power at internal node $p$ is
\begin{align*}
P_{p} & = \left\langle P\left(z\right),P\left(z\right)\right\rangle 
\end{align*}
Since the denominator $D_{N}\left(z\right)$ is a Schur polynomial,
\begin{align*}
P\left(z\right) & = \sum_{i}c_{i}\Phi_{i}\left(z\right)
\end{align*}
and, since the Schur algorithm inner product is linear and orthonormal
\begin{align*}
P_{p} & = \sum_{i}c_{i}^{2}
\end{align*}
\section{Derivation of Digital Lattice Filters}
The Schur polynomials are obtained by the degree reduction procedure
\begin{align}
\Phi_{i-1}\left(z\right) & = \frac{z^{-1}\left\{ \Phi_{i}\left(z\right)-k_{i}\tilde{\Phi}_{i}\left(z\right)\right\} }{s_{i}}\label{eq:SchurDegreeReduction}
\end{align}
where $s_{i}$ is a scaling factor and $k_{i}=\Phi_{i}\left(0\right)/\tilde{\Phi}_{i}\left(0\right)$. Note that the $s_{i}$ cancel out when calculating $k_{i}$ so the
$k_{i}$ are the same regardless of the choice of $s_{i}$.
If $s_{i}=\sqrt{1-k_{i}^{2}}$ then the Schur polynomials are orthonormal.
In the following the i-th order Schur polynomial with this choice
of $s_{i}$ is denoted $\Phi_{i}\left(z\right)$; if $s_{i}=1-\epsilon_{i}k_{i}$
is chosen, by $\Lambda_{i}$, and if $s_{i}=1-k_{i}^{2}$ is chosen,
by $\Psi_{i}\left(z\right)$. 

Note that since 
\begin{align*}
\tilde{\Phi}_{i-1}\left(z\right) & = z^{i-1}\Phi_{i-1}\left(z^{-1}\right)\\
 & = \frac{\tilde{\Phi}_{i}\left(z\right)-k_{i}\Phi_{i}\left(z\right)}{s_{i}}
\end{align*}
by rearranging
\begin{align*}
\Phi_{i}\left(z\right) & = \frac{s_{i}}{1-k_{i}^{2}}\left\{ z\Phi_{i-1}\left(z\right)+k_{i}\tilde{\Phi}_{i-1}\left(z\right)\right\} \\
\tilde{\Phi}_{i}\left(z\right) & = \frac{s_{i}}{1-k_{i}^{2}}\left\{ zk_{i}\Phi_{i-1}\left(z\right)+\tilde{\Phi}_{i-1}\left(z\right)\right\} 
\end{align*}
\subsection{Derivation of FIR, All-Pole and All-Pass Lattice Filters}
Initialise an N-th order Schur polynomial as
\begin{align*}
\Psi_{N}\left(z\right) & = \sum_{i=0}^{N}\psi_{i}z^{i}
\end{align*}
Form $\Psi_{N-1}\left(z\right)$ by degree reduction
\begin{align}
\Psi_{N-1}\left(z\right) & = \frac{z^{-1}\left\{ \Psi_{N}\left(z\right)-k_{N}\tilde{\Psi}_{N}\left(z\right)\right\} }{1-k_{N}^{2}}\label{eq:PsiN_1}
\end{align}
The reverse Schur polynomial is
\begin{align}
\tilde{\Psi}_{N-1}\left(z\right) & = z^{N-1}\Psi_{N-1}(z^{-1})\\
 & = \frac{\tilde{\Psi}_{N}\left(z\right)-k_{N}\Psi_{N}\left(z\right)}{1-k_{N}^{2}}\label{eq:PsiN_1Star}
\end{align}
so
\begin{align}
\tilde{\Psi}_{N}\left(z\right) & = \left(1-k_{N}^{2}\right)\tilde{\Psi}_{N-1}\left(z\right)+k_{N}\Psi_{N}\left(z\right)\nonumber \\
 & = \tilde{\Psi}_{N-1}\left(z\right)+k_{N}\left\{ \Psi_{N}-k_{N}\tilde{\Psi}_{N-1}\left(z\right)\right\} \label{eq:PsiStarN}
\end{align}
Substituting Equation~\ref{eq:PsiStarN} into Equation~\ref{eq:PsiN_1}
\begin{align*}
\Psi_{N-1}\left(z\right) & = z^{-1}\left\{ \Psi_{N}\left(z\right)-k_{N}\tilde{\Psi}_{N-1}\left(z\right)\right\} 
\end{align*}
so
\begin{align}
\Psi_{N}\left(z\right) & = z\Psi_{N-1}\left(z\right)+k_{N}\tilde{\Psi}_{N-1}\left(z\right)\label{eq:FIRN}
\end{align}
and, applying the definition of the reverse polynomial
\begin{align}
\tilde{\Psi}_{N}\left(z\right) & = zk_{N}\Psi_{N-1}\left(z\right)+\tilde{\Psi}_{N-1}\left(z\right)\label{eq:FIRNstar}
\end{align}
Equations~\ref{eq:FIRN}~and~\ref{eq:FIRNstar} represent the FIR filter
shown in Figure~\ref{fig:FIR-filter-structure}. This structure
has twice the number of multipliers of the direct form structure.
However, the structure is useful for implementing adaptive filters.
\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_FIR_filter}
\caption{FIR filter structure (after 
\emph{Parhi}~\cite[Fig. 12.8]{Parhi_VLSIDigitalSignalProcessingSystems}).}
\label{fig:FIR-filter-structure}
\end{figure}
Equations~\ref{eq:PsiN_1}~and~\ref{eq:PsiN_1Star} represent the IIR
filter section shown in Figure~\ref{fig:All-pass-and-all-pole}.
This structure implements both an all-pole filter $\Psi_{0}\left(z\right)/\Psi_{N}\left(z\right)$
and an all-pass filter $\tilde{\Psi}_{N}\left(z\right)/\Psi_{N}\left(z\right)$.
\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_AllPole_filter}
\caption{All-pass and all-pole filter structure (after 
\emph{Parhi}~\cite[Fig. 12.5]{Parhi_VLSIDigitalSignalProcessingSystems}).}
\label{fig:All-pass-and-all-pole}
\end{figure}
The relation between $\Phi_{i}\left(z\right)$ and $\Psi_{i}\left(z\right)$
is 
\begin{align*}
\Psi_{N}\left(z\right) & = \Phi_{N}\left(z\right)\\
\Psi_{i}\left(z\right) & = \frac{\Phi_{i}\left(z\right)}{\sqrt{\left(1-k_{N}^{2}\right)\left(1-k_{N-1}^{2}\right)\cdots\left(1-k_{i+1}^{2}\right)}}\,,\quad0\leq i < N
\end{align*}
Note that $\Phi_{i}\left(z\right)$ and $\Psi_{i}\left(z\right)$
differ only by a scale factor so the $k$-parameters are unchanged
\begin{align*}
k_{i}=\frac{\Psi_{i}\left(0\right)}{\tilde{\Psi}_{i}\left(0\right)}
     =\frac{\Phi_{i}\left(0\right)}{\tilde{\Phi}_{i}\left(0\right)}
\end{align*}
 Also the $\Psi_{i}$ are orthogonal but not orthonormal since
\begin{align*}
\left\langle \Psi_{i}\left(z\right),\Psi_{i}\left(z\right)\right\rangle  & = \left\langle \tilde{\Psi}_{i}\left(z\right),\tilde{\Psi}_{i}\left(z\right)\right\rangle \\
 & = \frac{1}{\left(1-k_{N}^{2}\right)\left(1-k_{N-1}^{2}\right)\cdots\left(1-k_{i+1}^{2}\right)}
\end{align*}
Clearly, the $\left\langle \Psi_{i}\left(z\right),\Psi_{i}\left(z\right)\right\rangle $
increase as $i$ decreases since $k_{i}<1$. When most of the $k$-parameters
are nearly one, the difference of powers among the nodes in the filter
is very large and the input needs to be scaled down by a large factor
to prevent overflow at a critical node. As a result the effect of
roundoff noise increases significantly.
\section{Derivation of the One-Multiplier IIR Lattice Filter}
If $s_{i}=1-\epsilon_{i}k_{i}$ in Equation~\ref{eq:SchurDegreeReduction}
then 
\begin{align*}
\Lambda_{i-1}\left(z\right) & = \frac{z^{-1}\left\{ \Lambda_{i}\left(z\right)-k_{i}\tilde{\Lambda}_{i}\left(z\right)\right\} }{1-\epsilon_{i}k_{i}}
\end{align*}
where $\epsilon_{i}=\pm1$ is a sign parameter. For an $N$-th order
IIR transfer function, $H\left(z\right)=N_{N}\left(z\right)/D_{N}\left(z\right)$,
initialise $\Lambda_{N}\left(z\right)=D_{N}\left(z\right)$. Then
\begin{align*}
\Lambda_{N-1}\left(z\right) & = \frac{z^{-1}\left\{ \Lambda_{N}\left(z\right)-k_{N}\tilde{\Lambda}_{N}\left(z\right)\right\} }{1-\epsilon_{N}k_{N}}\\
\tilde{\Lambda}_{N-1}\left(z\right) & = \frac{\tilde{\Lambda}_{N}\left(z\right)-k_{N}\Lambda_{N}\left(z\right)}{1-\epsilon_{N}k_{N}}
\end{align*}
where $k_{i}=\Lambda_{i}\left(0\right)/\tilde{\Lambda}_{i}\left(0\right)$.
Rearranging
\begin{align}
\tilde{\Lambda}_{N}\left(z\right) & = k_{N}\Lambda_{N}\left(z\right)+\left(1-\epsilon_{N}k_{N}\right)\tilde{\Lambda}_{N-1}\left(z\right)\label{eq:OneMultSynthesisStar}\\
\Lambda_{N-1}\left(z\right) & = z^{-1}\left\{ \left(1+\epsilon_{N}k_{N}\right)\Lambda_{N}-k_{N}\tilde{\Lambda}_{N-1}\left(z\right)\right\} \label{eq:OneMultSynthesis}
\end{align}
By repeated application for $i=N,N-1,\cdots1$, the denominator $D_{N}\left(z\right)$
is synthesised. The relation between $\Lambda_{i}\left(z\right)$
and $\Phi_{i}\left(z\right)$ is
\begin{align*}
\Lambda_{N}\left(z\right) & = \Phi_{N}\left(z\right)\\
\Lambda_{i}\left(z\right) & = \Phi_{i}\left(z\right)\sqrt{\frac{\left(1+\epsilon_{N}k_{N}\right)\left(1+\epsilon_{N-1}k_{N-1}\right)\cdots\left(1+\epsilon_{i+1}k_{i+1}\right)}{\left(1-\epsilon_{N}k_{N}\right)\left(1-\epsilon_{N-1}k_{N-1}\right)\cdots\left(1-\epsilon_{i+1}k_{i+1}\right)}}
\end{align*}
where $0\leq i<N$. Note that $\Phi_{i}\left(z\right)$ and $\Lambda_{i}\left(z\right)$
differ only by a scale factor so the $k$-parameters are unchanged
\begin{align*}
k_{i}=\Lambda_{i}\left(0\right)/\tilde{\Lambda}_{i}\left(0\right)=\Phi_{i}\left(0\right)/\tilde{\Phi}_{i}\left(0\right)
\end{align*}
 Also the $\Lambda_{i}$ are orthogonal but not orthonormal since
\begin{align}
\left\langle \Lambda_{i}\left(z\right),\Lambda_{i}\left(z\right)\right\rangle  & = \left\langle \tilde{\Lambda}_{i}\left(z\right),\tilde{\Lambda}_{i}\left(z\right)\right\rangle \label{eq:OneMultPowerStar}\\
 & = \frac{\left(1+\epsilon_{N}k_{N}\right)\left(1+\epsilon_{N-1}k_{N-1}\right)\cdots\left(1+\epsilon_{i+1}k_{i+1}\right)}{\left(1-\epsilon_{N}k_{N}\right)\left(1-\epsilon_{N-1}k_{N-1}\right)\cdots\left(1-\epsilon_{i+1}k_{i+1}\right)}\label{eq:OneMultAmplitude}
\end{align}
The magnitude of $\left\langle \Lambda_{i}\left(z\right),\Lambda_{i}\left(z\right)\right\rangle $
can be adjusted by choosing the sign parameters so that the one-multiplier
lattice filter can avoid the severe input scaling of the basic lattice
filter and have better round-off noise behaviour. One criterion for
choosing the sign parameters is to require that the node associated
with the largest $k$-parameter in magnitude have the largest 
amplitude\cite{GrayMarkel_DigitalLatticeAndLadderFilterSynthesis}.
The sign parameters are found recursively by requiring that the amplitudes
at other nodes be as large as possible without exceeding the maximum
value. If the maximum occurs for $k_{l}$ then the recursion proceeds
for $m=l-1,l-2,\ldots,0$ and again for $m=l+1,l+2,\ldots,N$. The
recursion is simple because:
\begin{align*}
\frac{\left\langle \Lambda_{i}\left(z\right),\Lambda_{i}\left(z\right)\right\rangle }{\left\langle \Lambda_{i+1}\left(z\right),\Lambda_{i+1}\left(z\right)\right\rangle } & = \frac{1+\epsilon_{i+1}k_{i+1}}{1-\epsilon_{i+1}k_{i+1}}
\end{align*}

By changing the sign parameter, this ratio can always be made smaller or larger 
than one. Algorithm~\ref{alg:One-multiplier-sign-assignment} shows the method
used to assign the sign parameters in the Octave function
\emph{schurOneMscale}~\cite[Figure 3]{MarkelGray_FixedPointImplementationPolynomialFilters}.

\begin{algorithm}[htbp]
Assume that $k_{l}$ has the largest magnitude of the $k_{m}$ for
$m=1,2,\ldots,N$. Define the quantities
\begin{align*}
Q_{m} &= \frac{\left\langle \Lambda_{m}\left(z\right),\Lambda_{m}\left(z\right)\right\rangle }{\left\langle \Lambda_{l}\left(z\right),\Lambda_{l}\left(z\right)\right\rangle }\\
q_{m} &= \frac{1+\left|k_{m}\right|}{1-\left|k_{m}\right|}
\end{align*}

so that $Q_{l}=1$. Each $Q_{m}$ should be as large as possible without
exceeding $Q_{l}$. Successive ratios are:
\begin{align}
\frac{Q_{m}}{Q_{m+1}} = \begin{cases}
q_{m} & if\,\epsilon_{m}=sgn\left(k_{m}\right)\\
1/q_{m} & if\,\epsilon_{m}=-sgn\left(k_{m}\right)
\end{cases}\label{eq:OneMultRecursiveKCalc}
\end{align}

Now assign the $\epsilon_{m}$:
\begin{algorithmic}
\For {$m=l-1,l-2,\hdots,1$}
  \If {$Q_{m+1}<1/q_{m}$}
    \State $\epsilon_{m}=-sgn\left(k_{m}\right)$
  \Else
    \State $\epsilon_{m}=sgn\left(k_{m}\right)$
  \EndIf
\EndFor
\For {$m=l+1,l+2,\hdots,N$}
  \If {$Q_{m}<1/q_{m}$}
    \State $\epsilon_{m}=sgn\left(k_{m}\right)$
  \Else
    \State $\epsilon_{m}=-sgn\left(k_{m}\right)$
  \EndIf
\EndFor
\end{algorithmic}
\caption{One-multiplier lattice sign assignment~\cite[Page
  496]{GrayMarkel_DigitalLatticeAndLadderFilterSynthesis}.} 
\label{alg:One-multiplier-sign-assignment}
\end{algorithm}

Since the polynomials $\left\{ \Lambda_{N}\left(z\right),\Lambda_{N-1}\left(z\right),\ldots,\Lambda_{0}\left(z\right)\right\} $
form an orthogonal basis, the numerator polynomial can be synthesised as 
\begin{align*}
N_{N}\left(z\right) & = \sum_{i=0}^{N}c_{i}\Lambda_{i}\left(z\right)
\end{align*}
The synthesised filter structure is shown in 
Figure~\ref{fig:One-multiplier-lattice-structure}.
\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_OneMultiplier}
\caption{One-multiplier lattice structure (after 
\emph{Parhi}~\cite[Fig. 12.11]{Parhi_VLSIDigitalSignalProcessingSystems}).}
\label{fig:One-multiplier-lattice-structure}
\end{figure}
The Octave function \emph{tf2schurOneMlattice} calculates the coefficients of 
the one-multiplier Schur lattice from the transfer function. Note that if the
$\epsilon_{m}$ sign parameters are changed then the $\Lambda_{i}$ polynomials
will also change.

\section{Derivation of the Normalised Lattice Filter }
For an N-th order IIR transfer function
$H_{N}\left(z\right)=N_{N}\left(z\right)/D_{N}\left(z\right)$
initialise the N-th order Schur polynomial as
$\Phi_{N}\left(z\right)=D_{N}\left(z\right)$
and
\begin{align*}
\Phi_{N}\left(z\right) & = \sum_{i=0}^{N}\phi_{i}z^{i}
\end{align*}
Form $\Phi_{N-1}\left(z\right)$ by degree reduction
\begin{align*}
\Phi_{N-1}\left(z\right) & = \frac{z^{-1}\left\{ \Phi_{N}\left(z\right)-k_{N}\tilde{\Phi}_{N}\left(z\right)\right\} }{\sqrt{1-k_{N}^{2}}}
\end{align*}
where $k_{i}=\Phi_{i}(0)/\tilde{\Phi}_{i}(0)$. The reverse polynomial is
\begin{align*}
\tilde{\Phi}_{N-1}\left(z\right) & = z^{N-1}\Phi_{N-1}(z^{-1})\\
 & = \frac{\tilde{\Phi}_{N}\left(z\right)-k_{N}\Phi_{N}\left(z\right)}{\sqrt{1-k_{N}^{2}}}
\end{align*}
So 
\begin{align}
\tilde{\Phi}_{N}\left(z\right) & = \sqrt{1-k_{N}^{2}}\tilde{\Phi}_{N-1}\left(z\right)+k_{N}\Phi_{N}\left(z\right)\label{eq:NormScaledPhiStarN}\\
\Phi_{N-1}\left(z\right) & = z^{-1}\left\{ \sqrt{1-k_{N}^{2}}\Phi_{N}\left(z\right)-k_{N}\tilde{\Phi}_{N-1}\left(z\right)\right\} \\
\Phi_{N}\left(z\right) & = \frac{1}{\sqrt{1-k_{N}^{2}}}\left\{ z\Phi_{N-1}\left(z\right)+k_{N}\tilde{\Phi}_{N-1}\left(z\right)\right\} \label{eq:NormScaledPhiN_1}
\end{align}
Figure~\ref{fig:Normalised-lattice-filter} shows an implementation
of Equations~\ref{eq:NormScaledPhiStarN}~and~\ref{eq:NormScaledPhiN_1}. 

\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_Norm}
\caption{Normalised lattice filter (after 
\emph{Parhi}~\cite[Fig. 12.20]{Parhi_VLSIDigitalSignalProcessingSystems}).}
\label{fig:Normalised-lattice-filter}
\end{figure}
For module $i$ 
\begin{align*}
\sigma_{20}^{(i)} & = -\sigma_{02}^{(i)}=k_{i}\\
\sigma_{00}^{(i)} & = \sigma_{22}^{(i)}=\sqrt{1-k_{i}^{2}}
\end{align*}
These equations synthesise the denominator $D_{N}\left(z\right)$ of the transfer
function. The numerator is expanded in the orthonormal basis
\begin{align*}
N_{N}\left(z\right) & = \sum_{i=0}^{N}c_{i}\Phi_{i}\left(z\right)\\
\sigma_{10}^{(i)} & = c_{i}
\end{align*}
This is a \emph{normalised} lattice filter. The nodes in the feedback
path have unit power since the $\Phi_{i}\left(z\right)$ form an orthonormal
basis. For an all-pole filter the state covariance matrix, $K$, is
the unit matrix and the structure is orthonormal. However, for a pole-zero
filter the states corresponding to the numerator part are not scaled
and the filter is not orthonormal.
\section{Derivation of the Scaled Normalised Lattice Filter}
We can introduce a delay at each node in the normalised lattice by
making the transformation $z\rightarrow z^{2}$ and retiming so that
each node corresponds to a state in the state variable description.
Figure~\ref{fig:Slowed-and-retimed} shows one module of the retimed,
slowed lattice. 
\begin{figure}
\centering
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_RetimedA}
\caption{Original lattice section.}
\vspace{1cm}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_RetimedB}
\caption{After slow-down.}
\vspace{1cm}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_RetimedC}
\caption{After slow-down and re-timing.}
\end{subfigure}
\caption{Slowed and retimed lattice section.}
\label{fig:Slowed-and-retimed}
\end{figure}
The state-variable description of the re-timed lattice
has a state for every node so that the signal at each node can be
scaled\footnote{The roundoff-noise performance of the transformed filter is the
same as that of the original filter}. The orthogonality of the 
$\Phi_{i}\left(z\right)$ means that the additional diagonal elements of the 
state covariance matrix have the form $\sum c_{i}^{2}$. The elements of 
the diagonal scaling matrix have the form $T=\sqrt{\sum c_{i}^{2}}$. This 
suggests the following section-by-section scaling:
\begin{enumerate}
\item For module N:
\begin{align}
\sigma_{10}^{(N)} & = c_{N}\label{eq:ScaleNormS10}\\
\sigma_{11}^{(N)} & = \sqrt{\sum_{j=0}^{N}c_{j}^{2}}\label{eq:ScaleNormS11}
\end{align}

\item For modules $N-1$ to $1$:
\begin{align}
\sigma_{10}^{(i)} & = \frac{c_{i}}{\sqrt{\sum_{j=0}^{i}c_{j}^{2}}}\label{eq:ScaleNormS10other}\\
\sigma_{11}^{(i)} & = \frac{\sqrt{\sum_{j=0}^{i-1}c_{j}^{2}}}{\sqrt{\sum_{j=0}^{i}c_{j}^{2}}}\label{eq:ScaleNormS11other}
\end{align}

\item Any module $N$ to $1$:
\begin{align}
\sigma_{20}^{(i)} & = -\sigma_{02}^{(i)}=k_{i}\label{eq:ScaleNormS20}\\
\sigma_{00}^{(i)} & = \sigma_{22}^{(i)}=\sqrt{1-k_{i}^{2}}\label{eq:ScaleNormS00}
\end{align}
\end{enumerate}
The structure of an N-th order normalised-scaled lattice filter is shown in 
Figure~\ref{fig:Normalised-scaled-lattice}. 
\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_ScaledNorm}
\caption{Normalised-scaled lattice filter (after 
\emph{Parhi}~\cite[Fig. 12.19]{Parhi_VLSIDigitalSignalProcessingSystems}).}
\label{fig:Normalised-scaled-lattice}
\end{figure}
Note that $\sigma_{10}^{(0)}=\operatorname{sign} c_{0}$. The Octave function 
\emph{schurNSscale} implements the scaling of the $\sigma_{10}$ and $\sigma_{11}$
lattice coefficients from the $c_{i}$ expansion coefficients. For convenience,
\emph{schurNSscale} combines $\sigma_{10}^{(0)}$ and $\sigma_{11}^{(1)}$. The Octave
function \emph{tf2schurNSlattice} calculates the coefficients of the 
normalised-scaled Schur lattice from the transfer function.
\subsection{\label{sub:Example-butt3NS-synthesis}Example: synthesis of a 3rd order Butterworth lattice filter}
\emph{Parhi}~\cite[Example 12.6.1]{Parhi_VLSIDigitalSignalProcessingSystems}
uses as an example a third order Butterworth low-pass filter with cutoff at 
angular frequency $0.1\pi$ (where the sampling frequency is normalised to 
$2\pi)$. The squared magnitude of the $n$-th order Butterworth response is
defined to be
\begin{align*}
\left|\hat{H}(\imath\omega)\right|^{2} & = \left[1+\left(\frac{\omega}{\omega_{c}}\right)^{2n}\right]^{-1}
\end{align*}
The poles of the response are evenly distributed around the unit circle.
For stability, we choose the poles in the left-hand $s$-plane, 
$\lambda_{k}=\omega_{c}e^{\imath\theta_{k}}$,
$\theta_{k}=\frac{\pi}{2}\left(1+\frac{\left(2k-1\right)}{n}\right)$ with
$1\leq k\leq n$ and:
\begin{align*}
\hat{H}(s) & = \frac{-\lambda_{0}\lambda_{1}\lambda_{1}^{\ast}}{(s-\lambda_{0})(s-\lambda_{1})(s-\lambda_{1}^{\ast})}
\end{align*}
where $\lambda_{0}=\Omega_{c}$, the cutoff frequency of the analog
low pass filter, and:
$\lambda_{1}=-\Omega_{c}\left[\left(1-\imath\sqrt{3}\right)/2\right]$ so:
\begin{align*}
  \hat{H}(s)
  &= \frac{\Omega_{c}^{3}}
    {\left(s+\Omega_{c}\right)\left(s^{2}+s\Omega_{c}+\Omega_{c}^{2}\right)}
\end{align*}
Choose the bi-linear transformation from the $s$-plane to the $z$-plane
so that the transfer function of the digital filter is
$H\left(z\right)=\hat{H}(\frac{z-1}{z+1})$.
If the cutoff frequency of the digital filter $H\left(z\right)$ is
$\theta_{c}=\omega_{c}t_{0}$ (where $\omega_{c}$ is the $s$-plane cutoff angular
frequency and $t_{0}$ is the sampling interval) then \emph{pre-warp} the
$s$-plane frequency axis so that the corresponding cut-off in the $s$-plane
is:
\begin{align*}
\Omega(\omega_{c}) & = \tan(\omega_{c}t_{0}/2)
\end{align*}
(found by substituting $z=e^{\imath\omega t_{0}}$ into the bi-linear
transformation). For the third order Butterworth filter:
\begin{align*}
H\left(z\right) & = \frac{\Omega^{3}(z+1)^{3}}
{\left[\left(1+\Omega\right)z+\left(-1+\Omega\right)\right]
 \left[\left(1+\Omega+\Omega^{2}\right)z^{2}+
       \left(-2+2\Omega^{2}\right)z+\left(1-\Omega+\Omega^{2}\right)\right]}
\end{align*}
In the example, the cut-off frequency is $0.05/t_{0}$ so $\omega_{c}t_{0}=0.1\pi$
and $\Omega=0.158384$ giving:
\begin{align*}
H\left(z\right) & = \frac{0.0028982(z+1)^{3}}{z^{3}-2.37409z^{2}+1.92836z-0.53208}
     & = \frac{(z+1)^{3}}{345.04z^{3}-819.16z^{2}+665.71z-183.59}
\end{align*}
For the denominator of $H\left(z\right)$ the Schur basis is:
\begin{align*}
\Phi_{3}\left(z\right) & = 345.1z^{3}-819.3z^{2}+665.8z-183.6\\
\Phi_{2}\left(z\right) & = 292.2072z^{2}-549.2662z+271.5337\\
\Phi_{1}\left(z\right) & = 107.956z-105.1841\\
\Phi_{0}\left(z\right) & = 24.3064
\end{align*}
The Schur expansion of the numerator polynomial of $H\left(z\right)$ is:
\begin{enumerate}
\item For $H\left(z\right)$ initialise $Q\left(z\right)=z^{3}+3z^{2}+3z+1$. Then 
$c_{3}=1/345.1=0.0029$. 
\item Update $Q\left(z\right)=5.3741z^{2}+1.0707z+1.532$. Then 
$c_{2}=5.3741/292.2072=0.0184$.
\item Update $Q\left(z\right)=11.1725z-3.4619$. Then $c_{1}=11.1725/107.956=0.10349$.
\item Update $Q\left(z\right)=7.4238$. Then $c_{0}=7.4238/24.3064=0.3054$
\end{enumerate}
The sum of the expansion coefficients, the output signal power, is
$0.1043$. The lattice ``reflection coefficients'' are $k_{3}=-0.532$,
$k_{2}=0.9293$ and $k_{1}=-0.9743$.

Figure~\ref{fig:Butterworth-3rd-order} shows the signal-flow graph
of the normalised-scaled lattice implementation of $H\left(z\right)$. 

\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{Example_Butt3NS}
\caption{Butterworth 3rd order normalised-scaled lattice filter example (after 
\emph{Parhi}~\cite[Fig. 12.20]{Parhi_VLSIDigitalSignalProcessingSystems}).}
\label{fig:Butterworth-3rd-order}
\end{figure}
\clearpage
\section{State Variable Descriptions for Schur Lattice Filters}
\subsection{State variable description of the Schur FIR lattice filter}
Figure~\ref{fig:FIR-filter-structure} shows the Schur FIR lattice structure. 
For convenience, call $x_{n}^{\prime}$ the input to state $x_{n}$ of
the $n$-th section, $y_{n}$ the upper output of the $n$-th section
and $\hat{y}_{n}$ the lower output of the $n$-th section. Construction of the
state variable description of the Schur FIR lattice is summarised in
Algorithm~\ref{alg:Construction-state-variable-Schur-FIR-lattice}.

\begin{algorithm}[htbp]
Given $\left\{k_{1},k_{2},\hdots,k_{N}\right\}$:
\begin{algorithmic}
\State $y_{0} = u$
\State $\hat{y}_{0} = u$
\For{$n=1,\hdots,N$}
  \State $x_{n}^{\prime} = \hat{y}_{n-1}$
  \State $y_{n} = k_{n}x_{n} + y_{n-1}$
  \State $\hat{y}_{n} = x_{n}+k_{n}y_{n-1}$
\EndFor
\State $y = y_{N}$
\end{algorithmic}
\caption{Construction of a state variable description of the Schur FIR lattice
  filter.}
\label{alg:Construction-state-variable-Schur-FIR-lattice}
\end{algorithm}

As shown in Section~\ref{Sec:Construction-factored-state-variable-description},
the state variable description can be expressed as a series of matrix
multiplications linking the input and state outputs to the output and the next
state inputs:

\begin{align*}
\left[\begin{array}{c}
y_{0}\\
\hat{y}_{0}\\
x_{1}\\
\vdots\\
x_{N}
\end{array}\right] & = \left[\begin{array}{ccccc}
0 & & \cdots & 0 & 1 \\
0 & & \cdots & 0 & 1 \\
1 & & \cdots & 0 & 0 \\
\vdots & & \ddots & & \vdots \\
0 & & \cdots & 1 & 0
\end{array}\right]\left[\begin{array}{c}
x_{1}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{N}\\
u                          
\end{array}\right]
\end{align*}
\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
y_{1}\\
\hat{y}_{1}\\
x_{2}\\
\vdots\\
x_{N}
\end{array}\right] & = \left[\begin{array}{cccccc}
0 & 1 & 0 & 0 & \cdots & 0\\
1 & 0 & k_{1} & 0 & \cdots & 0\\
k_{1} & 0 & 1 & 0 & \cdots & 0\\
0 & 0 & 0 & 1 & \cdots & 0\\
\vdots &  &  & & \ddots & \vdots\\
0 & & & & \cdots & 1
\end{array}\right]\left[\begin{array}{c}
y_{0}\\
\hat{y}_{0}\\
x_{1}\\
x_{2}\\
\vdots\\
x_{N}
\end{array}\right]
\end{align*}
\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
x_{2}^{\prime}\\
y_{2}\\
\hat{y}_{2}\\
x_{3}\\
\vdots\\
x_{N}
\end{array}\right] & = \left[\begin{array}{ccccccc}
1 & 0 & 0 & 0 & 0 &\cdots & 0\\
0 & 0 & 1 & 0 & 0 &\cdots & 0\\
0 & 1 & 0 & k_{2} & 0 &\cdots & 0\\
0 & k_{2} & 0 & 1 & 0 &\cdots & 0\\
0 & 0 & 0 & 0 & 1 & \cdots & 0\\
\vdots &  & & &  & \ddots & \vdots\\
0 & \cdots &  & & & \cdots & 1
\end{array}\right]\left[\begin{array}{c}
x_{1}^{\prime} \\
y_{1}\\
\hat{y}_{1}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{N}
\end{array}\right]
\end{align*}
\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
x_{N-1}^{\prime}\\
y_{N-1}\\
\hat{y}_{N-1}\\
x_{N}
\end{array}\right] & = \left[\begin{array}{ccccccc}
1 & \cdots & & & & \cdots & 0\\
\vdots & \ddots & & & & & \vdots\\
0 & \cdots & & 0 & 1 & 0 & 0\\
0 & \cdots & & 1 & 0 & k_{N-1} & 0\\
0 & \cdots & & k_{N-1} & 0 & 1 & 0\\
0 & \cdots & & 0 & 0 & 0 & 1
\end{array}\right]\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
y_{N-2}\\
\hat{y}_{N-2}\\
x_{N-1}\\
x_{N}
\end{array}\right]
\end{align*}
\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
x_{N}^{\prime}\\
y_{N}\\
\hat{y}_{N}
\end{array}\right] & = \left[\begin{array}{cccccc}
1 & 0 & \cdots & & \cdots & 0\\
\vdots & \ddots & & & & \vdots \\
0 & & & 0 & 1 & 0\\
0 & & & k_{N} & 0 & 1\\
0 & \cdots & & 1 & 0 & k_{N}
\end{array}\right]\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
y_{N-1}\\
\hat{y}_{N-1}\\
x_{N}
\end{array}\right]
\end{align*}
The Octave function \emph{schurFIRlattice2Abcd} returns the state variable
description of a Schur FIR lattice filter.
The Octave script \emph{schurFIRlattice2Abcd\_symbolic\_test.m} creates a symbolic
state variable description of the Schur FIR lattice filter.

\subsection{\label{State-Variable-Description-One-Multiplier-IIR-Lattice-Filter}State variable description of the one-multiplier IIR lattice filter}
In Figure~\ref{fig:State-variable-description-One-Multiplier-Lattice},
Figure~\ref{fig:One-multiplier-lattice-structure} is redrawn with
$x_{n}^{\prime}$ corresponding to the input to state $x_{n}$ of
the $n$-th section, $y_{n}$ being the output of the $n$-th section
and $\hat{y}_{n}$ the all-pass output of the $n$-th section.

\begin{figure}[!ht]
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_OneMultiplier_SV_derivation}
\caption{State variable description of the Schur one-multiplier lattice filter.}
\label{fig:State-variable-description-One-Multiplier-Lattice}
\end{figure}

Construction of the state variable description is summarised in
Algorithm~\ref{alg:Construction-state-variable-One-Multiplier-lattice}.

\begin{algorithm}[!ht]
Given $\left\{k_{1},k_{2},\hdots,k_{N}\right\}$,
$\left\{\epsilon_{1},\epsilon_{2},\hdots,\epsilon_{N}\right\}$ and
$\left\{c_{0},c_{1},\hdots,c_{N}\right\}$:
\begin{algorithmic}
\State $\hat{y}_{0} = x_{1}$
\For{$n=1,\hdots,N-1$}
  \State $x_{n}^{\prime}=-k_{n}\hat{y}_{n-1}+\left(1+k_{n}\epsilon_{n}\right)x_{n+1}$
  \State $\hat{y}_{n}= \left(1-k_{n}\epsilon_{n}\right)\hat{y}_{n-1}+k_{n}x_{n+1}$
\EndFor
\State $x_{N} = -k_{N}\hat{y}_{N-1}+\left(1+k_{N}\epsilon_{N}\right)u$
\State $\hat{y} = \left(1-k_{N}\epsilon_{N}\right)\hat{y}_{N-1}+k_{N}u$
\State $y  = c_{0}x_{1}+c_{1}x_{2}+\cdots+c_{N-1}x_{N}+c_{N}u$
\end{algorithmic}
\caption{Construction of a state variable description of the Schur
  one-multiplier lattice filter.}
\label{alg:Construction-state-variable-One-Multiplier-lattice}
\end{algorithm}

The state variable description can be expressed as a series of matrix
multiplications linking the input and state outputs to the output
and the next state inputs. The all-pass output of the Schur one-multiplier
lattice filter is constructed as follows\footnote{Noting that
$\det\left[\begin{array}{cc}
-k_{l}&1+k_{l}\epsilon_{l}\\
1-k_{l}\epsilon_{l} & k_{l}\end{array}\right]=-1$ and $\det{} PQ=\det{}P\det{}Q$,
then, by inspection, $\det{}A_{1\hdots{}l,1\hdots{}l}=-1^lk_{l}$.}:
\begin{align*}
\left[\begin{array}{c}
\hat{y}_{0}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{N}\\
u
\end{array}\right] & = \left[\begin{array}{cccccc}
1 & 0 & \cdots &  & \cdots & 0\\
0 & 1 &  &  &  & \vdots\\
\vdots &  & \ddots\\
 &  &  & \ddots &  & \vdots\\
0 &  &  &  & 1 & 0\\
0 & \cdots &  & \cdots & 0 & 1
\end{array}\right]\left[\begin{array}{c}
x_{1}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{N}\\
u
\end{array}\right]
\end{align*}
\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
\hat{y}_{1}\\
x_{3}\\
\vdots\\
x_{N}\\
u
\end{array}\right] & = \left[\begin{array}{cccccc}
-k_{1} & \left(1+k_{1}\epsilon_{1}\right) & 0 & \cdots & \cdots & 0\\
\left(1-k_{1}\epsilon_{1}\right) & k_{1} & 0 &  &  & \vdots\\
0 & 0 & 1\\
\vdots &  &  & \ddots &  & \vdots\\
0 &  &  &  & 1 & 0\\
0 & \cdots &  & \cdots & 0 & 1
\end{array}\right]\left[\begin{array}{c}
\hat{y}_{0}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{N}\\
u
\end{array}\right]
\end{align*}
\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
x_{2}^{\prime}\\
\hat{y}_{2}\\
\vdots\\
x_{N}\\     
u
\end{array}\right] & = \left[\begin{array}{cccccc}
1 & 0 & 0 & 0 & \cdots & 0\\
0 & -k_{2} & \left(1+k_{2}\epsilon_{2}\right) & 0 &  & \vdots\\
0 & \left(1-k_{2}\epsilon_{2}\right) & k_{2} & 0\\
\vdots &  &  & \ddots &  & \vdots\\
0 &  &  &  & 1 & 0\\
0 & \cdots &  & \cdots & 0 & 1
\end{array}\right]\left[\begin{array}{c}
x_{1}^{\prime}\\
\hat{y}_{1}\\
x_{3}\\
\vdots\\
x_{N}\\
u
\end{array}\right]
\end{align*}
\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
x_{2}^{\prime}\\
\vdots\\
x_{N-1}^{\prime}\\
\hat{y}_{N-1}\\
u
\end{array}\right] & = \left[\begin{array}{cccccc}
1 & 0 & \cdots &  & \cdots & 0\\
0 & 1 &  &  &  & \vdots\\
\vdots &  & \ddots &  &  & \vdots\\
0 &  &  & -k_{N-1} & \left(1+k_{N-1}\epsilon_{N-1}\right) & 0\\
0 &  &  & \left(1-k_{N-1}\epsilon_{N-1}\right) & k_{N-1} & 0\\
0 & \cdots & \cdots & 0 & 0 & 1
\end{array}\right]\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
x_{N-2}^{\prime}\\
\hat{y}_{N-2}\\
x_{N}\\
u
\end{array}\right]
\end{align*}
\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
x_{2}^{\prime}\\
x_{3}^{\prime}\\
\vdots\\
x_{N}^{\prime}\\
\hat{y}
\end{array}\right] & = \left[\begin{array}{cccccc}
1 & 0 & \cdots &  & \cdots & 0\\
0 & 1 &  &  &  & \vdots\\
\vdots &  & \ddots & & & \vdots\\
0 &  &  & 1 & 0 & 0\\
0 &  &  &  0 & -k_{N} & \left(1+k_{N}\epsilon_{N}\right)\\
0 & \cdots &  & 0 & \left(1-k_{N}\epsilon_{N}\right) & k_{N}
\end{array}\right]\left[\begin{array}{c}
x_{1}^{\prime}\\
x_{2}^{\prime}\\
\vdots\\
x_{N-1}^{\prime}\\
\hat{y}_{N-1}\\
u
\end{array}\right]
\end{align*}

The Octave function \emph{schurOneMlattice2Abcd} returns the state variable
description of a one multiplier lattice filter (including the all-pass
filter $Cap$ and $Dap$ output matrixes).
The Octave script \emph{schurSchurOneMlattice2Abcd\_symbolic\_test.m} creates a
symbolic state variable description of the Schur one multiplier lattice filter.
\subsection{\label{sec:State-variable-pipelined-One-multiplier-Schur-lattice-filter}State variable description of a pipelined one-multiplier Schur lattice filter}
Figure~\ref{subfig:example-lattice-filter} shows a representation $3$rd order
lattice filter and Figure~\ref{subfig:example-lattice-filter-after-pipelining}
shows the filter after pipelining by moving the second filter delay to the upper
and lower branches of the signal flow graph. The total delay in each loop of
the signal flow graph is unchanged so the transfer function of the filter is
also unchanged. This pipelining limits the maximum latency of each filter update
calculation to the latency of two sections and changes the round-off noise
performance of the filter\footnote{The tapped output could alse be retimed by
  pipelining the arithmetic operations in a tree structure. The all-pass
  lattice ouput calculation is recursive and cannot be retimed in that way.}.

\begin{figure}[!ht]
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{lattice_pipelined_a}
\caption{Original filter.}
\label{subfig:example-lattice-filter}
\vspace{1cm}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{lattice_pipelined_b}
\caption{Filter after retiming.}
\label{subfig:example-lattice-filter-after-pipelining}
\end{subfigure}
\caption{Example of pipelining a 3rd order lattice filter.}
\end{figure}

Figure~\ref{fig:State-variable-description-pipelined-One-Multiplier-Lattice}
shows a second order segment of the pipelined Schur one-multiplier lattice
filter in Figure~\ref{subfig:example-lattice-filter-after-pipelining}. 

\begin{figure}[!ht]
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_OneMultiplierPipelined}
\caption{Second order segment of the pipelined Schur one-multiplier lattice
  filter.}
\label{fig:State-variable-description-pipelined-One-Multiplier-Lattice}
\end{figure}

Construction of a state variable description of the pipelined Schur
one-multiplier lattice filter is summarised in
Algorithm~\ref{alg:Construction-state-variable-pipelined-One-Multiplier-lattice}.

\begin{algorithm}[!ht]
Given $\left\{k_{1},k_{2},\hdots,k_{N}\right\}$,
$\left\{\epsilon_{1},\epsilon_{2},\hdots,\epsilon_{N}\right\}$ and
$\left\{c_{0},c_{1},\hdots,c_{N}\right\}$:
\begin{algorithmic}
\State $y_{0} = c_{0}x_{1}$
\State $\hat{y}_{0} = x_{1}$
\For{$n=1,\hdots,\left\lceil\frac{N}{2}\right\rceil-1$}
\State $x_{3n-2}^{\prime}=-k_{2n-1}\hat{y}_{n-1}
  -\left(1+k_{2n-1}\epsilon_{2n-1}\right)k_{2n}x_{3n}+
  \left(1+k_{2n-1}\epsilon_{2n-1}\right)\left(1+k_{2n}\epsilon_{2n}\right)x_{3n+1}$
  \State $x_{3n-1}^{\prime}=y_{n-1}-c_{2n-1}k_{2n}x_{3n}+
  c_{2n-1}\left(1+k_{2n}\epsilon_{2n}\right)x_{3n+1}$
  \State $x_{3n}^{\prime}=\left(1-k_{2n-1}\epsilon_{2n-1}\right)\hat{y}_{n-1}
  -k_{2n-1}k_{2n}x_{3n}+
  k_{2n-1}\left(1+k_{2n}\epsilon_{2n}\right)x_{3n+1}$
  \State $y_{n} = x_{3n-1}+c_{2n}x_{3n+1}$
  \State $\hat{y}_{n}=\left(1-k_{2n}\epsilon_{2n}\right)x_{3n}+k_{2n}x_{3n+1}$
\EndFor
\If{N is odd}
\State $x_{3\left\lceil\frac{N}{2}\right\rceil-2}^{\prime}=
  -k_{N}\hat{y}_{\left\lceil\frac{N}{2}\right\rceil-1}+
  \left(1+k_{N}\epsilon_{N}\right)u$
\State $y  = y_{\left\lceil\frac{N}{2}\right\rceil-1}+c_{N}u$
\State $\hat{y}=
  \left(1-k_{N}\epsilon_{N}\right)\hat{y}_{\left\lceil\frac{N}{2}\right\rceil-1}+k_{N}u$
\Else
\State $x_{3\frac{N}{2}-2}^{\prime} = -k_{N-1}\hat{y}_{\frac{N}{2}-1}
  -\left(1+k_{N-1}\epsilon_{N-1}\right)k_{N}x_{3\frac{N}{2}} +
  \left(1+k_{N-1}\epsilon_{N-1}\right)\left(1+k_{N}\epsilon_{N}\right)u$
\State $x_{3\frac{N}{2}-1}^{\prime} = y_{\frac{N}{2}-1} -c_{N-1}k_{N}x_{3\frac{N}{2}} +
    c_{N-1}\left(1+k_{N}\epsilon_{N}\right)u$
\State $x_{3\frac{N}{2}}^{\prime} =
    \left(1-k_{N-1}\epsilon_{N-1}\right)\hat{y}_{\frac{N}{2}-1}
    -k_{N-1}k_{N}x_{3\frac{N}{2}}+
    k_{N-1}\left(1+k_{N}\epsilon_{N}\right)u$
\State $y = x_{3\frac{N}{2}-1}+c_{N}u$
\State $\hat{y} = \left(1-k_{N}\epsilon_{N}\right)x_{3\frac{N}{2}}+k_{N}u$
\EndIf
\end{algorithmic}
\caption{Construction of a state variable description of the pipelined Schur
  one-multiplier lattice filter.}
\label{alg:Construction-state-variable-pipelined-One-Multiplier-lattice}
\end{algorithm}

As in Section~\ref{State-Variable-Description-One-Multiplier-IIR-Lattice-Filter},
the state variable description can be expressed as a series of matrix
multiplications. For an even order filter:

\begin{align*}
\left[\begin{array}{c}
y_{0}\\
\hat{y}_{0}\\
x_{1}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{3\frac{N}{2}}\\
u
\end{array}\right] & = \left[\begin{array}{ccccc}
c_{0} & 0 & \cdots & \cdots & 0 \\
1 & 0 & \cdots & \cdots & 0 \\
1 & 0 & \cdots & \cdots & 0 \\
\vdots & \ddots & & & \vdots \\
\vdots &  & \ddots &  & \vdots\\
0 &  &  & 1 & 0\\
0 & \cdots & \cdots & 0 & 1
\end{array}\right]
\left[\begin{array}{c}
x_{1}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{3\frac{N}{2}}\\
u
\end{array}\right]
\end{align*}

\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
x_{2}^{\prime}\\
x_{3}^{\prime}\\
y_{1}\\
\hat{y}_{1}\\
x_{4}\\
\vdots\\
x_{3\frac{N}{2}}\\
u
\end{array}\right] & = \left[\begin{array}{ccccccccc}
    0 & -k_{1} & 0 & 0 & -\left(1+k_{1}\epsilon_{1}\right)k_{2} &
    \left(1+k_{1}\epsilon_{1}\right)\left(1+k_{2}\epsilon_{2}\right)
    & & \cdots & 0 \\
1 & 0 & 0 & 0 & -c_{1}k_{2} & c_{1}\left(1+k_{2}\epsilon_{2}\right) & &\cdots&0\\
0 & \left(1-k_{1}\epsilon_{1}\right) & 0 & 0 & -k_{1}k_{2} &
    k_{1}\left(1+k_{2}\epsilon_{2}\right) &  & \cdots & 0\\
0 & 0 & 0 & 1 & 0 & c_{2} &  & \cdots & 0\\
0 & 0 & 0 & 0 & \left(1-k_{2}\epsilon_{2}\right) & k_{2} & & \cdots & 0 \\
  &   &   &   &   &      & \ddots  &  & \vdots\\
0 & \cdots & & & & & \cdots & 1 & 0\\
0 & \cdots & & & & & \cdots & 0 & 1
  \end{array}\right]
\left[\begin{array}{c}
y_{0}\\
\hat{y}_{0}\\
x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\\
\vdots\\
x_{3\frac{N}{2}}\\
u
\end{array}\right]
\end{align*}

\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
x_{3\frac{N}{2}}^{\prime}\\
y \\
\hat{y}
\end{array}\right] &=
\left[\begin{array}{cccccccc}
1 & \cdots & & & & & \cdots & 0\\
\vdots  & \ddots & & & & & & \vdots\\
0 & \cdots & 0 & -k_{N-1} & 0 & 0 & -\left(1+k_{N-1}\epsilon_{N-1}\right)k_{N} &
  \left(1+k_{N-1}\epsilon_{N-1}\right)\left(1+k_{N}\epsilon_{N}\right)\\
0 & \cdots & 1 & 0 & 0 & 0 & -c_{N-1}k_{N} &
  c_{N-1}\left(1+k_{N}\epsilon_{N}\right)\\
0 & \cdots & 0 & 1-k_{N-1}\epsilon_{N-1} & 0 & 0 &-k_{N-1}k_{N} & 
  k_{N-1}\left(1+k_{N}\epsilon_{N}\right) \\
0  & \cdots & 0 & 0 & 0 & 1 & 0 & c_{N} \\
0  & \cdots & 0 & 0 & 0 & 0 & \left(1-k_{N}\epsilon_{N}\right) & k_{N}  
\end{array}\right]\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
x_{3\frac{N}{2}-3}^{\prime}\\
y_{\frac{N}{2}-1}\\
\hat{y}_{\frac{N}{2}-1}\\
x_{3\frac{N}{2}-2}\\
x_{3\frac{N}{2}-1}\\
x_{3\frac{N}{2}}\\
u  
\end{array}\right]
\end{align*}

For an odd order filter, the final matrix multiplication is:
\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
x_{3\left\lceil\frac{N}{2}\right\rceil-2}^{\prime}\\
y \\
\hat{y}
\end{array}\right] &=
\left[\begin{array}{cccccc}
1  & \cdots & & & \cdots & 0\\
\vdots  & \ddots & & & & \vdots\\
0  & \cdots & 0 & -k_{N} & 0 & \left(1+k_{N}\epsilon_{N}\right)\\
0  & \cdots & 1 & 0 & 0 & c_{N} \\
0  & \cdots & 0 & \left(1-k_{N}\epsilon_{N}\right) & 0 & k_{N}  
\end{array}\right]
\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
x_{3\left\lceil\frac{N}{2}\right\rceil-3}^{\prime}\\
y_{\left\lceil\frac{N}{2}\right\rceil-1}\\
\hat{y}_{\left\lceil\frac{N}{2}\right\rceil-1}\\
x_{3\left\lceil\frac{N}{2}\right\rceil-2}\\
u  
\end{array}\right]
\end{align*}

The Octave function \emph{schurOneMlatticePipelined2Abcd} returns the state
variable description of a pipelined Schur one-multiplier lattice filter
(including the all-pass filter $Aap$, $Bap$, $Cap$ and $Dap$ output matrixes).

The Octave script \emph{schurOneMlatticePipelined2Abcd\_symbolic\_test.m}
creates a symbolic state variable description of a retimed Schur one-multiplier
lattice filter. 

\subsection{\label{sec:State-variable-doubly-pipelined-One-multiplier-Schur-lattice-filter}State variable description of a doubly-pipelined one-multiplier Schur lattice filter}
Figure~\ref{fig:State-variable-description-doubly-pipelined-One-Multiplier-Lattice}
shows a first order segment of a doubly-pipelined Schur one-multiplier lattice
filter. In this case, the state transition matrix is linear in the coefficients
and there are two delays in each filter loop rather than the original single
delay. In other words, the filter calculations are assumed to be performed at
double the input sample rate.

\begin{figure}[!ht]
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_OneMultiplierDoublyPipelined}
\caption{First order segment of a doubly pipelined Schur one-multiplier lattice
  filter.}
\label{fig:State-variable-description-doubly-pipelined-One-Multiplier-Lattice}
\end{figure}

Construction of a state variable description of the doubly-pipelined Schur
one-multiplier lattice filter is summarised in
Algorithm~\ref{alg:Construction-state-variable-doubly-pipelined-One-Multiplier-lattice}. 

\begin{algorithm}[!ht]
Given $\left\{k_{1},k_{2},\hdots,k_{N}\right\}$,
$\left\{\epsilon_{1},\epsilon_{2},\hdots,\epsilon_{N}\right\}$ and
$\left\{c_{0},c_{1},\hdots,c_{N}\right\}$:
\begin{algorithmic}
\State $y_{0} = c_{0}x_{1}$
\State $\hat{y}_{0} = x_{1}$
\State $x_{1}^{\prime} = x_{2}$  
\For{$n=1,\hdots,N$}
\State $x_{3n-1}^{\prime}=-k_{n}\hat{y}_{n-1}+\left(1+k_{n}\epsilon_{n}\right)x_{3n+2}$
\State $x_{3n}^{\prime}=y_{n-1}+c_{n}x_{3n+2}$
\State $x_{3n+1}^{\prime}=\left(1-k_{n}\epsilon_{n}\right)\hat{y}_{n-1}+k_{n}x_{3n+2}$
\State $y_{n} = x_{3n}$
\State $\hat{y}_{n} = x_{3n+1}$
\EndFor
\State $x_{3N+2}^{\prime}=u$
\State $y=y_{N}$
\State $\hat{y}=\hat{y}_{N}$
\end{algorithmic}
\caption{Construction of a state variable description of the doubly-pipelined
  Schur one-multiplier lattice filter.}
\label{alg:Construction-state-variable-doubly-pipelined-One-Multiplier-lattice}
\end{algorithm}

As in Section~\ref{State-Variable-Description-One-Multiplier-IIR-Lattice-Filter},
the state variable description can be expressed as a series of matrix
multiplications:

\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
y_{0}\\
\hat{y}_{0}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{3N+2}\\
u
\end{array}\right] & = \left[\begin{array}{cccccc}
      0 &  1 &   0 & \cdots &      0 & 0 \\
   c_{0} &  0 &   0 &        &      0 & 0 \\
      1 &  0 &   0 &        &      0 & 0 \\
      0 &  1 &   0 &        &      0 & 0 \\
      0 &  0 &   1 &        &      0 & 0 \\
 \vdots &    &     & \ddots & \vdots & \vdots \\
      0 &    &     & \cdots &      1 & 0 \\
      0 &    &     & \cdots &      0 & 1
\end{array}\right]
\left[\begin{array}{c}
x_{1}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{3N+2}\\
u
\end{array}\right]
\end{align*}

\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
x_{2}^{\prime}\\
x_{3}^{\prime}\\
x_{4}^{\prime}\\
y_{1}\\         
\hat{y}_{1}\\   
x_{5}\\
x_{6}\\
\vdots\\        
x_{3N+2}\\      
u
\end{array}\right] & = \left[\begin{array}{ccccccccccc}
   1&  0&     0& 0& 0& 0&                             0& 0& \cdots& 0& 0\\   
   0&  0&-k_{1}& 0& 0& 0&\left(1+k_{1}\epsilon_{1}\right)& 0& \cdots& 0& 0\\
   0&  1&     0& 0& 0& 0&                          c_{1}& 0& \cdots& 0& 0\\   
   0&  0&\left(1-k_{1}\epsilon_{1}\right)& 0& 0& 0& k_{1}& 0& \cdots& 0& 0\\
   0&  0&     0& 0& 1& 0&                              0& 0& \cdots& 0& 0\\   
   0&  0&     0& 0& 0& 1&                              0& 0& \cdots& 0& 0\\   
   0&  0&     0& 0& 0& 0&                              1& 0& \cdots& 0& 0\\
   0&  0&     0& 0& 0& 0&                              0& 1& \cdots& 0& 0\\
\vdots& &      &  &  &  &                               & &\ddots&\vdots&\vdots\\
   0&  0&     0& 0& 0& 0&                              0& 0& \cdots& 1& 0\\
   0&  0&     0& 0& 0& 0&                              0& 0& \cdots& 0& 1
\end{array}\right]
\left[\begin{array}{c}
x_{1}^{\prime} \\  
y_{0}\\            
\hat{y}_{0}\\      
x_{2}\\            
x_{3}\\            
x_{4}\\            
x_{5}\\            
x_{6}\\            
\vdots\\           
x_{3N+2}\\         
u
\end{array}\right]
\end{align*}

\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\   
\vdots\\           
x_{3N-1}^{\prime}\\
x_{3N}^{\prime}\\
x_{3N+1}^{\prime}\\
y_{N}\\            
\hat{y}_{N}\\ 
x_{3N+2}\\            
u\end{array}\right] & = \left[
\begin{array}{ccccccccc}
       1& \cdots& 0&    0& 0& 0& 0&                              0& 0\\
  \vdots& \ddots&  &     &  &  &  &                               & \vdots\\
       0& \cdots& 0&-k_{N}& 0& 0& 0&\left(1+k_{N}\epsilon_{N}\right)& 0\\
       0& \cdots& 1&    0& 0& 0& 0&                           c_{N}& 0\\
       0& \cdots& 0&\left(1-k_{N}\epsilon_{N}\right)& 0& 0& 0& k_{N}& 0 \\
       0& \cdots& 0&    0& 0& 1& 0&                               0& 0\\
       0& \cdots& 0&    0& 0& 0& 1&                               0& 0\\
       0& \cdots& 0&    0& 0& 0& 0&                               1& 0\\
       0& \cdots& 0&    0& 0& 0& 0&                               0& 1
\end{array}\right]
\left[\begin{array}{c}
x_{1}^{\prime} \\
\vdots\\
y_{N-1}\\
\hat{y}_{N-1}\\
x_{3N-1}\\
x_{3N}\\
x_{3N+1}\\
x_{3N+2}\\
u\end{array}\right]
\end{align*}

\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
x_{3N+2}^{\prime}\\
y\\
\hat{y}\end{array}\right] & = \left[
\begin{array}{ccccccccc}
      1& \cdots& 0& 0& 0& 0& 0& 0& 0\\
 \vdots& \ddots&  &  &  &  &  &  & \vdots\\
      0& \cdots& 0& 0& 0& 0& 0& 0& 1\\
      0& \cdots& 0& 0& 0& 1& 0& 0& 0\\
      0& \cdots& 0& 0& 0& 0& 1& 0& 0\end{array}\right]
\left[\begin{array}{c}
x_{1}^{\prime} \\
\vdots\\
y_{N}\\
\hat{y}_{N}\\
x_{3N+2}\\
u\end{array}\right]
\end{align*}

The Octave function \emph{schurOneMlatticeDoublyPipelined2Abcd} returns the state
variable description of a doubly-pipelined Schur one-multiplier lattice filter
(including the all-pass filter $Aap$, $Bap$, $Cap$ and $Dap$ output matrixes).

The Octave script \emph{schurOneMlatticeDoublyPipelined2Abcd\_symbolic\_test.m}
creates a symbolic state variable description of a doubly-pipelined Schur
one-multiplier lattice filter.
\subsection{\label{sec:State-variable-all-pass-doubly-pipelined-One-multiplier-Schur-lattice-filter}State variable description of an all-pass doubly-pipelined one-multiplier Schur lattice filter}
Figure~\ref{fig:State-variable-description-all-pass-doubly-pipelined-One-Multiplier-Lattice} shows only the all-pass part of a first order segment of the
doubly-pipelined Schur one-multiplier lattice filter of
Figure~\ref{fig:State-variable-description-doubly-pipelined-One-Multiplier-Lattice}.

\begin{figure}[!ht]
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_OneMultiplier_AllPass_Pipelined}
\caption{First order segment of an all-pass doubly pipelined Schur one-multiplier lattice filter.}
\label{fig:State-variable-description-all-pass-doubly-pipelined-One-Multiplier-Lattice}
\end{figure}

Construction of a state variable description of the all-pass doubly-pipelined
Schur one-multiplier lattice filter is summarised in
Algorithm~\ref{alg:Construction-state-variable-all-pass-doubly-pipelined-One-Multiplier-lattice}. 

\begin{algorithm}[!ht]
Given $\left\{k_{1},k_{2},\hdots,k_{N}\right\}$ and
$\left\{\epsilon_{1},\epsilon_{2},\hdots,\epsilon_{N}\right\}$:
\begin{algorithmic}
\State $\hat{y}_{0} = x_{1}$
\State $x_{1}^{\prime} = x_{2}$  
\For{$n=1,\hdots,N$}
\State $x_{2n}^{\prime}=-k_{n}\hat{y}_{n-1}+\left(1+k_{n}\epsilon_{n}\right)x_{2n+2}$
\State $x_{2n+1}^{\prime}=\left(1-k_{n}\epsilon_{n}\right)\hat{y}_{n-1}+k_{n}x_{2n+2}$
\State $\hat{y}_{n} = x_{2n+1}$
\EndFor
\State $x_{2N+2}^{\prime}=u$
\State $\hat{y}=\hat{y}_{N}$
\end{algorithmic}
\caption{Construction of a state variable description of the all-pass
  doubly-pipelined Schur one-multiplier lattice filter.}
\label{alg:Construction-state-variable-all-pass-doubly-pipelined-One-Multiplier-lattice}
\end{algorithm}

\subsection{\label{State-Variable-Description-Scaled-Normalised-IIR-Lattice-Filter}State variable description of the scaled-normalised IIR lattice filter}
In Figure~\ref{fig:State-variable-description-Scaled-Normalised-lattice},
Figure~\ref{fig:Normalised-scaled-lattice} is redrawn with $x_{n}^{\prime}$
corresponding to the input to state $x_{n}$ of the $n$-th section,
$y_{n}$ being the output of the $n$-th section and $\hat{y}_{n}$
the all-pass output of the $n$-th section.

\begin{figure}[!ht]
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_ScaledNorm_SV_derivation}
\caption{State variable description of the Schur Scaled-Normalised lattice
  filter.}
\label{fig:State-variable-description-Scaled-Normalised-lattice}
\end{figure}

Construction of the state variable description is summarised in  
Algorithm~\ref{alg:Construction-state-variable-Scaled-Normalised-lattice}
\footnote{The Octave function \emph{schurNSlattice} combines 
  $\sigma_{10}^{\left(0\right)}$ and $\sigma_{11}^{\left(1\right)}$}.

\begin{algorithm}[!ht]
\begin{algorithmic}
\State $\hat{y}_{0} = x_{1}$
\State $y_{0} = \sigma_{10}^{\left(0\right)}x_{1}$
\For{$n=1,\hdots,N-1$}
  \State $x_{n}^{\prime}=\sigma_{02}^{\left(n\right)}\hat{y}_{n-1}+\sigma_{00}^{\left(n\right)}x_{n+1}$
  \State $\hat{y}_{n}=\sigma_{22}^{\left(n\right)}\hat{y}_{n-1}+\sigma_{20}^{\left(n\right)}x_{n+1}$
  \State $y_{n}=\sigma_{11}^{\left(n\right)}y_{n-1}+\sigma_{10}^{\left(n\right)}x_{n+1}$
\EndFor
\State $x_{N}^{\prime}=\sigma_{02}^{\left(N\right)}\hat{y}_{N-1}+\sigma_{00}^{\left(N\right)}u$
\State $\hat{y}=\sigma_{22}^{\left(N\right)}\hat{y}_{N-1}+\sigma_{20}^{\left(N\right)}u$
\State $y=\sigma_{11}^{\left(N\right)}y_{N-1}+\sigma_{10}^{\left(N\right)}u$
\end{algorithmic}
\caption{Construction of a state variable description of the Scaled-Normalised
  Lattice.}
\label{alg:Construction-state-variable-Scaled-Normalised-lattice}
\end{algorithm}

The state variable description can be expressed as a series of matrix
multiplications linking the input and state outputs to the output
and the next state inputs:

\begin{align*}
\left[\begin{array}{c}
\hat{y}_{0}\\
y_{0}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{N}\\
u
\end{array}\right] & = \left[\begin{array}{cccccc}
1 & 0 & \cdots & \cdots & 0\\
\sigma_{10}^{\left(0\right)} & 0 & \cdots & & \vdots\\
0 & 1 & & & \\
\vdots & & \ddots & & \vdots\\
0 & & & 1 & 0 \\
0 & \cdots & \cdots & 0 & 1
\end{array}\right]\left[\begin{array}{c}
x_{1}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{N}\\
u
\end{array}\right]
\end{align*}

\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
\hat{y}_{1}\\
y_{1}\\
x_{3}\\
\vdots\\
x_{N}\\
u
\end{array}\right] & = \left[\begin{array}{ccccccc}
\sigma_{02}^{\left(1\right)} & 0 & \sigma_{00}^{\left(1\right)} & 0 & 0 & \cdots & 0\\
\sigma_{22}^{\left(1\right)} & 0 & \sigma_{20}^{\left(1\right)} & 0 &  &  & \vdots\\
0 & \sigma_{11}^{\left(1\right)} & \sigma_{10}^{\left(1\right)} & 0\\
0 & 0 & 0 & 1\\
\vdots &  &  &  & \ddots &  & \vdots\\
0 &  &  &  &  & 1 & 0\\
0 & \cdots &  &  & \cdots & 0 & 1
\end{array}\right]\left[\begin{array}{c}
\hat{y}_{0}\\
y_{0}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{N}\\
u
\end{array}\right]
\end{align*}

\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
x_{2}^{\prime}\\
\hat{y}_{2}\\
y_{2}\\
\vdots\\
u
\end{array}\right] & = \left[\begin{array}{ccccccc}
1 & 0 & 0 & 0 & 0 & \cdots & 0\\
0 & \sigma_{02}^{\left(2\right)} & 0 & \sigma_{00}^{\left(2\right)} &  &  & \vdots\\
0 & \sigma_{22}^{\left(2\right)} & 0 & \sigma_{20}^{\left(2\right)}\\
0 & 0 & \sigma_{11}^{\left(2\right)} & \sigma_{10}^{\left(2\right)}\\
\vdots &  &  &  &  & \ddots & \\
0 &  &  &  &  &  & 0\\
0 & \cdots &  &  & \cdots & 0 & 1
\end{array}\right]\left[\begin{array}{c}
x_{1}^{\prime}\\
\hat{y}_{1}\\
y_{1}\\
x_{3}\\
\vdots\\
x_{N}\\
u
\end{array}\right]
\end{align*}

\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
x_{2}^{\prime}\\
\vdots\\
x_{N-1}^{\prime}\\
\hat{y}_{N-1}\\
y_{N-1}\\
u
\end{array}\right] & = \left[\begin{array}{ccccccc}
1 & 0 & \cdots &  &  & \cdots & 0\\
0 & 1 &  &  &  &  & \vdots\\
\vdots &  & \ddots\\
0 &  &  & \sigma_{02}^{\left(N-1\right)} & 0 & \sigma_{00}^{\left(N-1\right)}\\
0 &  &  & \sigma_{22}^{\left(N-1\right)} & 0 & \sigma_{20}^{\left(N-1\right)} & \vdots\\
0 &  &  & 0 & \sigma_{11}^{\left(N-1\right)} & \sigma_{10}^{\left(N-1\right)} & 0\\
0 & \cdots &  &  &  & \cdots & 1
\end{array}\right]\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
\hat{y}_{N-2}\\
y_{N-2}\\
x_{N}\\
u
\end{array}\right]
\end{align*}

\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
x_{2}^{\prime}\\
x_{3}^{\prime}\\
\vdots\\
x_{N}^{\prime}\\
\hat{y}\\
y
\end{array}\right] & =  \left[\begin{array}{ccccccc}
1 & 0 & \cdots &  &  & \cdots & 0\\
0 & 1 &  &  &  &  & \vdots\\
\vdots &  &  \ddots&  &  &  & \vdots\\
0 &  &  &  & \sigma_{02}^{\left(N\right)} & 0 & \sigma_{00}^{\left(N\right)}\\
0 &  &  &  & \sigma_{22}^{\left(N\right)} & 0 & \sigma_{20}^{\left(N\right)}\\
0 & \cdots &  & \cdots & 0 & \sigma_{11}^{\left(N\right)} & \sigma_{10}^{\left(N\right)}
\end{array}\right]\left[\begin{array}{c}
x_{1}^{\prime}\\
x_{2}^{\prime}\\
\vdots\\
\hat{y}_{N-1}\\
y_{N-1}\\
u
\end{array}\right]
\end{align*}

The Octave function \emph{schurNSlattice2Abcd} returns the state variable
description of a normalised-scaled lattice filter (including the all-pass
filter $Cap$ and $Dap$ output matrixes).
\clearpage
\section{Roundoff Noise Calculation in Schur Lattice Filters}
In this section I rely on the state-variable analysis of round-off noise
presented by \emph{Roberts} and
\emph{Mullis}~\cite{RobertsMullis_DigitalSignalProcessing},~\cite{MullisRoberts_RoundoffNoiseInDigitalFiltersFrequencyTransformations},~\cite{MullisRoberts_SynthesisMinimumRoundoffNoiseDigitalFilters}
and the transposed signal flow graph analysis of
\emph{Parhi}~\cite[Section 12.7]{Parhi_VLSIDigitalSignalProcessingSystems}.

Lattice filter roundoff noise can be calculated by the $K$ and $W$
matrices derived from the state variable description of the filter.
An alternative method uses the Schur polynomials and the transposed
graph of the filter. To compute the output roundoff noise, the transfer
functions from the internal nodes to the output node are needed. These
are the same as the transfer functions from the input to the internal
nodes of the transposed filter. Again, these transfer functions can
be derived from the Schur decomposition or the state variable description.
In the following I try to distinguish between pipelining a filter to reduce the
latency of internal calculations and retiming a filter to determine the noise
gain without necessarily maintaining the desired filter transfer function.

\subsection{\label{sec:Round-off-normalised-scaled-lattice}Round-off noise of the normalised-scaled lattice filter}
\subsubsection{Calculation of the normalised-scaled lattice filter round-off noise with the transposed signal flow graph}
\noindent Figure~\ref{fig:Transposed-normalised-scaled} shows module
$m$ of $N,\ldots,1$ of the transposed graph of a normalised-scaled
lattice filter (with $k=\sigma_{20}=-\sigma_{02}$, and 
$k_{c}=\sqrt{1-k^{2}}=\sigma_{00}=\sigma_{22}$).

\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_TransposeScaledNorm}
\caption{Transposed normalised-scaled lattice filter module (after 
\emph{Parhi}~\cite[Fig. 12.24]{Parhi_VLSIDigitalSignalProcessingSystems}).}
\label{fig:Transposed-normalised-scaled}
\end{figure}

The transposed graph of the module gives:

\begin{align*}
\left[\begin{array}{c}
z^{-1}N_{m-1}\left(z\right)\\
D_{m-1}\left(z\right)\\
E_{m-1}\left(z\right)
\end{array}\right] & = \frac{1}{k_{c}}\left[\begin{array}{ccc}
1 & -\sigma_{10} & -k\\
0 & k_{c}\sigma_{11} & 0\\
-k & k\sigma_{10} & 1
\end{array}\right]\left[\begin{array}{c}
N_{m}\left(z\right)\\
D_{m}\left(z\right)\\
E_{m}\left(z\right)
\end{array}\right]
\end{align*}

For module $N$, the input, $D_{N}\left(z\right)$, and output, $N_{N}\left(z\right)$,
are given by the transfer function $H\left(z\right)=N\left(z\right)/D\left(z\right)$
and $E_{N}\left(z\right)=0$. Similarly, for the all-pass response, $D_{N}\left(z\right)=0$,
$N_{N}\left(z\right)=z^{N}D\left(z^{-1}\right)$ and $E_{N}\left(z\right)=D\left(z\right)$.
The transfer function polynomials of the modules to the right hand
of module $N$ are found by repeated matrix multiplication. Since
$D\left(z\right)$ is a Schur polynomial, the output noise variance due to round
off at each node is calculated from the coefficients of the Schur
orthonormal basis decomposition of these transfer function polynomials.

The Octave script \emph{butt3NS\_test.m}
uses the transposed transfer function to calculate the round-off noise 
of the normalised-scaled 3rd order low-pass Butterworth filter of the example
in Section~\ref{sub:Example-butt3NS-synthesis}. The coefficients of the 
lattice are floating-point, not truncated. Coefficient truncation implies a
different Schur basis and the polynomial division used to find the output noise
is inaccurate. Annotated output from \emph{butt3NS\_test.m} follows.

The filter cutoff frequency is
\begin{small}
\begin{verbatim}
fc = 0.050000
\end{verbatim}
\end{small}
The denominator and numerator polynomials are
\begin{small}
\begin{verbatim}
n = 0.0028982  0.0086946  0.0086946  0.0028982
\end{verbatim}
\end{small}
\begin{small}
\begin{verbatim}
d = 1.00000   -2.37409    1.92936   -0.53208
\end{verbatim}
\end{small}
The Schur orthonormal basis corresponding to the denominator polynomial
is
\begin{small}
\begin{verbatim}
S =  0.07045   0.00000   0.00000   0.00000
    -0.30483   0.31286   0.00000   0.00000
     0.78677  -1.59152   0.84670   0.00000
    -0.53208   1.92936  -2.37409   1.00000
\end{verbatim}
\end{small}
The Schur expansion of the numerator polynomial is
\begin{small}
\begin{verbatim}
c =  0.3053850  0.1034929  0.0183952  0.0028982
\end{verbatim}
\end{small}

The coefficients of filter sections (input/output at the right end
of each vector) are
\begin{small}
\begin{verbatim}
s10 =  0.3209629 0.0569565 0.0028982
s11 =  0.94709   0.99838   0.32297
s20 = -0.97432   0.92923  -0.53208
s00 =  0.22518   0.36951   0.84670
s02 =  0.97432  -0.92923   0.53208
s22 =  0.22518   0.36951   0.84670
\end{verbatim}
\end{small}
The noise gain of the filter (with un-quantised coefficients) is 
\begin{small}
\begin{verbatim}
ng =  1.1906
\end{verbatim}
\end{small}
The nodes corresponding to $D_{0}\left(z\right)$ and $E_{0}\left(z\right)$,
that is at the output of state $x_{1}$, make no contribution to round-off
noise and are omitted from the noise gain. The noise gain can be reduced
slightly by summing the output in one pass (assuming a double-length
accumulator holds the intermediate sums along the top edge of
Figure~\ref{fig:Butterworth-3rd-order}).

The noise gain of the associated all-pass filter is
\begin{small}
\begin{verbatim}
ngap =  5.0000
\end{verbatim}
\end{small}
Recall that for a unit variance white noise input the internal nodes
of the normalised-scaled filter have unit signal variance and that
the transfer functions from the internal nodes of the all-pass filter
to the all-pass output have unity gain by definition. Therefore the
noise gain of the all-pass filter is simply the number of internal
nodes at which arithmetic truncation occurs. In this case there are
five internal nodes in the all-pass filter at which round-off occurs.
Three of these are at the inputs to the internal delay element state
storage and two are at calculation of the reverse Schur polynomial
output, $\tilde{\Phi}_{i}\left(z\right)$. By convention the third of
the reverse Schur polynomial output truncations is represented separately
as the all-pass filter output truncation. (Truncation of the internal
reverse Schur polynomial outputs could be avoided by storing them
in temporary double precision storage). 

For comparison the noise gain of a globally optimised Butterworth filter
is $ngopt=0.47049$ and for a direct form implementation, $ngdir=68.980$.
The corresponding noise gains for the globally optimised and direct-form
all-pass filters are $ngoptap=3.0000$ and $ngdirap=818.90$.

The filters were tested with a uniformly distributed random noise
signal with variance $0.5$ of full-scale. The filter outputs were
calculated with floating point arithmetic and again with rounding-to-nearest
truncation and $10$ bit word storage. 

Figure~\ref{fig:Freq-response-butt3NS} shows the amplitude response of the 
Schur normalised-scaled lattice implementation of the Butterworth filter and
all-pass filter determined from the cross-correlation of the filter input and
outputs.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{butt3NS_test_response}}
\caption{Amplitude response of the 3rd order Butterworth filter implemented with
  a Schur normalised-scaled lattice structure.}
\label{fig:Freq-response-butt3NS}
\end{figure}

The estimated and simulated round-off noise variances are for the Schur lattice
implementation of the Butterworth filter ($\sigma^{2}=\left(1+ng\right)/12$):
\begin{small}
\begin{verbatim}
est_varyd =  0.1825
varyd =  0.1819
\end{verbatim}
\end{small}
and for the Schur lattice all-pass filter
\begin{small}
\begin{verbatim}
est_varyapd =  0.5000
varyapd =  0.4913
\end{verbatim}
\end{small}
Similarly, the estimated and simulated round-off noise variances for the
globally optimised Butterworth filter are:
\begin{small}
\begin{verbatim}
est_varyoptd =  0.1225
varyoptd =  0.1215
\end{verbatim}
\end{small}
and the estimated and simulated round-off noise variances for the scaled 
direct-form Butterworth filter are:
\begin{small}
\begin{verbatim}
est_varydird =  5.8317
varydird =  1.8148
\end{verbatim}
\end{small}
The factor of about $3$ discrepancy between the estimated and measured
output roundoff noise of the scaled direct-form filter suggests that the
output roundoff noise of that filter is correlated with the input signal
rather than having the uniform random distribution assumed in the noise 
calculations. Figure~\ref{fig:Freq-response-butt3NS-direct-form-noise} 
compares the response of the output roundoff noise of the scaled direct-form 
implementation to that of the globally optimised filter.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{butt3NS_test_response_direct_form_noise}}
\caption{Comparison of the amplitude response of the output noise of the 3rd
  order Butterworth filter when implemented with a scaled direct-form and
  globally optimised state variable structure.}
\label{fig:Freq-response-butt3NS-direct-form-noise}
\end{figure}

The standard deviations of the internal states of the Schur lattice filter are
\begin{small}
\begin{verbatim}
stdxx =  131.21   129.39   127.97
\end{verbatim}
\end{small}
The standard deviations of the internal states of the globally-optimum and
scaled direct-form filters are
similar. Figures~\ref{fig:State-variables-butt3NS-noise-schur-lattice},~\ref{fig:State-variables-butt3NS-noise-global-optimum}
and~\ref{fig:State-variables-butt3NS-noise-direct-form} show part of the state 
trajectories for the Schur lattice, globally-optimised and direct-form
state variable versions of the Butterworth filter with a random noise input.
 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{butt3NS_test_sv_noise_schur_lattice}}
\caption{Internal states in the 3rd order Butterworth filter implemented in a
  normalised-scaled Schur lattice structure with a random noise input.}
\label{fig:State-variables-butt3NS-noise-schur-lattice}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{butt3NS_test_sv_noise_global_optimum}}
\caption{Internal states in the 3rd order Butterworth filter implemented 
  in the globally optimised state variable structure with a random noise input.}
\label{fig:State-variables-butt3NS-noise-global-optimum}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{butt3NS_test_sv_noise_direct_form}}
\caption{Internal states in the 3rd order Butterworth filter implemented 
  in a direct-form structure with a random noise input.}
\label{fig:State-variables-butt3NS-noise-direct-form}
\end{figure}

Figure~\ref{fig:State-variables-butt3NS-sine-schur-lattice} 
shows part of the state trajectories for the Schur lattice implementation of
the Butterworth filter in response to a sine wave input.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{butt3NS_test_sv_sine_schur_lattice}}
\caption{Internal states in the 3rd order Butterworth filter implemented 
  with a Schur lattice structure with a sine wave input.}
\label{fig:State-variables-butt3NS-sine-schur-lattice}
\end{figure}

\subsubsection{\label{sec:Calc-normalised-scaled-round-off-noise-retimed-state-variable}Calculation of the normalised-scaled lattice filter round-off noise with a retimed state-variable description}
\emph{Parhi}~\cite[Chapter 12, p. 450]{Parhi_VLSIDigitalSignalProcessingSystems} 
suggests that the normalised-scaled lattice filter round-off noise variance can
also be determined from the state variable representation if the filter is
slowed and retimed as shown in Figure~\ref{fig:Slowed-and-retimed-3rdButt-Norm}.
Each intermediate node is now associated with a state. The additional states
alter the overall transfer function but the round-off noise gains are unchanged.

\begin{figure}[!ht]
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{Example_Butt3NS_SV_retimed}
\caption{Slowed and retimed normalised-scaled lattice for the 3rd order 
  Butterworth example.}
\label{fig:Slowed-and-retimed-3rdButt-Norm}
\end{figure}

The Octave function \emph{schurNSlatticeRetimedNoiseGain} converts the Schur
normalised-scaled lattice implementation to a retimed state variable form
used to calculate the noise gains. The Octave script \emph{butt3NSSV\_test.m}
demonstrates roundoff noise
calculations in the retimed state variable form. The Butterworth and all-pass
filter noise gains with floating-point coefficients are found to be the same as
those for the transposed filter calculation above. With $10$ bit $2$ signed-digit
coefficients the retimed state variable form of the Schur lattice Butterworth
and all-pass filters have noise gains $ng=1.1334$ and $ngap=5.6989$. The
equivalent floating point signed-digit coefficients are calculated by the
Octave function \emph{flt2SD} which calls \emph{bin2SD}. The latter function
approximates an integer by adding successive signed-digits\footnote{
\emph{Parhi}~\cite[Section 13.6.1, p.507]{Parhi_VLSIDigitalSignalProcessingSystems}
shows an algorithm that calculates the complete signed-digit representation.
The Octave function \emph{bin2SPT} and \emph{oct}-file \emph{bin2SPT.cc}
implement this algorithm.}. The \emph{oct}-file \emph{bin2SD.cc} implements a 
C++ version of \emph{bin2SD}. The filter amplitude responses for the
corresponding Butterworth and all-pass filters with $10$-bit $2$-signed-digit
coefficients are shown in Figure~\ref{fig:Freq-response-butt3NSSV}.

\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{butt3NSSV_test_response}}
\caption{Amplitude response of the 3rd order Butterworth filter implemented
  with a normalised-scaled lattice structure and 10-bit 2 signed-digit
  coefficients.}
\label{fig:Freq-response-butt3NSSV}
\end{figure}

The response demonstrates a drawback of the normalised-scaled lattice filters:
they are not \emph{structurally loss-less} in the sense of Vaidyanathan et
al.~\cite{VaidyanathanMitraNuevo_LowSensitivityIIRDigitalFilters,VaidyanathanMitra_LowPassbandSensitivityDigitalFilters}
(see Appendix~\ref{app:Low-passband-sensitivity-IIR-digital-filters}). The
normalised-scaled lattice does not preserve the all-pass characteristic when its
coefficients are truncated.

\subsubsection{\label{sec:Frequency-transformations-and-normalised-scaled-lattice-filter-round-off-noise}Frequency transformations and Schur normalised-scaled lattice filter round-off noise}
Section~\ref{sec:Frequency-Transformations-of-State-Variable-Filters} shows
the frequency transformation of a state variable filter. 
Section~\ref{sec:Frequency-transformations-and-round-off-noise} shows some
results, given by \emph{Mullis} and \emph{Roberts}~\cite[Section III]
{MullisRoberts_RoundoffNoiseInDigitalFiltersFrequencyTransformations},
concerning the noise gain of a frequency transformed state variable filter. 
\emph{Koshita et al.}~\cite{Koshita_et_al_GramianPreservingFrequencyTransformationNormalisedLattice} 
point out that the normalised-scaled Schur lattice all-pass filter has 
controllability and observability Grammians $K=W=I$. It follows from 
Equation~\ref{eqn:Frequency-transformations-and-round-off-noise-K-W-Q} that 
the frequency transformed filter constructed with the state variable 
implementation of that Schur normalised-scaled all-pass lattice 
filter has the same noise gain as the globally optimised implementation of the
frequency transformed filter (see 
Section~\ref{sec:Minimisation-of-round-off-noise}). Further, the 
state-transition matrix of the lattice all-pass frequency transformation filter
is Hessenberg in form so the state-transition matrix of the frequency 
transformed filter has many zero entries. The Octave function
\emph{tfp2schurNSlattice2Abcd} implements the frequency transformation of a 
prototype filter as follows:
\begin{enumerate} 
\item construct the state variable implementation, 
$\left\{\alpha,\beta,\gamma,\delta\right\}$, of the Schur normalised-scaled
lattice filter corresponding to the all-pass frequency transformation, 
$F\left(z\right)$
\item construct the globally optimised state-variable implementation,
$\left\{a,b,c,d\right\}$, of the low-pass filter prototype, $H\left(z\right)$
\item construct the state variable implementation, $\left\{A,B,C,D\right\}$,
of the frequency transformed filter, $H\left(F\left(z\right)\right)$
\end{enumerate}

The Octave script \emph{tfp2schurNSlattice2Abcd\_test.m} exercises 
\emph{tfp2schurNSlattice2Abcd} with the 5th order elliptic low-pass to 
multiple stop-band filter example of 
Section~\ref{sec:example-frequency-transformations-of-5-th-order-elliptic-filter}
shown in Figure~\ref{fig:tfp2g-bs}.

Table~\ref{tab:Schur-NS-lattice-frequency-transformation-example} shows the 
number of non-zero coefficients, the noise gain and the estimated noise variance
in bits of the multiple band-stop filter implemented by 
\emph{tfp2schurNSlattice2Abcd}, a globally optimised state variable filter, 
a Schur normalised-scaled lattice filter and a Schur one-multiplier lattice 
filter (neglecting the one-multiplier state scaling).
\input{tfp2schurNSlattice2Abcd_test.tab}

\subsection{Round-off noise of the one multiplier lattice filter}
\subsubsection{Calculation of the one multiplier lattice filter round-off noise with the transposed signal flow graph}
Figure~\ref{fig:Transposed-One-Multiplier} shows module $m$ of $N,\ldots,1$
of the transposed graph of a one multiplier lattice filter.

\begin{figure}[!ht]
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schur_TransposeOneMult}
\caption{Transposed one multiplier lattice filter module.}
\label{fig:Transposed-One-Multiplier}
\end{figure}

The transposed graph of the module gives
\begin{align*}
E_{m-1} & = -\epsilon_{m}^{2}k_{m}z^{-1}N_{m-1}+\left(1-k_{m}\epsilon_{m}\right)E_{m}\\
N_{m} & = \left(1+\epsilon_{m}k_{m}\right)z^{-1}N_{m-1}+c_{m}D_{m}+k_{m}E_{m}\\
\left(1+\epsilon_{m}k_{m}\right)z^{-1}N_{m-1} & = N_{m}-c_{m}D_{m}-k_{m}E_{m}\\
\left(1+\epsilon_{m}k_{m}\right)E_{m-1} & = -k_{m}N_{m}+c_{m}k_{m}D_{m}+E_{m}
\end{align*}
Finally
\begin{align*}
\left[\begin{array}{c}
z^{-1}N_{m-1}\left(z\right)\\
D_{m-1}\left(z\right)\\
E_{m-1}\left(z\right)
\end{array}\right] & = \frac{1}{1+\epsilon_{m}k_{m}}\left[\begin{array}{ccc}
1 & -c_{m} & -k_{m}\\
0 & 1+\epsilon_{m}k_{m} & 0\\
-k_{m} & c_{m}k_{m} & 1
\end{array}\right]\left[\begin{array}{c}
N_{m}\left(z\right)\\
D_{m}\left(z\right)\\
E_{m}\left(z\right)
\end{array}\right]
\end{align*}
The single-multiplier lattice basis functions, $\Lambda_{i}\left(z\right)$,
are orthogonal but not orthonormal. The basis functions, 
$\Phi_{i}\left(z\right)$,
of the normalised-scaled lattice are orthonormal so, for a unit-power
white noise input, each node of the normalised-scaled lattice has
unit-power. Equation~\ref{eq:OneMultAmplitude} shows the expected
power at each lattice node of the unscaled one multiplier lattice.
Recall that this follows from the definition of the inner product
of Schur polynomials and Parseval's equality:
\begin{align*}
\| g_{i}\| _{2}^{2} & = \frac{1}{2\pi \imath}\oint G\left(z\right)G_{i}\left(z^{-1}\right)\frac{dz}{z}
\end{align*}
where $G_{i}\left(z\right)$ is the $z$-transform of $g_{i}$, the
unit-impulse response from internal node $i$ to the output. Similarly,
for the scaled filter with unit-impulse response from the input to
internal node $i$, $f_{i}(k)$, the $\ell_{2}$ scaling rule gives
\begin{align*}
\| f_{i}\| ^{2} & = \sum_{k=0}^{\infty}f_{i}^{2}\left(k\right)=1
\end{align*}
The noise gain calculation assumes that there is an equivalent white
noise input at the $i$-th node of variance $q^{2}/12$ where $q$
is the quantisation step size. The noise at the output is due to this
node is $q\| g_{i}\| ^{2}/12$. If the filter is
not scaled then the unit impulse response from the input to internal
node $i$ is not unity. The filter is scaled by dividing coefficients
on branches entering node $i$ by $\| f_{i}\| $
and multiplying coefficients on branches leaving the $i$-th node
by $\| f_{i}\| $. Therefore the output noise variance
for scaled filters is 
\begin{align*}
\sigma^{2} & = \frac{q^{2}}{12}\sum_{i}\| f_{i}\| ^{2}\| g_{i}\| ^{2}
\end{align*}
The Octave function \emph{schurOneMlatticeFilter} implements this scaling.

The Octave script \emph{butt3OneM\_test.m}
implements a 3rd order Butterworth filter with the single-multiplier
lattice structure. Annotated results of the script follow. 

The multiplier and sign coefficients are
\begin{small}
\begin{verbatim}
k = -0.97432   0.92923  -0.53208
epsilon = -1  -1  -1
\end{verbatim}
\end{small}
The scaling factors for each section are
\begin{small}
\begin{verbatim}
p =   3.03862   0.34657   1.80947
\end{verbatim}
\end{small}
The numerator polynomial expands in the orthonormal Schur basis, 
$\Phi_{i}\left(z\right)$, found above, as
\begin{small}
\begin{verbatim}
c =  0.1005013   0.2986163   0.0101661   0.0028982
\end{verbatim}
\end{small}
The scaled Butterworth filter noise gain with floating-point coefficients is
\begin{small}
\begin{verbatim}
ng = 0.98228
\end{verbatim}
\end{small}
and the scaled all-pass noise gain is
\begin{small}
\begin{verbatim}
ngap =  5.0000
\end{verbatim}
\end{small}
Using the $10$-bit random test signal above, the estimated and measured 
round-off noise variance at the Butterworth output is
\begin{small}
\begin{verbatim}
est_varyd =  0.16519
varyd =  0.1654
\end{verbatim}
\end{small}
and at the all-pass output the estimated and measured round-off noise variance is
\begin{small}
\begin{verbatim}
est_varyapd = 0.50000
varyapd = 0.4913
\end{verbatim}
\end{small}
For the scaled filter, the signal at each internal unit delay storage
element has standard deviation 
\begin{small}
\begin{verbatim}
stdxf =   131.21   129.39   127.96
\end{verbatim}
\end{small}
Note that the noise gain for the low-pass filter is slightly smaller than
for the normalised-scaled lattice filter. 
\subsubsection{Calculation of the one multiplier lattice filter round-off noise with a retimed state-variable description}
The single-multiplier lattice round-off noise variance can also be determined
from the state variable representation if the signal flow graph is slowed
and retimed as shown in Figure~\ref{fig:Slowed-and-retimed-3rdButt-Single-Mult}.
Each intermediate node is now associated with a state. The additional
states alter the overall transfer function but the round-off noise
gains are unchanged.

\begin{figure}[!ht]
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{Example_Butt3OneM_SV_retimed}
\caption{Slowed and retimed single-multipler lattice for the 3rd order
  Butterworth example.}
\label{fig:Slowed-and-retimed-3rdButt-Single-Mult}
\end{figure}

The state-variable equations for this single-multiplier lattice example
after slowing and re-timing are calculated in the Octave function 
\emph{schurOneMlatticeRetimedNoiseGain}. The Octave function 
\emph{schurOneMlatticeFilter} calculates the upper, Butterworth output, edge of 
Figure~\ref{fig:One-multiplier-lattice-structure} in a single operation,
ie: with a single large accumulator, and the lower, all-pass output, edge
with separate truncated accumulations. On the other hand, the Octave function
\emph{svf} implements a general
state-variable filter with truncated accumulations for each state and a wide
accumulator for both the outputs. The round-off noise estimation in 
\emph{schurOneMlatticeRetimedNoiseGain} illustrates that the retiming method of 
calculating noise gain is much more flexible than the transposed filter 
method. In addition, as noted in 
Section~\ref{sec:Round-off-normalised-scaled-lattice}, the Schur basis is not 
truncated at the same time as the lattice coefficients but is still used
to calculate the noise gain after truncation. Consequently, it is 
simpler to use the state-variable description to calculate the round-off noise
of the one multiplier lattice with truncated coefficients. 

The \emph{schurOneMlatticeRetimedNoiseGain} function can calculate round-off 
noise gain for three different one multiplier lattice filter implementations by 
selecting the states included through the \emph{filterStr} argument:
\begin{itemize}
\item For ``\textbf{schur}'' \emph{schurOneMlatticeFilter} calculates the 
  Butterworth  output (the upper row of
  Figure~\ref{fig:Slowed-and-retimed-3rdButt-Single-Mult}) in a single
wide accumulator and ignores the states on the top edge 
\item For ``\textbf{ABCD}'' \emph{svf} calculates both the Butterworth output 
and the all-pass output in wide accumulators and ignores the states on both
the top and bottom edges
\end{itemize}
In both these cases, states $x_{1}$ and $x_{2}$ in
Figure~\ref{fig:Slowed-and-retimed-3rdButt-Single-Mult} do not contribute to the
round-off noise. (In the case of $x_{2}$, $c_{0}$ is included in the 
calculation of state $x_{5}$).

The Octave script \emph{butt3OneMSV\_test.m} implements this state-variable 
description and calculates the round-off noise. The results of the script are 
shown in the following. 

When filter type \emph{``schur''} is selected the round-off noise gains 
for floating-point filter coefficients calculated with the Octave function
\emph{schurOneMlatticeRetimedNoiseGain} match those found with
\emph{schurOneMlatticeNoiseGain}.

When filter type \emph{``ABCD''} is selected the Butterworth filter noise
gain is $ngABCD=0.75000$ and the all-pass noise gain is $ngABCDap=3.0000$.

With floating-point coefficients, the globally optimised state-variable
implementation has a noise gain of $ngopt=0.47049$ for the Butterworth filter
and $ngoptap=3.0000$ for the all-pass filter.

After truncating the $k$ and $c$ coefficients to $10$ bit 3-signed-digits the
Butterworth and all-pass noise gains were $ngf=1.1019$ and $ngfap=5.0000$
respectively. Note that the state scaling factors, $p$, are not truncated. 
With $10$ bit 2 signed-digit coefficients (as used for the normalised-scaled 
lattice in
Section~\ref{sec:Calc-normalised-scaled-round-off-noise-retimed-state-variable})
the passband response of the filter was unacceptable.

With rounding-to-nearest arithmetic truncation in the accumulator, the 
estimated and measured round-off noise variance of the one multiplier Schur
lattice filter with 10-bit 3-signed-digit truncated coefficients are, for 
the Butterworth filter:
\begin{small}
\begin{verbatim}
est_varyd =  0.1752
varyd =  0.1740
\end{verbatim}
\end{small}
and for the allpass filter:
\begin{small}
\begin{verbatim}
est_varyapd =  0.5000
varyapd =  0.4931
\end{verbatim}
\end{small}
The standard deviations of the internal states of the filter are
\begin{small}
\begin{verbatim}
stdxf = 137.07   129.01   127.79
\end{verbatim}
\end{small}

Figure~\ref{fig:Butt3OneMSV-Resp-Schur-lattice} shows the amplitude responses of
the filter found by cross-correlation of the input and Butterworth and all-pass
filter outputs when the filter is calculated as a Schur scaled one multiplier
lattice with 10-bit 3-signed-digit truncated coefficients in the Octave 
function \emph{schurOneMlatticeFilter}.

\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{butt3OneMSV_test_response_schur_lattice}}
\caption{Amplitude responses of the slowed and retimed one multiplier lattice
  3rd order Butterworth filter implemented in Schur lattice form with 10-bit
  3-signed-digit truncated coefficients.}
\label{fig:Butt3OneMSV-Resp-Schur-lattice}
\end{figure}

\subsection{Round-off noise of the pipelined one multiplier lattice filter}
The Octave script \emph{schurOneMlatticePipelinedFilter\_test.m} demonstrates
calculation of the round-off noise of the pipelined one-multiplier lattice
filter from the state variable description, as shown in
Section~\ref{sec:Estimation-of-output-round-off-noise-in-state-variable-filters}.

\section{\label{sec:Examples-pipelining-Schur-lattice-filters}Examples of pipelining Schur lattice filters}
\subsection{\label{sec:Pipelining-NS-Schur-lattice-filter}Pipelining a
4th order Schur normalised-scaled lattice filter}
The normalised-scaled lattice filter of order N shown in
Figure~\ref{fig:Normalised-scaled-lattice} has a delay-free path, or latency,
of $N$ adds and $N$ multiplies to the tapped and all-pass outputs, $y$ and
$y_{ap}$ respectively.
Section~\ref{sec:Factored-state-variable-filters-with-fractional-delays}
describes a procedure for inserting fractional delays in the signal flowgraph
of the filter to reduce the length of the delay free path. The clock rate of
the resulting filter is a multiple of the sample rate.
\emph{Parhi}~\cite[Chapter 4]{Parhi_VLSIDigitalSignalProcessingSystems}
discusses formal methods for pipelining a signal flow graph.
Figure~\ref{subfig:example-normalised-scaled-Schur-lattice-filter} shows a
simplified view of a normalised-scaled Schur lattice filter implementing a
$4$-th order transfer function with a denominator polynomial having
coefficients only in $z^{-2}$.
Figure~\ref{subfig:example-normalised-scaled-Schur-lattice-filter-after-pipelining}
shows the example filter after redistributing the delay in each loop of the
graph so that the total delay around that loop is unchanged. Each state update
in the resulting filter has the form \emph{$pq+rs$}. In this case the filter
group delay is increased by $2$ samples. In general, this pipelining scheme
increases the group delay by $1$ sample for each second-order section.

\begin{figure}[!ht]
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{Example_Schur_pipelinedA}
\caption{In original form.}
\label{subfig:example-normalised-scaled-Schur-lattice-filter}
\vspace{1cm}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{Example_Schur_pipelinedB}
\caption{After retiming.}
\label{subfig:example-normalised-scaled-Schur-lattice-filter-after-pipelining}
\end{subfigure}
\caption{Signal flow graph of a 4th order normalised-scaled Schur lattice filter
  with a denominator polynomial having coefficients only in $z^{-2}$.}
\end{figure}

Following the notation of 
Figure~\ref{fig:State-variable-description-Scaled-Normalised-lattice}, the state 
variable equations for the filter shown in 
Figure~\ref{subfig:example-normalised-scaled-Schur-lattice-filter-after-pipelining} are:
\begin{align*}
x_{1}\left(k+1\right)  &= x_{3}\left(k\right) \\
x_{2}\left(k+1\right)  &= \sigma_{11}^{\left(1\right)}x_{1}\left(k\right) +
                         \sigma_{10}^{\left(1\right)}x_{3}\left(k\right) \\
x_{3}\left(k+1\right)  &= \sigma_{02}^{\left(2\right)}x_{1}\left(k\right) + 
                        \sigma_{00}^{\left(2\right)}x_{9}\left(k\right) \\
x_{4}\left(k+1\right)  &= x_{9}\left(k\right) \\
x_{5}\left(k+1\right)  &= x_{9}\left(k\right) \\
x_{6}\left(k+1\right)  &= \sigma_{11}^{\left(2\right)}x_{2}\left(k\right) +
                         \sigma_{10}^{\left(2\right)}x_{4}\left(k\right) \\
x_{7}\left(k+1\right)  &= \sigma_{22}^{\left(2\right)}x_{1}\left(k\right) +
                        \sigma_{20}^{\left(2\right)}x_{9}\left(k\right) \\
x_{8}\left(k+1\right)  &= \sigma_{10}^{\left(3\right)}x_{5}\left(k\right) +
                        \sigma_{11}^{\left(3\right)}x_{6}\left(k\right) \\
x_{9}\left(k+1\right)  &= \sigma_{02}^{\left(4\right)}x_{7}\left(k\right) + 
                        \sigma_{00}^{\left(4\right)}u\left(k\right) \\
x_{10}\left(k+1\right) &= x_{11}\left(k\right) \\
x_{11}\left(k+1\right) &= u\left(k\right) \\
y\left(k\right)       & = \sigma_{11}^{\left(4\right)}x_{8}\left(k\right) +
                          \sigma_{10}^{\left(4\right)}x_{10}\left(k\right) \\
y_{ap}\left(k\right)   &= \sigma_{22}^{\left(4\right)}x_{7}\left(k\right) +
                         \sigma_{20}^{\left(4\right)}u\left(k\right)
\end{align*}

The Octave script \emph{schur\_pipelined\_test.m} designs a $4$-th order low-pass
filter with cutoff frequency $0.05f_{S}$ and denominator coefficients in
$z^{-2}$. The script minimises the amplitude response error with the Octave
\emph{fminunc} function. The barrier function of \emph{Tarczynski et
al.}~\cite{TarczynskiCainHermanowiczRojewski_WISEMethodDesignIIRFilters} is 
added to the response error to constrain the locations of the roots of the 
denominator polynomial and ensure that the filter is stable. The barrier 
function is implemented in Octave function \emph{WISEJ.m}. 
Figure~\ref{fig:schur-pipelined-output-response} shows the simulated amplitude 
response of the pipelined Schur lattice filter.

\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schur_pipelined_test_output_response}}
\caption{Simulated amplitude response of the pipelined 4th order
  normalised-scaled Schur lattice filter.} 
\label{fig:schur-pipelined-output-response}
\end{figure}
\clearpage
\subsection{\label{sec:Pipelining-OneM-Schur-lattice-filter}Pipelining a
6th-order Schur one-multiplier lattice filter}
Figure~\ref{fig:example-pipelining-a-one-multplier-Schur-lattice-filter} shows
the signal flow graph of a retimed 6th order one-multiplier Schur lattice filter
with a denominator polynomial having coefficients only in $z^{-2}$. Both filter
implementations have the same number of delays around the corresponding loops of
their signal flow graphs. Retiming the filter reduces the latency in the
calculation of the outputs and does not change the amplitude and group delay
responses. If $N$ is the filter order then the pipelined filter has an additional
$\frac{N}{2}-1$ states.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schurOneMR2lattice}
\caption{Signal flow graph of a 6th order one-multiplier Schur lattice filter
  with a denominator polynomial having coefficients in $z^{-2}$.}
\label{subfig:example-one-multplier-Schur-lattice-filter}
\vspace{5mm}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schurOneMR2lattice_pipelined}
\caption{Signal flow graph of a 6th order one-multiplier Schur lattice filter
  with a denominator polynomial having coefficients in $z^{-2}$ after
  pipelining.}
\label{subfig:example-pipelined-one-multplier-Schur-lattice-filter}
\vspace{5mm}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{schurOneMR2lattice_allpass_pipelined}
\caption{Signal flow graph of a 6th order one-multiplier Schur all-pass lattice
  filter with a denominator polynomial having coefficients in $z^{-2}$ after
  pipelining.}
\label{subfig:example-pipelined-one-multplier-Schur-all-pass-lattice-filter}
\end{subfigure}
\caption{Original and pipelined signal flow graphs of a 6th order one-multiplier
  Schur lattice filter with a denominator polynomial having coefficients in
  $z^{-2}$ only. The number of delays around each loop of the signal flow
  graph is unchanged.}
\label{fig:example-pipelining-a-one-multplier-Schur-lattice-filter}
\end{figure}

Algorithm~\ref{alg:State-variable-pipelined-One-Multiplier-R2-lattice}
shows a state variable description of the pipelined Schur one-multiplier lattice
filter with coefficients in $z^{-2}$.
\begin{algorithm}[!htbp]
Given $N$ even, $\left\{k_{2},k_{4}\hdots,k_{N}\right\}$,
$\left\{\epsilon_{2},\epsilon_{4},\hdots,\epsilon_{N}\right\}$ and
$\left\{c_{0},c_{1},\hdots,c_{N}\right\}$:
\begin{algorithmic}
\State $x^{\prime}_{1}=x_{2}$
\State $x^{\prime}_{2}=-k_{2}x_{1}+\left(1+k_{2}\epsilon_{2}\right)x_{5}$
\State $x^{\prime}_{3}=\left(1-k_{2}\epsilon_{2}\right)x_{1}+k_{2}x_{5}$
\State $x^{\prime}_{4}=c_{0}x_{1}+c_{1}x_{2}+c_{2}x_{5}$

\For{$n=2,\hdots,\frac{N}{2}-1$}
\State $x^{\prime}_{3n-1}=-k_{2n}x_{3n-3}+
\left(1+k_{2n}\epsilon_{2n}\right)x_{3n+2}$
\State $x^{\prime}_{3n}=\left(1-k_{2n}\epsilon_{2n}\right)x_{3n-3}+ k_{2n}x_{3n+2}$
\State $x^{\prime}_{3n+1}=x_{3n-2}+c_{2n-1}x_{3n-1}+c_{2n}x_{3n+2}$
\EndFor

\State $x_{3\frac{N}{2}-1}^{\prime} = -k_{N}x_{3\frac{N}{2}-3}+
\left(1+k_{N}\epsilon_{N}\right)u$
\State $y = x_{3\frac{N}{2}-2}+c_{N-1}x_{3\frac{N}{2}-1}+c_{N}u$
\State $\hat{y} = \left(1-k_{N}\epsilon_{N}\right)x_{3\frac{N}{2}-3}+k_{N}u$
\end{algorithmic}
\caption{Construction of a state variable description of the pipelined Schur
  one-multiplier lattice filter with denominator coefficients in $z^{-2}$ only.}
\label{alg:State-variable-pipelined-One-Multiplier-R2-lattice}
\end{algorithm}

Similarly,
Algorithm~\ref{alg:State-variable-pipelined-One-Multiplier-R2-all-pass-lattice}
shows a state variable description of the pipelined Schur one-multiplier all-pass
lattice filter with coefficients in $z^{-2}$.
\begin{algorithm}[!htbp]
Given $N$ even, $\left\{k_{2},k_{4}\hdots,k_{N}\right\}$ and
$\left\{\epsilon_{2},\epsilon_{4},\hdots,\epsilon_{N}\right\}$:
\begin{algorithmic}
\State $x^{\prime}_{1}=x_{2}$
\For{$n=1,\hdots,\frac{N}{2}-1$}
\State $x^{\prime}_{2n}=-k_{2n}x_{2n-1}+ \left(1+k_{2n}\epsilon_{2n}\right)x_{2n+2}$
\State $x^{\prime}_{2n+1}=\left(1-k_{2n}\epsilon_{2n}\right)x_{2n-1}+ k_{2n}x_{2n+2}$
\EndFor
\State $x_{N}^{\prime} = -k_{N}x_{N-1}+\left(1+k_{N}\epsilon_{N}\right)u$
\State $\hat{y} = \left(1-k_{N}\epsilon_{N}\right)x_{N-1}+k_{N}u$
\end{algorithmic}
\caption{Construction of a state variable description of the pipelined Schur
  one-multiplier all-pass lattice filter with denominator coefficients in
  $z^{-2}$ only.}
\label{alg:State-variable-pipelined-One-Multiplier-R2-all-pass-lattice}
\end{algorithm}

The Octave function \emph{schurOneMR2lattice2Abcd},
exercised by the Octave script \emph{schurOneMR2lattice2Abcd\_test.m},
implements pipelining of a one-multiplier Schur lattice filter with a denominator
polynomial having coefficients in $z^{-2}$ only.
The Octave script \emph{schurSchurOneMR2lattice2Abcd\_symbolic\_test.m} creates a
symbolic state variable description of the Schur one multiplier lattice filter
with a denominator polynomial having coefficients in $z^{-2}$ only.

\subsection{Frequency transformations of pipelined Schur lattice filters}
An implementation of a rational transfer function having
demominator coefficients only in powers of $z^{-2}$ can be 
pipelined so that the resulting filter is suitable for hardware 
implementation. This section gives an example of the effect of frequency
transformations on such a filter transfer function. The Octave script
\emph{freq\_trans\_structure\_test.m} designs an $8$-th order
low-pass filter prototype with a denominator polynomial having coefficients only
in powers of $z^{-2}$. The script minimises the amplitude response error with
the Octave \emph{fminunc} function and uses the WISE method of \emph{Tarczynski
  et  al.}~\cite{TarczynskiCainHermanowiczRojewski_WISEMethodDesignIIRFilters}
to ensure that the filter is stable. The transfer function numerator and
denominator polynomials for the low-pass filter prototype are, respectively:
\begin{small}
\begin{verbatim}
n = [   0.0857526461,   0.2721065334,   0.5924693555,   0.8872367637, ...
        1.0183181186,   0.8872367931,   0.5924694628,   0.2721066332, ...
        0.0857528266 ];
dR = [  1.0000000000,   0.0000000000,   2.0227725009,   0.0000000000, ...
        1.3779306177,   0.0000000000,   0.3584982390,   0.0000000000, ...
        0.0507148469 ];
\end{verbatim}
\end{small}
Figure~\ref{fig:freq-transform-structure-lowpass} shows the response of 
the low-pass prototype filter. 
Figure~\ref{fig:freq-transform-structure-bandpass-A} shows the response of a
band-pass filter generated from the low-pass prototype filter with the
following frequency transformation:
\begin{small}
\begin{verbatim}
pA = phi2P([0.1 0.25])
pA = [ 1.0000e+00  -6.7508e-01   3.2492e-01 ]
\end{verbatim}
\end{small}
The denominator polynomial of the resulting band-pass filter has coefficients
in powers of $z^{-1}$. 
Figure~\ref{fig:freq-transform-structure-bandpass-B} shows the response of
a band-pass filter generated from the low-pass prototype filter with a
frequency transformation that is symmetrical about $\frac{f_{S}}{4}$:
\begin{small}
\begin{verbatim}
pB = phi2P([0.2 0.3])
pB = [ 1.0000e+00   0.0000e+00   5.0953e-01 ]
\end{verbatim}
\end{small}
In this case, both the numerator and denominator polynomials of the band-pass
filter have coefficients only in powers of $z^{-2}$. 
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{freq_transform_structure_test_lowpass_response}}
\caption{Amplitude response of a low-pass filter prototype having denominator
  polynomial coefficients in $z^{-2}$.}
\label{fig:freq-transform-structure-lowpass}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{freq_transform_structure_test_bandpass_A_response}}
\caption{Amplitude response of a band-pass filter with frequency transformation
  [0.1 0.25].}
\label{fig:freq-transform-structure-bandpass-A}
\end{figure}
\clearpage
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{freq_transform_structure_test_bandpass_B_response}}
\caption{Amplitude response of a band-pass filter with frequency transformation
  [0.2 0.3].}
\label{fig:freq-transform-structure-bandpass-B}
\end{figure}
\section{Summary}
Given a transfer function $H\left(z\right)=N_{N}\left(z\right)/D_{N}\left(z\right)$ the design procedure
for the normalised-scaled lattice filter is:
\begin{enumerate}
\item Compute the Schur polynomials from the denominator $D_{N}\left(z\right)$
\item Compute the parameters $k_{i}$ for $i=N,N-1,\cdots1$
\item Expand the numerator $N_{N}\left(z\right)$ in the Schur polynomial basis by
the polynomial expansion algorithm
\item Synthesise the filter by Equations~\ref{eq:ScaleNormS10},~\ref{eq:ScaleNormS11},~\ref{eq:ScaleNormS10other},~\ref{eq:ScaleNormS11other},~\ref{eq:ScaleNormS20}~and~\ref{eq:ScaleNormS00}
\end{enumerate}

Given a transfer function $H\left(z\right)=N_{N}\left(z\right)/D_{N}\left(z\right)$ the design procedure
for the one multiplier lattice filter is:
\begin{enumerate}
\item Compute the Schur polynomials from the denominator $D_{N}\left(z\right)$
\item Compute the parameters $k_{i}$ for $i=N,N-1,\cdots1$
\item Find the $k_{i}$ with greatest magnitude and recursively compute
the sign parameters by Algorithm~\ref{alg:One-multiplier-sign-assignment}.
Scale the Schur polynomial basis functions appropriately
\item Expand the numerator $N_{N}\left(z\right)$ in the Schur polynomial basis by
the polynomial expansion algorithm
\item Synthesise the filter by 
Equations~\ref{eq:OneMultSynthesisStar}~and~\ref{eq:OneMultSynthesis}
\end{enumerate}
The normalised-scaled lattice filter is not structurally passive, as is the
one multiplier lattice filter, but the normalised-scaled lattice filter
appears to be less sensitive to coefficient truncation than the 
one multiplier lattice filter. The normalised-scaled lattice filter is 
inherently scaled. The one multiplier lattice filter is not orthonormal and 
requires scaling.

\chapter{Orthogonal state variable filters\label{sec:Orthogonal-state-variable-filters}}
Chapter~\ref{sec:Schur-decomposition} described the Schur decomposition of 
an arbitrary rational filter transfer function into the normalised-scaled
or one-multiplier tapped all-pass lattice representations with state covariance
matrix $K=I$. The all-pass lattice filters so constructed are (in the 
terminology of \emph{Roberts} and \emph{Mullis}) \emph{orthogonal} filters. 
In this chapter I review the method of \emph{Roberts} and 
\emph{Mullis}~\cite[Section 10.4]{RobertsMullis_DigitalSignalProcessing} for 
decomposing an arbitrary transfer function into $2\times{}2$ block diagonal 
coordinate rotations that can be ``\emph{manipulated to achieve either
high-speed, parallel computation using a sparsely connected array of processor
modules or low-speed single processor realisations}''\footnote{In 
Appendix~\ref{app:Low-passband-sensitivity-IIR-digital-filters}, I review the 
method presented by
\emph{Vaidyanathan and Mitra}~\cite{VaidyanathanMitraNuevo_LowSensitivityIIRDigitalFilters, VaidyanathanMitra_LowPassbandSensitivityDigitalFilters} 
for decomposing an odd-order transfer function into the sum of two all-pass 
filters}.

\section{Definition of orthogonal state variable filters}
If, for matrix $O$, $OO^{\top}=I$, then $O \in \mathcal{O}$, the group of
\emph{orthogonal} matrixes. If $U$ has \emph{complex} elements and
$UU^{\mathconj}=I$ then $U \in \mathcal{U}$, where $\mathconj$ is the 
complex conjugate transpose matrix operator, and $\mathcal{U}$ is the group of 
\emph{unitary} matrixes. An all pass filter has magnitude response 
$\left|H\left(e^{\imath\theta}\right)\right|=1$ for all real $\theta$. The 
$m \times m$ matrix transfer function $H\left(z\right)$ of $m$ inputs and 
$m$ outputs and complex elements is \emph{all-pass} if 
$H\left(e^{\imath\theta}\right)$ is unitary:
\begin{align*}
H\left(e^{\imath\theta}\right)\in\mathcal{U}\left(m\right) 
~ \forall\; \text{real } \; \theta
\end{align*}

\textbf{Definition:}
A state variable filter $F=\left[\begin{array}{cc}
A & B\\
C & D
\end{array}\right]$ belongs to the set of orthogonal, all-pass filters 
$\mathcal{F}\left(m,n\right)$ if 
\begin{enumerate}
\item $AA^{\top}+BB^{\top}=I_{(n\times{}n)}$
\item $H\left(e^{\imath\theta}\right)=D+C\left(e^{\imath\theta}I-A\right)^{-1}B\,\,\in\mathcal{U}\left(m\right)~\forall{} \;\text{real} \; \theta$
\end{enumerate}
In addition, $F$ belongs to the sub-set $\mathcal{F}_{0}\left(m,n\right)$
if it has the following equivalent properties:
\begin{enumerate}
\item $F\in\mathcal{F}_{0}\left(m,n\right)$
\item $\left(A,B\right)$ is controllable
\item $\left(A,C\right)$ is observable
\item $\det\left(\lambda{}I-A\right)=0\;\Rightarrow\;\left|\lambda\right|<1$
\end{enumerate}
As noted above, apart from $F_{L}$, each factor in the factored state
variable description is an orthogonal matrix. For all-pass filters
$F_{L}$ is also orthogonal. More formally
\begin{align*}
F\in\mathcal{O}\left(m+n\right) & \Rightarrow  F\in\mathcal{F}\left(m,n\right)\\
F\in\mathcal{F}_{0}\left(m,n\right) & \Rightarrow  F\in\mathcal{O}\left(m+n\right)
\end{align*}
 For any orthogonal matrix $F\in\mathcal{O}\left(N\right)$, there
are $N$ possible filters, one each in $\mathcal{F}\left(m,N-n\right)$,
$1\leq m\leq N$. The choice of $m$ depends on how F is partitioned
\begin{align*}
F &=  \left[\begin{array}{ll}
A_{(N-m)\times(N-m)} & B_{(N-m)\times m}\\
C_{m\times(N-m)} & D_{m\times m}
\end{array}\right]
\end{align*}


Note that transformations of the all-pass filter by 
$T\in\mathcal{O}\left(N\right)$,
\begin{align*}
F^{\prime} &= \left[\begin{array}{cc}
A^{\prime} & B^{\prime}\\
C^{\prime} & D^{\prime}
\end{array}\right]\\
 &= \left[\begin{array}{l|l}
T^{\top}AT & T^{\top}B\\ \hline
CT & D
\end{array}\right]\\
 &= \left[\begin{array}{cc}
T & 0\\
0 & I
\end{array}\right]^{\top}\left[\begin{array}{cc}
A & B\\
C & D
\end{array}\right]\left[\begin{array}{cc}
T & 0\\
0 & I
\end{array}\right]
\end{align*}
are also members of $\mathcal{F}$ and that $F^{\prime}$ represents
an alternative realisation of $H{\left(z\right)=D+C\left(zI-A\right)}^{-1}B$.
\section{The Lattice Orthogonal All-Pass Filter Section}
Figure~\ref{fig:Lattice-section} shows a possible realisation of the
orthogonal lattice all-pass filter section. There are two inputs and two 
outputs. The filter matrix is given by
\begin{align*}
\left[\begin{array}{c}
x^{\prime}\\
y_{1}\\
y_{2}
\end{array}\right] &= \left[\begin{array}{ccc}
0 &  \cos\theta  & \sin\theta\\
1 &  0           & 0\\
0 &  -\sin\theta & \cos\theta
\end{array}\right]\left[\begin{array}{c}
x\\
u_{1}\\
u_{2}
\end{array}\right]
\end{align*}
and the corresponding transfer function is
\begin{align*}
H\left(z\right) &= \left[\begin{array}{cc}
z^{-1}\cos\theta & z^{-1}\sin\theta\\
-\sin\theta & \cos\theta
\end{array}\right]
\end{align*}

\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{lattice}
\caption{Lattice section.}
\label{fig:Lattice-section}
\end{figure}

\section{Noise gain of orthogonal filters\label{sec:Noise-gain-of-orthogonal-filters}}
For an orthogonal state variable structure, $K=I$, and the noise
gain is
\begin{align*}
g_{orth} &= \frac{1}{n}\sum_{i=1}^{n}K_{ii}W_{ii}\\
 &= \frac{1}{n}\sum_{i=1}^{n}\mu_{i}^{2}
\end{align*}
where the $\mu_{i}^{2}$ are the \emph{second order modes} or eigenvalues
of $KW$. For comparison, a globally optimised minimum noise filter with 
equal word-lengths has
\begin{align*}
g_{min} &= \frac{1}{n}\sum_{i=1}^{n}K_{ii}W_{ii}\\
       &= \left[\frac{1}{n}\sum_{i=1}^{n}\mu_{i}\right]^{2}
\end{align*}
Thus the difference between $g_{orth}$ and $g_{min}$ is the difference
between a second moment and the square of a first moment, which is
the variance. The two are only equal if the $\mu_{i}$ are all equal.
Recall that the second order modes of the globally optimised filter are
invariant under a frequency transformation.
\section{Realisation of arbitrary filters from orthogonal sub-filters}
Let $G\left(z\right)$ be the transfer function for an order $n$
filter with $1$ input and $1$ output. Suppose
\begin{align*}
G &= \left[\begin{array}{cc}
A & B\\
C_{1} & D_{1}
\end{array}\right]
\end{align*}
is an orthogonal filter implementation with
\begin{align*}
K &= AA^{\top}+BB^{\top} = I
\end{align*}
The first $n$ rows of $G$ are orthonormal, but have dimension $n+1$
so there exist $C$ and $D$ for which 
\begin{align*}
F &= \left[\begin{array}{cc}
A & B\\
C & D
\end{array}\right]\in\mathcal{O}\left(n+1\right)
\end{align*}
is orthonormal. The Schur decomposition of $G$ produces an all-pass filter
corresponding to $F$. The conversion from $F$ to $G$ can be found from
\begin{align*}
G &= \left[\begin{array}{ll}
A & B\\
C_{1} & D_{1}
\end{array}\right]F^{\top}F\\
 &= \left[\begin{array}{cc}
I & 0\\
C_{1}A^{\top}+D_{1}B^{\top} & C_{1}C^{\top}+D_{1}D^{\top}
\end{array}\right]F\\
 &= G_{0}F
\end{align*}
where
\begin{align*}
\left[\begin{array}{cc}\Gamma & \delta\end{array}\right] &= 
\left[\begin{array}{cc}
C_{1} & D_{1}\end{array}\right]F^{\top}\\
G_{0} &= \left[\begin{array}{cc}
I & 0\\
\Gamma & \delta
\end{array}\right]
\end{align*}
$G_{0}$ can be simplified by finding the transformation 
\begin{align*}
T &= \left[\begin{array}{cc}
T_{0} & 0\\
0 & 1
\end{array}\right]\in\mathcal{O}\left(n+1\right)
\end{align*}
so that 
\begin{align*}
\Gamma T_{0} &= \left[\begin{array}{cc}
0 & \gamma\end{array}\right]
\end{align*}
where $\gamma$ is a scalar. $T_{0}$ can be found as the product
of a series of rotations (each of which are members of
 $\mathcal{O}\left(n\right)$) that zero out the leading elements of $\Gamma$
\begin{align*}
\left[\begin{array}{cc} 
\gamma_{i} & \gamma_{i+1}
\end{array}\right]
\left[\begin{array}{cc}
\phantom{-}\cos \theta_{i} & \sin \theta_{i}\\
          -\sin \theta_{i} & \cos \theta_{i}
\end{array}\right] 
&= 
\left[\begin{array}{cc}
0 & \gamma_{i+1}^{\prime}
\end{array}\right]
\end{align*}
where $\theta_{i}$ is given by 
\begin{align*}
\tan\theta_{i} &= \frac{\gamma_{i}}{\gamma_{i+1}}
\end{align*}

Now transform $G$ by $T$
\begin{align*}
G^{\prime} &= T^{-1}GT\\
 &= T^{-1}\left(G_{0}F\right)T\\
 &= \left(T^{-1}G_{0}T\right)\left(T^{-1}FT\right)\\
 &= G_{0}^{\prime}F^{\prime}
\end{align*}
where
\begin{align*}
G_{0}^{\prime} &= \left[\begin{array}{ccc}
I & 0 & 0\\
0 & 1 & 0\\
0 & \gamma & \delta
\end{array}\right]
\end{align*}
In other words, $F^{\prime}\in\mathcal{F}\left(2,n-1\right)$ is a two-input,
two-output all-pass filter and one of the all-pass outputs of $F^{\prime}$ 
becomes a state of $G\left(z\right)$.
Figure~\ref{fig:Arbitrary-transfer-function-from-two-input-two-output-allpass} is
a representation of the corresponding implementation of $G\left(z\right)$
(see~\cite[Figure 10.4.5]{RobertsMullis_DigitalSignalProcessing}).

\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{arbitrary_to_two_in_two_out_allpass}
\caption{Signal flow graph of an arbitrary transfer function constructed from
  a two-input two-output all-pass filter.}
\label{fig:Arbitrary-transfer-function-from-two-input-two-output-allpass}
\end{figure}

\emph{Roberts} and
\emph{Mullis}~\cite[pp. 460-461]{RobertsMullis_DigitalSignalProcessing}
describe the following procedure for factoring a two-input, two-output
all-pass filter, $F$, into the product of $2\times2$ block diagonal coordinate
rotations of the form
\begin{align*}
\left[\begin{array}{ccc}
T_{1} & 0 & 0\\
   0 & 1 & 0 \\
   0 & 0 & 1
\end{array}\right] & \in{}\mathcal{O}\left(n+1\right)
\end{align*}
that preserve $G_{0}^{\prime}$\footnote{This procedure is known as the \emph{upper
Hessenberg reduction}~\cite[Section 7.4.2]{GolubVanLoan_MatrixComputations}.}:
\begin{enumerate}
\item Construct a series of similarity transformations that zero the elements
of $F$ which are more than 2 sub-diagonals below the main diagonal.
For example, with $G\left(z\right)$ of order $n=5$ so that 
$F \in \mathcal{O}\left(6\right)$:
\begin{align*}
F^{\prime} &= \left[\begin{array}{cccccc}
X & X & X & X & X & X\\
X & X & X & X & X & X\\
X & X & X & X & X & X\\
0_{6} & X & X & X & X & X\\
0_{4} & 0_{5} & X & X & X & X\\
0_{1} & 0_{2} & 0_{3} & X & X & X
\end{array}\right]=T_{6}^{\top}T_{5}^{\top}T_{4}^{\top}T_{3}^{\top}T_{2}^{\top}T_{1}^{\top}FT_{1}T_{2}T_{3}T_{4}T_{5}T_{6}
\end{align*}
The indexes on the sub-diagonal zeros indicate the order of construction. The
transformations $T_{i}$ are constructed in the same manner as those that zero
the leftmost elements of $\Gamma$. In the example:
\begin{align*}
\left[\begin{array}{ccc}
I_{4\times4} & 0 & 0 \\
0 & \phantom{-}\cos\theta & \sin\theta \\
0 &           -\sin\theta & \cos\theta 
\end{array}\right]^{\top}
\left[\begin{array}{cccccc}
X & X & X & X & X & X\\
X & X & X & X & X & X\\
X & X & X & X & X & X\\
F_{4,1} & X & X & X & X & X\\
F_{5,1} & F_{5,2} & X & X & X & X\\
F_{6,1} & F_{6,2} & F_{6,3} & X & X & X
\end{array}\right]\left[\begin{array}{ccc}
I_{4\times4} & 0 & 0 \\
0 & \phantom{-}\cos\theta & \sin\theta \\
0 &           -\sin\theta & \cos\theta  
\end{array}\right]
\end{align*}
\begin{align*}
=  \left[\begin{array}{cccccc}
X & X & X & X & X & X\\
X & X & X & X & X & X\\
X & X & X & X & X & X\\
F_{4,1}^{\prime} & X & X & X & X & X\\
F_{5,1}^{\prime} & F_{5,2}^{\prime} & X & X & X & X\\
0 & F_{6,2}^{\prime} & F_{6,3}^{\prime} & X & X & X
\end{array}\right]
\end{align*}
\item Factor $F^{\prime}$ with $q=2n-1$ coordinate rotations that zero the
sub-diagonal elements 
\begin{align*}
F^{\prime\prime} &= F^{\prime}F_{1}\cdots F_{q}
\end{align*}
These are \emph{not} similarity transformations. In fact, $F^{\prime\prime}$
will be diagonal with elements $\pm 1$\footnote{This is a consquence of 
$F^{\prime\prime}$ being upper-triangular and
$F^{\prime\prime} \in \mathcal{O}\left(n+1\right)$.}. The diagonal elements
 can be included in the rotations so that:
\begin{align*}
F^{\prime} &= F_{q}^{\top}\cdots F_{1}^{\top}
\end{align*}
For example:
\begin{align*}
F^{\prime\prime} &= \left[\begin{array}{cccccc}
X & X & X & X & X & X\\
0_{9} & X & X & X & X & X\\
0_{4} & 0_{8} & X & X & X & X\\
0 & 0_{3} & 0_{7} & X & X & X\\
0 & 0 & 0_{2} & 0_{6} & X & X\\
0 & 0 & 0 & 0_{1} & 0_{5} & X
\end{array}\right]=F^{\prime}F_{1}F_{2}F_{3}F_{4}F_{5}F_{6}F_{7}F_{8}F_{9}
\end{align*}
\end{enumerate}

This realisation of $G\left(z\right)$ as
a tapped lattice filter requires, as a starting point, an orthogonal state 
variable representation of $G\left(z\right)$ with $K=I$. The \emph{singular
value decomposition}~\cite[Theorem 2.5.2]{GolubVanLoan_MatrixComputations} 
provides the required similarity transform\footnote{The SVD of $K$ gives
$U^{\top}KV=\mathdiag\left(\sigma_{1},\ldots,\sigma_{n}\right)$ where $U$ and
$V$ are orthogonal $n\times{}n$ matrixes (ie: $U^{\top}U=I$)}. Alternatively, 
the Schur decomposition of a transfer function (reviewed in
Chapter~\ref{sec:Schur-decomposition}, based on 
\emph{Parhi}~\cite[Chapter 12]{Parhi_VLSIDigitalSignalProcessingSystems}) 
realises an orthogonal lattice filter without requiring the calculation of $K$ 
to find an initial similarity transformation\footnote{In fact the Schur 
decomposition of the transfer function is equivalent to the orthogonal 
decomposition of the state transition matrix presented here.}. In practice, for 
larger filters, I have found that the Schur decomposition is more accurate. 

The Octave function \emph{orthogonaliseTF} returns the orthogonal decomposition
of a rational polynomial transfer function. In the default configuration, 
\emph{orthogonaliseTF} uses the Schur decomposition of the transfer function
to find an orthogonal state transition matrix, $A$, and then finds the 
$2\times{}2$ block diagonal rotation matrixes in the orthogonal 
decomposition of the filter. As an example, the Octave script 
\emph{orthogonaliseTF\_test.m} finds the orthogonal decomposition of a $9$th
order elliptic low-pass filter with cutoff frequency $0.05f_{S}$. The orthogonal
decomposition of the filter contains $17$ non-trivial $2\times{}2$ block diagonal
rotation matrixes. The noise gain of the orthogonal filter is $2.83$. The noise
gain of the corresponding minimum noise state variable filter is $1.64$. 
\subsection{An example of structural variations}
The decomposition of the filter transfer function into $2\times{}2$ block
diagonal coordinate rotations permits straightforward modification of the
filter factorisation. For example, suppose we design a $5$-th order 
filter with the structure shown in
Figure~\ref{subfig:Orthogonal-filter-as-depth-10-pipeline}. The $2\times2$
rotation matrixes on the diagonals are represented by the letters across two
rows. All other elements are either $0$ or, on the diagonal, $1$.
The structure shown in 
Figure~\ref{subfig:Orthogonal-filter-as-depth-10-pipeline}
uses a single rotation time multiplexed across $9$ matrixes
(plus $G_{0}^{\prime}$, although that matrix is not orthogonal).
The orthogonal matrixes above the arrow in
Figure~\ref{subfig:Orthogonal-filter-as-depth-10-pipeline}
can be combined into a single similarity transform, $T$, and applied
to $G_{0}F$ to form a new filter factorisation: 
\begin{align*}
F^{\prime} &= T^{-1}FT
\end{align*}
This is equivalent to a circular shift of the order of the orthogonal
factor matrixes. Also, the individual factors commute if the $2\times2$
sub-matrixes on the diagonal have no common rows. Hence the filter
matrix can be compacted as shown in 
Figure~\ref{subfig:Orthogonal-filter-as-depth-4-pipeline},
which represents a sequence of $2,3,2,2$ rotation elements in a depth-$4$
pipeline.
\begin{figure}
\centering
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{depth10}
\caption{Orthogonal filter as a depth-10 pipeline with a single rotation
  element.}
\label{subfig:Orthogonal-filter-as-depth-10-pipeline}
\vspace{1cm}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{depth4}
\caption{Orthogonal filter as a depth-4 pipeline.}
\label{subfig:Orthogonal-filter-as-depth-4-pipeline}
\end{subfigure}
\caption{Orthogonal structures for a 5-th order filter.}
\end{figure}

\emph{Roberts} and
\emph{Mullis}~\cite[pp. 462-467]{RobertsMullis_DigitalSignalProcessing} show
other examples of orthogonal filter factorisation.

\chapter{Feedforward and feedback of state quantisation error in state variable filters}
Chapter~\ref{sec:Round-off-noise-in-state-variable-filters} reviewed the 
optimisation of a state variable digital filter for minimum roundoff noise. The
resulting filter has $\mathcal{O}\left(N^{2}\right)$ non-zero coefficients. 
Section~\ref{sec:Second-order-cascade} showed how a filter could be implemented
as a cascade of second-order sections with section optimal roundoff noise 
performance. Chapters~\ref{sec:Schur-decomposition}
and~\ref{sec:Orthogonal-state-variable-filters} reviewed the design of lattice
filters with good roundoff noise performance and low coefficient sensitivity.
An alternative technique for reducing the roundoff noise in the filter output is
the feedback of the state quantisation 
error~\cite{SpangShultheiss_ReductionOfQuantizingNoiseByFeedback,
LuHinamoto_JointlyOptimizedErrorFeedbackStateSpaceFilters,
Williamson_RoundoffNoiseMinimizationUsingResidueFeedback} in order to improve
the roundoff noise performance of the filter with a small increase in 
complexity. \emph{Mullis} and
\emph{Roberts}~\cite{MullisRoberts_InterpretationOfErrorSpectrumShapingInDigitalFilters}
show that complete or ``optimal'' error feedback is equivalent to increasing the 
word-lengths of the coefficients and state registers in the ``usual'' state
variable filter without feedback. They point out that sub-optimal error
feedback, that is choosing the registers that receive feedback and choosing
coefficients that are a power-of-2, may provide improved noise performance with
reduced complexity. Overflow oscillations and coefficient sensitivity must be 
considered on a case-by-case basis. \emph{Li} and \emph{Gevers} show that the 
``delta'' operator method, where the usual time-shift operator, $z$, is 
replaced by $\delta = \frac{z-1}{\Delta}$ is a special case of the residue 
feed back method of 
\emph{Williamson}~\cite{Williamson_RoundoffNoiseMinimizationUsingResidueFeedback}
.
\emph{Lu} and 
\emph{Hinamoto}~\cite{LuHinamoto_JointlyOptimizedErrorFeedbackStateSpaceFilters} 
describe use of SQP-Relaxation non-linear optimisation to find the near-optimal
signed-digit coefficients of a diagonal feedback matrix. Here I follow the paper
by 
\emph{Williamson}~\cite{Williamson_RoundoffNoiseMinimizationUsingResidueFeedback}
.
\section{Problem formulation}
Figure~\ref{fig:error-feedback-in-state-variable-digital-filter}~\cite[Figure
2]{LuHinamoto_JointlyOptimizedErrorFeedbackStateSpaceFilters} 
shows a block diagram of a state variable digital filter with feedback and 
feed-forward of the state quantisation error $e$. The state variable quantiser 
is $Q$, the feedback error transfer function is $\delta$ and the feed-forward
error transfer function is $\eta$.

\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{errorfeedback}
\caption{Error feedback and feed-forward in state variable digital
  filters, (\emph{Lu} and \emph{Hinamoto}~\cite[Figure
  2]{LuHinamoto_JointlyOptimizedErrorFeedbackStateSpaceFilters}).} 
\label{fig:error-feedback-in-state-variable-digital-filter}
\end{figure}
As shown in Section~\ref{sec:State-variable-description-of-a-signal-flow-graph}
the unquantised state variable equations are
\begin{align*}
x\left(k+1\right)&=Ax\left(k\right) + Bu\left(k\right) \\
y\left(k\right)&=Cx\left(k\right) + Du\left(k\right)
\end{align*}
In his treatment 
Williamson~\cite{Williamson_RoundoffNoiseMinimizationUsingResidueFeedback}  
states that 
``the coefficients $\left\{A,B,C,D\right\}$, while not necessarily less than $1$
in magnitude, are assumed to have an exact fractional $B_{0}$ bit representation.
The filter states $\tilde{x\left(k\right)}$ and the ouptput
$\tilde{y\left(k\right)}$ all have a fractional $B+B_{0}$ bit representation 
and the input $u\left(k\right)$ is a $B$ bit fraction. The quantiser 
$Q\left[\tilde{x\left(k\right)}\right]$ \emph{rounds} the $B+B_{0}$ fraction 
$\tilde{x\left(k\right)}$ to $B$ bits after the arithmetic operations are 
complete. Fixed point arithmetic is implemented using a two's complement 
representation (where the sign bit is not counted)''. The \emph{roundoff 
residue}, $e\left(k\right)$, is a $B+B_{0}$ bit fraction having zero in the most
significant $B$ bits:
\begin{align*}
e\left(k\right) &= \tilde{x}\left(k\right) - 
Q\left[\tilde{x}\left(k\right)\right] \\
\end{align*}
The roundoff residue sequence, $e\left(k\right)$, is modelled as
a zero-mean noise process with covariance
\begin{align*}
\sigma_{e}&=E\left\{e\left(k\right)e^{\top}\left(k\right)\right\}\\
&=\frac{q^{2}}{12}I
\end{align*}
where $q=2^{-B}$. When the state variables are quantised, the 
state variable equations for the error feedback/feed-forward filter of
Figure~\ref{fig:error-feedback-in-state-variable-digital-filter} are
\begin{align*}
\tilde{x}\left(k+1\right) &=
AQ\left[\tilde{x}\left(k\right)\right] + Bu\left(k\right) + 
\delta e\left(k\right) \\
\tilde{y}\left(k\right) &= CQ\left[\tilde{x}\left(k\right)\right] +
Du\left(k\right) + \eta e\left(k\right)
\end{align*}
The round off noise for the filter is
\begin{align*}
\Delta x\left(k+1\right) &= A\Delta x\left(k\right) + 
\left(A-\delta\right)e\left(k\right) \\
\Delta y\left(k\right) &= C\Delta x\left(k\right) + 
\left(C-\eta\right)e\left(k\right)
\end{align*}
where $\Delta x\left(k\right)= \tilde{x}\left(k\right)-x\left(k\right)$ and
$\Delta y\left(k\right)= \tilde{y}\left(k\right)-y\left(k\right)$. As shown in
Section~\ref{sec:Transfer-function}, the frequency domain transfer function
from the state quantisation error to the output roundoff noise is:
\begin{align*}
\Delta H\left(z\right) &= C\left(zI-A\right)^{-1}\left(A-\delta\right) + 
\left(C-\eta\right)
\end{align*}
Section~\ref{sec:Scaling-State-Variable-Filters-To-Avoid-Overflow} shows that
the probability of overflow can be minimised by appropriate $l_{2}$-norm scaling
of the state variables. If the input signal, $u\left(k\right)$, is zero-mean and
unit variance, then the steady-state covariance of the state variables is,
since $\tilde{x}\left(k\right)$ and $e\left(k\right)$
are uncorrelated
\begin{align*}
K&=AKA^{\top} +BB^{\top}+q^{2}\left(A-\delta\right)\left(A-\delta\right)^{\top}
\end{align*}
If $q^{2}\ll 1$ then
\begin{align*}
K&\approx AKA^{\top} + BB^{\top}
\end{align*}
For optimum $l_{2}$-norm scaling $\mathdiag\left\{K\right\}=I$.
As shown in Section~\ref{sec:Unit-pulse-response}, for 
$\Delta y\left(0\right)=0$, the output roundoff noise error is
\begin{align*}
\Delta y\left(k\right)&=
\sum_{l=0}^{k-1}CA^{l}\left(A-\delta\right)e\left(k-m-1\right)
+ \left(C-\eta\right)e\left(k\right)
\end{align*}
As shown in 
Section~\ref{sec:Estimation-of-output-round-off-noise-in-state-variable-filters},
the output roundoff noise variance due to truncation of each state is 
$\sigma_{e}^{2}\sigma^{2}$, where
\begin{align*}
\sigma^{2}&=\mathtrace\left\{\left(A-\delta\right)\left(A-\delta\right)^{\top}W+
\left(C-\eta\right)\left(C-\eta\right)^{\top}\right\}\\
W&=AWA^{\top}+CC^{\top}
\end{align*}
Williamson considers the noise minimisation problem of finding a realisation 
$\left\{A,B,C,D\right\}$ of $H\left(z\right)$ and integer-valued feedback
gains $\left\{\delta,\eta\right\}$ such that the output noise gain, $g$,
is minimised, subject to the state scaling constraint,
$\mathdiag\left\{K\right\}=I$.

Given an initial realisation, $\left\{A_{0},B_{0},C_{0},D\right\}$, of 
$H\left(z\right)$, Williamson~\cite[Section III]
{Williamson_RoundoffNoiseMinimizationUsingResidueFeedback} defines the 
\emph{residue matrix} as
\begin{align*}
P_{0}=\left(I-A\right)^{\top}W_{0}+W_{0}\left(I-A\right)
\end{align*}
where
\begin{align*}
W_{0}&=A_{0}W_{0}A_{0}^{\top}+C_{0}C_{0}^{\top}
\end{align*}
He shows that the eigenvalues, $\left\{\mu^{2}_{i}\right\}$ of $K_{0}W_{0}$,
and $\left\{\rho^{2}_{i}\right\}$ of $K_{0}P_{0}$, are invariant under a 
similarity transformation, $T$, and are positive. In 
Section~\ref{sec:Noise-gain-of-orthogonal-filters}, the eigenvalues 
$\left\{\mu^{2}_{i}\right\}$ are referred to as the \emph{second-order modes} of 
$H\left(z\right)$. Williamson calls $\left\{\rho^{2}_{i}\right\}$ the 
\emph{residue modes}. Further, he calls a realisation
$\left\{A_{0},B_{0},C_{0},D\right\}$ \emph{input balanced} if $K_{0}=I$ and
$W_{0}=M^{2}=\mathdiag\left\{\mu_{1}^{2},\hdots,\mu_{N}^{2}\right\}$, where
$N$ is the order of $H\left(z\right)$\footnote{If $K=I$, then the
filter is \emph{orthogonal}. See 
Part~\ref{sec:Orthogonal-state-variable-filters}. An SVD transformation of the
corresponding $W$ matrix gives the input balanced structure.}. An input balanced
structure can be transformed to an \emph{internally balanced} structure with 
$K_{1}=W_{1}=M$ by means of the similarity transformation $T_{1}=M^{-\frac{1}{2}}$.
\section{Minimisation of round-off noise with \texorpdfstring{$\delta=I$ and $\eta=0$}{d=I and n=0}}
Williamson~\cite[Section V]
{Williamson_RoundoffNoiseMinimizationUsingResidueFeedback} considers the
``problem of finding the optimal transformation, $T$, and the optimal integer
residue feedback matrixes $\delta_{T}$ and $\eta_{T}$, which together minimise
the output round-off noise''. He proves the theorem shown as 
Algorithm~\ref{alg:Minimisation-of-round-off-noise-in-error-feedback-feedforward-state-variable-filters} 
for the suboptimal case for a low-pass narrow-band filter in which 
$\delta_{T}=I$ and $\eta_{T}=0$. (For a high-pass narrow-band filter 
$\delta_{T}=-I$). If $\delta_{T}=0$ and $\eta_{T}=0$ then the minimum noise
gain is
\begin{align*}
g_{M}&=\frac{\sum_{k=1}^{N}\mu_{k}}{\sqrt{N}}
\end{align*}
Hence, error feedback reduces the noise gain only if the sum of the residue 
modes is less than the sum of the second-order modes.
\begin{algorithm}[htbp]
Let $M$ define the second-order modes of a stable $N$th order filter,
$H\left(z\right)$, with an input-balanced realisation, 
$\left\{A_{0},B_{0},C_{0},D\right\}$. Consider the finite word length 
implementation 
$\left\{A_{T}=T^{-1}A_{0}T,B_{T}=T^{-1}B_{0},C_{T}=T^{\top}C_{0},D\right\}$. Then 
subject to the $l_{2}$-norm scaling constraint, the identity state residue
correction, $\delta_{T}=I$, and the zero output residue correction,
$\eta_{T}=0$, the minimum noise filter is defined by
\begin{align*}
T &= R_{1}\Pi R_{0}^{\top}\\
\Pi &= \mathdiag\left\{ \pi_{1},\ldots,\pi_{N}\right\}\\
\end{align*}
where
\begin{align*}
\pi_{m}^{2} &= \frac{1}{\rho_{m}}\frac{\sum_{k=1}^{N}\rho_{k}}{N}
\end{align*}
and for unitary matrixes $R_{0}$ and $R_{1}$
\begin{align*}
\mathdiag\left\{R_{0}\Pi^{-1}R_{0}^{\top}\right\}&=I\\
R_{1}^{\top}P_{0}R_{1} & \quad\text{is}\quad\text{diagonal}
\end{align*}
where
\begin{align*}
P_{0}=\left(I-A_{0}\right)^{\top}M^{2}+M^{2}\left(I-A_{0}\right)
\end{align*}
The residue modes $\left\{\rho_{k}\right\}$ are the square roots of the
eigenvalues of $P_{0}$. The corresponding minimum noise gain, $g_{I}$ is
\begin{align*}
g_{I}&=\frac{\sum_{k=1}^{N}\rho_{k}}{\sqrt{N}}
\end{align*}
\caption{Minimisation of round off noise in error feedback/feedforward state
  variable filters. (See \emph{Williamson}~\cite[Theorem 5.2]
  {Williamson_RoundoffNoiseMinimizationUsingResidueFeedback}).}
\label{alg:Minimisation-of-round-off-noise-in-error-feedback-feedforward-state-variable-filters}
\end{algorithm}

The Octave script \emph{error\_feedback\_test.m}
attempts to reproduce Williamson's 
\emph{Example 6.3}. This example considers error feedback for the $6$th order
filter given by $H\left(z\right)=\frac{q\left(z\right)}{p\left(z\right)}$ where
\begin{small}
\begin{verbatim}
q=[0.0047079 -0.0251014 0.0584417 -0.0760820 0.0584417 -0.0251014 0.0047079];
p=[1 -5.6526064 13.3817570 -16.9792460 12.1764710 -4.6789191 0.7525573];
\end{verbatim}
\end{small}
I found different values for the second order modes. I found that the optimum
noise gain was $1.333$ and the noise gain for an orthogonal filter was $2.086$
whereas Williamson reports a noise gain of $g_{M}^{2}=5.8272$ in the latter case.
I found the following values for the residue modes:
\begin{small}
\begin{verbatim}
rho = [ 0.268561 0.141649 0.127042 0.058299 0.021251 0.005512]
\end{verbatim}
\end{small}
and a noise gain of $g_{I}=0.254$. The error-feedback filter was simulated with
8 bit coefficients by adding $2$ bits to the state storage in the Octave 
function \emph{svf.m} (as the mantissa, to the right of the binary point). The
estimated output roundoff noise is $0.323$ bits. The measured output roundoff
noise is $0.308$ bits. The output round-off noise is dominated by the noise due
to the rounding of the output, $y\left(k\right)$: $\frac{1}{\sqrt{12}}=0.2887$
bits. The simulated response is shown in 
Figure~\ref{fig:Simulated-response-of-6th-order-filter-with-error-feedback}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{error_feedback_test_simulated_error_feedback_response}}
\caption{Simulated response of a $6$-th order filter with $8$ bit coefficients
  and a $2$ bit mantissa (for error feedback) in the state variables. (After 
  \emph{Williamson}~\cite[Example 6.3]
{Williamson_RoundoffNoiseMinimizationUsingResidueFeedback}).}
\label{fig:Simulated-response-of-6th-order-filter-with-error-feedback}
\end{figure}
\cleardoublepage
\part{\label{sec:Constrained-Optimisation-of-IIR-frequency-response}Constrained optimisation of the IIR filter frequency response}
\cleardoublepage

\chapter{\label{sec:Constrained-Optimisation-of-IIR-by-Quadratic-Programming-Pole-Zero-Location}IIR filter design using Sequential Quadratic Programming with the transfer function defined by pole and zero locations}
The transfer function or response of an IIR digital filter is usually written
in the $z$-transform domain similarly to
\begin{align}
H\left(z\right) &= \frac{b\left(z\right)}{a\left(z\right)} = 
\frac{\sum^{m}_{l=0}b_{l}z^{-l}}{1+\sum^{n}_{l=1}a_{l}z^{-l}}
\label{eqn:Transfer-function-H}
\end{align}
Where $0 \le m \le n$. Poles at zero may be added to ensure that the filter is
 \emph{causal}. For a causal filter, the output of the
filter only depends inputs from the past. When $z$ is interpreted as a single 
sample delay this means that the order of the numerator is less than or equal
to the order of the denominator. A non-causal filter can be used to process 
signals off-line. Alternatively, the non-causal filter can be decomposed by
polynomial division into a parallel and cascade combination. A \emph{stable} 
filter has all the roots of the denominator polynomial inside the unit circle
in the $z$-plane. A \emph{minimum phase} filter has both poles and zeros inside
the unit circle in the $z$-plane so that the inverse filter is also stable.

Equation~\ref{eqn:Definition-of-squared-response-error} minimises the error in
the \emph{complex} response (amplitude and phase). In contrast, in the following
the weighted amplitude and group-delay response squared-error is minimised and
filter stability is obtained by constraints on the pole location. The 
\emph{sequential quadratic programming} (SQP) optimisation method
linearises the response error at the current estimate of the solution
and solves the corresponding constrained quadratic programming problem to 
find a new estimate that minimises the linearised error. The procedure stops
at a \emph{local} minimum of the error surface. Unfortunately, the filter 
design error surface usually has many, many local minima. Achieving success in
finding a good solution (for which the error value at the local minimum is 
close to the \emph{global} minimum) depends on the initial solution and the 
formulation and weighting of the error function\footnote{An 
alternative to Equation~\ref{eqn:Definition-of-squared-response-error} is to
linearise the cost function, $\mathcal{E}_{H}$, by:
\begin{align*}
\hat{\mathcal{E}}_{H} &= \sum_{j=1}^{NB}\intop_{f_{l,j}}^{f_{u,j}}
\frac{W_{j}\left(f\right)}{\left| \hat{D}\left(f\right) \right|^{2}}
{\left|N\left(f\right)-D\left(f\right)H_{d}\left(f\right)\right|^{2}}df
\end{align*}
where $\hat{D}$ is the previous estimate of $D$. See, for example,
\emph{Dumitrescu and Niemist\"\o} 
~\cite{DumitrescuNiemisto_IIRFilterPositiveRealness}}.

\section{Problem statement}
The magnitude and group delay responses of an IIR digital 
filter are optimised in terms of a coefficient vector containing the
gain-zero-pole definition of the transfer function
\begin{align}
x &= \left[
   K         , 
\; R_{0,1}    , \ldots , R_{0,U}            , 
\; R_{p,1}    , \ldots , R_{p,V}            , 
\; r_{0,1}    , \ldots , r_{0,\frac{M}{2}}    , 
\; \phi_{0,1} , \ldots , \phi_{0,\frac{M}{2}} , 
\; r_{p,1}    , \ldots , r_{p,\frac{Q}{2}}    , 
\; \phi_{p,1} , \ldots , \phi_{p,\frac{Q}{2}}
\right]\label{eqn:Filter-gain-zeros-poles}
\end{align}
This vector represents the poles and zeros of a filter with gain factor $K$,
the radiuses of $U$ real zeros and $V$ real poles and the radiuses and angle of
$\frac{M}{2}$ pairs of conjugate zeros and $\frac{Q}{2}$ pairs of conjugate
poles. Note that for decimation factor, $R$, the poles are in fact on the
$z^{R}$ plane and each pole in $x$ corresponds to $R$ poles on the $z$ plane.
Appendix~\ref{app:IIR-filter-response} shows the amplitude, phase and
group delay responses and their gradients in terms of the coefficient vector.

The weighted squared-magnitude of the response error, $\mathcal{E}_{A}$, is:
\begin{align*}
\mathcal{E}_{A}\left(x\right) &= 
\sum_{j=1}^{NB}\intop_{f_{l,j}}^{f_{u,j}}W_{Aj}\left(f\right)\left[A\left(x,f\right)-
A_{D}\left(x,f\right)\right]^{2}df
\end{align*}
where $NB$ is the number of frequency bands, $f_{u,j}$ the upper
and $f_{l,j}$ the lower frequency band edges, $W_{Aj}$ the weighting
function for each frequency band, and $A$ is the actual and $A_{D}$ the desired
magnitude response. 
The weighted time delay error, $\mathcal{E}_{T}$, is similarly expressed in
terms of  $W_{Tj}$ the weighting function for each frequency band, the
actual group delay response, $T$, and the desired group delay response, $T_{D}$.

The optimal filter design minimises the total weighted squared response error, 
$\mathcal{E}=\mathcal{E}_{A}+\mathcal{E}_{T}$, subject to constraints 
$g_{i}\left(x\right)\ge 0$ where $x\in\mathcal{D}\subset\mathbb{R}^{N}$ and the
filter is stable for $x\in\mathcal{D}$. The method of 
\emph{Lagrange multipliers} minimises the \emph{Lagrangian} function:
\begin{align*}
\mathcal{L}\left(x,\lambda_{i}\right) &= \mathcal{E}\left(x\right)-
\sum_{i\in\mathcal{A}\left(x\right)}\lambda_{i}g_{i}\left(x\right)
\end{align*}
where $\mathcal{A}\left(x\right)$ represents the set of active constraints
at $x$ and $\lambda_{i}$ are the Lagrange multipliers (or \emph{dual variables})
for those constraints. The \emph{Karush-Kuhn-Tucker} conditions for the minimum
are:
\begin{align}
\nabla_{x}\left\{\mathcal{E}\left(x\right)-
\sum_{i\in\mathcal{A}\left(x\right)}\lambda_{i}g_{i}\left(x\right)\right\} 
&= 0\label{eqn:KKT-cond-1}\\
g_{i}\left(x\right) & \ge 0\label{eqn:KKT-cond-2}\\
\lambda_{i} & \ge 0\\
\left\langle \lambda_{i},g_{i}\left(x\right)\right\rangle  &= 0
\end{align}
The gradient of the magnitude error is:
\begin{align*}
\nabla_{x}\mathcal{E}_{A}\left(x\right) &= 
\sum_{j=1}^{NB}2\intop_{f_{l,j}}^{f_{u,j}}W_{Aj}\left(f\right)\left[A\left(x,f\right)-
A_{D}\left(x,f\right)\right]\nabla_{x}A\left(x,f\right)df
\end{align*}
The gradient of the delay error is similar. 

The literature often refers to the \emph{dual} problem, finding the 
greatest lower bound of the dual function:
\begin{align*}
\Lambda\left(\lambda_{i}\right) &= \inf_{x\in\mathcal{D}}\left\{
\mathcal{E}\left(x\right)-
\sum_{i\in\mathcal{A}\left(x\right)}\lambda_{i}g_{i}\left(x\right)\right\}
\end{align*}
\subsection{\label{sub:Solution-quasi-Newton-optimisation}Solution of the constrained quasi-Newton optimisation problem}
The second-order \emph{Taylor expansion} of $\mathcal{E}\left(x\right)$ at
$x^{k}$ is:
\begin{align}\label{eqn:Quasi-Newton-second-order-Taylor-expansion}
  \mathcal{E}\left(x\right)
  &\approx\mathcal{E}\left(x^{k}\right) +
    \nabla_{x}\mathcal{E}\left(x^{k}\right)\left(x-x^{k}\right) +
    \frac{1}{2}\left(x-x^{k}\right)^{\top}
    \nabla_{x}^{2}\mathcal{E}\left(x^{k}\right)\left(x-x^{k}\right)
\end{align}
Express the \emph{Karush-Kuhn-Tucker} conditions (Equations~\ref{eqn:KKT-cond-1}
and~\ref{eqn:KKT-cond-2}) for a minimum at $x^{k}$ in terms of the gradient of
the second-order expansion of the error and linearised constraints as (see 
Appendix~\ref{app:Newtons-method-quadratic-function}):
\begin{align}
\nabla_{x}\mathcal{E}\left(x^{k}\right)+\nabla_{x}^{2}\mathcal{E}\left(x^{k}\right)\left(x-x^{k}\right)-\sum_{i\in\mathcal{A}\left(x\right)}\lambda_{i}\nabla_{x}g_{i}\left(x^{k}\right) &= 0\label{eqn:Linearised-KKT}\\
g_{i}\left(x^{k}\right)+\nabla_{x}g_{i}\left(x^{k}\right)\left(x-x^{k}\right) & \ge 0\nonumber 
\end{align}
where the Hessian of the squared-magnitude response error, $\mathcal{E}_{A}$, is:
\begin{align*}
\nabla_{x}^{2}\mathcal{E}_{A}\left(x\right) &= 
\sum_{j=1}^{NB}2\intop_{f_{l,j}}^{f_{u,j}}W_{Aj}\left(f\right)
\left\{ \left[\nabla_{x}A\left(x,f\right)\right]^{2}+
\left[A\left(x,f\right)-A_{D}\left(x,f\right)\right]
\nabla_{x}^{2}A\left(x,f\right)\right\} df
\end{align*}
and the Hessian of the group delay error, $\mathcal{E}_{T}$, is similar.

Appendix~\ref{sub:Local-Convergence} shows that for a particular set of 
constraints, 
$\left\{ g_{i}\left(x^{k}\right)\mid i\in\mathcal{A}\left(x^{k}\right)\right\}$,
the IIR design problem can be approximated by 
\begin{align}
\mathcal{W}_{k}d^{k}-\mathcal{B}_{k}\lambda^{k} &= 
-\nabla_{x}\mathcal{E}\left(x^{k}\right)
\label{eqn:IIR-SQP-system}\\
-\mathcal{B}_{k}^{\top}d^{k} &= g\left(x^{k}\right)\nonumber 
\end{align}
where $\mathcal{W}_{k}$ is a positive-definite approximation to the true Hessian
matrix derived using the \emph{Broyden-Fletcher-Goldfarb-Shanno} formula (see 
Appendix~\ref{Updating-with-the-BFGS-formula}) and $\mathcal{B}_{k}$ is the 
matrix whose columns are the gradients of the active constraints. This is a 
matrix equation that can be solved for the Lagrange multipliers $\lambda^{k}$ 
and the direction vector $d^{k}$:
\begin{align*}
\lambda^{k} &= 
-\left(\mathcal{B}_{k}^{\top}\mathcal{W}_{k}^{-1}\mathcal{B}_{k}\right)^{-1}
\left[g\left(x^{k}\right)- 
\mathcal{B}_{k}^{\top}\mathcal{W}_{k}^{-1}\nabla_{x}\mathcal{E}
\left(x^{k}\right)\right]\\
d^{k} &= -\mathcal{W}_{k}^{-1}\left[\nabla_{x}\mathcal{E}\left(x^{k}\right)-
\mathcal{B}_{k}\lambda^{k}\right]
\end{align*}
At each iteration of the sequential programming method the coefficient
vector is updated by 
\begin{align*}
x^{k+1} &= x^{k}+\tau^{k}d^{k}
\end{align*}
where $d^{k}$ is the step direction vector and $\tau^{k}\in\left[0,1\right]$
is the step-size. $\tau^{k}$ is found by a line search for the minimum
of the Lagrangian function
\begin{align*}
\mathcal{L}\left(\tau^{k}\right) &= \mathcal{E}\left(x^{k}+\tau^{k}d^{k}\right)
 -\sum_{i\in\mathcal{A}\left(x^{k}\right)}\lambda_{i}^{k}
 g_{i}\left(x^{k}+\tau^{k}d^{k}\right)
\end{align*}
subject to the constraints. The iteration finishes when the
\emph{Karush-Kuhn-Tucker} conditions are satisfied.
\subsection{\label{sub:Choice-of-Active-Constraints}Choice of active constraints}
\emph{Selesnick, Lang and
  Burrus}~\cite{SelesnickLangBurrus_ConstrainedLeastSquareFIRFilters}
describe a simple algorithm for selecting the constraints on the magnitude
response that apply at each iteration in the design of an FIR filter. The 
general discussion accompanying that description is applicable here. The 
following applies equally to the group delay error component, 
$\mathcal{E}_{T}$, of the total error, $\mathcal{E}$.

The amplitude $A\left(f\right)$ of the filter response minimising the $L_{2}$
error subject to the peak constraints will touch the upper and lower bound
functions at the extremal frequencies of $A\left(f\right)$. At each iteration
of the algorithm, the set of frequency points at which $A\left(f\right)$
touches the constraints is updated. The equality-constrained problem
is then solved by the method of Lagrange multipliers. According to
the \emph{Karush-Kuhn-Tucker} conditions, the solution to the 
\emph{equality}-constrained
problem solves the corresponding \emph{inequality} constrained problem
if all the Lagrange multipliers are non-negative (where the signs
of the multipliers are defined appropriately). If on some iteration
a multiplier is negative, then the solution to the equality-constrained
problem does not solve the corresponding inequality-constrained one.
For this reason, constraints corresponding to negative multipliers
are sequentially dropped from the set of constraints. Although not
proved in theory, this technique appears to converge in practice.

Let the constraint set $S$ be the set of frequencies
$S=\left\{ f_{1},\ldots,f_{r}\right\} $
where $f\in\left[0,\pi\right]$. Let $S$ be partitioned into two
sets $S_{L}$ and $S_{U}$, where $S_{L}$ is the set of frequencies
where the lower bounds apply
\begin{align*}
A\left(x,f\right) &= L\left(f\right)
\end{align*}
and $S_{U}$ is the set of frequencies where the upper bounds apply
\begin{align*}
A\left(x,f\right) &= U\left(f\right)
\end{align*}
Suppose $S_{L}=\left\{ f_{1},\ldots,f_{q}\right\} $ and $S_{U}=\left\{ f_{q+1},\ldots,f_{r}\right\}$.
To minimise $\mathcal{E}_{A}\left(x,f\right)$ subject to these constraints,
form the Lagrangian
\begin{align*}
\mathcal{L}\left(x,\lambda\right) &= \mathcal{E}_{A}\left(x,f\right)-\sum_{i=1}^{q}\lambda_{i}\left[A\left(x,f\right)-L\left(f\right)\right]-\sum_{i=q+1}^{r}\lambda_{i}\left[U\left(f\right)-A\left(x,f\right)\right]
\end{align*}
At the minimum of $\mathcal{E}_{A}\left(x,f\right)$ the gradient
$\nabla_{x}\mathcal{L}\left(x,\lambda\right)=0$ and
\begin{align*}
\nabla_{x}\mathcal{E}_{A}\left(x,f\right)-\sum_{i=1}^{q}\lambda_{i}\nabla_{x}A\left(x,f\right)+\sum_{i=q+1}^{r}\lambda_{i}\nabla_{x}A\left(x,f\right) &= 0\\
A\left(x,f_{i}\right) &= L\left(f_{i}\right)\quad \text{for} \quad 1\le i\le q\\
A\left(x,f_{i}\right) &= U\left(f_{i}\right)\quad \text{for} \quad q+1\le i\le r
\end{align*}

According to the \emph{Karush-Kuhn-Tucker} conditions, when the Lagrange
multipliers $\lambda_{1},\ldots,\lambda_{r}$ are all non-negative,
then the solution to these equations minimises $\epsilon\left(x,f\right)$
subject to the inequality constraints 
\begin{align*}
A\left(x,f_{i}\right) & \ge L\left(f_{i}\right)\quad\text{for}\quad 1\le i\le q\\
A\left(x,f_{i}\right) & \le U\left(f_{i}\right)\quad\text{for}\quad q+1\le i\le r
\end{align*}

\emph{Selesnick et al.} 
~\cite[p.498]{SelesnickLangBurrus_ConstrainedLeastSquareMultiBandFIRFilters}
modify the algorithm of \emph{Selesnick et
  al.}~\cite{SelesnickLangBurrus_ConstrainedLeastSquareFIRFilters} 
so that it can be used in the design of multiband FIR filters, as
shown in Algorithm~\ref{alg:Exchange-algorithm-for-multi-band-FIR-filters}. 
In the following, this algorithm is referred to as the 
Peak-Constrained-Least-Square (PCLS) error algorithm. The modification referred
to is the addition of a second set of constraints. It avoids the cycling of 
constraint sets that otherwise occurs with multi-band filter designs.
 
\emph{Selesnick et al.}~\cite[Section
IV.A]{SelesnickLangBurrus_ConstrainedLeastSquareFIRFilters} 
justify the removal of the most negative Lagrange multiplier as follows:

\begin{quotation}
The constraints are on the values of $A\left(\omega_{i}\right)$ for the 
frequency points $\omega_{i}$ in a constraint set. On each iteration, the
constraint set is updated so that at convergence, the only frequency points at
which equality constraints are imposed are those where $A\left(\omega\right)$
touches the constraint. The equality constrained problem is solved with Lagrange
multipliers. The algorithm below associates an inequality-constrained problem
with each equality constrained one. According to the Kuhn-Tucker conditions,
the solution to the \emph{equality} constrained problem solves the corresponding
\emph{inequality} constrained problem if all the Lagrange multipliers are
non-negative (where the signs of the multipliers are defined appropriately). If
on some iteration a multiplier is negative, then the solution to the 
equality constrained problem does not solve the corresponding inequality
constrained one. For this reason, before the constraint set is updated in the
algorithm described below, constraints corresponding to negative multipliers
(when they appear) are sequentially dropped from the constraint set. In this
way, an inequality constrained problem is solved on each iteration, albeit over
a smaller constraint set. It turns out that in the special case of a lowpass
filter design considered here, this simple iterative technique converges in
practice.
\end{quotation}

The Octave function files \emph{cl2lp.m} and \emph{cl2bp.m}, written by
\emph{Selesnick}~\cite{Selesnick_cl2lp}, are, respectively, low-pass and
band-pass implementations by \emph{Selesnick} of the PCLS filter design method. 

\begin{algorithm}
\begin{enumerate}
\item \label{itm:slb-initialisation} \emph{Initialisation}: Initialise the
  constraint sets $R$ and $S$ to the empty set.
\item \label{itm:slb-constrained-minimisation} \emph{Minimisation with Equality
  Constraints}: Calculate the Lagrange multipliers associated with the filter 
  that minimizes $\mathcal{E}_{A}\left(\omega\right)$ subject to the equality 
  constraints $A\left(\omega_{i}\right)=L\left(\omega_{i}\right)$ for 
  $\omega\in S_{L}$, and $A\left(\omega_{i}\right)=U\left(\omega_{i}\right)$ for 
  $\omega\in S_{U}$.
\item \label{itm:slb-KKT-conditions} \emph{Karush-Kuhn-Tucker Conditions}: If
  there is a constraint set frequency $\omega_{i}$, for which the Lagrange
  multiplier $\lambda_{i}$ is negative, then remove from the active constraint
  set, S, the frequency corresponding to the most negative multiplier, and go
  back to step~\ref{itm:slb-constrained-minimisation}. Otherwise go on to 
  step~\ref{itm:slb-check-violation-over-R}.
\item \label{itm:slb-check-violation-over-R} \emph{Check for Violation over R}:
  Calculate the new filter response, $A\left(\omega_{i}\right)$ for frequencies
  in the alternate constraint set, R. If
  $A\left(\omega_{i}\right)<L\left(\omega_{i}\right)$ or
  $A\left(\omega_{i}\right)>H\left(\omega_{i}\right)$ for some
  $\omega_{i}\in R$, then remove the frequency corresponding to the greatest
  violation from $R$, append that frequency to $S$, and go back to 
  step~\ref{itm:slb-constrained-minimisation}.
\item \label{itm:slb-multiple-exchange-of-constraints} \emph{Multiple Exchange
    of Constraint Set}: Overwrite the previous constraint set, $R$, with the
  current constraint set, $S$. Set the current constraint set $S$ equal to
  $S_{L}\cup S_{U}$, where $S_{L}$ is the set of frequency points $\omega$, in
  $\left[0,\pi\right]$ satisfying both $A^{\prime}\left(\omega_{i}\right)=0$ and
  $A\left(\omega_{i}\right)\le L\left(\omega_{i}\right)$ (ie: troughs failing
  the constraint) and where $S_{U}$, is the set of frequency points $\omega$, in
  $\left[0,\pi\right]$ satisfying both $A^{\prime}\left(\omega_{i}\right)=0$ and
  $A\left(\omega_{i}\right)\ge U\left(\omega_{i}\right)$ (ie: peaks failing the
  constraint).
\item \label{itm:slb-check-convergence}\emph{Check for Convergence}: If
  $A\left(\omega\right)\ge L\left(\omega\right)-\epsilon$
  for all frequency points in $S_{L}$ and if 
  $A\left(\omega\right)\le U\left(\omega\right)+\epsilon$
  for all frequency points in $S_{U}$, then convergence has been achieved.
  Otherwise, go back to step~\ref{itm:slb-constrained-minimisation}.
\end{enumerate}
\caption{Exchange algorithm for multiband FIR filter of
\emph{Selesnick, Lang and Burrus}~\cite[p.498]{SelesnickLangBurrus_ConstrainedLeastSquareMultiBandFIRFilters}.}
\label{alg:Exchange-algorithm-for-multi-band-FIR-filters}
\end{algorithm}

\begin{comment}
\emph{Adams and Sullivan}
\cite[Section IV]{AdamsSullivan_PeakConstrainedLeastSquaresOptimization}
describe a so-called \emph{generalised multiple exchange }(GME) algorithm
for peak-constrained least-squares optimisation, shown in 
Algorithm~\ref{alg:Peak-Constrained-Least-Squares-Optimisation} below. 
They distinguish between the inequality constraints that vary smoothly inside
of each frequency band and inequality constraints at the edges of frequency
bands. The GME algorithm includes the parameters $N_{DF}$, $INCR$
and $N_{KKT}$. $N_{DF}$ denotes the number of degrees of freedom.
$INCR$ denotes the limit on the increase in the number of constraints
in the active set $S_{A}$ from one iteration to the next. $N_{KKT}$
is used to control the number of constraints dropped in Step 2. Adams
and Sullivan recommend using $INCR=4+int\left(N_{DF}/8\right)$ and
$N_{KKT}=4+int\left(N_{DF}/16\right)$. The GME algorithm obtains
its initial guess in Step 0. It performs multiple exchanges in Step
1, and it performs single exchanges in Steps 2 and 3.

\begin{algorithm}
\bigskip{}
\emph{Step 0a)}\qquad{}Use the method of Lagrange multipliers to
minimize $\mathcal{E}_{A}$ subject to the set of equality constraints
$S_{E}$. If the solution is $0$, then go to Step 0b. Otherwise,
initialize $k=0$, $N_{A}=0$, $S_{A}=\emptyset$. Test for optimality
using the KKT conditions. Terminate if the solution is optimal. Else
compute $\mathcal{E}_{A}$ and go to Step 1.

\bigskip{}
\emph{Step 0b)}\qquad{}Select any inequality constraint that yields
a nonzero solution, put it into $S_{A}$, and use the method of Lagrange
multipliers to minimize $\mathcal{E}_{A}$ subject to $S_{E}$ and
$S_{A}$. (As an example of selecting a constraint corresponding to
a nonzero solution in a filter design problem, we can select a passband
edge frequency and activate the constraint corresponding to the minimum
passband gain specification. This allows us to get a nontrivial solution,
even when the passband squared-error weighting is zero.) Set $k=0$,
$N_{A}=1$. Test for optimality using the KKT conditions. Terminate
if the solution is optimal. Otherwise, compute $\mathcal{E}_{A}$
and go to Step 1.

\bigskip{}
\emph{Step 1)}\qquad{}Let $S_{AN}$ denote the subset of $S_{A}$
that corresponds to nonsmooth inequality constraints. Let $S_{AS}$
denote the subset of $S_{A}$ that corresponds to smooth inequality
constraints at local error extrema. Define $S_{AC}=S_{AN}\cup S_{AS}$.
Let $N_{AC}$ denote the number of constraints in $S_{AC}$. Let 
$S_{TV}=\left(S_{VN}\cup S_{VS}\right)-S_{AC}$.
$S_{VN}$ denotes the nonsmooth inequality constraints that violate
the specifications. $S_{VS}$ denotes the smooth inequality constraints
at local error extrema that violate the specifications. (At first,
it may seem unnecessary to exclude $S_{AC}$ from $S_{TV}$ because
any constraint that was active in the previous iteration should now
be satisfied with exact equality and, theoretically, should not violate
the specifications. However, due to machine rounding errors, we may
encounter small violations of constraints that were active in the
previous iteration.) Let $N_{TV}$ denote the number of constraints
in $S_{TV}$, and let $N_{T}=N_{TV}+N_{AC}$. If $N_{T}>N_{DF}-1$
or if $k>1$ and $N_{T}>N_{A}+INCR$, then go to Step 3. Otherwise,
define $S_{T}=S_{TV}\cup S_{AC}$. Use the method of Lagrange multipliers
to minimize $\mathcal{E}_{A}$ subject to the constraints in $S_{E}$
and $S_{T}$, and obtain $\mathcal{E}_{A,T}$. Terminate if the solution
is optimal. If any KKT multiplier is negative, then set $I_{KKT}=1$
and go to Step 2. Otherwise, if $\mathcal{E}_{A,T}>\mathcal{E}_{A}$
and all KKT multipliers are nonnegative, then let $k=k+1$, $S_{A}=S_{T}$,
$N_{A}=N_{T}$, $\mathcal{E}_{A}=\mathcal{E}_{A,T}$, and repeat Step
1. Otherwise, if $\mathcal{E}_{A,T}\le\mathcal{E}_{A}$, go to Step
3.

\bigskip{}
\emph{Step 2)}\qquad{}If $I_{KKT}>N_{KKT}$, then go to Step 3. Otherwise,
drop the constraint with the most negative KKT multiplier from $S_{T}$
and set $I_{KKT}=I_{KKT}+1$. Use the method of Lagrange multipliers
to minimize $\mathcal{E}_{A}$ subject to the constraints in $S_{E}$
and $S_{T}$, and obtain $\mathcal{E}_{A,T}$. Terminate if the solution
is optimal. Otherwise, if $\mathcal{E}_{A,T}>\mathcal{E}_{A}$ and
all KKT multipliers are non-negative, then let $k=k+1$, $S_{A}=S_{T}$,
$N_{A}=N_{T}$, $\mathcal{E}_{A}=\mathcal{E}_{A,T}$ and go to Step
1. If $\mathcal{E}_{A,T}>\mathcal{E}_{A}$ and any KKT multiplier
is negative and $I_{KKT}<N_{KKT}$, then repeat Step 2. If 
$\mathcal{E}_{A,T}\le\mathcal{E}_{A}$
or if any KKT multiplier is negative and $I_{KKT}>N_{KKT}$, then
go to Step 3.

\bigskip{}
\emph{Step 3)}\qquad{}Starting from $S_{A}$, perform an iteration
based on the \emph{Goldfarb-Idnani} algorithm, and obtain the
corresponding constraints $S_{A,GI}$ and error energy $\mathcal{E}_{A,GI}$.
If the solution is optimal, then terminate. If the problem is infeasible,
then notify the user and terminate. Otherwise, let $k=k+1$, $S_{A}=S_{A,GI}$,
$\mathcal{E}_{A}=\mathcal{E}_{A,GI}$, and go to Step 1.
\caption{Peak-Constrained Least-Squares Optimisation.}
\label{alg:Peak-Constrained-Least-Squares-Optimisation}
\end{algorithm}

Sullivan and Adams claim that:
\begin{quotation}
 ``The GME algorithm must converge to
the unique optimal solution of any feasible positive-definite quadratic
programming problem within a finite number of iterations. (Error energies
are always positive definite in filter design problems.) The number
of iterations is finite because each iteration terminates with a different
set of active constraints and because the number of different active
constraint sets is finite. (We can use a finite number of frequency
grid points in filter problems.) Each iteration terminates with a
different set of active constraints because the objective function
increases monotonically. The final solution must be optimal because
the algorithm cannot stop until the KT conditions are satisfied.
\end{quotation}
\end{comment}
\subsection{Linearisation of peak constraints}
At each iteration the magnitude response and group-delay are
linearised about $x^{k}$. I follow the description of the linearised 
constraints given by \emph{Sullivan} 
~\cite[p.2855]{SullivanAdams_PCLS_IIRDigitalFilters}. The linearised 
magnitude response is:
\begin{align*}
\hat{A}\left(x\right) &= A\left(x^{k}\right)+\nabla_{x}A\left(x^{k}\right)^{\top}\left(x-x^{k}\right)
\end{align*}
The frequency response magnitude inequality constraints are, in the
pass band
\begin{align*}
A_{D}-\hat{A}\left(x\right) & \ge 0\\
\hat{A}\left(x\right)-\left[A_{D}-\Delta_{A_{P}}\right] & \ge 0
\end{align*}
and in the stop band
\begin{align*}
\Delta_{A_{S}}-\hat{A}\left(x\right) & \ge 0
\end{align*}
where $\Delta_{A_{p}}$ is the pass band ripple for the desired gain
$A_{D}$ and $\Delta_{A_{S}}$ is the stop band ripple. After linearising
about $x^{k}$ these constraints become
\begin{align*}
A_{D}-A\left(x^{k}\right)-\nabla_{x}A\left(x^{k}\right)^{\top}\left(x-x^{k}\right) & \ge 0\\
A\left(x^{k}\right)+\nabla_{x}A\left(x^{k}\right)^{\top}\left(x-x^{k}\right)-\left[A_{D}-\Delta_{A_{P}}\right] & \ge 0\\
\Delta_{A_{S}}-A\left(x^{k}\right)-\nabla_{x}A\left(x^{k}\right)^{\top}\left(x-x^{k}\right) & \ge 0
\end{align*}
Similarly, the linearised group-delay is 
\begin{align*}
\hat{T}\left(x\right) &= T\left(x^{k}\right)+\nabla_{x}T\left(x^{k}\right)^{\top}\left(x-x^{k}\right)
\end{align*}
and the group-delay inequality constraints in the pass band are
\begin{align*}
\left[T_{D}+\Delta_{D}\right]-\hat{T}\left(x\right) & \ge 0\\
\hat{T}\left(x\right)-\left[T_{D}-\Delta_{T}\right] & \ge 0
\end{align*}
where $\Delta_{T}=T_{\text{max}}-T_{D}=T_{D}-T_{\text{min}}$ is the tolerance for
the group-delay error compared with the desired group-delay $T_{D}$.
As before, the two corresponding linearised constraints on the 
group-delay in the pass band are
\begin{align*}
\left[T_{D}+\Delta_{T}\right]-T\left(x^{k}\right)-\nabla_{x}T\left(x^{k}\right)^{\top}\left(x-x^{k}\right) & \ge 0\\
T\left(x^{k}\right)+\nabla_{x}T\left(x^{k}\right)^{\top}\left(x-x^{k}\right)-\left[T_{D}-\Delta_{T}\right] & \ge 0
\end{align*}
The frequency response inequality constraints are calculated at a
grid of frequency points. For a low-pass filter there are two amplitude
constraints and two group-delay constraints in the pass band and 
one amplitude constraint in the stop band. 
\subsection{Ensuring the stability of the IIR filter}
An IIR filter is stable if the poles of the filter transfer function lie within
the unit circle: $\left| z \right| < R < 1$. 
\emph{Deczky}~\cite{Deczky_MinPSynthesisIIRDigitalFilters} and 
\emph{Richards}~\cite{Richards_DeczkyRecursiveDecimator} define the transfer 
function in the form of gain, pole locations and zero locations. In this case
filter stability is ensured by a simple constraint on the pole radius.

The partial derivatives of the amplitude response with respect to the filter
coefficients are simpler when expressed in terms of the numerator and 
denominator polynomials of the transfer function. This has lead many authors to
suggest filter stability criteria expressed in terms of the coefficients of the
denominator polynomial. 
\emph{Tarczynski et al.}~\cite{TarczynskiCainHermanowiczRojewski_WISEMethodDesignIIRFilters} 
ensure stability by adding a \emph{barrier} function to the squared error based
on the impulse response of the digital filter that corresponds to the denominator
polynomial of the filter transfer function being optimised.
\emph{Lang}~\cite{Lang_LSDesignIIRDigitalFiltersPoleRadiusConstraint} describes
a method for finding successive coefficient vectors based on Rouch\'{e}'s
theorem. \emph{Dumitrescu and
  Niemist\"\o}~\cite{DumitrescuNiemisto_IIRFilterPositiveRealness} compare
Lang's method with one that ensures that the updated denominator polynomial
remains a Schur polynomial in the vicinity of the current coefficient vector.
\emph{Lu and
  Hinamoto}~\cite{LuHinamoto_IIRFrequencyMaskingFiltersConeProgramming} express
the denominator polynomial as a product of second-order sections and derive a
linear inequality stability constraint on the denominator coefficients.
\emph{Lu}~\cite{Lu_ArgumentPrincipleIIRFilterStability} describes a 
stability test based on Cauchy's Argument Principle.

In my opinion, expressing the filter transfer function in the gain-pole-zero
form is preferable to the usual polynomial fraction form because the former
provides the simplest possible stability criterion. 
\subsection{\label{sub:Selecting-an-initial-filter-design}Selecting an initial filter design}
The constraints on the filter design are the desired response and stability.
\subsubsection{Windowed FIR initial filters}
An FIR filter approximating the desired response can be designed with the
Octave \emph{remez} function. Alternatively, the FIR filter can be designed with
the ``windowing'' method, summarised here. The frequency response of a digital
filter
\begin{align*}
H\left(z\right)&=\sum^{\infty}_{k=-\infty}h_{k}z^{-k}
\end{align*}
with a lowpass response cutoff at $\omega_{p}$ is
\begin{align*}
H\left(\omega\right)&=\sum^{\infty}_{k=-\infty}h_{k}e^{-\imath k\omega}\\
&=\begin{cases}
1,&\left|\omega\right|<\omega_{p}\\
0,&\omega_{p}<\left|\omega\right|<\pi
\end{cases}
\end{align*}
The coefficients of the impulse response are
\begin{align*}
h_{k}&=\frac{1}{2\pi}\int_{-\omega_{p}}^{\omega_{p}}e^{\imath k \omega}d\omega\\
&=\frac{1}{\pi k}\sin k\omega_{p}\\
&=\frac{\omega_{p}}{\pi}\sinc k\omega_{p}
\end{align*}
To create an FIR response we truncate the response to length $L=2N+1$ with a 
window function. The window function is selected for main-lobe width and 
side-lobe suppression. A typical window function is
\begin{align*}
W_{k}&=\begin{cases}
\left[\alpha+\left(1-\alpha\right)\cos \frac{2\pi k}{N}\right],
&\left|k\right|\le N\\
0,&\left|k\right|>N
\end{cases}
\end{align*}
For the Hamming window, $\alpha=0.54$. The Octave code to implement a windowed
FIR filter is:
\begin{small}
\begin{verbatim}
b=2*fc*sinc((-((L-1)/2):((L-1)/2))*2*fc).*hamming(L)
\end{verbatim}
\end{small}
where $L$ is the FIR filter length and $fc<0.5$ is the low-pass cut-off 
frequency for sampling frequency $f_{S}=1$.
\subsubsection{\label{Tarczynski-unconstrained-minimisation-with-barrier}Tarzcynski's method of unconstrained optimisation of an IIR initial filter}
An arbitrary filter can be refined by unconstrained optimisation with a 
\emph{``barrier''} function (see Appendix~\ref{sub:Barrier-functions}). 
\emph{Tarczynski et al.} 
~\cite{TarczynskiCainHermanowiczRojewski_WISEMethodDesignIIRFilters}, propose
minimising the error with the following, so-called, \emph{WISE} barrier function:
\begin{align}
\label{eqn:WISE-barrier-function}
\left(1-\lambda\right)\mathcal{E}_{H}+\lambda\sum^{T+M}_{t=T+1}f^{2}\left(t\right)
\end{align}
where $\mathcal{E}_{H}$ is the filter response error defined in 
Equation~\ref{eqn:Definition-of-squared-response-error}, $\lambda$, $T$ and
$M$ are suitable constants and $f\left(t\right)$ is the impulse response of the 
filter $F\left(z\right)=\frac{1}{D\left(z\right)}$. \emph{Tarczynski et al.} 
provide heuristics for selecting $\lambda$, $T$ and $M$. Typically, 
$\lambda \in \left[10^{-10},10^{-3}\right]$, $T\in \left[ 100, 500 \right]$ and 
$M=RK$. The barrier function (the second part of Equation 
~\ref{eqn:WISE-barrier-function}) is intended to be small when the filter is 
stable and increase rapidly otherwise. \emph{Roberts and Mullis} 
~\cite[Section 8.3]{RobertsMullis_DigitalSignalProcessing} show that the state
space description of the direct-form implementation of 
$F\left(z\right)$ is:
\begin{align*}
\left[\begin{array}{c}
x\left(t+1\right)\\
y\left(t\right)
\end{array}\right] &= \left[\begin{array}{cc}
A & B\\
C & D
\end{array}\right]\left[\begin{array}{c}
x\left(t\right)\\
u\left(t\right)
\end{array}\right]
\end{align*}
where:
\begin{align*}
A &= \left[\begin{array}{cccc}
0 & 1 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 1\\
-d_{N_{d}} & -d_{N_{d}-1} & \cdots & -d_{1}
\end{array}\right]\\
B &= \left[\begin{array}{ccccc}0 & 0 & \cdots & 0 & 1\end{array}\right]^{\top}\\
C &= \left[\begin{array}{ccc}-d_{N_{d}} & \cdots & -d_{1}\end{array}\right]\\
D &= 1
\end{align*}

Alternatively, for the filter transfer function, 
$H\left(z\right)$, given by Equation~\ref{eqn:Transfer-function-H}, 
\emph{Tarczynski et al.}~\cite[Appendix 1]
{TarczynskiCainHermanowiczRojewski_WISEMethodDesignIIRFilters}
show that the filter $\frac{z^{-N_d}}{D\left(\rho z\right)}$ can be implemented
as a cascade of first order sections,
$\frac{z^{-1}}{1-p_{i}\left(\rho z\right)^{-1}}$. $0<\rho<1$ is 
chosen to limit the pole magnitudes. Let the output of the $i$th 
section, $y_{i}$, be the input to the $i+1$th section, $u_{i+1}$, and 
assume the poles are ordered so that 
$\left|p_{1}\right|\ge\left|p_{2}\right|\ge\hdots\ge\left|p_{N_{d}}\right|$,
then the state variable model for each section is:
\begin{align*}
  x_{i}\left(t+1\right) &= p_{i}\rho^{-1}x_{i}\left(t\right)+u_{i}\left(t\right)\\
  y_{i}\left(t\right)   &= x_{i}\left(t\right)
\end{align*}
The overall state variable model is (for $R=1$):
\begin{align*}
A &= \left[\begin{array}{ccccc}
p_{1}\rho^{-1} & 0             & 0      & \cdots & 0\\
1             & p_{1}\rho^{-1} & 0      & \cdots & 0\\
\vdots        & \vdots        & \vdots & \ddots & \vdots\\
0             & 0             & \hdots & 1      & p_{N_{d}}\rho^{-1}
\end{array}\right]\\
B &= \left[\begin{array}{ccccc}1 & 0 & \cdots & 0 & 0\end{array}\right]^{\top}\\
C &= \left[\begin{array}{ccccc}0 & 0 & \cdots & 0 & 1\end{array}\right]\\
D &= 0\\
\end{align*} 

In both cases, the corresponding impulse response is:
\begin{align*}
f\left(t\right) &= \begin{cases}
0 & t<0\\
D & t=0\\
CA^{t-1}B & t>0
\end{cases}
\end{align*}

\emph{Golub and van Loan} 
~\cite[Algorithm 11.2.2]{GolubVanLoan_MatrixComputations} show an algorithm,
reproduced as Algorithm~\ref{alg:Compute-powers-of-matrix}, 
for efficiently computing the powers of a matrix by cumulative products of the 
binary powers of the matrix. This algorithm requires at most 
$2\times\text{floor}\left[\log_{2}\left(s\right)\right]$ matrix multiplies. 
If $s$ is a power of $2$, then only $\log_{2}\left(s\right)$ matrix multiplies
are needed.

\begin{algorithm}[htbp]
The following algorithm computes $F=A^{s}$ for matrix 
$A \in \mathbb{R}^{n\times n}$ and a positive integer $s$ with binary 
expansion $s=\sum_{k=0}^{K}{\beta_{k}2^{k}}$.
\begin{algorithmic}
\State $Z=A$, $q=0$
\While{$\beta_{q}=0$}
  \State $Z=Z^{2}$
  \State $q=q+1$
\EndWhile
\State $F=Z$
\For{$k=q+1,\hdots,t$}
  \State $Z=Z^{2}$
  \If{$\beta_{k} \ne 0$}
    \State $F=FZ$
  \EndIf
\EndFor
\end{algorithmic}
\caption{Compute the powers of a matrix.
  (See \emph{Golub and van Loan}~\cite[Algorithm
  11.2.2]{GolubVanLoan_MatrixComputations}.)}
\label{alg:Compute-powers-of-matrix}
\end{algorithm}

The Octave script \emph{tarczynski\_ex2\_standalone\_test.m}, designs a filter 
for the specifications of \emph{Tarczynski et a.l} Example
2~\cite{TarczynskiCainHermanowiczRojewski_WISEMethodDesignIIRFilters} with 
$nN=24$, $nD=2$ and $R=2$ by unconstrained minimisation of
Equation~\ref{eqn:WISE-barrier-function} with \emph{fminunc}. The resulting
response is shown in Figure~\ref{fig:tarczynski-ex2-standalone-response} and the
pole-zero plot of the filter is shown in
Figure~\ref{fig:tarczynski-ex2-standalone-pz}. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{tarczynski_ex2_standalone_test_response}}
\caption{Tarczynski et al.\ Example 2, response for nN=24, nD=2 and R=2.}
\label{fig:tarczynski-ex2-standalone-response} with 
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{tarczynski_ex2_standalone_test_pz}}
\caption{Tarczynski et al.\ Example 2, pole-zero plot for nN=24, nD=2 and R=2.}
\label{fig:tarczynski-ex2-standalone-pz}
\end{figure}

The Octave function \emph{xInitHd} uses the WISE barrier function to design an 
initial filter in polynomial form and then calls the Octave \emph{qroots}
function to convert that polynomial into \emph{gain-pole-zero} form. As 
noted in the \hyperlink{sec:Introduction}{Introduction},  finding the roots
of a polynomial is a difficult problem in numerical analysis and the output of the \emph{qroots} function depends on the CPU architecture, operating system,
library versions, compiler version and Octave version.

\subsubsection{Surma-aho and Saram\"{a}ki method of designing an IIR initial filter}
Appendix~\ref{app:Saram\"{a}ki-unconstrained-minimisation-initial-IIR} describes
the method of \emph{Surma-aho} and
\emph{Saram\"{a}ki}~\cite{SurmaahoSaramaki_ApproximatelyLinearPhaseRecursiveDigitalFilters}
for designing an initial low-pass filter implemented as either a single filter
or as the parallel combination of two all-pass filters. Unfortunately, this
method requires root-finding of intermediate polynomials. I find the
method of \emph{Tarczynski et al.} to be more useful.

\section{\label{sec:Examples-of-IIR-filter-design-SQP}Examples of IIR filter design with SQP and constrained pole and zero locations}
\subsection{Introductory comments on the IIR filter design examples}
This section considers examples of IIR filter design. The design procedure is:
\begin{itemize} 
\item find a valid initial design
\item iteratively reduce the mean-square-error (MMSE) with the procedure
described in Section~\ref{sub:Solution-quasi-Newton-optimisation}. 
\item iteratively apply constraints with the peak-constrained-least-square-error
(PCLS) algorithm described in Section~\ref{sub:Choice-of-Active-Constraints}.
\end{itemize}
For the filter design examples in this section, the filter amplitude, phase and
group delay responses and their gradients are calculated by the Octave 
functions \emph{iirA}, \emph{iirP} and \emph{iirT}, respectively.

\textbf{!!! WARNING !!! The \emph{iirA}, \emph{iirP} and \emph{iirT} functions
do not attempt to handle the discontinuity and non-differentiability of
the properties of a zero at $z=1$ with $\omega=0$.} In general, I have found
that this does not cause difficulties but may result in a sub-optimal
result. The differentiator examples of
Section~\ref{sec:iir-R-2-differentiator-filter} and   
Section~\ref{sec:iir-sqp-slb-lowpass-differentiator} assume a zero at $z=1$ and
design a correction filter that provides the desired combined response.

Octave includes an SQP solver function, \emph{sqp}. I have not used this 
function because it calls separate functions to calculate the error and the
constraints. Instead I have written my own Octave SQP
solver, \emph{iir\_sqp\_mmse}, based on the BFGS update algorithm and, in the
PCLS solver, \emph{iir\_slb}, the constraints are calculated at the same
time as the error. Other open-source Quadratic Programming (QP) solvers exist.
For example, the \emph{Proximal Interior-Point Quadratic Programming
  Solver}(PIQP) of \emph{Schwan et al.}~\cite{Schwan_PIQP2023}.

\subsubsection{Finding an initial IIR filter design}
The initial IIR filter design must be stable and bear a passing resemblance
to the desired response. The multi-dimensional IIR filter design 
surface has many local minima and the minimum reached depends on the initial
point. After deciding the decimation ratio, $R$, a stable initial design can 
be found with:
\begin{itemize}
\item an FIR filter and an estimate of the number of poles required
\item an arbitrary IIR filter optimised with the Octave function \emph{xInitHd}
\end{itemize}

The Octave function \emph{xInitHd}
begins with an initial filter and designs a rational polynomial transfer 
function approximation to the desired response by repeated calls to the Octave
\emph{fminunc} function. Filter stability is assured by a barrier function 
based on the impulse response of a filter constructed from the poles of the 
approximate response. See Section~\ref{sub:Selecting-an-initial-filter-design}
and \emph{Tarczynski et al.}
~\cite{TarczynskiCainHermanowiczRojewski_WISEMethodDesignIIRFilters}.
The coefficient constraints are defined in the Octave function 
\emph{xConstraints}. In fact I only constrain the pole radiuses and do not 
constrain the scale factor, $K$, or the complex conjugate pole angles.
It is possible that the initial filter produced by \emph{xInitHd} has a
negative scale factor and the filter amplitude response is real but negative.
See, for example, the initial filter of the \emph{R=2 decimator} filter below. 
Presumably, the filter was found at a minimum so reversing the sign of the
scale factor reverses the sign of the initial amplitude gradients. In 
practice, a first pass of MMSE optimisation will (hopefully!) reverse the
sign of $K$ to match the sign of the desired response while, at the same time,
finding a new minimum. The constraints applied to the amplitude response by 
the implementation of PCLS optimisation in \emph{iir\_slb} assume that the 
amplitude function is positive so an attempt at PCLS optimisation of a filter
with a negative scale factor will most likely fail.

Appendix~\ref{sub:Initial-estimate-with-Goldfarb-Idnani} works through the 
derivation of the \emph{Goldfarb-Idnani} 
algorithm~\cite{GoldfarbIdnani_NumericallyStableDualQuadraticPrograms} for 
finding an initial solution that meets constraints. As an example, 
the Octave script \emph{goldfarb\_idnani\_fir\_minimum\_phase\_test.m}
begins with a 
non-minimum phase FIR bandpass filter and finds a minimum phase FIR filter, that
is, an FIR bandpass filter with the constraint that the zero locations lie on
or within the unit circle. When the number of constraints on the frequency 
response is more than ten or so the script fails due to numerical problems with
the Hessian matrix. The script does find a minimum-phase FIR filter albeit with a
very poor response. In this case I found that a ``by-eye'' or ``cut-and-fit''
iterative approach to finding an initial filter is more useful. For 
example see the Octave script \emph{iir\_sqp\_slb\_fir\_bandpass\_test.m}.
\subsubsection{MMSE optimisation}
MMSE optimisation is performed by calling Octave function \emph{iir\_sqp\_mmse}.
The response error is minimised
while the real and complex pole radiuses are constrained to 
$\left|r\right|<rho<1$.
The other parts of the coefficient vector (scale factor, zero radiuses and 
pole and zero angles) are not constrained. The \emph{vS} argument to
\emph{iir\_sqp\_mmse} specifies the indexes into the frequency vectors
$\omega_{a}$ etc.\ of linear constraints at the corresponding index into
$A_{du}$ or $A_{dl}$ etc. Function \emph{iir\_sqp\_mmse ()}
calls \emph{sqp\_bfgs} to minimise the objective function 
\emph{iir\_sqp\_mmse\_fx ()} with linear constraints calculated by
\emph{iir\_sqp\_mmse\_gx ()}. These functions calculate the squared-error in the
response amplitude and delay and linear constraints by calls to \emph{iirE ()}.
That function calculates the error
with trapezoidal integration. If the frequency bands are not contiguous then
zeros in the weight vector can make frequency transition bands.
A useful future improvement is to add a constraint on the slope of
the amplitude response in the transition band. For a lowpass filter:
$\frac{\partial{}A}{\partial\omega}<0$. 

I found by trial-and-error when running \emph{iir\_sqp\_mmse} that the SQP
Hessian matrix can be initialised with the diagonal elements of the amplitude
squared error Hessian. Similarly, the current SQP search point can be updated
with the \emph{Armijo-Kim} line-search algorithm and the 
\emph{Broyden-Fletcher-Goldfarb-Shanno} (BFGS) Hessian matrix update algorithm 
(see Appendix~\ref{Inexact-step-size-selection} and
Appendix~\ref{Updating-with-the-BFGS-formula} respectively). The error surface
is not quadratic and has many, many local minima. The SQP loop is more stable
if, at each iteration, the error surface is approximated by a quadratic surface
with the BFGS estimate of the Hessian matrix. Typically, the MMSE optimisation
process is iterative; the design process starts with a loose amplitude only
specification and the constraints on amplitude, phase and delay are gradually
tightened.

There are several reasons why an optimisation attempt might fail:
\begin{itemize}
\item the weighting factors for the comined squared error of, for example,
amplitude and group delay, are not appropriate. Experiment with the weights.
\item the number of iterations may exceed the limit. Increase the iteration
  limit, \emph{maxiter},
\item the tolerance used may be too low. Increase the tolerance, \emph{tol}.
\item the line-search direction does not satisfy the constraints:
\begin{verbatim}
warning: searching for d within constraints but norm(d)<tol^2!
\end{verbatim}
Reduce the maximum coefficient update size, \emph{dmax}.
\item the line-search algorithm may not find a minimum or
  the line-search algorithm may find that the objective function is not
  approximately quadratic in the search region:
\begin{verbatim}
Found tau = 0.000000 using goldensection search of Lagrangian
warning: norm(delta)<eps
\end{verbatim}
\end{itemize}
\subsubsection{PCLS optimisation}
The MMSE optimisation constrains the integrated error over a frequency interval.
PCLS optimisation constrains the peaks of the amplitude, phase and group-delay
responses. For example, the MMSE design of a low-pass filter may have amplitude
peaks above $0\text{dB}$. The PCLS algorithm of
\emph{Selesnick, Lang and Burrus}
~\cite[Fig.4,p.499]{SelesnickLangBurrus_ConstrainedLeastSquareMultiBandFIRFilters}
(reproduced above as Algorithm
~\ref{alg:Exchange-algorithm-for-multi-band-FIR-filters}), is implemented in the 
Octave function \emph{iir\_slb}.
The function handle of the MMSE solver (in this case \emph{iir\_sqp\_mmse})
is an argument to \emph{iir\_slb}.
The peak-exchange algorithm of \emph{Selesnick et al.} is much
simpler than that of Adams and Sullivan 
~\cite[Section IV]{AdamsSullivan_PeakConstrainedLeastSquaresOptimization}.

Figure~\ref{fig:iir-slb-update-constraints-test-x7A} shows the failed
constraints for the amplitude response of a low pass filter with an amplitude
constraint mask. The figure was generated by the Octave script 
\emph{iir\_slb\_update\_constraints\_test.m}.
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_slb_update_constraints_test_x7A}}
\caption{Example of failed constraints for a low pass filter.}
\label{fig:iir-slb-update-constraints-test-x7A} 
\end{figure}
When switching from MMSE to PCLS optimisation, the introduction of constraints
on the response peaks alters the Lagrangian and the pass-band and stop-band
weights must be modified by trial-and-error.
\clearpage
\subsection{Tarczynski et al.\ Example 2}
Figure~\ref{fig:tarczynski-ex2-standalone-response} shows the response of a
filter designed with the ``WISE'' method of \emph{Tarczynski et al.} 
~\cite{TarczynskiCainHermanowiczRojewski_WISEMethodDesignIIRFilters}. The
coefficients of the numerator and denominator polynomials of the filter are:
\begin{small}
\verbatiminput{tarczynski_ex2_standalone_test_N0_coef.m}
\verbatiminput{tarczynski_ex2_standalone_test_D0_coef.m}
\end{small}
In the above listing, the first line shows the gain, and subsequent lines show,
respectively, $2$ real zeros, $2$ real poles, the zero radiuses for $11$
conjugate pairs of zeros and the zero angles for $11$ conjugate pairs of zeros.
In practice, since $R=2$, the real poles are split into pairs of conjugate
poles lying on the imaginary axis. After some experimentation I modified the
filter to:
\begin{small}
\verbatiminput{iir_sqp_mmse_tarczynski_ex2_test_x0_coef.m}
\end{small}
In this case there are three real zeros. The Octave script
\emph{iir\_sqp\_mmse\_tarczynski\_ex2\_test.m} calls the
\emph{iir\_sqp\_mmse ()} function to MMSE optimise this filter. The optimised
filter is:
\begin{small}
\verbatiminput{iir_sqp_mmse_tarczynski_ex2_test_x1_coef.m}
\end{small}
The corresponding transfer function numerator and denominator polynomials are,
respectively:
\begin{small}
\verbatiminput{iir_sqp_mmse_tarczynski_ex2_test_N1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{iir_sqp_mmse_tarczynski_ex2_test_D1_coef.m}
\end{small}
Figure~\ref{fig:Tarczynski-ex2-mmse-x1} shows the response of the optimised
filter, Figure~\ref{fig:Tarczynski-ex2-mmse-x1pass} shows the pass-band response
and Figure~\ref{fig:Tarczynski-ex2-mmse-x1pz} shows the corresponding pole-zero
plot.
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_mmse_tarczynski_ex2_test_x1}}
\caption{Tarczynski et al.\ Example 2 response after MMSE optimisation.}
\label{fig:Tarczynski-ex2-mmse-x1}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_mmse_tarczynski_ex2_test_x1pass}}
\caption{Tarczynski et al.\ Example 2 pass-band response after MMSE
  optimisation.}
\label{fig:Tarczynski-ex2-mmse-x1pass}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_mmse_tarczynski_ex2_test_x1pz}}
\caption{Tarczynski et al.\ Example 2 pole-zero plot after MMSE optimisation.}
\label{fig:Tarczynski-ex2-mmse-x1pz}
\end{figure}
\clearpage
\subsection{\label{sub:Deczkys-Example-3}Deczky's Example 3}
\emph{Sullivan and Adams}~\cite[p. 2859]{SullivanAdams_PCLS_IIRDigitalFilters}
refer to the following example IIR filter design specification as 
\emph{``Filter 2-iv''}. It is a modified version of \emph{Deczky}'s Example 3,
~\cite{Deczky_MinPSynthesisIIRDigitalFilters}.
\begin{align*}
U &= 0\\
V &= 0\\
M &= 10\\
Q &= 6\\
R &= 1\\
A\left(f\right) &= \begin{cases}
1 & 0<f<0.15\\
0 & 0.3<f<0.5
\end{cases}\\
T\left(f\right) &= 10.00\quad0<f<0.25
\end{align*}
The Octave script \emph{deczky3\_sqp\_test.m} implements this example. The
filter specification defined in that file is
\begin{small}
\verbatiminput{deczky3_sqp_test_spec.m}
\end{small}
\emph{Sullivan} and \emph{Adams} 
initialise the filter coefficients with a set of coefficients called 
``IPZS-1''~\cite[IPZS-1, p. 2860]{SullivanAdams_PCLS_IIRDigitalFilters}
\begin{small}
\begin{verbatim}
z=[exp(j*2*pi*0.41),exp(j*2*pi*0.305), ...
   1.5*exp(j*2*pi*0.2),1.5*exp(j*2*pi*0.14),1.5*exp(j*2*pi*0.08)];
p=[0.7*exp(j*2*pi*0.16),0.6*exp(j*2*pi*0.12),0.5*exp(j*2*pi*0.05)];
K=0.0096312406;
x0=[K,abs(z),angle(z),abs(p),angle(p)]';
\end{verbatim}
\end{small}
The above listing shows that the initial filter has $0$ real zeros, $0$ real
poles, $5$ conjugate pairs of zeros, and $3$ conjugate pairs of poles. The
initial response is shown in Figure~\ref{fig:Deczky-Ex3-Initial-x0}. The
corresponding pole-zero plot is shown in
Figure~\ref{fig:Deczky-Ex3-Initial-x0-pz}.
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_sqp_test_initial_x0}}
\caption{Deczky Example 3, response for initial coefficients.}
\label{fig:Deczky-Ex3-Initial-x0}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_sqp_test_initial_x0pz}}
\caption{Deczky Example 3, pole-zero plot for initial coefficients.}
\label{fig:Deczky-Ex3-Initial-x0-pz}
\end{figure}
\clearpage
\subsubsection{MMSE optimisation of Deczky's Example 3}
With weights $W_{ap}=W_{as}=1$ and $W_{tp}=0.125$ the first MMSE optimisation
pass gives the response shown in Figure~\ref{fig:Deczky-Example-3-MMSE-x1}. 
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_sqp_test_mmse_x1}}
\caption{Deczky Example 3, MMSE optimised response after pass 1.}
\label{fig:Deczky-Example-3-MMSE-x1}
\end{figure}

After some experimentation, the second iteration, with $W_{tp}=0.5$, gives the 
response shown in Figure~\ref{fig:Deczky-Example-3-MMSE-x2} with pass-band 
details shown in Figure~\ref{fig:Deczky-Example-3-MMSE-x2-passband} and the 
pole-zero plot shown in Figure~\ref{fig:Deczky-Example-3-MMSE-x2-pz}.
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_sqp_test_mmse_x2}}
\caption{Deczky Example 3, MMSE optimised response after pass 2.}
\label{fig:Deczky-Example-3-MMSE-x2}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_sqp_test_mmse_x2pass}}
\caption{Deczky Example 3, MMSE optimised passband response after pass 2.}
\label{fig:Deczky-Example-3-MMSE-x2-passband}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_sqp_test_mmse_x2pz}}
\caption{Deczky Example 3, MMSE optimised pole-zero plot after pass 2.}
\label{fig:Deczky-Example-3-MMSE-x2-pz}
\end{figure}
\clearpage
\subsubsection{PCLS optimisation of Deczky's Example 3}
The test script \emph{deczky3\_sqp\_test.m} now switches to PCLS optimisation of
the MMSE filter. After some experimentation, the final specification becomes
$fap=0.15$, $dBap=0.1dB$, $Wap=1$, $fas=0.30$, $dBas=30dB$, $Was=1$, $ftp=0.25$,
$Wtp=2$, $tp=10$ samples group delay and $tpr=0.004$ samples 
of peak-to-peak group delay ripple. The resulting amplitude and delay responses 
are shown in Figure~\ref{fig:Deczky-Example-3-PCLS-d1} with pass-band detail 
shown in Figure~\ref{fig:Deczky-Example-3-PCLS-d1-passband}. The corresponding 
pole-zero plot is shown in Figure~\ref{fig:Deczky-Example-3-PCLS-d1-pz}.

\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_sqp_test_pcls_d1}}
\caption{Deczky Example 3, PCLS optimised response.}
\label{fig:Deczky-Example-3-PCLS-d1}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_sqp_test_pcls_d1pass}}
\caption{Deczky Example 3, PCLS optimised passband response.}
\label{fig:Deczky-Example-3-PCLS-d1-passband}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_sqp_test_pcls_d1pz}}
\caption{Deczky Example 3, PCLS optimised pole-zero plot.}
\label{fig:Deczky-Example-3-PCLS-d1-pz}
\end{figure}

The optimised filter vector is, in the gain, zeros and 
poles form of Equation~\ref{eqn:Filter-gain-zeros-poles}:
\begin{small}
\verbatiminput{deczky3_sqp_test_d1_coef.m}
\end{small}
and the corresponding transfer function numerator and denominator polynomials
(found with Octave function \emph{x2tf}) are, respectively:
\begin{small}
\verbatiminput{deczky3_sqp_test_N1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{deczky3_sqp_test_D1_coef.m}
\end{small}
\clearpage
\subsubsection{An alternative implementation of Deczky's Example 3}
The test script \emph{deczky3a\_sqp\_test.m} is an alternative implementation
of \emph{Deczky}'s Example 3 with filter specification:
\begin{small}
\verbatiminput{deczky3a_sqp_test_spec.m}
\end{small}

The resulting amplitude  and delay responses are shown in
Figure~\ref{fig:Deczky-Example-3a-PCLS-d1} with pass-band detail shown in
Figure~\ref{fig:Deczky-Example-3a-PCLS-d1-passband}. The corresponding pole-zero
plot is shown in  Figure~\ref{fig:Deczky-Example-3a-PCLS-d1-pz}. 
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3a_sqp_test_pcls_d1}}
\caption{Deczky Example 3a PCLS optimised response.}
\label{fig:Deczky-Example-3a-PCLS-d1}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3a_sqp_test_pcls_d1pass}}
\caption{Deczky Example 3a PCLS optimised passband response.}
\label{fig:Deczky-Example-3a-PCLS-d1-passband}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3a_sqp_test_pcls_d1pz}}
\caption{Deczky Example 3a PCLS optimised pole-zero plot.}
\label{fig:Deczky-Example-3a-PCLS-d1-pz}
\end{figure}
\clearpage
The PCLS optimised filter vector is, in gain-zero-pole form:
\begin{small}
\verbatiminput{deczky3a_sqp_test_d1_coef.m}
\end{small}
and the corresponding transfer function numerator and denominator polynomials
(found with Octave function \emph{x2tf}) are, respectively:
\begin{small}
\verbatiminput{deczky3a_sqp_test_N1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{deczky3a_sqp_test_D1_coef.m}
\end{small}

\subsection{\label{sec:PIQP-Deczky3}Deczky's Example 3 designed with the PIQP solver}
The Octave script \emph{deczky3\_piqp\_test.m} calls the
\emph{iir\_piqp\_mmse} and \emph{iir\_slb} functions to design a low-pass
IIR filter similar to that of \emph{deczky3\_sqp\_test.m} with the PIQP solver
of \emph{Schwan et al.}~\cite{Schwan_PIQP2023,OctaveForge_PIQPPackage}. PIQP
solves quadratic programs like:
\begin{align*}
\begin{split}
  \textbf{minimise}\quad &\frac{1}{2}x^{\top}Px+c^{\top}x \\
  \textbf{subject to}\quad &Ax=b \\
                         & Gx\le h \\
                         & x_{lb}\le x \le x_{ub}
\end{split}
\end{align*}
where $x\in\mathbb{R}^{n}$, $P\in\mathbb{S}^{n}_{+}$ (i.e.: $P\succ 0$),
$A\in\mathbb{R}^{p\times n}$, $G\in\mathbb{R}^{m\times n}$, $c\in\mathbb{R}^{n}$,
$b\in\mathbb{R}^{p}$, $h\in\mathbb{R}^{m}$, $x_{lb}\in\mathbb{R}^{n}$ and
$x_{ub}\in\mathbb{R}^{n}$. In this case, $P$ corresponds to the Hessian,
$\nabla^{2}_{x}\mathcal{E}\left(x\right)$, shown in
Equation~\ref{eqn:Quasi-Newton-second-order-Taylor-expansion}. When
designing an IIR, as opposed to FIR, filter, the squared-error,
$\mathcal{E}\left(x\right)$, represents a complicated surface that may not be
convex when $x$ is not particularly close to a local minimum. In other words, it
is possible that $\nabla^{2}_{x}\mathcal{E}\left(x\right)$ is not
positive-definite. PIQP appears to tolerate a $P$ matrix that is symmetric
but not positive-definite.

The filter specification is:
\begin{small}
\verbatiminput{deczky3_piqp_test_spec.m}
\end{small}

The resulting amplitude  and delay responses are shown in
Figure~\ref{fig:Deczky-Example-3-PCLS-PIQP-d1} with pass-band detail shown in
Figure~\ref{fig:Deczky-Example-3-PCLS-PIQP-d1-passband}. The corresponding
pole-zero plot is shown in Figure~\ref{fig:Deczky-Example-3-PCLS-PIQP-d1-pz}. 
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_piqp_test_pcls_d1}}
\caption{Deczky Example 3 PCLS PIQP optimised response.}
\label{fig:Deczky-Example-3-PCLS-PIQP-d1}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_piqp_test_pcls_d1pass}}
\caption{Deczky Example 3 PCLS PIQP optimised passband response.}
\label{fig:Deczky-Example-3-PCLS-PIQP-d1-passband}
\end{figure}

\clearpage
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_piqp_test_pcls_d1pz}}
\caption{Deczky Example 3 PCLS PIQP optimised pole-zero plot.}
\label{fig:Deczky-Example-3-PCLS-PIQP-d1-pz}
\end{figure}

The PCLS optimised filter vector is, in gain-zero-pole form:
\begin{small}
\verbatiminput{deczky3_piqp_test_d1_coef.m}
\end{small}
and the corresponding transfer function numerator and denominator polynomials
are:
\begin{small}
\verbatiminput{deczky3_piqp_test_N1_coef.m}
\verbatiminput{deczky3_piqp_test_D1_coef.m}
\end{small}
\clearpage
\subsection{\label{sub:Deczkys-Example-1}Deczky's Example 1}
The following example IIR filter design specification is similar to
\emph{Deczky}'s Example 1~\cite{Deczky_MinPSynthesisIIRDigitalFilters}. The
pass-band is $\left[0.0,0.25\right]$ with $1dB$ maximum amplitude ripple, the
pass-band delay is $8$ samples with $2$ sample maximum peak-to-peak ripple and
the stop band is $\left[0.3,0.5\right)$ with at least $36dB$ attenuation. The
PCLS optimisation in this example includes a constraint on the derivative
of the amplitude response in the transition band:
$\frac{\partial{}A\left(\omega\right)}{\partial\omega}<0$. The Octave script
\emph{deczky1\_sqp\_test.m} implements this example. The filter specification
defined in that file is:  
\begin{small}
\verbatiminput{deczky1_sqp_test_spec.m}
\end{small}
The initial filter design was found with the Octave script 
\emph{tarczynski\_deczky1\_test.m}. The initial frequency response is shown in
Figure~\ref{fig:Deczky-Ex1-Initial-x0}.

\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky1_sqp_test_initial_x0}}
\caption{Deczky Example 1, response for initial coefficients.}
\label{fig:Deczky-Ex1-Initial-x0}
\end{figure}

\subsubsection{MMSE optimisation of Deczky's Example 1}
The frequency response after MMSE optimisation is shown in
Figure~\ref{fig:Deczky-Ex1-MMSE-x1} and the pole-zero plot is shown in 
Figure~\ref{fig:Deczky-Ex1-MMSE-x1-pz}.
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky1_sqp_test_mmse_x1}}
\caption{Deczky Example 1, MMSE optimised response.}
\label{fig:Deczky-Ex1-MMSE-x1}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky1_sqp_test_mmse_x1pz}}
\caption{Deczky Example 1, MMSE optimised pole-zero plot.}
\label{fig:Deczky-Ex1-MMSE-x1-pz}
\end{figure}
\subsubsection{PCLS optimisation of Deczky's Example 1}
The frequency response after PCLS optimisation is shown in 
Figure~\ref{fig:Deczky-Ex1-PCLS-d1}, the pass-band detail is shown in 
Figure~\ref{fig:Deczky-Ex1-PCLS-d1-passband} and the pole-zero plot is shown in 
Figure~\ref{fig:Deczky-Ex1-PCLS-d1-pz}. 
The optimised filter vector is, in gain, zeros and poles form:
\begin{small}
\verbatiminput{deczky1_sqp_test_d1_coef.m}
\end{small}
and the corresponding transfer function numerator and denominator polynomials
are, respectively:
\begin{small}
\verbatiminput{deczky1_sqp_test_N1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{deczky1_sqp_test_D1_coef.m}
\end{small}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky1_sqp_test_pcls_d1}}
\caption{Deczky Example 1, PCLS optimised response.}
\label{fig:Deczky-Ex1-PCLS-d1}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky1_sqp_test_pcls_d1pass}}
\caption{Deczky Example 1, PCLS optimised passband response.}
\label{fig:Deczky-Ex1-PCLS-d1-passband}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky1_sqp_test_pcls_d1pz}}
\caption{Deczky Example 1, PCLS optimised pole-zero plot.}
\label{fig:Deczky-Ex1-PCLS-d1-pz}
\end{figure}
\clearpage
\subsection{\label{sec:Low-pass-R-2-decimation-filter}Low-pass R=2 decimation filter}
The second example design is a low-pass $R=2$ decimation filter with
compensation for the zero-order hold amplitude response:
\begin{align*}
U &= 0\\
V &= 0\\
M &= 10\\
Q &= 6\\
R &= 2\\
A\left(f\right) &= \begin{cases}
\frac{\pi f}{\sin \pi f} & 0<f<0.10\\
0 & 0.25<f<0.5
\end{cases}\\
T\left(f\right) &= 8 \quad 0<f<0.125
\end{align*}
The Octave script \emph{decimator\_R2\_test.m} implements this example.  The
filter specification is
\begin{small}
\verbatiminput{decimator_R2_test_spec.m}
\end{small}
The initial filter is found using the \emph{WISE} barrier function implemented in
the Octave function \emph{xInitHd} function. That filter design is itself
initialised with a ``guess'':
\begin{small}
\begin{verbatim}
xi=[ 0.001, ...
     [1,1,1,1,1], ...
     (7:11)*pi/12, ...
     0.7*[1,1,1], ...
     (1:3)*pi/8]';
\end{verbatim}
\end{small}
In this case the denominator decimation
factor is $R=2$ and each complex pole pair is split into $2$ complex pole pairs
so that the overall filter has $6$ complex conjugate pole pairs. In the above
listing, the first line shows the gain, and subsequent lines show,
respectively, $0$ real zeros, $0$ real poles, the zero radiuses for $5$
conjugate pairs of zeros, the zero angles for $5$ conjugate pairs of zeros, the
pole radiuses for $3$ conjugate quadruples of poles and the pole angles for $3$
conjugate quadruples of poles. The resulting initial response is shown in 
Figure~\ref{fig:Decimator-R-2-Initial-x0}. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_test_initial_x0}}
\caption{Low-pass decimator R=2, response for initial coefficients.}
\label{fig:Decimator-R-2-Initial-x0}
\end{figure}
\subsubsection{MMSE optimisation of the low-pass R=2 decimator}
After some experimentation and iteration, weights $Wap=1$, $Was=4$ and 
$Wtp=0.25$ give the response shown in Figure~\ref{fig:Decimator-R-2-MMSE-x1}
with the pass-band detail shown in 
Figure~\ref{fig:Decimator-R-2-MMSE-x1-passband}. The corresponding 
pole-zero plot is shown in Figure~\ref{fig:Decimator-R-2-MMSE-x1-pz}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_test_mmse_x1}}
\caption{Low-pass decimator R=2, MMSE optimised response.}
\label{fig:Decimator-R-2-MMSE-x1}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_test_mmse_x1pass}}
\caption{Low-pass decimator R=2, MMSE optimised passband response.}
\label{fig:Decimator-R-2-MMSE-x1-passband}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_test_mmse_x1pz}}
\caption{Low-pass decimator R=2, MMSE optimised pole-zero plot.}
\label{fig:Decimator-R-2-MMSE-x1-pz}
\end{figure}

\subsubsection{PCLS optimisation of the low-pass R=2 decimator}
Starting with the MMSE filter of Figure~\ref{fig:Decimator-R-2-MMSE-x1},
the weights $Wap=1$, $Was=3$ and $Wtp=0.25$ and the constraints $dBap=0.2$, 
$dBas=40$, $tp=8$ and $tpr=0.008$ give the response shown in
Figure~\ref{fig:Decimator-R-2-PCLS-d1} with pass-band detail 
shown in Figure~\ref{fig:Decimator-R-2-PCLS-d1-passband}. The corresponding 
pole-zero plot is shown in Figure~\ref{fig:Decimator-R-2-PCLS-d1-pz}.
The estimate of the optimised filter vector is, in the gain, zeros and 
poles form of Equation~\ref{eqn:Filter-gain-zeros-poles}:
\begin{small}
\verbatiminput{decimator_R2_test_d1_coef.m}
\end{small}
and the corresponding transfer function numerator and denominator polynomials
(found with Octave function \emph{x2tf}) are, respectively:
\begin{small}
\verbatiminput{decimator_R2_test_N1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{decimator_R2_test_D1_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_test_pcls_d1}}
\caption{Low-pass decimator R=2, PCLS optimised response.}
\label{fig:Decimator-R-2-PCLS-d1}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_test_pcls_d1pass}}
\caption{Low-pass decimator R=2, PCLS optimised passband response.}
\label{fig:Decimator-R-2-PCLS-d1-passband}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_test_pcls_d1pz}}
\caption{Low-pass decimator R=2, PCLS optimised pole-zero plot.}
\label{fig:Decimator-R-2-PCLS-d1-pz}
\end{figure}
\clearpage
\subsubsection{An alternative implementation of the low-pass R=2 decimator}
The Octave script \emph{decimator\_R2\_alternate\_test.m} designs an
alternative implementation of an $R=2$ decimation low-pass filter with a flat
pass-band amplitude response. The alternative filter specification is:
\begin{small}
\verbatiminput{decimator_R2_alternate_test_spec.m}
\end{small}
Figure~\ref{fig:Alternate-decimator-R-2-PCLS-d1-dual} shows the response of the
resulting filter. The corresponding pole-zero plot is shown in
Figure~\ref{fig:Alternate-decimator-R-2-PCLS-d1-pz}. 

The  gain, zeros and poles of the optimised filter are:
\begin{small}
\verbatiminput{decimator_R2_alternate_test_d1_coef.m}
\end{small}

The numerator and denominator polynomials of the PCLS optimised filter are: 
\begin{small}
\verbatiminput{decimator_R2_alternate_test_N1_coef.m}
\end{small}
\begin{small}
\verbatiminput{decimator_R2_alternate_test_D1_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_alternate_test_pcls_d1dual}}
\caption{Alternative PCLS optimised, low-pass, decimator, R=2, filter response.}
\label{fig:Alternate-decimator-R-2-PCLS-d1-dual}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_alternate_test_pcls_d1pz}}
\caption{Alternative PCLS optimised, low-pass, decimator, R=2, filter pole-zero plot.}
\label{fig:Alternate-decimator-R-2-PCLS-d1-pz}
\end{figure}
\clearpage
\subsubsection{An interpolated low-pass R=2 decimator}
\emph{Lyons}~\cite{Lyons_InterpolatedNarrowbandLowpassFIR} describes the design
of interpolated low-pass FIR filters. The Octave script
\emph{decimator\_R2\_interpolated\_test.m} first designs an interpolated $R=2$
IIR low-pass filter. The un-interpolated filter specification is:
\begin{small}
\verbatiminput{decimator_R2_interpolated_test_spec.m}
\end{small}
The  gain, zeros and poles of the optimised filter are:
\begin{small}
\verbatiminput{decimator_R2_interpolated_test_d1_coef.m}
\end{small}
The numerator and denominator polynomials of the PCLS optimised un-interpolated
filter are: 
\begin{small}
\verbatiminput{decimator_R2_interpolated_test_N1_coef.m}
\end{small}
\begin{small}
\verbatiminput{decimator_R2_interpolated_test_D1_coef.m}
\end{small}
Figure~\ref{fig:decimator-R2-interpolated-test-IIR-prototype} shows the
amplitude and delay responses of the prototype IIR filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_interpolated_test_prototype_response}}
\caption{Amplitude and delay responses of PCLS optimised prototype R=2 IIR
  filter.}
\label{fig:decimator-R2-interpolated-test-IIR-prototype}
\end{figure}

Next, an anti-aliasing filter is designed with the \emph{remez} function from
the Octave-Forge \emph{signal} package using the actual pass-band
edge, \input{decimator_R2_interpolated_test_actual_passband.tab},
stop-band edge, \input{decimator_R2_interpolated_test_actual_stopband.tab},
and interpolation factor, $P$. The coefficients of the FIR anti-aliasing filter
are:
\begin{small}
\verbatiminput{decimator_R2_interpolated_test_b_coef.m}
\end{small}
The interpolated, anti-aliased IIR filter has a nominal delay
of \input{decimator_R2_interpolated_test_nominal_delay.tab} samples
and \input{decimator_R2_interpolated_test_distinct_multipliers.tab} multipliers. 
Figure~\ref{fig:decimator-R2-interpolated-test-fir-antialiasing} shows the
responses of the IIR filter interpolated by the factor, $P$, and the FIR
anti-aliasing filter.
Figure~\ref{fig:decimator-R2-interpolated-test-response} shows the
amplitude response of the interpolated and anti-aliased IIR filter.
Figure~\ref{fig:decimator-R2-interpolated-test-passband-response} shows the
pass-band amplitude and group delay responses of the interpolated and
anti-aliased IIR filter.
Figure~\ref{fig:decimator-R2-interpolated-test-remez-comparison} compares the
amplitude response of the interpolated and anti-aliased IIR filter with that
of three equi-ripple FIR filters designed with the \emph{remez} function from the
Octave-Forge \emph{signal} package: firstly an interpolated and anti-aliased FIR
filter having the same frequency specifications as the IIR filter with a delay
of \input{decimator_R2_interpolated_test_bbeq_delay.tab} samples
and \input{decimator_R2_interpolated_test_bbeq_distinct_multipliers.tab}
distinct mulipliers; secondly, a direct-form FIR filter
with \input{decimator_R2_interpolated_test_fir_distinct_multipliers.tab} distinct
multipliers; thirdly, a direct form FIR filter
with \input{decimator_R2_interpolated_test_fir_delay.tab} samples delay. 

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_interpolated_test_fir_antialiasing}}
\caption{Responses of an interpolated low-pass PCLS optimised R=2 IIR filter and
  FIR anti-aliasing filter.}
\label{fig:decimator-R2-interpolated-test-fir-antialiasing}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_interpolated_test_response}}
\caption{Amplitude response of an interpolated anti-aliased low-pass IIR filter.}
\label{fig:decimator-R2-interpolated-test-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_interpolated_test_passband_response}}
\caption{Pass-band amplitude and group delay responses of an interpolated anti-aliased low-pass IIR filter.}
\label{fig:decimator-R2-interpolated-test-passband-response}
\end{figure}

\begin{figure}
\begin{subfigure}[b]{\textwidth}
\centering
\scalebox{0.45\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_interpolated_test_remez_comparison_interpolated_IIR}}
\caption{Response of an interpolated IIR filter with 25 multipliers and 34
  samples nominal delay.}
\end{subfigure}
\begin{subfigure}[b]{\textwidth}
\centering
\scalebox{0.45\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_interpolated_test_remez_comparison_interpolated_FIR}}
\caption{Response of an equivalent interpolated anti-aliased symmetric FIR
  filter with 17 distinct multipliers and 35 samples delay.}
\end{subfigure}
\begin{subfigure}[b]{\textwidth}
\centering
\scalebox{0.45\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_interpolated_test_remez_comparison_direct_FIR_multipliers}}
\caption{Response of a symmetric direct-form FIR filter with 25 distinct
  multipliers.}
\end{subfigure}
\begin{subfigure}[b]{\textwidth}
\centering
\scalebox{0.45\DesignOfIIRFiltersPdfScale}{\input{decimator_R2_interpolated_test_remez_comparison_direct_FIR}}
\caption{Response of a symmetric direct-form FIR filter with 35 samples nominal
  delay.}
\end{subfigure}
\caption{Comparison of the amplitude response of the interpolated and
  anti-aliased IIR filter with that of three FIR filters designed with the
  \emph{remez} function : firstly an interpolated and anti-aliased FIR filter
  having the same frequency specifications as the IIR filter; secondly, a
  direct-form FIR filter having the same number of distinct multipliers;
  thirdly, a direct form FIR filter having the same nominal delay.} 
\label{fig:decimator-R2-interpolated-test-remez-comparison}
\end{figure}
\clearpage
\subsection{\label{sec:Band-pass-R-2-decimation-filter}Band-pass R=2 decimation filter}
The Octave script \emph{iir\_sqp\_slb\_bandpass\_test.m} implements an $R=2$
decimation band-pass filter. The \emph{sqp} loop is implemented by the Octave
function \emph{iir\_slb}. The filter specification is:
\begin{small}
\verbatiminput{iir_sqp_slb_bandpass_test_spec.m}
\end{small}
The initial filter was ``guesstimated'' and has a pole-zero 
specification of $U=2$, $V=0$, $M=18$, $Q=10$ and $R=2$:
\begin{small}
\begin{verbatim}
U=2,V=0,M=18,Q=10,R=2
x0=[ 0.00005, ...
     1, -1, ...
     0.9*ones(1,6), [1 1 1], ...
     (11:16)*pi/20, (7:9)*pi/10, ...
     0.81*ones(1,5), ...
     (4:8)*pi/10 ]';
\end{verbatim}
\end{small}
In the above listing, the first line of $x0$ shows the gain, and subsequent
lines show, respectively, $2$ real zeros, $0$ real poles, the zero radiuses
for $9$ conjugate pairs of zeros, the zero angles for $9$ conjugate pairs of
zeros, the pole radiuses for $5$ conjugate pairs of poles and the pole angles
for $5$ conjugate pairs of poles. In this case the denominator decimation
factor is $R=2$ and each complex pole pair is split into $2$ complex pole pairs
so that the overall filter has $10$ complex conjugate pole pairs. The response of
the initial filter is shown in
Figure~\ref{fig:iir-sqp-slb-bandpass-test-initial-x0}. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_bandpass_test_initial_x0}}
\caption{IIR band-pass R=2 decimation filter, response of the initial filter.}
\label{fig:iir-sqp-slb-bandpass-test-initial-x0}
\end{figure}
\subsubsection{\label{sub:MMSE-optimisation-of-the-band-pass-R2-decimator}MMSE optimisation of the band-pass  R=2 decimator}
The response of the MMSE-optimised filter is shown in 
Figure~\ref{fig:iir-sqp-slb-bandpass-test-mmse-x1} with pass-band detail
shown in Figure~\ref{fig:iir-sqp-slb-bandpass-test-mmse-x1-passband}. The 
corresponding pole-zero plot is shown in 
Figure~\ref{fig:iir-sqp-slb-bandpass-test-mmse-x1-pz}. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_bandpass_test_mmse_x1}}
\caption{IIR band-pass R=2 decimation filter with delay tp=16 samples, response
  of the filter after MMSE optimisation.}
\label{fig:iir-sqp-slb-bandpass-test-mmse-x1}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_bandpass_test_mmse_x1pass}}
\caption{IIR band-pass R=2 decimation filter with delay tp=16 samples, passband
  response of the filter after MMSE optimisation.}
\label{fig:iir-sqp-slb-bandpass-test-mmse-x1-passband}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_bandpass_test_mmse_x1pz}}
\caption{IIR band-pass R=2 decimation filter with delay tp=16 samples, pole-zero
  plot of the filter after MMSE optimisation.}
\label{fig:iir-sqp-slb-bandpass-test-mmse-x1-pz}
\end{figure}
\clearpage
\subsubsection{PCLS optimisation of the band-pass R=2 decimator}
The response of the PCLS optimised filter is shown in
Figure~\ref{fig:iir-sqp-slb-bandpass-test-pcls-d1} with pass-band detail
shown in Figure~\ref{fig:iir-sqp-slb-bandpass-test-pcls-d1-passband}. The
corresponding pole-zero plot is shown in
Figure~\ref{fig:iir-sqp-slb-bandpass-test-pcls-d1-pz}. The estimate of the
optimised filter vector is, in the gain, zeros and poles form of
Equation~\ref{eqn:Filter-gain-zeros-poles}:
\begin{small}
\verbatiminput{iir_sqp_slb_bandpass_test_d1_coef.m}
\end{small}
and the corresponding transfer function numerator and denominator polynomials
(found with Octave function \emph{x2tf}) are, respectively:
\begin{small}
\verbatiminput{iir_sqp_slb_bandpass_test_N1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{iir_sqp_slb_bandpass_test_D1_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_bandpass_test_pcls_d1}}
\caption{IIR band-pass R=2 decimation filter with delay tp=16 samples, response
  of the filter after PCLS optimisation.}
\label{fig:iir-sqp-slb-bandpass-test-pcls-d1}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_bandpass_test_pcls_d1pass}}
\caption{IIR band-pass R=2 decimation filter with delay tp=16 samples, passband
  response of the filter after PCLS optimisation.}
\label{fig:iir-sqp-slb-bandpass-test-pcls-d1-passband}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_bandpass_test_pcls_d1pz}}
\caption{IIR band-pass R=2 decimation filter with delay tp=16 samples, pole-zero
  plot of the filter after PCLS optimisation.}
\label{fig:iir-sqp-slb-bandpass-test-pcls-d1-pz}
\end{figure}
\clearpage
\subsubsection{Comparison with FIR band-pass filter designs}
For comparison, an FIR filter was designed with the \emph{remez}
Octave function:
\begin{small}
\begin{verbatim}
N=1+U+V+M+Q;
brz=remez(N-1,2*[0 fasl fapl fapu fasu 0.5],[0 0 1 1 0 0], ...
          [Wasl Wap Wasu],'bandpass');
\end{verbatim}
\end{small}
Similarly,  an FIR filter was designed with \emph{Selesnick's}
Octave function, \emph{cl2bp}. The
nominal passband has been adjusted to provide a similar response to the
\emph{remez} and PCLS IIR filters. The specifications of the \emph{cl2bp}
filter design are:
\begin{small}
\begin{verbatim}
wl=fapl*2*pi*0.8;
wu=fapu*2*pi*1.1;
up=10.^([-dBas, 0, -dBas]/20);
lo=[-1,1,-1].*10.^([-dBas, -dBap, -dBas]/20);
Ccl=floor(N/2)
ncl=2048;
bcl = cl2bp(Ccl,wl,wu,up,lo,512);
\end{verbatim}
\end{small}
The FIR filter designs are linear phase with filter length set to the number of
coefficients of the IIR PCLS filter. Hence the group delay of the FIR filters
is $15$ samples compared to $16$ samples for the IIR PCLS filter. 

The responses of the FIR filters and the IIR PCLS filter are compared in
Figure~\ref{fig:iir-sqp-slb-bandpass-test-compare-magnitude}. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_bandpass_test_compare_magnitude}}
\caption{Comparison of the magnitude responses of the bandpass PCLS IIR filter
 and FIR filters designed by \emph{cl2bp} and \emph{remez}.}
\label{fig:iir-sqp-slb-bandpass-test-compare-magnitude}
\end{figure}
\clearpage
\subsection{\label{sec:Hilbert-transform-R-2-decimation-filter}Hilbert transform R=2 decimation filter}
A Hilbert transform filter\cite[p.118]{Papoulis_SignalAnalysis} has the transfer
function 
\begin{align*}
H_{d}\left(\omega\right)=-\imath sign\left(\omega\right)e^{-\imath\omega t_{d}}
\end{align*}
The Octave script \emph{iir\_sqp\_slb\_hilbert\_test.m} designs a Hilbert
transform filter with $U=7,\;V=2,\;M=4,\;Q=4,\;R=2$ and the group-delay of the
filter is $t_{d}=\frac{U+M}{2}=5.5$ samples. An initial filter was designed by
the method of Tarczynski et al.\ with the Octave script 
\emph{tarczynski\_hilbert\_test.m}. The initial filter coefficients are, in 
gain-pole-zero form:
\begin{small}
\verbatiminput{iir_sqp_slb_hilbert_test_x0_coef.m}
\end{small}
The amplitude, group delay and phase response of the initial filter, as
calculated by the Octave functions \emph{iirA}, \emph{iirT} and \emph{iirP}
are shown in Figure~\ref{fig:iir-sqp-slb-hilbert-initial-response}. The script
defines a phase response ``don't-care''transition band of $f_{pt}=\pm 0.05$
about $\omega=0$. Similarly, the group delay transition band is
$f_{pt}=\pm 0.075$.  Note that the \emph{iirA} function can return a negative
amplitude if, as in this case, the gain coefficient is negative. I do this so
that $\frac{\partial A}{\partial K}$ is well-defined at $K=0$ (since the
absolute value of $K$ is not differentiable at $0$). Consequently, the phase
returned by the \emph{iirP} function does not include the sign of the gain
coefficient.  The phase response, relative to $\pi$, is shown adjusted for the
group-delay by adding $\omega t_{d}$ where $\omega$ is the angular frequency
vector for which the response is calculated.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_hilbert_test_initial_response}}
\caption{Response of the initial Hilbert filter designed by 
  \emph{tarczynski\_hilbert\_test.m} with $R=2$ and $t_{d}=5.5$. The phase
  response shown is adjusted for the nominal delay.}
\label{fig:iir-sqp-slb-hilbert-initial-response}
\end{figure}
\subsubsection{\label{sub:MMSE-optimisation-of-the-Hilbert-transform-R2-decimator}MMSE optimisation of the Hilbert transform  R=2 decimator}
Figure~\ref{fig:iir-sqp-slb-hilbert-mmse-response} shows the response 
after MMSE optimisation of the initial filter. The phase
response shown is adjusted for the nominal delay. The relative weights of the
amplitude, group delay and phase were $W_{ap}=1$, $W_{tp}=0.0001$ and 
$W_{pp}=0.001$ respectively. The desired PCLS constraints are superimposed on 
the figure. The \emph{iirP} function does not calculate the Hessian of the
phase response. In the previous
examples only the diagonal of the Hessian matrix of the error response is used
to initialise the SQP loop. In this case the diagonal of the Hessian of the
phase response is approximated with the Octave function
\emph{iirP\_hessP\_DiagonalApprox.m}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_hilbert_test_mmse_response}}
\caption{Response of the Hilbert filter after MMSE optimisation. The phase
  response shown is adjusted for the nominal delay.}
\label{fig:iir-sqp-slb-hilbert-mmse-response}
\end{figure}
\subsubsection{PCLS optimisation of the Hilbert transform R=2 decimator}
Figure~\ref{fig:iir-sqp-slb-hilbert-pcls-response} shows the response 
after PCLS optimisation of the MMSE optimised filter of
Figure~\ref{fig:iir-sqp-slb-hilbert-mmse-response}.
Figure~\ref{fig:iir-sqp-slb-hilbert-pcls-pz} shows the pole-zero plot for the
PCLS optimised filter. The phase response shown is adjusted for the nominal
delay. The peak-to-peak amplitude, group delay and phase
ripple outside the transition band are $A_{r}=0.002$, $t_{dr}=0.4$ and 
$p_{r}=0.1\frac{\pi}{2}$ respectively. The PCLS optimised filter coefficients
are, in gain-pole-zero form
\begin{small}
\verbatiminput{iir_sqp_slb_hilbert_test_d1_coef.m}
\end{small}
and in transfer function form the numerator and denominator polynomials are:
\begin{small}
\verbatiminput{iir_sqp_slb_hilbert_test_N1_coef.m}
\verbatiminput{iir_sqp_slb_hilbert_test_D1_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_hilbert_test_pcls_response}}
\caption{Response of the Hilbert filter after PCLS optimisation. The phase
  response shown is adjusted for the nominal delay.}
\label{fig:iir-sqp-slb-hilbert-pcls-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_hilbert_test_pcls_pz}}
\caption{Pole-zero plot of the Hilbert filter after PCLS optimisation.}
\label{fig:iir-sqp-slb-hilbert-pcls-pz}
\end{figure}
\clearpage
\subsection{\label{sec:iir-R-2-differentiator-filter}R=2 differentiator filter}
A differentiator filter has transfer function
$H_{d}\left(\omega\right)=\frac{\imath\omega}{\pi}e ^{-\imath\omega t_{d}}$.
The Octave script \emph{iir\_sqp\_slb\_differentiator\_test.m} designs a
differentiator filter with the specification:
\begin{small}
\verbatiminput{iir_sqp_slb_differentiator_test_spec.m}
\end{small}
The filter is designed with the effect of a fixed zero at $z=1$ removed from the
desired response. That zero is added back after optimisation is complete.
\subsubsection{\label{sub:Initial-filter-R2-differentiator}Initial filter for the R=2 differentiator filter}
An initial filter was designed by the method of \emph{Tarczynski et al} with the
Octave script \emph{tarczynski\_differentiator\_test.m}. The initial filter
coefficients, in gain-pole-zero form, are:   
\begin{small}
\verbatiminput{iir_sqp_slb_differentiator_test_x0_coef.m}
\end{small}
Figure~\ref{fig:iir-sqp-slb-differentiator-initial-response} shows the initial
filter amplitude, phase and group delay responses. The phase response is
adjusted for the nominal group delay.
Figure~\ref{fig:iir-sqp-slb-differentiator-initial-pz} shows the pole-zero plot
of the initial filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_differentiator_test_initial_x0_response}}
\caption{Amplitude, phase and group delay responses of the
  initial $R=2$ differentiator filter. The phase response shown is adjusted for
  the nominal group delay.}
\label{fig:iir-sqp-slb-differentiator-initial-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_differentiator_test_initial_x0_pz}}
\caption{Pole-zero plot of the initial $R=2$ differentiator filter.}
\label{fig:iir-sqp-slb-differentiator-initial-pz}
\end{figure}

\subsubsection{\label{sub:MMSE-optimisation-of-the-R2-differentiator}MMSE optimisation of the R=2 differentiator filter}
Figure~\ref{fig:iir-sqp-slb-differentiator-mmse-response} shows the amplitude
response error and the phase and group delay responses after MMSE optimisation
of the initial filter. A zero near $z=1$ is removed from the initial filter
and the desired responses are adjusted to allow for a zero at exactly $z=1$. The
phase response is adjusted for the nominal group delay.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_differentiator_test_mmse_x1_error}}
\caption{Amplitude response error and phase and group delay responses of the
  $R=2$ differentiator filter, without a zero at $z=1$, after MMSE optimisation.
  The phase response shown is adjusted for the nominal group delay.}  
\label{fig:iir-sqp-slb-differentiator-mmse-response}
\end{figure}
\subsubsection{PCLS optimisation of the R=2 differentiator filter}
Figure~\ref{fig:iir-sqp-slb-differentiator-pcls-response} shows the amplitude
response error and the phase and group delay responses after PCLS optimised
filter. The zero at $z=1$ was added back after PCLS optimisation. The phase
response is adjusted for the nominal group delay. 
Figure~\ref{fig:iir-sqp-slb-differentiator-pcls-pz} shows the
pole-zero plot for the PCLS optimised $R=2$ differentiator filter. Note the
double poles on the real and imaginary axes. The PCLS optimised filter
coefficients are, in gain-pole-zero form:
\begin{small}
\verbatiminput{iir_sqp_slb_differentiator_test_d1_coef.m}
\end{small}
The numerator and denominator polynomials are:
\begin{small}
\verbatiminput{iir_sqp_slb_differentiator_test_N1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{iir_sqp_slb_differentiator_test_D1_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_differentiator_test_pcls_d1_error}}
\caption{Amplitude response error and phase and group delay responses of the
  $R=2$ differentiator filter after PCLS optimisation. The phase response 
  is adjusted for the nominal group delay.} 
\label{fig:iir-sqp-slb-differentiator-pcls-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_differentiator_test_pcls_d1_pz}}
\caption{Pole-zero plot of the $R=2$ differentiator filter after PCLS
  optimisation.}
\label{fig:iir-sqp-slb-differentiator-pcls-pz}
\end{figure}
\clearpage
\subsection{\label{sec:iir-sqp-slb-lowpass-differentiator}Low-pass differentiator filter}
The Octave script \emph{iir\_sqp\_slb\_lowpass\_differentiator\_test.m} designs
an IIR low-pass differentiator filter with the specification:
\begin{small}
\verbatiminput{iir_sqp_slb_lowpass_differentiator_test_spec.m}
\end{small}
The filter is designed with the effect of a fixed zero at $z=1$
removed from the desired response. That zero is added back after optimisation is
complete.

An initial filter was designed by the
method of \emph{Tarczynski et al} with the Octave script
\emph{tarczynski\_lowpass\_differentiator\_test.m}. The inital filter
numerator and denominator polynomials are:
\begin{small}
\verbatiminput{tarczynski_lowpass_differentiator_test_N0_coef.m}
\verbatiminput{tarczynski_lowpass_differentiator_test_D0_coef.m}
\end{small}

After conversion to gain-zero-pole form and removal of the zero at $z=1$, the
amplitude, group delay and phase response errors of the initial filter are shown
in Figure~\ref{fig:iir-sqp-slb-lowpass-differentiator-initial-response}.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_lowpass_differentiator_test_initial_response}}
\caption{Response of the initial low-pass differentiator filter. The phase
  response shown is adjusted for the nominal delay.}
\label{fig:iir-sqp-slb-lowpass-differentiator-initial-response}
\end{figure}

Figure~\ref{fig:iir-sqp-slb-lowpass-differentiator-pcls-response-error} shows
the response errors of the low-pass differentiator after PCLS optimisation.
Figure~\ref{fig:iir-sqp-slb-lowpass-differentiator-pcls-pz} shows the pole-zero
plot of the low-pass differentiator filter after PCLS optimisation. The
PCLS optimised overall filter coefficients are, in gain-zero-pole form:
\begin{small}
\verbatiminput{iir_sqp_slb_lowpass_differentiator_test_d1z_coef.m}
\end{small}
and, in transfer function form, the numerator and denominator polynomials of
the correction filter are, respectively:
\begin{small}
\verbatiminput{iir_sqp_slb_lowpass_differentiator_test_N1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{iir_sqp_slb_lowpass_differentiator_test_D1_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_lowpass_differentiator_test_pcls_error}}
\caption{Response errors of the low-pass differentiator filter after PCLS
  optimisation. The phase response shown is adjusted for the nominal delay.}
\label{fig:iir-sqp-slb-lowpass-differentiator-pcls-response-error}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_lowpass_differentiator_test_pcls_pz}}
\caption{Pole-zero plot of the low-pass differentiator filter after PCLS
  optimisation.}
\label{fig:iir-sqp-slb-lowpass-differentiator-pcls-pz}
\end{figure}
\subsubsection{\label{sec:iir-sqp-slb-lowpass-differentiator-alt}Alternate low-pass differentiator filter}
The Octave script
\emph{iir\_sqp\_slb\_lowpass\_differentiator\_alternate\_test.m} designs
an IIR low-pass differentiator filter with the specification:
\begin{small}
\verbatiminput{iir_sqp_slb_lowpass_differentiator_alternate_test_spec.m}
\end{small}
The filter is designed as $1-z^{-1}$ in series with a correction filter.
An initial correction filter was designed by the
method of \emph{Tarczynski et al} with the Octave script
\emph{tarczynski\_lowpass\_differentiator\_alternate\_test.m}. The inital filter
numerator and denominator polynomials are:
\begin{small}
\verbatiminput{tarczynski_lowpass_differentiator_alternate_test_N0_coef.m}
\verbatiminput{tarczynski_lowpass_differentiator_alternate_test_D0_coef.m}
\end{small}

Figure~\ref{fig:iir-sqp-slb-lowpass-differentiator-alt-initial-response}
shows the amplitude, group delay and phase responses of the initial low-pass
differentiator filter. The phase response is adjusted for linear-phase delay.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_lowpass_differentiator_alternate_test_initial_response}}
\caption{Amplitude, phase and group delay responses of the initial low-pass
  differentiator filter. The phase response shown is adjusted for the nominal
  delay.}
\label{fig:iir-sqp-slb-lowpass-differentiator-alt-initial-response}
\end{figure}

The PCLS optimised filter coefficients of the alternate low-pass differentiator
filter are, in gain-zero-pole form:
\begin{small}
\verbatiminput{iir_sqp_slb_lowpass_differentiator_alternate_test_d1z_coef.m}
\end{small}
and, in transfer function form, the numerator and denominator polynomials of
the correction filter are, respectively:
\begin{small}
\verbatiminput{iir_sqp_slb_lowpass_differentiator_alternate_test_N1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{iir_sqp_slb_lowpass_differentiator_alternate_test_D1_coef.m}
\end{small}

Figure~\ref{fig:iir-sqp-slb-lowpass-differentiator-alt-pcls-response-error} shows
the response errors of the low-pass differentiator after PCLS optimisation of
the correction filter.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_lowpass_differentiator_alternate_test_pcls_error}}
\caption{Response errors of the alternate low-pass differentiator filter after
  PCLS optimisation. The phase response shown is adjusted for the nominal delay.}
\label{fig:iir-sqp-slb-lowpass-differentiator-alt-pcls-response-error}
\end{figure}

Figure~\ref{fig:iir-sqp-slb-lowpass-differentiator-alt-pcls-pz} shows the
pole-zero plot of the low-pass differentiator after PCLS optimisation.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_lowpass_differentiator_alternate_test_pcls_pz}}
\caption{Pole-zero plot of the alternate low-pass differentiator filter after
  PCLS optimisation.}
\label{fig:iir-sqp-slb-lowpass-differentiator-alt-pcls-pz}
\end{figure}
\clearpage
\subsection{Pink noise filter}
Pink noise has equal noise power per octave. A ideal pink noise filter has
the transfer function
$H_{d}\left(\omega\right)=\frac{K}{\sqrt{\omega}}e^{-\imath\omega{}t_{d}}$ where
$K$ is a constant and $t_{d}$ is the nominal filter group delay. The Octave
script \emph{iir\_sqp\_slb\_pink\_test.m} designs an $11$th order IIR pink noise
filter with the specification:
\begin{small}
\verbatiminput{iir_sqp_slb_pink_test_spec.m}
\end{small}
The script defines a ``don't-care'' transition band from $f=0$ to $fat=0.005$
for the amplitude response and from $f=0$ to $ftt=0.025$ for the group delay
response. An initial filter was designed by the method of
\emph{Tarczynski et al.} in the Octave script \emph{tarczynski\_pink\_test.m}.
The initial filter coefficients are, in gain-pole-zero form:
\begin{small}
\verbatiminput{iir_sqp_slb_pink_test_x0_coef.m}
\end{small}
Figure~\ref{fig:iir-sqp-slb-pink-initial-response} compares the amplitude 
response of the initial filter to the desired response.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_pink_test_init_x0}}
\caption{Response of the initial pink noise filter designed by 
\emph{tarczynski\_pink\_test.m}.}
\label{fig:iir-sqp-slb-pink-initial-response}
\end{figure}
Figure~\ref{fig:iir-sqp-slb-pink-pcls-response} shows the amplitude and
group delay responses of the filter after MMSE and PCLS optimisation.
Figure~\ref{fig:iir-sqp-slb-pink-pcls-error-response} shows the errors of the
amplitude and group delay responses of the filter after MMSE and PCLS
optimisation. 
Figure~\ref{fig:iir-sqp-slb-pink-pcls-pz} shows the pole-zero plot of the filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_pink_test_pcls_d1}}
\caption{Amplitude and group-delay responses of the pink noise filter after PCLS
  optimisation.}
\label{fig:iir-sqp-slb-pink-pcls-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_pink_test_pcls_error_d1}}
\caption{Errors of the amplitude and group-delay responses of the pink noise
  filter after PCLS optimisation.}
\label{fig:iir-sqp-slb-pink-pcls-error-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_pink_test_pcls_d1pz}}
\caption{Pole-zero plot of the pink noise filter after PCLS optimisation.}
\label{fig:iir-sqp-slb-pink-pcls-pz}
\end{figure}

The PCLS  optimised filter coefficients are, in gain-pole-zero form
\begin{small}
\verbatiminput{iir_sqp_slb_pink_test_d1_coef.m}
\end{small}
and in transfer function form the numerator and denominator polynomials are,
respectively:
\begin{small}
\verbatiminput{iir_sqp_slb_pink_test_N1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{iir_sqp_slb_pink_test_D1_coef.m}
\end{small}
\clearpage
\subsection{Minimum phase R=2 low-pass filter}
A minimum phase filter has all the zeros of the transfer function on or within 
the unit circle in the $z$-plane $\left|z\right|\le 1$\footnote{If the inverse
  filter is required then the zeros must be within the unit circle,
  $\left|z\right|\le \rho < 1$.} The Octave script
\emph{iir\_sqp\_slb\_minimum\_phase\_test.m} designs a minimum phase
low-pass filter specified by:
\begin{small}
\verbatiminput{iir_sqp_slb_minimum_phase_test_spec.m}
\end{small}
The initial filter coefficients are, in gain-pole-zero form:
\begin{small}
\begin{verbatim}
x0=[ 0.004; ...
    -127/128;-127/128; ...
     0.6; ...
     127/128*ones(4,1); ...
     pi*(9:12)'/16; ...
     0.6;0.6; ...
     2*pi/3;pi/2 ];
\end{verbatim}
\end{small}
The inital filter is optimised with the PCLS algorithm.
The PCLS optimised pole and zero radiuses are contrained to be less than
$\frac{255}{256}$.
Figure~\ref{fig:iir-sqp-slb-minimum-phase-pcls-response} shows the response of
the PCLS optimised filter.
Figure~\ref{fig:iir-sqp-slb-minimum-phase-pcls-passband-response} shows the
pass-band detail of the response of the PCLS optimised filter.
Figure~\ref{fig:iir-sqp-slb-minimum-phase-pcls-pz} shows the pole-zero plot for
the PCLS optimised filter. The resulting filter coefficients are, in gain-pole-zero form:
\begin{small}
\verbatiminput{iir_sqp_slb_minimum_phase_test_d1_coef.m}
\end{small}
and in transfer function form the numerator and denominator polynomials are,
respectively
\begin{small}
\verbatiminput{iir_sqp_slb_minimum_phase_test_N1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{iir_sqp_slb_minimum_phase_test_D1_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_minimum_phase_test_pcls_d1}}
\caption{Response of the R=2 minimum phase filter after PCLS optimisation.}
\label{fig:iir-sqp-slb-minimum-phase-pcls-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_minimum_phase_test_pcls_d1pass}}
\caption{Passband response of the R=2 minimum phase filter after PCLS
  optimisation.}
\label{fig:iir-sqp-slb-minimum-phase-pcls-passband-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_minimum_phase_test_pcls_d1pz}}
\caption{Pole-zero plot of the R=2 minimum phase filter after PCLS optimisation.}
\label{fig:iir-sqp-slb-minimum-phase-pcls-pz}
\end{figure}
\clearpage
\subsection{\label{sec:SQP-non-linear-phase-FIR-lowpass-filter}Non-linear phase FIR low-pass filter}
The Octave script \emph{iir\_sqp\_slb\_fir\_lowpass\_test.m} designs an 
FIR low-pass filter that has approximately linear phase in the pass-band. The
impulse response is \emph{not} symmetric. The filter specification is:
\begin{small}
\verbatiminput{iir_sqp_slb_fir_lowpass_test_spec.m}
\end{small}
Figure~\ref{fig:iir-sqp-slb-fir-lowpass-pcls-response} shows the response of
the PCLS optimised filter.
Figure~\ref{fig:iir-sqp-slb-fir-lowpass-pcls-passband-response} shows the
pass-band detail of the response of the PCLS optimised filter.
The coefficients of the PCLS optimised FIR low-pass filter are, in
gain-pole-zero form:
\begin{small}
\verbatiminput{iir_sqp_slb_fir_lowpass_test_d1_coef.m}
\end{small}
and in transfer function form the FIR polynomial is:
\begin{small}
\verbatiminput{iir_sqp_slb_fir_lowpass_test_N1_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_fir_lowpass_test_pcls_d1}}
\caption{Response of the non-linear phase FIR low-pass filter after SQP PCLS
  optimisation.}
\label{fig:iir-sqp-slb-fir-lowpass-pcls-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_fir_lowpass_test_pcls_d1pass}}
\caption{Pass-band response of the non-linear phase FIR low-pass filter after
  SQP PCLS optimisation.}
\label{fig:iir-sqp-slb-fir-lowpass-pcls-passband-response}
\end{figure}
\clearpage
\subsection{\label{sec:Minimum-phase-FIR-bandpass-filter}Minimum phase FIR bandpass filter}
The Octave script \emph{iir\_sqp\_slb\_fir\_bandpass\_test.m} designs a minimum
phase FIR bandpass filter specified by:
\begin{small}
\begin{verbatim}
U=2,V=0,M=28,Q=0,R=1
fapl=0.1,fapu=0.2,dBap=1,Wap=1
fasl=0.05,fasu=0.25,dBas=36,Wasl=8,Wasu=2
\end{verbatim}
\end{small}
The initial filter coefficients are, in gain-pole-zero form:
\begin{small}
\begin{verbatim}
x0=[ 0.005, -0.7, 0.7, 0.7*ones(1,14), pi*[(1:3)/80, (13:23)/24] ]';
\end{verbatim}
\end{small}
The zero radiuses are constrained by $\left|z\right|<\frac{31}{32}$.
The inital filter is first MMSE optimised and then optimised with the PCLS
algorithm.  The radiuses of the zeros of the filter are constrained to
$\left|z\right|\le1$.
Figure~\ref{fig:iir-sqp-slb-fir-bandpass-pcls-response} shows the response of
the PCLS optimised filter.
Figure~\ref{fig:iir-sqp-slb-fir-bandpass-pcls-passband-response} shows the
pass-band detail of the response of the PCLS optimised filter.
Figure~\ref{fig:iir-sqp-slb-fir-bandpass-pcls-pz} shows the pole-zero plot for
the PCLS optimised filter. The coefficients of the PCLS optimised minimum phase
FIR bandpass filter are, in gain-pole-zero form:
\begin{small}
\verbatiminput{iir_sqp_slb_fir_bandpass_test_d1_coef.m}
\end{small}
and in transfer function form the FIR polynomial is:
\begin{small}
\verbatiminput{iir_sqp_slb_fir_bandpass_test_Nd1_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_fir_bandpass_test_pcls_d1}}
\caption{Response of the minimum phase FIR bandpass filter after PCLS
  optimisation.}
\label{fig:iir-sqp-slb-fir-bandpass-pcls-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_fir_bandpass_test_pcls_d1pass}}
\caption{Passband response of the minimum phase FIR bandpass filter after PCLS
  optimisation.}
\label{fig:iir-sqp-slb-fir-bandpass-pcls-passband-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_fir_bandpass_test_pcls_d1pz}}
\caption{Pole-zero plot of the minimum phase FIR bandpass filter after PCLS
  optimisation.}
\label{fig:iir-sqp-slb-fir-bandpass-pcls-pz}
\end{figure}

The script also calculates the FIR filter with complementary amplitude response.
The combined response is shown in
Figure~\ref{fig:iir-sqp-slb-fir-bandpass-d1c1-combined-response}.
Figure~\ref{fig:iir-sqp-slb-fir-bandpass-complementary-c1pz} shows the
pole-zero plot for complementary FIR filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_fir_bandpass_test_combined_d1c1}}
\caption{Combined response of the PCLS optimised minimum phase FIR bandpass
  filter and the complementary FIR filter.}
\label{fig:iir-sqp-slb-fir-bandpass-d1c1-combined-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_sqp_slb_fir_bandpass_test_complementary_c1pz}}
\caption{Pole-zero plot of the complementary FIR filter.}
\label{fig:iir-sqp-slb-fir-bandpass-complementary-c1pz}
\end{figure}

The coefficients of the complementary FIR filter are, in gain-pole-zero form:
\begin{small}
\verbatiminput{iir_sqp_slb_fir_bandpass_test_c1_coef.m}
\end{small}
and in transfer function form the FIR polynomial is:
\begin{small}
\verbatiminput{iir_sqp_slb_fir_bandpass_test_Nc1_coef.m}
\end{small}
Alternatively, given an FIR filter of order $N$, $H\left(z\right)$, with
the desired magnitude response,
$\left|H\left(e^{\imath\omega}\right)\right| \le 1$, a more accurate complementary
minimum-phase FIR spectral factor of
$1-z^{-N}H\left(z^{-1}\right)H\left(z\right) = 1-\left|H\left(z\right)\right|^{2}$
can be derived from the real cepstrum method of
 \emph{Mian} and
 \emph{Nainer}~\cite{MianNainer_FastDesignEquiRippleMinimumPhaseFIR} or
 directly by \emph{Orchard} and \emph{Willson}'s Newton-Raphson
solution~\cite{OrchardWillson_ComputationMinimumPhaseSpectralFactor}. See
Appendix~\ref{app:Design-of-complementary-FIR-digital-filter}.
\clearpage
\chapter{\label{sec:IIR-Design-Using-SOCP}IIR filter design using Second Order Cone Programming}
\section{Second Order Cone Programming}
Following \emph{Alizadeh} and \emph{Goldfarb}~\cite
{AlizadehGoldfarb_SecondOrderCone}, Second Order Cone
Programming (SOCP) is a class of convex optimisation problems in which a linear
function is minimised subject to a set of conic constraints
\begin{align*}
\textbf{minimise}\quad& \boldsymbol{f}^{\top}\boldsymbol{x}\\
\textbf{subject to}\quad & \| A_{i}\boldsymbol{x}+b_{i}\| 
\le c_{i}^{\top}\boldsymbol{x}+h_{i} \quad i=1,\hdots,N
\end{align*}
where $\|u\|=\sqrt{u^{\top}u}$ is the Euclidean norm of the vector $u$, 
$\boldsymbol{x}\in\mathfrak{\mathbb{R}}^{p\times 1}$, 
$\boldsymbol{f}\in\mathfrak{\mathbb{R}}^{p\times 1}$, 
$A_{i}\in\mathfrak{\mathbb{R}}^{\left(p-1\right)\times p}$, 
$b_{i}\in\mathfrak{\mathbb{R}}^{\left(p-1\right)\times 1}$, 
$c_{i}\in\mathfrak{\mathbb{R}}^{p\times 1}$ and $h_{i}\in\mathfrak{\mathbb{R}}$.
Each constraint is equivalent to:
\begin{align*}
\left[\begin{array}{c}
c_{i}^{\top}\\
A_{i}
\end{array}\right] \boldsymbol{x} + \left[\begin{array}{c}
h_{i}\\
b_{i}
\end{array}\right] \in \mathcal{C}_{i}
\end{align*}
where $\mathcal{C}_{i}$ is a cone in $\mathfrak{\mathbb{R}}^{p}$
\begin{align*}
\mathcal{C}_{i} = \left\{\left[\begin{array}{c}
t\\
u
\end{array}\right]\;:\; u \in \mathfrak{\mathbb{R}}^{\left(p-1\right)\times 1},\;
 t\ge 0,\; \| u \| \le t \right\}
\end{align*}

\section{Design of IIR filters with SOCP}
Equation~\ref{eqn:Definition-of-minimax-response-error} defined the mini-max
optimisation problem for the filter. Rewrite this in terms of an upper bound, 
$\epsilon$, as
\begin{align*}
\textbf{minimise}\quad & \epsilon \\
\textbf{subject to}\quad &\|W\left(\omega_{i}\right)\left[H\left(\boldsymbol{x},
\omega_{i} \right) -H_{d} \left(\omega_{i}\right)\right]\| \le 
\epsilon \quad \text{for } \omega_{i} \in \Omega \\
&H\left(\boldsymbol{x}\right) \text{ is stable} 
\end{align*}
where $\boldsymbol{x}$ is the vector of coefficients,
$\epsilon$ is an auxiliary optimisation variable, $W\left(\omega\right)$
is a weighting factor, $H\left(\boldsymbol{x},\omega\right)$ is the frequency
response with coefficients $\boldsymbol{x}$ and $H_{d}\left(\omega\right)$ is
the desired frequency response. $H\left(\boldsymbol{x},\omega\right)$ and 
$H_{d}\left(\omega\right)$ usually have complex values in the pass band. The 
optimisation problem may be formulated so that 
$H\left(\boldsymbol{x},\omega\right)$ and $H_{d}\left(\omega\right)$ are
complex scalars or vectors of complex values. In the latter case the norm is 
assumed to be summed over a range of frequencies.

If $\nabla_{x}H\left(\boldsymbol{x}_{k},\omega\right)$ is known and the step-size,
$\|\boldsymbol{x}-\boldsymbol{x}_{k}\|$, is small, then a useful
\emph{first-order} approximation to $H\left(\boldsymbol{x},\omega\right)$ is:
\begin{align*}
H\left(\boldsymbol{x},\omega\right) &\approx 
H\left(\boldsymbol{x}_{k},\omega\right) + 
\nabla_{x}H\left(\boldsymbol{x}_{k},\omega\right)^{\top}
\left(\boldsymbol{x}-\boldsymbol{x}_{k}\right)
\end{align*}
so that
\begin{align*}
W\left(\omega\right)\left|H\left(\boldsymbol{x},\omega\right)-H_{d}\left(\omega\right)\right| &\approx W\left(\omega\right)\left|
\nabla_{x}H\left(\boldsymbol{x}_{k},\omega\right)^{\top}
\left(\boldsymbol{x}-\boldsymbol{x}_{k}\right) +
H\left(\boldsymbol{x}_{k},\omega\right)-H_{d}\left(\omega\right)\right| \\
&= W\left(\omega\right)\left|\nabla_{x}H\left(\boldsymbol{x}_{k},\omega\right)^{\top}
\left(\boldsymbol{x}-\boldsymbol{x}_{k}\right) + \boldsymbol{e}_{k}\right|
\end{align*}
where $\boldsymbol{e}_{k}=H\left(\boldsymbol{x}_{k},\omega\right)-
H_{d}\left(\omega\right)$.

Similarly, a \emph{second-order} approximation to 
$H\left(\boldsymbol{x},\omega\right)$ is:
\begin{align*}
H\left(\boldsymbol{x},\omega\right) &\approx 
H\left(\boldsymbol{x}_{k},\omega\right) + 
\nabla_{x}H\left(\boldsymbol{x}_{k},\omega\right)^{\top}
\left(\boldsymbol{x}-\boldsymbol{x}_{k}\right)+ 
\frac{1}{2}\left(\boldsymbol{x}-\boldsymbol{x}_{k}\right)^{\top}
\nabla_{x}^{2}H\left(\boldsymbol{x}_{k},\omega\right)
\left(\boldsymbol{x}-\boldsymbol{x}_{k}\right)
\end{align*}
Unfortunately the IIR filter Hessian matrix, 
$\nabla_{x}^{2}H\left(\boldsymbol{x}_{k},\omega\right)$, is unlikely to be
positive definite.

Lu and Hinamoto~\cite{LuHinamoto_IIRFrequencyMaskingFiltersConeProgramming} add
linear constraints on the maximum filter response in the transition band, 
$\Omega_{t}$:
\begin{align*}
\|\nabla_{x}H\left(\boldsymbol{x}_{k},\omega_{t}\right)^{\top}
\left(\boldsymbol{x}-\boldsymbol{x}_{k}\right) +
H\left(\boldsymbol{x}_{k},\omega_{t}\right)\| &\le 
\gamma\quad \text{for }\omega_{t}\in\Omega_{t}
\end{align*}
Similar linear constraints can be added to control the peaks of the response
in the pass and stop bands.

The linearised SOCP optimisation problem is
\begin{align*}
\textbf{minimise}\quad & \epsilon \\
\textbf{subject to}\quad &\|W\left(\omega_{i}\right)\left[\nabla_{x}
H\left(\boldsymbol{x}_{k},\omega_{i}\right)^{\top}
\left(\boldsymbol{x}-\boldsymbol{x}_{k}\right) + \boldsymbol{e}_{k}\right]\|
\le \epsilon\quad \text{for }\omega_{i}\in\Omega\\
&\|\nabla_{x}H\left(\boldsymbol{x}_{k},\omega_{t}\right)^{\top}
\left(\boldsymbol{x}-\boldsymbol{x}_{k}\right) +
H\left(\boldsymbol{x}_{k},\omega_{t}\right)\| \le 
\gamma\quad \text{for }\omega_{t}\in\Omega_{t}\\
&\|\boldsymbol{x}-\boldsymbol{x}_{k}\| \le \beta\\
&H\left(\boldsymbol{x}\right) \text{ is stable} 
\end{align*}

There are three sets of second-order cone constraints (for the desired response,
the transition band response  and for the coefficient step size) and one set of
linear constraints (for filter stability). The optimisation is repeated until
the step size, $\left(\boldsymbol{x}-\boldsymbol{x}_{k}\right)$, is satisfactory
or the iteration limit is exceeded. Typically, $\epsilon$ minimises the weighted
sum of, for example, the amplitude and delay errors, $\mathcal{E}_{A}$ and 
$\mathcal{E}_{T}$. Separately minimising the amplitude and delay errors implies
the minimisation of of two auxiliary variables $\epsilon_{A}$ and $\epsilon_{T}$.

The complex frequency response can be written in terms of amplitude and phase as
\begin{align*}
H\left(\boldsymbol{x}_{k},\omega_{i}\right) &= 
H_{a}\left(\boldsymbol{x}_{k},\omega_{i}\right)
e^{\imath H_{p}\left(\boldsymbol{x}_{k},\omega_{i}\right)}\\
&= H_{a}\left(\boldsymbol{x}_{k},\omega_{i}\right) \left[
\cos H_{p}\left(\boldsymbol{x}_{k},\omega_{i}\right) +
\imath \sin H_{p}\left(\boldsymbol{x}_{k},\omega_{i}\right) \right]
\end{align*}
so that, at each $\omega_{i}$, the gradient of the complex frequency response is
\begin{align*}
\begin{split}
\nabla_{x}H\left(\boldsymbol{x}_{k},\omega_{i}\right) =
&\left[ \cos H_{p}\left(\boldsymbol{x}_{k},\omega_{i}\right) 
\nabla_{x}H_{a}\left(\boldsymbol{x}_{k},\omega_{i}\right) -
H_{a}\left(\boldsymbol{x}_{k},\omega_{i}\right) 
\sin H_{p}\left(\boldsymbol{x}_{k},\omega_{i}\right) 
\nabla_{x}H_{p}\left(\boldsymbol{x}_{k},\omega_{i}\right) \right]
\quad \dots\\
& +\imath\left[ \sin H_{p}\left(\boldsymbol{x}_{k},\omega_{i}\right) 
\nabla_{x}H_{a}\left(\boldsymbol{x}_{k},\omega_{i}\right) +
H_{a}\left(\boldsymbol{x}_{k},\omega_{i}\right) 
\cos H_{p}\left(\boldsymbol{x}_{k},\omega_{i}\right) 
\nabla_{x}H_{p}\left(\boldsymbol{x}_{k},\omega_{i}\right) \right]
\end{split}
\end{align*}

The squared magnitude of the response is used if there is no design constraint
on the phase of the filter response (for example in the stop band). In this case
\begin{align*}
\left|H\left(\boldsymbol{x}_{k},\omega_{i}\right)\right|^{2}&=
H\left(\boldsymbol{x}_{k},\omega_{i}\right)
H\left(\boldsymbol{x}_{k},\omega_{i}\right)^{\ast}\\
\nabla_{x}\left|H\left(\boldsymbol{x}_{k},\omega_{i}\right)\right|^{2}&=
\left(\nabla_{x}H\left(\boldsymbol{x}_{k},\omega_{i}\right)\right)
H\left(\boldsymbol{x}_{k},\omega_{i}\right)^{\ast} +
H\left(\boldsymbol{x}_{k},\omega_{i}\right)
\left(\nabla_{x}H\left(\boldsymbol{x}_{k},\omega_{i}\right)\right)^{\ast}\\
&=2\Re\nabla_{x}H\left(\boldsymbol{x}_{k},\omega_{i}\right)
\Re H\left(\boldsymbol{x}_{k},\omega_{i}\right)+
2\Im\nabla_{x}H\left(\boldsymbol{x}_{k},\omega_{i}\right)
\Im H\left(\boldsymbol{x}_{k},\omega_{i}\right)
\end{align*}
where $\ast$ represents the complex conjugate.
The squared-magnitude response can be used in linear constraints on the 
upper and lower peaks of the pass-band and stop-band magnitude responses
\begin{align*}
\left|H\left(\boldsymbol{x}_{k},\omega_{i}\right)\right|^{2} +
\left(\boldsymbol{x}-\boldsymbol{x}_{k}\right)^{\top}
\nabla_{x}\left|H\left(\boldsymbol{x}_{k},\omega_{i}\right)\right|^{2}
&\ge H_{d,l}^{2}\left(\omega_{i}\right) \\
\left|H\left(\boldsymbol{x}_{k},\omega_{i}\right)\right|^{2} +
\left(\boldsymbol{x}-\boldsymbol{x}_{k}\right)^{\top}
\nabla_{x}\left|H\left(\boldsymbol{x}_{k},\omega_{i}\right)\right|^{2}
&\le H_{d,u}^{2}\left(\omega_{i}\right)
\end{align*}
where $H_{d,l}^{2}\left(\omega\right)$ and $H_{d,u}^{2}\left(\omega\right)$ 
are the lower and upper constraints on the squared-magnitude 
response. A similar linear constraint on the phase response uses
\begin{align*}
\phi_{H}\left(\boldsymbol{x}_{k},\omega_{i}\right)=
&\arctan\frac{\Im H\left(\boldsymbol{x}_{k},\omega_{i}\right)}
{\Re H\left(\boldsymbol{x}_{k},\omega_{i}\right)}\\
\nabla_{x}\phi_{H}\left(\boldsymbol{x}_{k},\omega_{i}\right)=
&\frac{\Re H\left(\boldsymbol{x}_{k},\omega_{i}\right)
\Im\nabla_{x} H\left(\boldsymbol{x}_{k},\omega_{i}\right) -
\Im H\left(\boldsymbol{x}_{k},\omega_{i}\right)
\Re \nabla_{x} H\left(\boldsymbol{x}_{k},\omega_{i}\right)}
{\left|H\left(\boldsymbol{x}_{k},\omega_{i}\right)\right|^{2}}
\end{align*}
\section{Using the \emph{SeDuMi} SOCP solver}
In the following I use the \emph{SeDuMi}
(\emph{Se}lf-\emph{Du}al-\emph{Mi}nimisation) SOCP solver originally written
by \emph{Jos Sturm}~\cite{Sturm_SeDuMi_GitHub}. 
\emph{Lu}~\cite[Section III]{Lu_SedumiRemarks} provides an example of expressing
an optimisation problem in the form accepted by SeDuMi. In \emph{Lu}'s notation
the problem is:
\begin{subequations}
\begin{align}
\textbf{minimise}  \quad&\boldsymbol{b}^{\top}\boldsymbol{x}
\label{eqn:Lu-SeDuMi-Remarks-problem-format}\\
\textbf{subject to}\quad&\|\boldsymbol{A}_{i}^{\top}\boldsymbol{x}+
\boldsymbol{c}_{i}\| \le \boldsymbol{b}_{i}^{\top}\boldsymbol{x}+d_{i}
\quad \text{for}\;i=1,\hdots,q
\label{eqn:Lu-SeDuMi-Remarks-problem-format-conic-constraints}\\
&\boldsymbol{D}^{\top}\boldsymbol{x}+\boldsymbol{f}\ge\boldsymbol{0}
\label{eqn:Lu-SeDuMi-Remarks-problem-format-linear-constraints}
\end{align}
\end{subequations}
where $\boldsymbol{x}\in\mathfrak{\mathbb{R}}^{m\times 1}$, 
$\boldsymbol{b}\in\mathfrak{\mathbb{R}}^{m\times 1}$,
$\boldsymbol{A}_{i}\in\mathfrak{\mathbb{R}}^{m\times\left(n_{i}-1\right)}$
\footnote{$n_{i}-1$ to allow for the column $b_{i}$ in the matrix 
$\boldsymbol{A}_{t}^{\left(i\right)}$ and $d_{i}$ in the column vector 
$\boldsymbol{c}_{t}^{\left(i\right)}$}, 
$\boldsymbol{c}_{i}\in\mathfrak{\mathbb{R}}^{\left(n_{i}-1\right)\times 1}$,
$\boldsymbol{b}_{i}\in\mathfrak{\mathbb{R}}^{m\times 1}$, 
$d_{i}\in\mathfrak{\mathbb{R}}$ for $1 \le i \le q$,
$\boldsymbol{D}\in\mathfrak{\mathbb{R}}^{m\times p}$ and
$\boldsymbol{f}\in\mathfrak{\mathbb{R}}^{p\times 1}$. The problem is cast into
SeDuMi format by defining
\begin{align}
\label{eqn:Lu-SeDuMi-Remarks-problem-matrixes}
\boldsymbol{A}_{t}&=\left[-\boldsymbol{D} \quad \boldsymbol{A}_{t}^{\left(1\right)}
\hdots \quad \boldsymbol{A}_{t}^{\left(q\right)}\right]\\
\boldsymbol{A}_{t}^{\left(i\right)} &= -\left[\boldsymbol{b}_{i} \quad
\boldsymbol{A}_{i}\right]\nonumber\\
\boldsymbol{b}_{t}&=-\boldsymbol{b}\nonumber\\
\boldsymbol{c}_{t}&=\left[\boldsymbol{f};\quad \boldsymbol{c}_{t}^{\left(1\right)}
;\quad \hdots\quad \boldsymbol{c}_{t}^{\left(q\right)}\right]\nonumber\\
\boldsymbol{c}_{t}^{\left(i\right)}&=\left[d_{i} ;\quad \boldsymbol{c}_{i}\right]
\nonumber
\end{align}

The Octave commands to solve the SOCP problem with SeDuMi are
\begin{small}
\begin{verbatim}
K.l = p;
K.q = q;
[xs,ys,info] = sedumi(At,bt,ct,K);
info
x = ys;
\end{verbatim}
\end{small}
where $p$ is the number of linear constraints in 
Equation~\ref{eqn:Lu-SeDuMi-Remarks-problem-format-linear-constraints} and 
$\boldsymbol{q}$ is a vector giving the dimensions of the $q$ sets of conic
constraints in 
Equation~\ref{eqn:Lu-SeDuMi-Remarks-problem-format-conic-constraints},
$\boldsymbol{q}=\left[\begin{array}{cccc}n_{1} & n_{2} & \hdots & n_{q}
\end{array}\right]$. The Octave script \emph{Lu\_remarks\_example\_4\_test.m}
shows \emph{Lu}'s Example 4~\cite[Section III]{Lu_SedumiRemarks}, an SOCP
problem with linear and quadratic constraints.
\clearpage
\section{\label{sec:Deczky3-IIR-filter-gain-zero-pole-with-SeDuMi}An example of SOCP design of an IIR filter expressed in \emph{gain-zero-pole} format with the \emph{SeDuMi} SOCP solver}
The Octave script \emph{deczky3\_socp\_test.m} implements the design of Deczky's
Example 3, used previously in Section~\ref{sub:Deczkys-Example-3}, with MMSE 
optimisation of the weighted response error by the \emph{SeDuMi} SOCP solver.
As in Part~\ref{sec:Constrained-Optimisation-of-IIR-by-Quadratic-Programming-Pole-Zero-Location}, 
the coefficients of this example filter are expressed in \emph{gain-zero-pole}
form and the amplitude and group-delay are calculated with the \emph{iirA} and
\emph{iirT} functions. Similarly, filter stability is ensured
by linear constraints on the upper and lower values of the coefficients.

As for the filter design in Section~\ref{sub:Deczkys-Example-3}, the 
\emph{deczky3\_socp\_test.m} script has two phases. First, starting with the
``IPSZ-1'' coefficients the sum of the coefficient step-size and MMSE error
is minimised in the the Octave function \emph{iir\_socp\_mmse.m}. Linesearch
along the minimal direction is not required. The minimisation variables are
\begin{align*}
\text{\textsf{\textbf{x}}} &= \left[\begin{array}{c}
\epsilon \\
\beta \\
\boldsymbol{\delta}
\end{array}\right]
\end{align*}
where $\epsilon$ is the MMSE error, 
$\boldsymbol{\delta}$ is the step direction from coefficient vector 
$\boldsymbol{x}_{k}$, and $\beta$ is the constraint on the coefficient
step-size, $\|\boldsymbol{\delta}\| \le \beta$.

In a similar fashion to the MMSE error used in 
Chapter~\ref{sec:Constrained-Optimisation-of-IIR-by-Quadratic-Programming-Pole-Zero-Location},
the MMSE frequency response constraint can be expressed as a weighted sum of 
pass-band amplitude response, $A$, stop-band amplitude response, $S$, pass-band
phase response, $P$, and the pass-band group-delay response, $T$. In this
example I do not attempt to control the transition band amplitude response.
In \emph{SeDuMi} format:
\begin{align*}
\boldsymbol{A}_{i}^{\top} &= \left[\begin{array}{cc}
\boldsymbol{0} & W_{a}\left(\omega_{a}\right) 
\nabla_{x}A\left(\boldsymbol{x}_{k},\omega_{a}\right) \\
\boldsymbol{0} & W_{s}\left(\omega_{s}\right)
\nabla_{x}S\left(\boldsymbol{x}_{k},\omega_{s}\right)\\
\boldsymbol{0} & W_{p}\left(\omega_{p}\right) 
\nabla_{x}P\left(\boldsymbol{x}_{k},\omega_{p}\right) \\
\boldsymbol{0} & W_{t}\left(\omega_{t}\right) 
\nabla_{x}T\left(\boldsymbol{x}_{k},\omega_{t}\right)
\end{array}\right] \\
\boldsymbol{b}_{i}^{\top} &= \left[\begin{array}{ccc} 
1 & 0 & \boldsymbol{0} \end{array}\right] \\
\boldsymbol{c}_{i} &= \left[\begin{array}{c}
W_{a}\left(\omega_{a}\right)\;
\left[A\left(\boldsymbol{x}_{k},\omega_{a}\right)-
A_{d}\left(\omega_{a}\right)\right] \\
W_{s}\left(\omega_{s}\right)\;
\left[S\left(\boldsymbol{x}_{k},\omega_{s}\right)-
S_{d}\left(\omega_{s}\right)\right] \\
W_{p}\left(\omega_{p}\right)\;
\left[P\left(\boldsymbol{x}_{k},\omega_{p}\right)-
P_{d}\left(\omega_{p}\right)\right]\\
W_{t}\left(\omega_{t}\right)\;
\left[T\left(\boldsymbol{x}_{k},\omega_{t}\right)-
T_{d}\left(\omega_{t}\right)\right]
\end{array}\right]\\
d_{i} &= 0
\end{align*}
where $\omega_{a}\in\Omega_{a}$, $\omega_{s}\in\Omega_{s}$,
$\omega_{p}\in\Omega_{p}$ and $\omega_{t}\in\Omega_{t}$ are the pass-band
amplitude, stop-band amplitude, pass band-phase and pass-band group delay
response grid frequencies and $A_{d}\left(\omega_{a}\right)$,
$S_{d}\left(\omega_{s}\right)$, $P_{d}\left(\omega_{p}\right)$  and
$T_{d}\left(\omega_{t}\right)$ are the desired pass-band amplitude, stop-band
amplitude, pass-band phase and pass-band delay responses, respectively.

The gain-zero-pole coefficients have upper and lower constraints, 
$\boldsymbol{x}_{u}$ and $\boldsymbol{x}_{l}$ respectively, ensuring stability
with
\begin{align*}
- \left( \boldsymbol{x} -    \boldsymbol{x}_{k} \right)  
- \left( \boldsymbol{x}_{k} - \boldsymbol{x}_{u} \right) & \ge 0 \\ 
\phantom{-}\left( \boldsymbol{x} - \boldsymbol{x}_{k} \right) 
- \left( \boldsymbol{x}_{l} - \boldsymbol{x}_{k} \right) & \ge 0 
\end{align*}

The stability constraint is a linear constraint on the coefficients
\begin{align*}
\boldsymbol{D}^{\top} &= \left[\begin{array}{cc} \boldsymbol{0} & \boldsymbol{-I}\\
\boldsymbol{0} & \boldsymbol{\phantom{-}I} \end{array}\right] \\
\boldsymbol{f} &= \left[\begin{array}{c}
-\left(\boldsymbol{x}_{k}-\boldsymbol{x}_{u}\right) \\
-\left(\boldsymbol{x}_{l}-\boldsymbol{x}_{k}\right)\end{array}\right]
\end{align*}

During the second, PCLS, phase, the Octave function, \emph{iir\_slb.m}
minimises the sum of the coefficient step-size and the MMSE error subject to
linear constraints on the pass-band amplitude response, stop-band amplitude
response and group-delay response. For example, the pass-band amplitude
response upper and lower constraints are
\begin{align*}
\mathbin{\phantom{-}}A_{du}\left(\boldsymbol{x}_{k},\omega_{au}\right) 
- \left[A\left(\boldsymbol{x}_{k},\omega_{au}\right) + 
\nabla_{x}A\left(\boldsymbol{x}_{k},\omega_{au}\right)^{\top}
\boldsymbol{\delta}\right]&\ge 0\\
-A_{dl}\left(\boldsymbol{x}_{k},\omega_{al}\right) + 
\left[A\left(\boldsymbol{x}_{k},\omega_{al}\right) + 
\nabla_{x} A\left(\boldsymbol{x}_{k},\omega_{al}\right)^{\top}
\boldsymbol{\delta}\right]&\ge 0
\end{align*}
where $\omega_{au}\in\Omega_{au}$ and $\omega_{al}\in\Omega_{al}$ are the upper
and lower pass-band amplitude response constraint frequencies. These constraints
are added to the \emph{SeDuMi} problem as linear constraints. The constraint
frequencies are determined by the PCLS peak-exchange algorithm of 
\emph{Selesnick et al.} shown in
Algorithm~\ref{alg:Exchange-algorithm-for-multi-band-FIR-filters}.

The \emph{deczky3\_socp\_test.m} script has somewhat tighter constraints on the
pass-band group-delay ripple than the SQP design of \emph{deczky3\_sqp\_test.m}
shown in Section~\ref{sub:Deczkys-Example-3}. The filter specification is
\begin{small}
\verbatiminput{deczky3_socp_test_spec.m}
\end{small}
The result of the PCLS SOCP SeDuMi pass in \emph{deczky3\_socp\_test.m} is shown
in Figure~\ref{fig:SOCP-Deczky-Example-3-PCLS-d2} with pass-band details
shown in Figure~\ref{fig:SOCP-Deczky-Example-3-PCLS-d2-passband} and 
pole-zero plot shown in Figure~\ref{fig:SOCP-Deczky-Example-3-PCLS-d2-pz}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_socp_test_pcls_d2}}
\caption{Deczky Example 3, response after PCLS SOCP SeDuMi optimisation.}
\label{fig:SOCP-Deczky-Example-3-PCLS-d2}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_socp_test_pcls_d2pass}}
\caption{Deczky Example 3, passband response after PCLS SOCP SeDuMi
optimisation.}
\label{fig:SOCP-Deczky-Example-3-PCLS-d2-passband}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_socp_test_pcls_d2pz}}
\caption{Deczky Example 3, pole-zero plot after PCLS SOCP SeDuMi optimisation.}
\label{fig:SOCP-Deczky-Example-3-PCLS-d2-pz}
\end{figure}

The PCLS SOCP SeDuMi optimised filter is, in the gain, zeros and poles form of
Equation~\ref{eqn:Filter-gain-zeros-poles}:
\begin{small}
\verbatiminput{deczky3_socp_test_d2_coef.m}
\end{small}
and the corresponding transfer function numerator and denominator polynomials
(found with Octave function \emph{x2tf}) are, respectively:
\begin{small}
\verbatiminput{deczky3_socp_test_N2_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{deczky3_socp_test_D2_coef.m}
\end{small}

The \emph{deczky3a\_socp\_test.m} script also calls the SeDuMi solver through
the function \emph{iir\_socp\_mmse.m}. This script has looser constraints
on the pass-band group-delay ripple and increases the required stop-band
attenuation:
\begin{small}
\verbatiminput{deczky3a_socp_test_spec.m}
\end{small}
The result of the PCLS SOCP SeDuMi pass in \emph{deczky3a\_socp\_test.m} is
shown in Figure~\ref{fig:SOCP-Deczky-Example-3a-PCLS-d2} with pass-band details
shown in Figure~\ref{fig:SOCP-Deczky-Example-3a-PCLS-d2-passband} and 
pole-zero plot shown in Figure~\ref{fig:SOCP-Deczky-Example-3a-PCLS-d2-pz}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3a_socp_test_pcls_d2}}
\caption{Deczky Example 3, response after PCLS SOCP SeDuMi optimisation,
  alternative specification.}
\label{fig:SOCP-Deczky-Example-3a-PCLS-d2}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3a_socp_test_pcls_d2pass}}
\caption{Deczky Example 3, passband response after PCLS SOCP SeDuMi optimisation,
  alternative specification.}
\label{fig:SOCP-Deczky-Example-3a-PCLS-d2-passband}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3a_socp_test_pcls_d2pz}}
\caption{Deczky Example 3, pole-zero plot after PCLS SOCP SeDuMi optimisation,
  alternative specification.}
\label{fig:SOCP-Deczky-Example-3a-PCLS-d2-pz}
\end{figure}
The estimate of the PCLS SOCP SeDuMi optimised filter vector is, in the gain,
zeros and poles form of Equation~\ref{eqn:Filter-gain-zeros-poles}:
\begin{small}
\verbatiminput{deczky3a_socp_test_d2_coef.m}
\end{small}

In Section~\ref{sub:Solution-quasi-Newton-optimisation}, I expressed the filter
design problem as a \emph{sequential quadratic programming}, or SQP, problem:
\begin{align*}
\textbf{minimise}\quad&q\left(\boldsymbol{x}\right)=
\frac{1}{2}\boldsymbol{x}^{\top}\boldsymbol{Q}\boldsymbol{x}+
\boldsymbol{a}^{\top}\boldsymbol{x}+\beta
\end{align*}
where $\boldsymbol{Q}$ is positive definite and symmetric and linear constraints
are neglected for clarity. This SQP optimisation problem can be converted to 
an SOCP problem by rearranging $q\left(\boldsymbol{x}\right)$:
\begin{align*}
q\left(\boldsymbol{x}\right)&=
\frac{1}{2}\|\boldsymbol{Q}^{\frac{1}{2}}\boldsymbol{x}+
\boldsymbol{Q}^{-\frac{1}{2}}\boldsymbol{a}\|^{2}+
\beta-\frac{1}{2}\boldsymbol{a}^{\top}\boldsymbol{Q}^{-1}\boldsymbol{a}
\end{align*}
See \emph{Alizadeh} and 
\emph{Goldfarb}~\cite[Section 2.1]{AlizadehGoldfarb_SecondOrderCone} or
\emph{Antoniou} and 
\emph{Lu}~\cite[Section 14.7.2]{AntoniouLu_PracticalOptimization}. 

The Octave script \emph{deczky3\_socp\_bfgs\_test.m} implements the design of 
Deczky's Example 3, with the SeDuMi SOCP solver, as in 
Section~\ref{sec:Deczky3-IIR-filter-gain-zero-pole-with-SeDuMi}, but with
MMSE optimisation of the weighted response error, 
$\mathcal{E}\left(\boldsymbol{x}\right)$, represented as $
\|\boldsymbol{Q}^{\frac{1}{2}}\boldsymbol{x}+
\boldsymbol{Q}^{-\frac{1}{2}}\nabla_{x}\mathcal{E}\left(\boldsymbol{x}\right)\|$, 
where $\boldsymbol{Q}$ is initialised with the diagonal of 
$\nabla_{x}^{2}\mathcal{E}\left(\boldsymbol{x}\right)$ and updated with the
BFGS Hessian matrix update algorithm shown in 
Appendix~\ref{Updating-with-the-BFGS-formula}. 

The filter specification is
\begin{small}
\verbatiminput{deczky3_socp_bfgs_test_spec.m}
\end{small}

The result of the PCLS SOCP SeDuMi pass in \emph{deczky3\_socp\_bfgs\_test.m} is
shown in Figure~\ref{fig:SOCP-BFGS-Deczky-Example-3-PCLS-d2} with pass-band
details  shown in Figure~\ref{fig:SOCP-BFGS-Deczky-Example-3-PCLS-d2-passband}
and  pole-zero plot shown in
Figure~\ref{fig:SOCP-BFGS-Deczky-Example-3-PCLS-d2-pz}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_socp_bfgs_test_pcls_d2}}
\caption{Deczky Example 3, response after PCLS SOCP SeDuMi optimisation with BFGS
  update of the Hessian.}
\label{fig:SOCP-BFGS-Deczky-Example-3-PCLS-d2}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_socp_bfgs_test_pcls_d2pass}}
\caption{Deczky Example 3, passband response after PCLS SOCP SeDuMi optimisation
  with BFGS update of the Hessian.}
\label{fig:SOCP-BFGS-Deczky-Example-3-PCLS-d2-passband}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_socp_bfgs_test_pcls_d2pz}}
\caption{Deczky Example 3, pole-zero plot after PCLS SOCP SeDuMi optimisation
  with BFGS update of the Hessian.}
\label{fig:SOCP-BFGS-Deczky-Example-3-PCLS-d2-pz}
\end{figure}

The PCLS SOCP SeDuMi optimised filter is, in the gain, zeros and poles form of
Equation~\ref{eqn:Filter-gain-zeros-poles}:
\begin{small}
\verbatiminput{deczky3_socp_bfgs_test_d2_coef.m}
\end{small}
The corresponding transfer function numerator and denominator polynomials are:
\begin{small}
\verbatiminput{deczky3_socp_bfgs_test_N2_coef.m}
\verbatiminput{deczky3_socp_bfgs_test_D2_coef.m}
\end{small}
\clearpage
\section{\label{sec:Deczky3-IIR-filter-gain-zero-pole-with-SCSi}An example of SOCP design of an IIR filter expressed in \emph{gain-zero-pole} format with the \emph{SCS} SOCP solver}
The \emph{deczky3\_scs\_test.m} script calls the SCS~\cite{Bodonoghue_SCS,
BODonoghueAbbott_Matlab_SCS,BODonoghueChuParikhBoyd_SCS} SOCP solver through
the Octave function \emph{iir\_scs\_mmse.m}. The filter specification is:
\begin{small}
\verbatiminput{deczky3_scs_test_spec.m}
\end{small}

The result of the PCLS SOCP SCS pass in \emph{deczky3\_scs\_test.m} is shown
in Figure~\ref{fig:SCS-Deczky-Example-3-PCLS-d2} with pass-band details
shown in Figure~\ref{fig:SCS-Deczky-Example-3-PCLS-d2-passband} and 
pole-zero plot shown in Figure~\ref{fig:SCS-Deczky-Example-3-PCLS-d2-pz}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_scs_test_pcls_d2}}
\caption{Deczky Example 3, response after PCLS SOCP SCS optimisation.}
\label{fig:SCS-Deczky-Example-3-PCLS-d2}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_scs_test_pcls_d2pass}}
\caption{Deczky Example 3, passband response after PCLS SOCP SCS optimisation.}
\label{fig:SCS-Deczky-Example-3-PCLS-d2-passband}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{deczky3_scs_test_pcls_d2pz}}
\caption{Deczky Example 3, pole-zero plot after PCLS SOCP SCS optimisation.}
\label{fig:SCS-Deczky-Example-3-PCLS-d2-pz}
\end{figure}
\clearpage
The PCLS SOCP SCS optimised filter is, in the gain, zeros and poles form of
Equation~\ref{eqn:Filter-gain-zeros-poles}:
\begin{small}
\verbatiminput{deczky3_scs_test_d2_coef.m}
\end{small}
The corresponding transfer function numerator and denominator polynomials are:
\begin{small}
\verbatiminput{deczky3_scs_test_N2_coef.m}
\verbatiminput{deczky3_scs_test_D2_coef.m}
\end{small}

\clearpage
\section{\label{sec:SOCP-non-linear-phase-FIR-lowpass-filter}SOCP design of a non-linear phase FIR low-pass filter}
The Octave script \emph{iir\_socp\_slb\_fir\_lowpass\_test.m} designs an 
FIR low-pass filter that has approximately linear phase in the pass-band. The
impulse response is \emph{not} symmetric. The filter specification is:
\begin{small}
\verbatiminput{iir_socp_slb_fir_lowpass_test_spec.m}
\end{small}
Figure~\ref{fig:iir-socp-slb-fir-lowpass-pcls-response} shows the response of
the PCLS optimised filter.
Figure~\ref{fig:iir-socp-slb-fir-lowpass-pcls-passband-response} shows the
pass-band detail of the response of the PCLS optimised filter.
The coefficients of the PCLS optimised minimum phase
FIR bandpass filter are, in gain-pole-zero form:
\begin{small}
\verbatiminput{iir_socp_slb_fir_lowpass_test_d1_coef.m}
\end{small}
and in transfer function form the FIR polynomial is:
\begin{small}
\verbatiminput{iir_socp_slb_fir_lowpass_test_N1_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_socp_slb_fir_lowpass_test_pcls_d1}}
\caption{Response of the non-linear phase FIR low-pass filter after SOCP PCLS
  optimisation.}
\label{fig:iir-socp-slb-fir-lowpass-pcls-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_socp_slb_fir_lowpass_test_pcls_d1pass}}
\caption{Pass-band response of the non-linear phase FIR low-pass filter after
  SOCP PCLS optimisation.}
\label{fig:iir-socp-slb-fir-lowpass-pcls-passband-response}
\end{figure}

The Octave script \emph{iir\_socp\_slb\_fir\_lowpass\_alternate\_test.m} designs
an alternative minimum-phase FIR low-pass filter that has approximately linear
phase in the pass-band. The filter specification is:
\begin{small}
\verbatiminput{iir_socp_slb_fir_lowpass_alternate_test_spec.m}
\end{small}
Figure~\ref{fig:iir-socp-slb-fir-lowpass-alternate-pcls-response} shows the
response of the PCLS optimised filter.
Figure~\ref{fig:iir-socp-slb-fir-lowpass-alternate-pcls-passband-response} shows
the pass-band detail of the response of the PCLS optimised filter.
The coefficients of the PCLS optimised alternative minimum phase
FIR bandpass filter are, in gain-pole-zero form:
\begin{small}
\verbatiminput{iir_socp_slb_fir_lowpass_alternate_test_d1_coef.m}
\end{small}
and in transfer function form the FIR polynomial is:
\begin{small}
\verbatiminput{iir_socp_slb_fir_lowpass_alternate_test_N1_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_socp_slb_fir_lowpass_alternate_test_pcls_d1}}
\caption{Response of the alternative non-linear phase FIR low-pass filter after
  SOCP PCLS optimisation.}
\label{fig:iir-socp-slb-fir-lowpass-alternate-pcls-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_socp_slb_fir_lowpass_alternate_test_pcls_d1pass}}
\caption{Pass-band response of the alternative non-linear phase FIR low-pass
  filter after SOCP PCLS optimisation.}
\label{fig:iir-socp-slb-fir-lowpass-alternate-pcls-passband-response}
\end{figure}
\clearpage
\section{\label{sec:Comparison-FIR-IIR-low-pass-filter-gain-zero-pole-with-SeDuMi}Comparison of FIR and IIR low-pass filters having approximately flat pass-band group delay with symmetric FIR filters}
The Octave script \emph{compare\_fir\_iir\_socp\_slb\_lowpass\_test.m}
compares the performance of FIR and IIR implementations of a low-pass filter
having $31$ coefficients and a pass-band group delay of approximately $10$
samples designed by the \emph{SeDuMi} solver with symmetric FIR low-pass
filters having $21$ and $31$ coefficients designed by the Octave \emph{remez}
function. The low-pass filter pass-band and stop-band edges are $0.15$ and
$0.2$, respectively, and the allowed pass-band ripple is $3dB$. The IIR filter
specification is:
\begin{small}
\verbatiminput{iir_socp_slb_lowpass_test_spec.m}
\end{small}
The \emph{gain-zero-pole} FIR filter specification is:
\begin{small}
\verbatiminput{fir_socp_slb_lowpass_test_spec.m}
\end{small}
The symmetric FIR filters were designed with:
\begin{small}
\begin{verbatim}
d10=remez(20,[0 0.15 0.2 0.5]*2,[1 1 0 0],[1 7]);
\end{verbatim}
\end{small}
and
\begin{small}
\begin{verbatim}
d15=remez(30,[0 0.15 0.2 0.5]*2,[1 1 0 0],[1 50]);
\end{verbatim}
\end{small}

Figure~\ref{fig:FIR-IIR-low-pass-filter-gain-zero-pole-with-SeDuMi-amplitude}
compares the amplitude responses of the four filters and
Figure~\ref{fig:FIR-IIR-low-pass-filter-gain-zero-pole-with-SeDuMi-delay}
compares the delay responses (the flat delay of $15$ samples of the order $30$
symmetric FIR filter is not shown).

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{compare_fir_iir_socp_slb_lowpass_test_A}}
\caption{Comparison of FIR and IIR low-pass filters, amplitude responses.}
\label{fig:FIR-IIR-low-pass-filter-gain-zero-pole-with-SeDuMi-amplitude}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{compare_fir_iir_socp_slb_lowpass_test_T}}
\caption{Comparison of FIR and IIR low-pass filters, group delay responses.}
\label{fig:FIR-IIR-low-pass-filter-gain-zero-pole-with-SeDuMi-delay}
\end{figure}
\clearpage
\section{\label{sec:iir-socp-slb-lowpass-differentiator}SOCP design of a low-pass differentiator filter}
The Octave script \emph{iir\_socp\_slb\_lowpass\_differentiator\_test.m} designs
an IIR low-pass differentiator filter with the specification:
\begin{small}
\verbatiminput{iir_socp_slb_lowpass_differentiator_test_spec.m}
\end{small}
The filter is designed with the effect of a fixed zero at $z=1$
removed from the desired response. That zero is added back after optimisation is
complete.

As shown in Section~\ref{sec:iir-sqp-slb-lowpass-differentiator}, the Octave
script \emph{tarczynski\_lowpass\_differentiator\_test.m} designs an initial
filter by the method of \emph{Tarczynski et al}.

Figure~\ref{fig:iir-socp-slb-lowpass-differentiator-pcls-response-error} shows
the response errors of the low-pass differentiator after PCLS optimisation.
Figure~\ref{fig:iir-socp-slb-lowpass-differentiator-pcls-pz} shows the pole-zero
plot of the low-pass differentiator filter after PCLS optimisation. The
PCLS optimised overall filter coefficients are, in gain-zero-pole form:
\begin{small}
\verbatiminput{iir_socp_slb_lowpass_differentiator_test_d1z_coef.m}
\end{small}
and, in transfer function form, the numerator and denominator polynomials of
the correction filter are, respectively:
\begin{small}
\verbatiminput{iir_socp_slb_lowpass_differentiator_test_N1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{iir_socp_slb_lowpass_differentiator_test_D1_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_socp_slb_lowpass_differentiator_test_pcls_error}}
\caption{Response errors of the low-pass differentiator filter after PCLS
  optimisation. The phase response shown is adjusted for the nominal delay.}
\label{fig:iir-socp-slb-lowpass-differentiator-pcls-response-error}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_socp_slb_lowpass_differentiator_test_pcls_pz}}
\caption{Pole-zero plot of the low-pass differentiator filter after PCLS
  optimisation.}
\label{fig:iir-socp-slb-lowpass-differentiator-pcls-pz}
\end{figure}
\clearpage
\section{\label{sec:Bandpass-R-2-IIR-filter-gain-zero-pole-with-SeDuMi}SOCP MMSE design of a bandpass R=2 filter expressed in \emph{gain-zero-pole} format with \emph{SeDuMi}}
The Octave script \emph{iir\_socp\_slb\_bandpass\_test.m} uses the \emph{SeDuMi}
SOCP solver to design an $R=2$ bandpass filter similar to that designed with the
SQP solver in Section~\ref{sec:Band-pass-R-2-decimation-filter}. After some 
experimentation, the filter specification is:
\begin{small}
\verbatiminput{iir_socp_slb_bandpass_test_spec.m}
\end{small}
The \emph{SeDuMi} solver seems to require the initial filter to be a closer
approximation than that required by the SQP solver. In this case, the initial
filter is calculated by the Octave function \emph{tarczynski\_bandpass\_test.m}.
The response of the initial filter is shown in
Figure~\ref{fig:iir-socp-slb-bandpass-test-initial-x0}. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_socp_slb_bandpass_test_initial_x0}}
\caption{IIR band-pass R=2 decimation filter, response of the initial filter
calculated with the WISE method of \emph{Tarcynzki et al.}\;.}
\label{fig:iir-socp-slb-bandpass-test-initial-x0}
\end{figure}
After PCLS SOCP optimimisation, the response of the resulting filter is shown 
in Figure~\ref{fig:iir-socp-slb-bandpass-test-pcls-d1} with pass-band detail
shown in Figure~\ref{fig:iir-socp-slb-bandpass-test-pcls-d1-passband}. The
corresponding pole-zero plot is shown in
Figure~\ref{fig:iir-socp-slb-bandpass-test-pcls-d1-pz}. The estimate of the
optimised filter vector is, in the gain, zeros and poles form of
Equation~\ref{eqn:Filter-gain-zeros-poles}:
\begin{small}
\verbatiminput{iir_socp_slb_bandpass_test_d1_coef.m}
\end{small}
and the corresponding transfer function numerator and denominator polynomials
(found with Octave function \emph{x2tf}) are, respectively:
\begin{small}
\verbatiminput{iir_socp_slb_bandpass_test_N1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{iir_socp_slb_bandpass_test_D1_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_socp_slb_bandpass_test_pcls_d1}}
\caption{IIR band-pass R=2 decimation filter with delay tp=16 samples, response
of the filter after PCLS SOCP optimisation.}
\label{fig:iir-socp-slb-bandpass-test-pcls-d1}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_socp_slb_bandpass_test_pcls_d1pass}}
\caption{IIR band-pass R=2 decimation filter with delay tp=16 samples, passband
  response of the filter after PCLS SOCP optimisation.}
\label{fig:iir-socp-slb-bandpass-test-pcls-d1-passband}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_socp_slb_bandpass_test_pcls_d1pz}}
\caption{IIR band-pass R=2 decimation filter with delay tp=16 samples, pole-zero
  plot of the filter after PCLS SOCP optimisation.}
\label{fig:iir-socp-slb-bandpass-test-pcls-d1-pz}
\end{figure}
\clearpage
\section{\label{sec:Multi-bandpass-IIR-filter-gain-zero-pole-with-SeDuMi}SOCP MMSE design of a multi-band-pass filter expressed in \emph{gain-zero-pole} format with \emph{SeDuMi}}
The Octave script
\emph{iir\_socp\_slb\_multiband\_test.m}
implements the design of a multi-band-pass IIR filter expressed in
\emph{gain-pole-zero} format with SOCP and PCLS optimisation using
\emph{SeDuMi}. The specification of the filter is:
\begin{small}
\verbatiminput{iir_socp_slb_multiband_test_spec.m}
\end{small}
The initial filter is designed by frequency transformation of a prototype
elliptic filter. The gain-zero-pole description of the SOCP PCLS optimised
filter is:
\begin{small}
\verbatiminput{iir_socp_slb_multiband_test_x2_coef.m}
\end{small}
The numerator and denominator polynomials of the SOCP PCLS optimised filter are:
\begin{small}
\verbatiminput{iir_socp_slb_multiband_test_N2_coef.m}
\verbatiminput{iir_socp_slb_multiband_test_D2_coef.m}
\end{small}
Figure~\ref{fig:IIR-multiband-SOCP-PCLS} shows the
amplitude and delay responses of the PCLS SOCP optimised filter, calculated
with the \emph{iirA} and \emph{iirT} functions respectively.
Figure~\ref{fig:IIR-multiband-SOCP-PCLS-pass} shows the pass-band response of
the filter.
Figure~\ref{fig:IIR-multiband-SOCP-PCLS-pz} shows the pole-zero plot of the
filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_socp_slb_multiband_test_pcls}}
\caption{IIR multi-band filter, response after SOCP PCLS optimisation.}
\label{fig:IIR-multiband-SOCP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_socp_slb_multiband_test_pcls_pass}}
\caption{IIR multi-band filter, pass-band response after SOCP PCLS optimisation.}
\label{fig:IIR-multiband-SOCP-PCLS-pass}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_socp_slb_multiband_test_pcls_pz}}
\caption{Pole-zero plot of the IIR multi-band filter after SOCP PCLS
  optimisation.}
\label{fig:IIR-multiband-SOCP-PCLS-pz}
\end{figure}

\chapter{\label{sec:IIR-Filter-Design-With-Predefined-Structure}IIR filter design with a pre-defined structure}
In this chapter I describe the design of IIR filters with a predefined structure.

\section{Design of an IIR filter composed of second-order sections}
In this section I consider the MMSE design of an IIR filter consisting of a 
cascade of second-order sections (with one first-order section if the transfer
function polynomial order is odd). The stability of the IIR filter is ensured 
by a linear constraint on the coefficients of the denominator second-order
sections. (See \emph{Lu} and 
\emph{Hinamoto}~\cite{LuHinamoto_IIRRobustStabilityQuadraticProgramming}).
\subsection{\label{sec:Stability-of-second-order-filter-sections}Linear constraints on the stability of second-order filter sections}
A digital filter is stable if its poles (the zeros of the denominator polynomial 
of the filter transfer function) lie within the unit circle in the $z$-plane,
$\left|z\right|<1$. Suppose the filter denominator polynomial is 
decomposed into one first order section, $z+d_{0}$, and second order sections of
the form $z^{2}+d_{1}z+d_{2}$. The pole location of the first order section 
is constrained by
\begin{align*}
 d_{0} &> -1\\
-d_{0} &> -1
\end{align*}
If the roots of the second order polynomial lie within the unit circle 
$\left|z\right|<1$ then
\begin{align*}
\left|\frac{-d_{1} \pm \sqrt{d_{1}^{2}-4d_{2}}}{2}\right|< 1
\end{align*}
If the roots are complex then $d_{1}^{2} \le 4d_{2}$ and
\begin{align*}
\frac{d_{1}^{2} +4d_{2}-d_{1}^{2}}{4}<1
\end{align*}
so $-d_{2}>-1$. 

If the roots are real then $d_{1}^{2} \ge 4d_{2}$ and
\begin{align*}
\left|\frac{-d_{1} \pm \sqrt{d_{1}^{2}-4d_{2}}}{2} \right| &<1 \\
\pm \sqrt{d_{1}^{2}-4d_{2}} &< 2 \pm d_{1}
\end{align*}
Squaring both sides
\begin{align*}
\pm d_{1} + d_{2} > -1
\end{align*}
If a margin $0<\tau\ll 1$ is applied to the first and second order sections then:
\begin{align*}
d_{0}&>-1+\tau\\
-d_{0}&>-1+\tau\\
d_{1} + d_{2} &> -1+\tau \\
-d_{1} + d_{2} &> -1+\tau \\
-d_{2} &>-1+\tau
\end{align*}

Suppose the denominator polynomial has odd order $2L+1$. Define the
coefficients of the corresponding first and second order sections and the
stability constraint matrixes as
\begin{align*}
\boldsymbol{d}&=\left[\begin{array}{c}
d_{0} \\
\boldsymbol{d}_{1} \\
\vdots \\
\boldsymbol{d}_{L}
\end{array}\right]
 &\text{ where } \boldsymbol{d}_{i}=\left[\begin{array}{c}
d_{i1} \\
d_{i2}
\end{array}\right]\\
\boldsymbol{C}&=\left[\begin{array}{cccc}
c_{1} &       & & \boldsymbol{0} \\
      & c_{2} &               &  \\
      &      & \ddots        & \\
\boldsymbol{0} & & & c_{2}\end{array}\right]
 &\text{ where } c_{1}=\left[\begin{array}{c}
\phantom{-}1\\
-1\\
\end{array}\right] &\text{ and } c_{2}=\left[\begin{array}{cc}
\phantom{-}1 & 1\\
-1 & 1\\
\phantom{-}0 & 1\\
\end{array}\right]\\
\boldsymbol{e}&=\left[\begin{array}{c}
e_{1}\\
e_{2}\\
\vdots\\
e_{2}
\end{array}\right]
&\text{ where } e_{1}=\left[\begin{array}{c}
1\\
1\\
\end{array}\right] &\text{ and } e_{2}=\left[\begin{array}{c}
1\\
1\\
1\\
\end{array}\right]
\end{align*}

The stability constraint on the filter denominator polynomial is 
\begin{align*}
\boldsymbol{C}\boldsymbol{d}+\left(1-\tau\right)\boldsymbol{e} \ge \boldsymbol{0}
\end{align*}
Suppose the coefficient vector, $\boldsymbol{d}$, is perturbed by 
$\boldsymbol{\delta}$. Then the stability constraint becomes
\begin{align*}
\boldsymbol{C}\boldsymbol{\delta}+\boldsymbol{h} \ge \boldsymbol{0}
\end{align*}
where $\boldsymbol{h}=\boldsymbol{C}\boldsymbol{d}+
\left(1-\tau\right)\boldsymbol{e}$.

\subsection{\label{sec:Limit-cycle-oscillations-second-order-filter-sections}Linear constraints on limit-cycle oscillations in second-order filter sections}
Section~\ref{sec:Limit-cycle-oscillation-digital-filters} states that
second-order section limit-cycle oscillations can be suppressed by adding the
constraint:
\begin{align*}
\left|d_{1}\right|+\left|d_{2}\right|\le 1
\end{align*}
so that, in addition to the stability constraints shown in the previous section:
\begin{align*}
d_{1}-d_{2} &> -1+\tau \\
-d_{1}-d_{2} &> -1+\tau 
\end{align*}
and
\begin{align*}
e_{2}&=\left[\begin{array}{c}
1\\
1\\
1\\
1\\
1\\
\end{array}\right]\\
c_{2}&=\left[\begin{array}{cc}
\phantom{-}1 & \phantom{-}1\\
          -1 & \phantom{-}1\\
\phantom{-}1 &           -1\\
          -1 &           -1\\
\phantom{-}0 & \phantom{-}1\\
\end{array}\right]
\end{align*}

\subsection{\label{sec:Design-IIR-filter-2nd-order-sections-with-SeDuMi}Design of an IIR filter composed of second order sections with \emph{SeDuMi}}
For the IIR filter transfer function
\begin{align*}
H\left(z\right) &= \frac{a\left(z\right)}{d\left(z\right)}
\end{align*}
where
\begin{align*}
a\left(z\right) &= \sum^{n}_{i=0}a_{i}z^{-i}
\end{align*}
and $d\left(z\right)$ is a polynomial of order $r$ expressed as a product of 
second order sections (with one first order section if $r$ is odd)
\begin{align*}
d\left(z\right) &= \begin{cases}
\left(1+d_{0}z^{-1}\right)
\prod^{\frac{r-1}{2}}_{i=1}\left(1+d_{i1}z^{-1}+d_{i2}z^{-2}\right),
&\text{if $r$ odd}\\
\prod^{\frac{r}{2}}_{i=1}\left(1+d_{i1}z^{-1}+d_{i2}z^{-2}\right),&\text{if $r$ even}
\end{cases}
\end{align*}
Define the two filter coefficient vectors as
\begin{align*}
\boldsymbol{a}&=\left[\begin{array}{cccc}
a_{0} & a_{1} & \hdots & a_{n}\\
\end{array}\right]^{\top}
\end{align*}
and
\begin{align*}
\boldsymbol{d}&=\left[\begin{array}{c}
d_{0}\\
\boldsymbol{d}_{1}\\
\vdots\\
\boldsymbol{d}_{L}
\end{array}\right]\\
\boldsymbol{d}_{i}&=\left[\begin{array}{c}
d_{i1}\\
d_{i2}
\end{array}\right],\quad\text{for } 1\le i\le L\\
L&=\begin{cases}
\frac{r-1}{2},&\text{if $r$ odd}\\
\frac{r}{2},&\text{if $r$ even}
\end{cases}
\end{align*}
The frequency response of the filter is 
\begin{align*}
H\left(\omega\right) &=\frac{\boldsymbol{a}^{\top}\boldsymbol{v}\left(\omega\right)}
{d\left(\omega\right)}\\
\end{align*}
where
\begin{align*}
\boldsymbol{v}\left(\omega\right) &= 
\boldsymbol{c}\left(\omega\right) - \imath\boldsymbol{s}\left(\omega\right)\\ 
\boldsymbol{c}\left(\omega\right) &= \left[\begin{array}{ccc}
1 & \hdots & \cos n\omega
\end{array}\right]^{\top}\\
\boldsymbol{s}\left(\omega\right) &= \left[\begin{array}{ccc}
0 & \hdots & -\sin n\omega
\end{array}\right]^{\top}\\
v_{1}\left(\omega\right) &= \cos \omega - \imath \sin\omega \\
\boldsymbol{v}_{2}\left(\omega\right) &= \left[\begin{array}{c}
\cos \omega\\
\cos 2\omega
\end{array}\right]-\imath\left[\begin{array}{c}
\sin \omega\\
\sin 2\omega
\end{array}\right]
\end{align*}
and
\begin{align*}
d\left(\omega\right) &= \begin{cases}
\left[1 + d_{0}v_{1}\left(\omega\right)\right]
\prod^{L}_{i=1}\left[1 + \boldsymbol{d}_{i}^{\top}
\boldsymbol{v}_{2}\left(\omega\right)\right],&\text{if $r$ odd} \\
\prod^{L}_{i=1}\left[1 + \boldsymbol{d}_{i}^{\top}
\boldsymbol{v}_{2}\left(\omega\right)\right],&\text{if $r$ even}
\end{cases}\\
\end{align*}
The gradients of $H\left(\omega\right)$ with respect to the coefficients are
\begin{align*}
\frac{\partial H\left(\omega\right)}{\partial\boldsymbol{a}}&=
\frac{\boldsymbol{v}\left(\omega\right)}{d\left(\omega\right)}\\
\frac{\partial H\left(\omega\right)}{\partial d_{0}}&=
-H\left(\omega\right)\frac{v_{1}\left(\omega\right)}
{1+d_{0}v_{1}\left(\omega\right)}\\
\frac{\partial H\left(\omega\right)}{\partial \boldsymbol{d}_{i}}&=
-H\left(\omega\right)\frac{\boldsymbol{v}_{2}\left(\omega\right)}
{1+\boldsymbol{d}_{i}^{\top}\boldsymbol{v}_{2}\left(\omega\right)}\quad
\text{for $1\le i \le L$}
\end{align*}
In this case we optimise the complex frequency response (gain and delay).
For each of the response frequencies the format for solution by \emph{SeDuMi} is
\begin{align*}
\boldsymbol{A}_{i}^{\top} &= W\left(\omega_{i}\right)\left[\begin{array}{cc}
0 & \Re\nabla_{x}H\left(\omega_{i}\right)^{\top} \\
0 & \Im\nabla_{x}H\left(\omega_{i}\right)^{\top} \\
\end{array}\right] \\
\boldsymbol{b}_{i}^{\top} &= \left[\begin{array}{cc} 
1 & \boldsymbol{0} \end{array}\right] \\
\boldsymbol{c}_{i} &= W\left(\omega_{i}\right)\left[
\begin{array}{cc}
0 & \Re\left[H\left(\omega_{i}\right)-
H_{d}\left(\omega_{i}\right)\right] \\
0 & \Im\left[H\left(\omega_{i}\right)-
H_{d}\left(\omega_{i}\right)\right]
\end{array}\right] \\
d_{i} &= 0
\end{align*}
where $x$ represents the vector of coefficients and the desired low pass
filter frequency response is
\begin{align*}
H_{d}\left(\omega\right)&=\begin{cases}
e^{-\imath\omega t_{d}}&\text{if}\; 0\le\omega\le\omega_{pass}\\
10^{-\frac{dBstop}{20}}&\text{if}\;\omega_{pass}<\omega
\end{cases}
\end{align*}

The Octave script \emph{lowpass2ndOrderCascade\_socp\_test.m} calls the Octave 
function \emph{lowpass2ndOrderCascade\_socp} to implement MMSE SOCP design of
a low pass filter similar to that of Deczky's Example 3:
\begin{small}
\verbatiminput{lowpass2ndOrderCascade_socp_test_spec.m}
\end{small}
The filter coefficients are initialised with the ``IPZS-1'' set. The script
does not enforce the limit-cycle constraints. After SOCP MMSE optimisation,
the numerator and denominator polynomials are respectively:
\begin{small}
\verbatiminput{lowpass2ndOrderCascade_socp_test_a_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{lowpass2ndOrderCascade_socp_test_d_coef.m}
\end{small}
The overall frequency response of the MMSE SOCP design is shown in
Figure~\ref{fig:Deczky-Example-3-2ndOrder-MMSE-SOCP-x1} with pass-band details
shown in Figure~\ref{fig:Deczky-Example-3-2ndOrder-MMSE-SOCP-x1-passband} and 
pole-zero plot shown in
Figure~\ref{fig:Deczky-Example-3-2ndOrder-MMSE-SOCP-x1-pz}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{lowpass2ndOrderCascade_socp_test_x1}}
\caption{Deczky Example 3, response with 2nd order sections and MMSE SOCP
  optimisation.}
\label{fig:Deczky-Example-3-2ndOrder-MMSE-SOCP-x1}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{lowpass2ndOrderCascade_socp_test_x1pass}}
\caption{Deczky Example 3, passband response with 2nd order sections and MMSE
  SOCP optimisation.}
\label{fig:Deczky-Example-3-2ndOrder-MMSE-SOCP-x1-passband}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{lowpass2ndOrderCascade_socp_test_x1pz}}
\caption{Deczky Example 3, pole-zero plot with 2nd order sections and MMSE SOCP
  optimisation.}
\label{fig:Deczky-Example-3-2ndOrder-MMSE-SOCP-x1-pz}
\end{figure}

Additionally, the Octave function \emph{lowpass2ndOrderCascade\_socp.m} 
optimises only the squared-magnitude response and ignores the group delay 
response. The resulting overall magnitude and delay responses are shown in 
Figure~\ref{fig:Deczky-Example-3-2ndOrder-MMSE-SOCP-x1sqm}, the passband 
responses are shown in 
Figure~\ref{fig:Deczky-Example-3-2ndOrder-MMSE-SOCP-x1sqmpass} and the pole-zero 
plot is shown in Figure~\ref{fig:Deczky-Example-3-2ndOrder-MMSE-SOCP-x1sqm-pz}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{lowpass2ndOrderCascade_socp_test_x1sqm}}
\caption{Deczky Example 3, response with 2nd order sections and MMSE SOCP
  optimisation of the squared-magnitude response.}
\label{fig:Deczky-Example-3-2ndOrder-MMSE-SOCP-x1sqm}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{lowpass2ndOrderCascade_socp_test_x1sqmpass}}
\caption{Deczky Example 3, passband response with 2nd order sections and MMSE
  SOCP optimisation of the squared-magnitude response.}
\label{fig:Deczky-Example-3-2ndOrder-MMSE-SOCP-x1sqmpass}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{lowpass2ndOrderCascade_socp_test_x1sqmpz}}
\caption{Deczky Example 3, pole-zero plot with 2nd order sections and MMSE SOCP
  optimisation of the squared-magnitude response.}
\label{fig:Deczky-Example-3-2ndOrder-MMSE-SOCP-x1sqm-pz}
\end{figure}
\clearpage
\subsection{Some notes on the design of an IIR filter composed of second order sections with \emph{SeDuMi}}
Some notes on SOCP optimisation of a filter composed of a cascade of second
order sections with \emph{SeDuMi}:
\begin{itemize}
\item{when running SeDuMi under Octave with the default options, SeDuMi 
  sometimes fails due to numerical problems. This indicates that the 
  optimisation problem is not feasible with the current constraints.}
\item{a better response is obtained by using a single constraint
  on the summed response error (MMSE) rather than a large number of separate
  frequency response constraints.}
\item{the response is sensitive to the stop band weight.}
\item{the passband response is improved if the desired stop band amplitude
  response is set to a small non-zero value.}
\item{I did not find a useful filter when attempting to optimise the complex 
  response in the pass band simultaneously with the squared-magnitude response
  in the stop band.}
\item{a second order section may have complex conjugate roots or two real roots.
  In the gain-zero-pole format the total number of real and complex conjugate
  roots is specified in advance.}
\end{itemize}
\clearpage
\section{Design of an IIR filter as the sum of two all-pass filters}
In this section I consider the design of a low-pass IIR filter that is the sum
of two parallel all-pass filters, $A\left(z\right)$ and $B\left(z\right)$
\begin{align}
H\left(z\right) &= \frac{A\left(z\right) + B\left(z\right)}{2}
\label{eqn:Parallel-allpass-transfer-function}  
\end{align}
\emph{Vaidyanathan et al.}~\cite{VaidyanathanMitraNuevo_LowSensitivityIIRDigitalFilters}
demonstrate that the ``classical'' odd-order lowpass digital filter 
approximations can be implemented as the sum of two allpass filters. The 
resulting filters have low sensitivity to coefficient quantisation. 
\subsection{\label{sec:Parallel-Allpass-2nd-Order-Sections}Design of an IIR filter as the sum of two all-pass filters each composed of second-order sections}
Following \emph{Lu} and 
\emph{Hinamoto}~\cite{LuHinamoto_IIRRobustStabilityQuadraticProgramming}, 
the transfer functions of the $A\left(z\right)$ and $B\left(z\right)$ filters 
are expressed as the product of second-order sections. As shown in 
Section~\ref{sec:Stability-of-second-order-filter-sections}, the second-order
filter sections permit a simple linear stability constraint on the coefficients
of each section.

Assume that the order of $H\left(z\right)$ is odd and that
that
\begin{align*}
a\left(z\right) &=
\left(1+a_{0}z^{-1}\right)\prod_{k=1}^{\frac{m-1}{2}}1+a_{k1}z^{-1}+a_{k2}z^{-2}\\
A\left(z\right) &=z^{-m}\frac{a\left(z^{-1}\right)}{a\left(z\right)}
\end{align*}
and
\begin{align*}
b\left(z\right) &=\prod_{k=1}^{\frac{n}{2}}1+b_{k1}z^{-1}+b_{k2}z^{-2}\\
B\left(z\right) &=z^{-n}\frac{b\left(z^{-1}\right)}{b\left(z\right)}
\end{align*}
Here the coefficients $a_{k1}$ etc. are real, $m$ is odd, $n$ is even and the
order of $H$ is $p=n+m$. In the following, references to $A\left(z\right)$ 
apply to $B\left(z\right)$ as appropriate. The frequency response of
$A\left(z\right)$ is:
\begin{align*}
A\left(\omega\right) &=e^{-\imath m\omega}
\frac{a\left(-\omega\right)}{a\left(\omega\right)}\\
a\left(\omega\right) &=\left(1+a_{0}v_{1}\right)
\prod_{k=1}^{\frac{m-1}{2}}1+\boldsymbol{v}_{2}\boldsymbol{a}_{k}
\end{align*}
where $\boldsymbol{a}_{k}=\left[\begin{array}{c}
a_{k1}\\
a_{k2}
\end{array}\right]$, $v_{1}=\cos\omega-\imath\sin\omega$, 
$\boldsymbol{v}_{2}=\left[\begin{array}{cc}
\cos\omega & \cos 2 \omega
\end{array}\right]-\imath\left[\begin{array}{cc}
\sin\omega & \sin 2 \omega
\end{array}\right]$ and $A\left(\omega\right)$ is understood to mean 
$A\left(e^{\imath\omega}\right)$.

The gradients of $A\left(z\right)$ with respect to its coefficients $a_{0}$, 
$a_{k1}$ and $a_{k2}$ are
\begin{align*}
\frac{\partial A\left(z\right)}{\partial a_{0}} &= A\left(z\right)
\frac{z-z^{-1}}{1+a_{0}^{2}+a_{0}\left(z+z^{-1}\right)}\\
\frac{ \partial A\left(z\right)}{\partial a_{k1}} &= A\left(z\right)
\frac{\left(z-z^{-1}\right)\left(1-a_{k2}\right)}
{1+a_{k1}^{2}+a_{k2}^{2}+a_{k1}\left(1+a_{k2}\right)\left(z+z^{-1}\right)+
a_{i2}\left(z^{2}+z^{-2}\right)}\\
\frac{\partial A\left(z\right)}{\partial a_{k2}} &= A\left(z\right)
\frac{\left(z-z^{-1}\right)\left(a_{k1}+z+z^{-1}\right)}
{1+a_{k1}^{2}+a_{k2}^{2}+a_{k1}\left(1+a_{k2}\right)\left(z+z^{-1}\right)+
a_{k2}\left(z^{2}+z^{-2}\right)}\\
\end{align*}
The Octave function \emph{allpass2ndOrderCascade.m} returns the complex
frequency response and gradient of an allpass filter consisting of a cascade of
2nd-order allpass sections (with a single additional first order section if the
filter order is odd). 

Similarly to Section~\ref{sec:Deczky3-IIR-filter-gain-zero-pole-with-SeDuMi},
the parallel allpass filter design problem can be expressed in SOCP form as
\begin{align*}
\textbf{minimise}  \quad&\epsilon ,\;\beta\\
\textbf{subject to}\quad&
\|W\left(\omega_{i}\right)\left[\begin{array}{c}
\Re\nabla 
H\left(\boldsymbol{a}_{k},\boldsymbol{b}_{k},\omega_{i}\right)^{\top}\\
\Im\nabla 
H\left(\boldsymbol{a}_{k},\boldsymbol{b}_{k},\omega_{i}\right)^{\top}
\end{array}\right]\;\boldsymbol{\delta} + 
W\left(\omega_{i}\right)\left[\begin{array}{c}
\Re H\left(\boldsymbol{a}_{k},\boldsymbol{b}_{k},\omega_{i}\right)-
\Re H_{d}\left(\omega_{i}\right)\\
\Im H\left(\boldsymbol{a}_{k},\boldsymbol{b}_{k},\omega_{i}\right)-
\Im H_{d}\left(\omega_{i}\right)
\end{array}\right]\|\le\epsilon\nonumber\\
&\|\boldsymbol{\delta}\|\le\beta
\nonumber\\
&\boldsymbol{C}\boldsymbol{\delta}+\boldsymbol{h} \ge \boldsymbol{0}\nonumber\\
\textbf{where}\quad&
\boldsymbol{\delta}=\left[\begin{array}{c}
\boldsymbol{a} - \boldsymbol{a}_{k}\\ 
\boldsymbol{b} - \boldsymbol{b}_{k}
\end{array}\right]\\
&H\left(\boldsymbol{a}_{k},\boldsymbol{b}_{k},\omega_{i}\right) =
0.5\left[A\left(\boldsymbol{a}_{k},\omega_{i}\right) +
B\left(\boldsymbol{b}_{k},\omega_{i}\right)\right]\\
&\nabla H\left(\boldsymbol{a}_{k},\boldsymbol{b}_{k},\omega_{i}\right)=
0.5\left[\nabla_{a} A\left(\boldsymbol{a}_{k},\omega_{i}\right)+
\nabla_{b} B\left(\boldsymbol{b}_{k},\omega_{i}\right)\right]
\end{align*}
A quadratic constraint on the squared-magnitude response at the stop-band
frequencies is
\begin{align*}
\|\nabla H^{2}\left( \boldsymbol{a}_{k},\boldsymbol{b}_{k},\omega_{i}\right)^{\top}
\boldsymbol{\delta} + 
H^{2}\left( \boldsymbol{a}_{k},\boldsymbol{b}_{k}, \omega_{i} \right) \| & 
\le \left|H_{d}\left(\omega_{i}\right)\right|^{2}
\end{align*}
where
\begin{align*}
H^{2}\left(\boldsymbol{a}_{k},\boldsymbol{b}_{k},\omega_{i}\right) =&
\;\|H\left(\boldsymbol{a}_{k},\boldsymbol{b}_{k},\omega_{i}\right) \|^{2} \\
=&\; 0.25\left[
\Re A\left(\boldsymbol{a}_{k},\omega_{i}\right)+
\Re B\left(\boldsymbol{b}_{k},\omega_{i}\right)\right]^{2}+
0.25\left[
\Im A\left(\boldsymbol{a}_{k},\omega_{i}\right)+
\Im B\left(\boldsymbol{b}_{k},\omega_{i}\right)\right]^{2}\\
\begin{split}
\nabla H^{2}\left(\boldsymbol{a}_{k},\boldsymbol{b}_{k},\omega_{i}\right)=&
\;0.5\left[
\Re A\left(\boldsymbol{a}_{k},\omega_{i}\right)+
\Re B\left(\boldsymbol{b}_{k},\omega_{i}\right)\right]
\left[
\Re\nabla_{a}A\left(\boldsymbol{a}_{k},\omega_{i}\right)+
\Re\nabla_{b}B\left(\boldsymbol{b}_{k},\omega_{i}\right)\right]
+ \hdots\\
&\;0.5\left[
\Im A\left(\boldsymbol{a}_{k},\omega_{i}\right)+
\Im B\left(\boldsymbol{b}_{k},\omega_{i}\right)\right]
\left[
\Im\nabla_{a}A\left(\boldsymbol{a}_{k},\omega_{i}\right)+
\Im\nabla_{b}B\left(\boldsymbol{b}_{k},\omega_{i}\right)\right]
\end{split}
\end{align*}

\subsubsection{Design of an IIR filter as the sum of two 2nd order cascade all-pass filters with MMSE optimisation of the complex response}
The Octave script \emph{allpass2ndOrderCascade\_socp\_test.m} calls the
Octave function \emph{allpass2ndOrderCascade\_socp} to design a low-pass
filter composed of two parallel all-pass filters with MMSE optimisation of 
the complex response of the filter. The filter specification is similar to 
Deczky's Example 3. The desired low pass filter frequency response is:
\begin{align*}
H_{d}\left(\omega\right)&=\begin{cases}
e^{-\imath\omega t_{d}}&\text{if}\; 0\le\omega\le\omega_{pass}\\
0&\text{if}\;\omega_{pass}<\omega
\end{cases}
\end{align*}
and the filter specification is
\begin{small}
\verbatiminput{allpass2ndOrderCascade_socp_test_spec.m}
\end{small}
The initial allpass filters were designed by the Octave script 
\emph{tarczynski\_allpass2ndOrderCascade\_test.m} with $flat\_delay=true$. 
The initial response is shown in 
Figure~\ref{fig:Parallel-2nd-order-cascade-allpass-initial-response}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass2ndOrderCascade_socp_test_ab0}}
\caption{Parallel 2nd order cascaded allpass filters, initial response found
  with the WISE barrier function.}
\label{fig:Parallel-2nd-order-cascade-allpass-initial-response}
\end{figure}

After optimisation with the \emph{SeDuMi} SOCP solver the response is shown in
Figure~\ref{fig:Parallel-2nd-order-cascade-allpass-filter-SOCP-response} with
passband detail shown in
Figure~\ref{fig:Parallel-2nd-order-cascade-allpass-filter-SOCP-passband-response}
and pole-zero plot shown in
Figure~\ref{fig:Parallel-2nd-order-cascade-allpass-filter-SOCP-pz}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass2ndOrderCascade_socp_test_ab1}}
\caption{Parallel 2nd order cascade allpass filters, response after SOCP
  optimisation.}
\label{fig:Parallel-2nd-order-cascade-allpass-filter-SOCP-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass2ndOrderCascade_socp_test_ab1pass}}
\caption{Parallel 2nd order cascade allpass filters, pass-band response after
  SOCP optimisation.}
\label{fig:Parallel-2nd-order-cascade-allpass-filter-SOCP-passband-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass2ndOrderCascade_socp_test_ab1pz}}
\caption{Parallel 2nd order cascade allpass filters, pole-zero plot after SOCP
  optimisation.}
\label{fig:Parallel-2nd-order-cascade-allpass-filter-SOCP-pz}
\end{figure}
The second-order section coefficients are
\begin{small}
\verbatiminput{allpass2ndOrderCascade_socp_test_a1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{allpass2ndOrderCascade_socp_test_b1_coef.m}
\end{small}
The corresponding allpass filter denominator polynomials are
\begin{small}
\verbatiminput{allpass2ndOrderCascade_socp_test_Da1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{allpass2ndOrderCascade_socp_test_Db1_coef.m}
\end{small}

\subsubsection{Design of an IIR filter as the sum of two 2nd order cascade all-pass filters with MMSE optimisation of the squared-magnitude response}
The Octave script 
\emph{allpass2ndOrderCascade\_socp\_sqmag\_test.m} calls the Octave 
function \emph{allpass2ndOrderCascade\_socp} to design a low-pass filter
composed of two parallel all-pass filters with MMSE optimisation of the
squared-magnitude response of the filter. The filter specification is
\begin{small}
\verbatiminput{allpass2ndOrderCascade_socp_sqmag_test_spec.m}
\end{small}
The initial allpass filters were designed by the Octave script 
\emph{tarczynski\_allpass2ndOrderCascade\_test.m} with $flat\_delay=false$.
The initial response is shown in 
Figure~\ref{fig:Parallel-2nd-order-cascade-allpass-sqmag-initial-response}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass2ndOrderCascade_socp_sqmag_test_ab0}}
\caption{Parallel 2nd order allpass cascade filters (squared magnitude), initial
  response found with the WISE barrier function.}
\label{fig:Parallel-2nd-order-cascade-allpass-sqmag-initial-response}
\end{figure}

After optimisation with the \emph{SeDuMi} SOCP solver the response is shown in
Figure~\ref{fig:Parallel-2nd-order-cascade-allpass-sqmag-SOCP-response} and
the pole-zero plot is shown in
Figure~\ref{fig:Parallel-2nd-order-cascade-allpass-sqmag-SOCP-pz}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass2ndOrderCascade_socp_sqmag_test_ab1dual}}
\caption{Parallel 2nd order cascade allpass filters (squared magnitude),
  response after SOCP optimisation.}
\label{fig:Parallel-2nd-order-cascade-allpass-sqmag-SOCP-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass2ndOrderCascade_socp_sqmag_test_ab1pz}}
\caption{Parallel 2nd order cascade allpass filters (squared magnitude),
  pole-zero plot after SOCP optimisation.}
\label{fig:Parallel-2nd-order-cascade-allpass-sqmag-SOCP-pz}
\end{figure}
The second-order section coefficients are
\begin{small}
\verbatiminput{allpass2ndOrderCascade_socp_sqmag_test_a1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{allpass2ndOrderCascade_socp_sqmag_test_b1_coef.m}
\end{small}
The corresponding allpass filter denominator polynomials are
\begin{small}
\verbatiminput{allpass2ndOrderCascade_socp_sqmag_test_Da1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{allpass2ndOrderCascade_socp_sqmag_test_Db1_coef.m}
\end{small}

For comparison, Figures~\ref{fig:Parallel-2nd-order-allpass-elliptic-filter}
and~\ref{fig:Parallel-2nd-order-allpass-elliptic-filter-pz} show the response and
pole-zero plot of an elliptic filter designed with a similar specification:
\begin{small}
\begin{verbatim}
ma=5,mb=6,fap=0.15,dBap=0.02,fas=0.17,dBas=84
[Nellip,Dellip]=ellip(ma+mb,dBap,dBas,fap*2);
\end{verbatim}
\end{small}

The corresponding filter polynomials are:
\begin{small}
\verbatiminput{allpass2ndOrderCascade_socp_sqmag_test_Nellip_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{allpass2ndOrderCascade_socp_sqmag_test_Dellip_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass2ndOrderCascade_socp_sqmag_test_ellipdual}}
\caption{Response of an elliptic filter with fap=0.15, dBap=0.02, dBas=84.}
\label{fig:Parallel-2nd-order-allpass-elliptic-filter}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass2ndOrderCascade_socp_sqmag_test_ellippz}}
\caption{Pole-zero plot of an elliptic filter with fap=0.15, dBap=0.02, dBas=84.}
\label{fig:Parallel-2nd-order-allpass-elliptic-filter-pz}
\end{figure}
\clearpage
\subsection{\label{sec:Parallel-Allpass-2nd-Order-Sections-Delay}Design of an IIR filter as the sum of an all-pass filter composed of second-order sections and a delay}
The Octave script \emph{allpass2ndOrderCascadeDelay\_socp\_test.m} designs a 
lowpass filter consisting of an allpass filter in parallel with a pure delay. 
The allpass filter is composed of a cascade of second-order sections, as 
described in Section~\ref{sec:Parallel-Allpass-2nd-Order-Sections}. The filter
specification is:
\begin{small}
\verbatiminput{allpass2ndOrderCascadeDelay_socp_test_spec.m}
\end{small}
This script produces two designs. The first attempts to optimise the filter for
flat group-delay in the passband and the second ignores the phase response
and optimises the weighted squared-magnitude response. The relative weights in
each case are shown in the specification. The initial allpass filter was 
designed by the Octave script \emph{tarczynski\_allpass\_phase\_shift\_test.m} to
have a phase shift of $0$ radians in the pass band and $\pi$ radians in the stop
band. The phase response of the initial allpass filter is shown in 
Figure~\ref{fig:Allpass-2nd-order-cascade-delay-initial-phase-response}. The
phase has been adjusted by $\omega{}D$, where $D$ is the number of samples
in the pure delay branch.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass2ndOrderCascadeDelay_socp_test_a0phase}}
\caption{Parallel all-pass 2nd order cascade filter and delay, phase response
  of the initial all-pass filter adjusted for the group delay of the fixed
  delay branch.}
\label{fig:Allpass-2nd-order-cascade-delay-initial-phase-response}
\end{figure}

The allpass filter polynomial found for the optimised delay case is:
\begin{small}
\verbatiminput{allpass2ndOrderCascadeDelay_socp_test_Da1_coef.m}
\end{small}
with the overall filter response shown in 
Figure~\ref{fig:Allpass-2nd-order-cascade-delay-flat-delay-response}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass2ndOrderCascadeDelay_socp_test_a1}}
\caption{Parallel all-pass 2nd order cascade filter and delay, overall response
  optimised for flat pass band group delay.}
\label{fig:Allpass-2nd-order-cascade-delay-flat-delay-response}
\end{figure}

The allpass filter polynomial found for the optimised squared-magnitude case is:
\begin{small}
\verbatiminput{allpass2ndOrderCascadeDelay_socp_test_Da1sqm_coef.m}
\end{small}
with the overall filter response shown in 
Figure~\ref{fig:Allpass-2nd-order-cascade-delay-squared-magnitude-response}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{allpass2ndOrderCascadeDelay_socp_test_a1sqm}}
\caption{Parallel all-pass 2nd order cascade filter and delay, overall response
  optimised for squared-magnitude.}
\label{fig:Allpass-2nd-order-cascade-delay-squared-magnitude-response}
\end{figure}
At the filter band edges the change in phase of the allpass branch produces a 
corresponding transient in the group delay response.
\clearpage
\subsection{\label{sec:Design-IIR-filter-sum-all-pass-filters-pole-zero}Design of an IIR filter as the sum of two all-pass filters each represented in pole-zero form}
Rewriting Equation~\ref{eqn:Parallel-allpass-transfer-function} in terms of
the phase responses of the component all-pass filters gives
\begin{align*}
H\left(z\right)=\frac{e^{\imath\phi_{1}\left(z\right)}+e^{\imath\phi_{2}\left(z\right)}}{2}
\end{align*}
where $\phi_{1}\left(z\right)=\phi_{A_{1}}\left(z\right)$ and 
$\phi_{2}\left(z\right)=\phi_{A_{2}}\left(z\right)$. The squared magnitude
response and phase of the frequency response, $H\left(\omega\right)$, are:
\begin{align*}
\left|H\left(\omega\right)\right|^{2} &=
\frac{1+\cos\left(\phi_{1}\left(\omega\right)-
                  \phi_{2}\left(\omega\right)\right)}{2}\\
\phi_{H}\left(\omega\right) &=
\frac{\phi_{1}\left(\omega\right)+\phi_{2}\left(\omega\right)}{2}
\end{align*}
The group delay response is
\begin{align*}
T\left(\omega\right) &= 
-\frac{1}{2}\left[
\frac{\partial\phi_{1}\left(\omega\right)}{\partial\omega}+
\frac{\partial\phi_{2}\left(\omega\right)}{\partial\omega}
\right]
\end{align*}
The partial derivatives of the squared-magnitude, phase and group delay with
respect to the real and complex conjugate pole radiuses of filters $A_{1}$ and
$A_{2}$ (for convenience all represented here by $\boldsymbol{r}$), are:
\begin{align*}
\frac{\partial \left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{r}} &=
  -\frac{1}{2}\sin\left(\phi_{1}\left(\omega\right)-
                        \phi_{2}\left(\omega\right)\right)\left\{
  \frac{\partial\phi_{1}\left(\omega\right)}{\partial\boldsymbol{r}}-
  \frac{\partial\phi_{2}\left(\omega\right)}{\partial\boldsymbol{r}}\right\} \\
\frac{\partial \phi_{H}\left(\omega\right)}{\partial\boldsymbol{r}} &=
  \frac{1}{2}\left\{
  \frac{\partial\phi_{1}\left(\omega\right)}{\partial\boldsymbol{r}}+
  \frac{\partial\phi_{2}\left(\omega\right)}{\partial\boldsymbol{r}}\right\}\\
\frac{\partial T\left(\omega\right)}{\partial\boldsymbol{r}} &=
-\frac{1}{2}\left\{\frac{\partial^{2}\phi_{1}\left(\omega\right)}
                        {\partial\boldsymbol{r}\partial\omega} +
                   \frac{\partial^{2}\phi_{2}\left(\omega\right)}
                        {\partial\boldsymbol{r}\partial\omega}\right\}
\end{align*}
The partial derivatives with respect to the filter pole angles, $\theta$, are
similar. Appendix~\ref{app:Allpass-filter-phase-response} derives the phase
response of an all-pass filter and the partial derivatives of the phase
response with respect to the real and complex conjugate pole locations. The
Octave function \emph{allpassP} calculates the phase response and partial
derivatives of the phase response of an all-pass IIR filter. The
Octave function \emph{allpassT} calculates the group delay response and partial
derivatives of the group delay response of an all-pass IIR filter.
The Octave function \emph{parallel\_allpassAsq} calls \emph{allpassP} to 
calculate the squared-magnitude and partial derivatives of the squared
magnitude response of the parallel combination of two allpass IIR filters 
and is exercised by the test script \emph{parallel\_allpassAsq\_test.m}.
Similarly, the Octave function \emph{parallel\_allpassP} calls \emph{allpassP}
to calculate the phase and partial derivatives of the phase response of the
parallel combination of two all-pass IIR filters and is exercised by the test
script \emph{parallel\_allpassP\_test.m}. Finally, the Octave function 
\emph{parallel\_allpassT} calls \emph{allpassT} to calculate the group delay
and partial derivatives of the group delay response of the parallel combination
of two all-pass IIR filters and is exercised by the test script 
\emph{parallel\_allpassT\_test.m}.

\subsubsection{\label{sec:Design-IIR-filter-sum-all-pass-filters-pole-zero-no-constraints-on-group-delay}Design of an IIR filter as the sum of two all-pass filters each represented in pole-zero form with no constraints on the group delay}
The Octave script \emph{parallel\_allpass\_socp\_slb\_test.m} calls the Octave
function \emph{parallel\_allpass\_slb} to perform the PCLS design of a low-pass
filter composed of two parallel all-pass filters in terms of the all-pass filter
pole locations. This script does not constrain the group delay of the filter. 
The PCLS algorithm of \emph{Selesnick}, \emph{Lang} and 
\emph{Burrus} was reviewed in Section~\ref{sub:Choice-of-Active-Constraints}. At
each iteration of the PCLS optimisation the Octave function 
\emph{parallel\_allpass\_socp\_mmse} optimises the filter response subject to 
the current constraints. The filter specification is
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_test_spec.m}
\end{small}
Compare this filter with the elliptic filter shown in
Figure~\ref{fig:Parallel-2nd-order-allpass-elliptic-filter}. The response
of that filter is slightly wider than the specification. The response of the
filter shown here is intended to match that slight extra width in the transition
band.

The initial parallel all-pass filters were designed by the Octave script 
\emph{tarczynski\_parallel\_allpass\_test.m} (with $flat\_delay=false$), 
using the \emph{WISE} method described in 
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}. The response
of the initial filter is shown in
Figure~\ref{fig:Parallel-allpass-filter-initial-response}.
The pole-zero plot of the initial filter is shown in
Figure~\ref{fig:Parallel-allpass-filter-initial-response-pz}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_test_ab0}}
\caption{Parallel all-pass filters, initial response found with the WISE barrier
  function.}
\label{fig:Parallel-allpass-filter-initial-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_test_ab0pz}}
\caption{Parallel all-pass filters, pole zero plot of the initial response found
  with the WISE barrier function.}
\label{fig:Parallel-allpass-filter-initial-response-pz}
\end{figure}

The script first runs an MMSE pass on the initial filter. The
squared-amplitude error weighting function increases linearly near the band
edges. The resulting MMSE optimised response is shown in
Figure~\ref{fig:Parallel-allpass-filter-MMSE-SOCP-response}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_test_abmdual}}
\caption{Parallel all-pass filters, response found with MMSE SOCP optimisation.}
\label{fig:Parallel-allpass-filter-MMSE-SOCP-response}
\end{figure}

The PCLS pass does not attempt to minimise the stop-band response minimum
mean-squared squared-amplitude error. Instead the stop-band squared-amplitude
response is controlled by the PCLS constraints. In this case, the desired
stop-band attenuation is more than $80dB$ and the filter response is
scaled to make the stop-band squared-amplitude greater than the machine
precision. The default SeDuMi \emph{pars.eps} is of the same order as the
desired stop-band attenuation and must be reduced to avoid the PCLS algorithm
cycling between solutions. The denominator polynomials of the two all-pass
filters are: 
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_test_Da1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_test_Db1_coef.m}
\end{small}
The corresponding filter numerator and denominator polynomials of the overall
filter are:
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_test_Nab1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_test_Dab1_coef.m}
\end{small}

The PCLS filter response is shown in
Figure~\ref{fig:Parallel-allpass-filter-PCLS-SOCP-response} and the pole-zero
plot is shown in Figure~\ref{fig:Parallel-allpass-filter-PCLS-SOCP-pz}. The
pole-zero plots of the allpass filters are shown in
Figure~\ref{fig:Parallel-allpass-filter-PCLS-SOCP-a1pz} and
Figure~\ref{fig:Parallel-allpass-filter-PCLS-SOCP-b1pz}.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_test_ab1dual}}
\caption{Parallel all-pass filters, response after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-filter-PCLS-SOCP-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_test_ab1pz}}
\caption{Parallel all-pass filters, pole-zero plot after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-filter-PCLS-SOCP-pz}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_test_a1pz}}
\caption{Parallel all-pass filters, pole-zero plot of the A allpass filter
  branch after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-filter-PCLS-SOCP-a1pz}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_test_b1pz}}
\caption{Parallel all-pass filters, pole-zero plot of the B allpass filter
  branch after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-filter-PCLS-SOCP-b1pz}
\end{figure}
\clearpage
\subsubsection{\label{sec:Design-IIR-filter-sum-all-pass-filters-pole-zero-constrained-group-delay}Design of an IIR filter as the sum of two all-pass filters each represented in pole-zero form with constraints on the group delay}
\paragraph{Design of an IIR lowpass filter with a flat passband delay as the sum of two allpass filters}
The Octave script \emph{parallel\_allpass\_socp\_slb\_flat\_delay\_test.m} calls 
the Octave function \emph{parallel\_allpass\_slb} to perform the PCLS design of
a low-pass filter composed of two parallel all-pass filters in terms of the 
all-pass filter pole locations. This script does constrain the group delay of 
the filter. The PCLS algorithm of \emph{Selesnick}, \emph{Lang} and 
\emph{Burrus} was reviewed in Section~\ref{sub:Choice-of-Active-Constraints}. At
each iteration of the PCLS optimisation the Octave function 
\emph{parallel\_allpass\_socp\_mmse} optimises the filter response subject to 
the current constraints. The filter specification is
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_flat_delay_test_spec.m}
\end{small}

The initial parallel allpass filters were designed by the Octave script 
\emph{tarczynski\_parallel\_allpass\_test.m} (with $flat\_delay=true$), 
using the \emph{WISE} method described in 
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}. The response
of the initial filter is shown in
Figure~\ref{fig:Parallel-allpass-filter-flat-delay-initial-response}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_flat_delay_test_ab0}}
\caption{Parallel all-pass filters with flat pass-band delay, initial response
  found with the WISE barrier function.}
\label{fig:Parallel-allpass-filter-flat-delay-initial-response}
\end{figure}
Figure~\ref{fig:Parallel-allpass-filter-flat-delay-PCLS-SOCP-response}
shows the PCLS optimised filter response.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_flat_delay_test_ab1}}
\caption{Parallel all-pass filters with flat pass-band delay, response after
  PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-filter-flat-delay-PCLS-SOCP-response}
\end{figure}
Figure~\ref{fig:Parallel-allpass-filter-flat-delay-PCLS-SOCP-pass-band-response}.
shows the PCLS optimised filter response in the pass-band.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_flat_delay_test_ab1pass}}
\caption{Parallel all-pass filters with flat pass-band delay, pass-band response
  after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-filter-flat-delay-PCLS-SOCP-pass-band-response}
\end{figure}
Figure~\ref{fig:Parallel-allpass-filter-flat-delay-PCLS-SOCP-phase-response}
shows the phase responses of the two all-pass fiters.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_flat_delay_test_ab1phase}}
\caption{Parallel all-pass filters with flat pass-band delay, phase responses
  after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-filter-flat-delay-PCLS-SOCP-phase-response}
\end{figure}
Figures~\ref{fig:Parallel-allpass-filter-flat-delay-PCLS-SOCP-a1pz}
and~\ref{fig:Parallel-allpass-filter-flat-delay-PCLS-SOCP-b1pz} show the
pole-zero plots of the branch allpass filters.
Figure~\ref{fig:Parallel-allpass-filter-flat-delay-PCLS-SOCP-ab1pz} shows
the pole-zero plot of the overall filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_flat_delay_test_a1pz}}
\caption{Parallel all-pass filters with flat pass-band delay, pole-zero plot of
  the A allpass filter branch after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-filter-flat-delay-PCLS-SOCP-a1pz}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_flat_delay_test_b1pz}}
\caption{Parallel all-pass filters with flat pass-band delay, pole-zero plot of
  the B allpass filter branch after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-filter-flat-delay-PCLS-SOCP-b1pz}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_flat_delay_test_ab1pz}}
\caption{Parallel all-pass filters with flat pass-band delay, pole-zero plot of
  the overall filter after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-filter-flat-delay-PCLS-SOCP-ab1pz}
\end{figure}

The denominator polynomials of the two all-pass filters are
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_flat_delay_test_Da1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_flat_delay_test_Db1_coef.m}
\end{small}
The corresponding filter numerator and denominator polynomials of the overall
filter are
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_flat_delay_test_Nab1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_flat_delay_test_Dab1_coef.m}
\end{small}

The overall numerator polynomial is symmetric to within the precision of the
calculations and has pairs of reciprocal zeros that do not lie on the unit 
circle. This should be compared with the pole-zero plot resulting when the
delay is not constrained, Figure~\ref{fig:Parallel-allpass-filter-PCLS-SOCP-pz},
and the pole-zero plot for the elliptic filter example, 
Figure~\ref{fig:Parallel-2nd-order-allpass-elliptic-filter-pz}.

\paragraph{Design of an IIR low-pass differentiator filter as the sum of two all-pass filters} 
The Octave script \newline
\emph{parallel\_allpass\_socp\_slb\_lowpass\_differentiator\_test.m}
uses the SeDuMi SOCP solver to design a low-pass differentiator filter
consisting of $1-z^{-1}$ followed by a correction filter, implemented as the sum
of two all-pass
filters\footnote{Section~\ref{sec:iir-sqp-slb-lowpass-differentiator-alt}
  shows the design of a low-pass differentiator filter with coefficients given
  in gain-pole-zero form. The  numerator polynomial of the filter designed in
  Section~\ref{sec:iir-sqp-slb-lowpass-differentiator-alt} is not symmetric so
  that filter cannot be decomposed into allpass filters with the spectral
  factorisation method described in
  Appendix~\ref{app:Low-passband-sensitivity-IIR-digital-filters}.}.
The script calls the Octave function \emph{parallel\_allpass\_slb} to perform
the PCLS design of the filter in terms of the all-pass filter pole locations
with constraints on the filter group-delay and phase.

The parallel all-pass low-pass differentiator filter specification is:
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_lowpass_differentiator_test_spec.m}
\end{small}

The Octave script
\emph{tarczynski\_parallel\_allpass\_lowpass\_differentiator\_test.m}
designs an initial low-pass differentiator correction filter with the
\emph{WISE} method described in
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}.
Figure~\ref{fig:Parallel-allpass-lowpass-differentiator-filter-initial-response}.
shows the initial low-pass differentiator filter response.
The phase response shown is adjusted for the nominal delay.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_lowpass_differentiator_test_ab0}}
\caption{Initial response of the low-pass differentiator filter implemented as
  the sum of two all-pass filters. The phase response shown is
  adjusted for the nominal delay.} 
\label{fig:Parallel-allpass-lowpass-differentiator-filter-initial-response}
\end{figure}

After PCLS optimisation, the denominator polynomials of the all-pass filters in
the low-pass differentiator correction filter are:
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_lowpass_differentiator_test_Da1_coef.m}
\verbatiminput{parallel_allpass_socp_slb_lowpass_differentiator_test_Db1_coef.m}
\end{small}

The corresponding numerator and denominator polynomials of the correction
filter are:
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_lowpass_differentiator_test_Nab1_coef.m}
\verbatiminput{parallel_allpass_socp_slb_lowpass_differentiator_test_Dab1_coef.m}
\end{small}

Figure~\ref{fig:Parallel-allpass-lowpass-differentiator-filter-PCLS-error}.
shows the response error of the low-pass differentiator filter after PCLS
optimisation. The phase response shown is adjusted for the nominal delay.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_lowpass_differentiator_test_ab1error}}
\caption{Response error of the low-pass differentiator filter implemented as the
  sum of two all-pass filters after PCLS SOCP optimisation. The phase response
  shown is adjusted for the nominal delay.} 
\label{fig:Parallel-allpass-lowpass-differentiator-filter-PCLS-error}
\end{figure}

Figure~\ref{fig:Parallel-allpass-lowpass-differentiator-filter-PCLS-phase} shows
the phase responses of the parallel all-pass correction filters (including
a series $1-z^{-1}$) after PCLS SOCP optimisation.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_lowpass_differentiator_test_ab1phase}}
\caption{Phase responses of the low-pass differentiator filter
  parallel allpass filters (including a series $1-z^{-1}$) after PCLS SOCP
  optimisation.}
\label{fig:Parallel-allpass-lowpass-differentiator-filter-PCLS-phase}
\end{figure}

Figure~\ref{fig:Parallel-allpass-lowpass-differentiator-filter-PCLS-pz} shows the
pole-zero plot of the low-pass differentiator after PCLS optimisation.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_lowpass_differentiator_test_ab1pz}}
\caption{Pole-zero plot of the parallel-allpass low-pass differentiator filter
  after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-lowpass-differentiator-filter-PCLS-pz}
\end{figure}

Figure~\ref{fig:Parallel-allpass-lowpass-differentiator-filter-PCLS-correction}
shows the response of the correction filter of the low-pass differentiator after
PCLS optimisation. The amplitude response plot demonstrates that the parallel
allpass filter is not an appropriate structure for the low-pass differentiator.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_lowpass_differentiator_test_ab1correction}}
\caption{Response of the correction filter of the parallel-allpass low-pass
  differentiator filter after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-lowpass-differentiator-filter-PCLS-correction}
\end{figure}
\clearpage
\paragraph{Design of an IIR band-pass differentiator filter as the difference of two all-pass filters} 
The Octave script \newline
\emph{parallel\_allpass\_socp\_slb\_bandpass\_differentiator\_test.m}
uses the SeDuMi SOCP solver to design a band-pass differentiator filter
consisting of $1-z^{-2}$ followed by a correction filter, implemented as the sum
of two all-pass filters.
The script calls the Octave function \emph{parallel\_allpass\_slb} to perform
the PCLS design of the filter in terms of the all-pass filter pole locations
with constraints on the filter group-delay and phase.

The parallel all-pass band-pass differentiator filter specification is:
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_bandpass_differentiator_test_spec.m}
\end{small}

The Octave script
\emph{tarczynski\_parallel\_allpass\_bandpass\_differentiator\_test.m}
designs an initial band-pass differentiator correction filter with the
\emph{WISE} method described in
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}.
Figure~\ref{fig:Parallel-allpass-bandpass-differentiator-filter-initial}.
shows the initial band-pass differentiator filter response.
The phase response shown is adjusted for the nominal delay.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_bandpass_differentiator_test_ab0}}
\caption{Initial response of the band-pass differentiator filter implemented as
  the sum of two all-pass filters. The phase response shown is
  adjusted for the nominal delay.} 
\label{fig:Parallel-allpass-bandpass-differentiator-filter-initial}
\end{figure}

After PCLS optimisation, the denominator polynomials of the all-pass filters in
the band-pass differentiator correction filter are:
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_bandpass_differentiator_test_Da1_coef.m}
\verbatiminput{parallel_allpass_socp_slb_bandpass_differentiator_test_Db1_coef.m}
\end{small}

The corresponding numerator and denominator polynomials of the correction
filter are:
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_bandpass_differentiator_test_Nab1_coef.m}
\verbatiminput{parallel_allpass_socp_slb_bandpass_differentiator_test_Dab1_coef.m}
\end{small}

Figure~\ref{fig:Parallel-allpass-bandpass-differentiator-filter-PCLS-error}.
shows the response error of the band-pass differentiator filter after PCLS
optimisation. The phase response shown is adjusted for the nominal delay.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_bandpass_differentiator_test_ab1error}}
\caption{Response error of the band-pass differentiator filter implemented as the
  sum of two all-pass filters after PCLS SOCP optimisation. The phase response
  shown is adjusted for the nominal delay.} 
\label{fig:Parallel-allpass-bandpass-differentiator-filter-PCLS-error}
\end{figure}

Figure~\ref{fig:Parallel-allpass-bandpass-differentiator-filter-PCLS-phase} shows
the phase responses of the parallel all-pass correction filters after PCLS SOCP
optimisation.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_bandpass_differentiator_test_ab1phase}}
\caption{Phase responses of the band-pass differentiator filter
  parallel allpass filters after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-bandpass-differentiator-filter-PCLS-phase}
\end{figure}

Figure~\ref{fig:Parallel-allpass-bandpass-differentiator-filter-PCLS-pz} shows the
pole-zero plot of the band-pass differentiator after PCLS optimisation.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_bandpass_differentiator_test_ab1pz}}
\caption{Pole-zero plot of the parallel-allpass band-pass differentiator filter
  after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-bandpass-differentiator-filter-PCLS-pz}
\end{figure}
\clearpage
\subsubsection{\label{sec:Design-IIR-filter-difference-all-pass-filters-pole-zero-constrained-group-delay}Design
  of an IIR filter as the difference of two all-pass filters each represented 
  in pole-zero form with constraints on the group delay}
If the filter of Equation~\ref{eqn:Parallel-allpass-transfer-function} is
rewritten as the difference of two all-pass filters:
\begin{align*}
H\left(z\right)=\frac{e^{\imath\phi_{1}\left(z\right)}-e^{\imath\phi_{2}\left(z\right)}}{2}
\end{align*}
then the squared magnitude response and phase of the frequency response,
$H\left(\omega\right)$, are, with simple trigonometry
\begin{align*}
\left|H\left(\omega\right)\right|^{2} &=
\frac{1-\cos\left(\phi_{1}\left(\omega\right)-
                  \phi_{2}\left(\omega\right)\right)}{2}\\
\phi_{H}\left(\omega\right) &=
\frac{\phi_{1}\left(\omega\right)+\phi_{2}\left(\omega\right)}{2}+\frac{\pi}{2}
\end{align*}
The group delay response is:
\begin{align*}
T\left(\omega\right) &= 
-\frac{1}{2}\left[
\frac{\partial\phi_{1}\left(\omega\right)}{\partial\omega}+
\frac{\partial\phi_{2}\left(\omega\right)}{\partial\omega}
\right]
\end{align*}

The Octave script \emph{parallel\_allpass\_socp\_slb\_bandpass\_test.m} uses
the SeDuMi SOCP solver to design a band-pass filter consisting of the
difference of two all-pass filters. The script calls the Octave function
\emph{parallel\_allpass\_slb} to perform the PCLS design of the filter in
terms of the all-pass filter pole locations with constraints on the filter
group-delay. The PCLS algorithm of \emph{Selesnick}, \emph{Lang} and
\emph{Burrus} was reviewed in
Section~\ref{sub:Choice-of-Active-Constraints}. At each iteration of the PCLS
optimisation the Octave function \emph{parallel\_allpass\_socp\_mmse}
optimises the filter response subject to the current constraints. The filter
specification is
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_bandpass_test_spec.m}
\end{small}
The initial filter was designed by the Octave script
\emph{tarczynski\_parallel\_allpass\_bandpass\_test.m} using the \emph{WISE}
method described in
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}. The response
of the initial filter is shown in  
Figure~\ref{fig:Parallel-allpass-bandpass-filter-initial-response}.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_bandpass_test_ab0}}
\caption{Band-pass filter implemented as the difference of two all-pass filters,
  initial response found with the WISE barrier function.}
\label{fig:Parallel-allpass-bandpass-filter-initial-response}
\end{figure}

The denominator polynomials of the all-pass filters in the final band-pass
filter are:
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_bandpass_test_Da1_coef.m}
\verbatiminput{parallel_allpass_socp_slb_bandpass_test_Db1_coef.m}
\end{small}

Figure~\ref{fig:Parallel-allpass-bandpass-filter-PCLS-SOCP-response} and
Figure~\ref{fig:Parallel-allpass-bandpass-filter-PCLS-SOCP-pass-band-response}
show the PCLS optimised parallel allpass bandpass filter response.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_bandpass_test_ab1}}
\caption{Band-pass filter implemented as the difference of two all-pass filters,
  response after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-bandpass-filter-PCLS-SOCP-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_bandpass_test_ab1pass}}
\caption{Band-pass filter implemented as the difference of two all-pass filters,
  pass-band response after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-bandpass-filter-PCLS-SOCP-pass-band-response}
\end{figure}

Figure~\ref{fig:Parallel-allpass-bandpass-filter-PCLS-SOCP-pz} shows the
pole-zero plot of the PCLS optimised parallel allpass bandpass filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_bandpass_test_ab1pz}}
\caption{Band-pass filter implemented as the difference of two all-pass filters,
  pole-zero plot after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-bandpass-filter-PCLS-SOCP-pz}
\end{figure}

Figure~\ref{fig:Parallel-allpass-bandpass-filter-PCLS-SOCP-ab1phase} compares
the phase responses of the parallel all-pass filters.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_bandpass_test_ab1phase}}
\caption{Band-pass filter implemented as the difference of two all-pass filters,
  comparison of all-pass filter phase responses after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-bandpass-filter-PCLS-SOCP-ab1phase}
\end{figure}
\clearpage

\subsubsection{\label{sec:Design-IIR-filter-difference-all-pass-filters-pole-zero-constrained-group-delay-and-phase}Design
  of an IIR filter as the difference of two all-pass filters each represented
  in pole-zero form with constraints on the group delay and phase}
The Octave script
\emph{parallel\_allpass\_socp\_slb\_bandpass\_hilbert\_test.m}
uses the SeDuMi SOCP solver to design a band-pass Hilbert filter consisting of
the difference of two all-pass filters. The script calls the Octave function
\emph{parallel\_allpass\_slb} to perform the PCLS design of the filter in
terms of the all-pass filter pole locations with constraints on the filter
group-delay and phase. The filter specification is
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_bandpass_hilbert_test_spec.m}
\end{small}
The initial filter was designed by the Octave script
\emph{tarczynski\_parallel\_allpass\_bandpass\_hilbert\_test.m} using the
\emph{WISE} method described in
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}.

The denominator polynomials of the all-pass filters in the final band-pass
filter are:
\begin{small}
\verbatiminput{parallel_allpass_socp_slb_bandpass_hilbert_test_Da1_coef.m}
\verbatiminput{parallel_allpass_socp_slb_bandpass_hilbert_test_Db1_coef.m}
\end{small}

The final filter response is shown in
Figure~\ref{fig:Parallel-allpass-bandpass-Hilbert-filter-PCLS-SOCP-response} and
Figure~\ref{fig:Parallel-allpass-bandpass-Hilbert-filter-PCLS-SOCP-pass-band-response}.
The phase response shown is adjusted for the nominal delay.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_bandpass_hilbert_test_ab1}}
\caption{Band-pass Hilbert filter implemented as the difference of two all-pass
  filters, response after PCLS SOCP optimisation. The phase response shown is
  adjusted for the nominal delay.} 
\label{fig:Parallel-allpass-bandpass-Hilbert-filter-PCLS-SOCP-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_socp_slb_bandpass_hilbert_test_ab1pass}}
\caption{Band-pass Hilbert filter implemented as the difference of two
  all-pass filters, pass-band response after PCLS SOCP optimisation. The
  phase response shown is adjusted for the nominal delay.}
\label{fig:Parallel-allpass-bandpass-Hilbert-filter-PCLS-SOCP-pass-band-response}
\end{figure}
\clearpage
\subsection{\label{sec:Design-IIR-filter-sum-delay-all-pass-filter-pole-zero}Design of an IIR filter as the sum of a delay and an all-pass filter represented in pole-zero form}
\emph{Kunold}~\cite{Kunold_LinearPhaseRealizationWaveDigitalFilters} suggests
realisation of a low-pass filter with flat pass-band delay by the parallel
combination of a wave-digital lattice filter and a pure delay. The parallel
fixed delay means that the all-pass filter phase change during the pass-band
to stop-band transition of the overall amplitude response must result in a
large peak in the group delay response over that transition band. 
\subsubsection{\label{sec:Design-IIR-filter-sum-delay-all-pass-filter-pole-zero-SOCP}Design of an IIR filter as the sum of a delay and an all-pass filter represented in pole-zero form using SOCP}
The Octave script \emph{parallel\_allpass\_delay\_socp\_slb\_test.m} uses the
SeDuMi SOCP solver to design a low-pass filter consisting of an all-pass
filter in parallel with a delay. The script calls the Octave function
\emph{parallel\_allpass\_delay\_slb} to perform the PCLS design of the filter
in terms of the all-pass filter pole locations. The PCLS algorithm of
\emph{Selesnick}, \emph{Lang} and \emph{Burrus} was reviewed in
Section~\ref{sub:Choice-of-Active-Constraints}. At each iteration of the PCLS
optimisation the Octave function \emph{parallel\_allpass\_delay\_socp\_mmse}
optimises the filter response subject to the current constraints. The filter
specification is
\begin{small}
\verbatiminput{parallel_allpass_delay_socp_slb_test_spec.m}
\end{small}
There are no group delay constraints.

The initial allpass filter was designed by the Octave script 
\emph{tarczynski\_parallel\_allpass\_delay\_test.m} using the \emph{WISE}
method described in 
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}. The response
of the initial filter is shown in
Figure~\ref{fig:Parallel-allpass-delay-filter-initial-response}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_delay_socp_slb_test_a0}}
\caption{Parallel delay and all-pass filter, initial response found with the
  WISE barrier function.}
\label{fig:Parallel-allpass-delay-filter-initial-response}
\end{figure}

The final filter response is shown in
Figure~\ref{fig:Parallel-allpass-delay-filter-PCLS-SOCP-response} with pass-band
and stop-band details shown in 
Figure~\ref{fig:Parallel-allpass-delay-filter-PCLS-SOCP-detail-response}. 
The pole-zero plot of the filter is shown in 
Figure~\ref{fig:Parallel-allpass-delay-filter-PCLS-SOCP-a1pz}.
The denominator polynomial of the final all-pass filter is
\begin{small}
\verbatiminput{parallel_allpass_delay_socp_slb_test_Da1_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_delay_socp_slb_test_a1}}
\caption{Parallel delay and all-pass filter, response after PCLS SOCP
  optimisation.}
\label{fig:Parallel-allpass-delay-filter-PCLS-SOCP-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_delay_socp_slb_test_a1dual}}
\caption{Parallel delay and all-pass filter, detail of the pass-band and
  stop-band responses after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-delay-filter-PCLS-SOCP-detail-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_delay_socp_slb_test_a1pz}}
\caption{Parallel delay and all-pass filter, pole-zero plot of the filter
  after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-delay-filter-PCLS-SOCP-a1pz}
\end{figure}
\clearpage
\subsubsection{\label{sec:Design-IIR-filter-sum-delay-all-pass-filter-pole-zero-SQP}Design of an IIR filter as the sum of a delay and an all-pass filter represented in pole-zero form using SQP}
The Octave script \emph{parallel\_allpass\_delay\_sqp\_slb\_test.m} repeats
the design example of
Section~\ref{sec:Design-IIR-filter-sum-delay-all-pass-filter-pole-zero-SOCP}
with the SQP solver. The script calls the Octave function
\emph{parallel\_allpass\_delay\_slb} to perform the PCLS design of the filter
in terms of the all-pass filter pole locations. At each iteration of the PCLS
optimisation the Octave function \emph{parallel\_allpass\_delay\_sqp\_mmse}
optimises the filter response subject to the current constraints. The filter
specification is
\begin{small}
  \verbatiminput{parallel_allpass_delay_sqp_slb_test_spec.m}
\end{small}
There are no group delay constraints.

The final filter response is shown in
Figure~\ref{fig:Parallel-allpass-delay-filter-PCLS-SQP-response} with pass-band
and stop-band details shown in 
Figure~\ref{fig:Parallel-allpass-delay-filter-PCLS-SQP-detail-response}. 
Figure~\ref{fig:Parallel-allpass-delay-filter-PCLS-SQP-a1phase} shows
the phase response of the all-pass branch of the filter after adjustment
for the delay of the fixed delay branch.
The denominator polynomial of the final all-pass filter is
\begin{small}
\verbatiminput{parallel_allpass_delay_sqp_slb_test_Da1_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_delay_sqp_slb_test_a1}}
\caption{Parallel delay and all-pass filter, response after PCLS SQP
  optimisation.}
\label{fig:Parallel-allpass-delay-filter-PCLS-SQP-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_delay_sqp_slb_test_a1dual}}
\caption{Parallel delay and all-pass filter, detail of the pass-band and
  stop-band responses after PCLS SQP optimisation.}
\label{fig:Parallel-allpass-delay-filter-PCLS-SQP-detail-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_delay_sqp_slb_test_a1phase}}
\caption{Parallel delay and all-pass filter, phase response of the all-pass
  filter branch after PCLS SQP optimisation. The response has been adjusted
  for the group delay of the fixed delay branch.}
\label{fig:Parallel-allpass-delay-filter-PCLS-SQP-a1phase}
\end{figure}
\clearpage
\subsubsection{\label{sec:Design-IIR-filter-sum-delay-all-pass-filter-pole-zero-SOCP-delay}Design of an IIR filter as the sum of a delay and an all-pass filter represented in pole-zero form using SOCP with a group delay constraint}
The Octave script \emph{parallel\_allpass\_flat\_delay\_socp\_slb\_test.m} uses
the SeDuMi SOCP solver to design a low-pass filter consisting of an all-pass
filter in parallel with a delay with a constraint on the pass-band delay. The
script calls the Octave function \emph{parallel\_allpass\_delay\_slb} to perform
the PCLS design of the filter in terms of the all-pass filter pole locations.
The PCLS algorithm of \emph{Selesnick}, \emph{Lang} and \emph{Burrus} was
reviewed in Section~\ref{sub:Choice-of-Active-Constraints}. At each iteration of
the PCLS optimisation the Octave function
\emph{parallel\_allpass\_delay\_socp\_mmse} optimises the filter response
subject to the current constraints. The filter specification is
\begin{small}
\verbatiminput{parallel_allpass\_flat\_delay_socp_slb_test_spec.m}
\end{small}

The initial allpass filter was designed by the Octave script 
\emph{tarczynski\_parallel\_allpass\_delay\_test.m} using the \emph{WISE}
method described in 
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}. The response
of the initial filter is shown in
Figure~\ref{fig:Parallel-allpass-flat-delay-filter-initial-response}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_flat_delay_socp_slb_test_a0}}
\caption{Parallel delay and all-pass filter, with delay constraint, initial
  response found with the WISE barrier function.}
\label{fig:Parallel-allpass-flat-delay-filter-initial-response}
\end{figure}

The final filter response is shown in
Figure~\ref{fig:Parallel-allpass-flat-delay-filter-PCLS-SOCP-response} with
pass-band and stop-band details shown in 
Figure~\ref{fig:Parallel-allpass-flat-delay-filter-PCLS-SOCP-detail-response}. 
The pole-zero plot of the filter is shown in 
Figure~\ref{fig:Parallel-allpass-flat-delay-filter-PCLS-SOCP-a1pz}.
The denominator polynomial of the final all-pass filter is
\begin{small}
\verbatiminput{parallel_allpass_flat_delay_socp_slb_test_Da1_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_flat_delay_socp_slb_test_a1}}
\caption{Parallel delay and all-pass filter, with delay constraint, response
  after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-flat-delay-filter-PCLS-SOCP-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_flat_delay_socp_slb_test_a1dual}}
\caption{Parallel delay and all-pass filter, with delay constraint, detail of
  the pass-band and stop-band responses after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-flat-delay-filter-PCLS-SOCP-detail-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{parallel_allpass_flat_delay_socp_slb_test_a1pz}}
\caption{Parallel delay and all-pass filter, with delay constraint, pole-zero
  plot of the filter after PCLS SOCP optimisation.}
\label{fig:Parallel-allpass-flat-delay-filter-PCLS-SOCP-a1pz}
\end{figure}
\clearpage
\subsection{\label{sec:IIR-filter-polyphase-decomposition-all-pass-filters}Design of an IIR filter as the polyphase decomposition into two all-pass filters each represented in pole-zero form}
The IIR filter of Equation~\ref{eqn:Parallel-allpass-transfer-function} can be
represented in ``polyphase''
form~\cite{RenforsSaramaki_RecursiveNthBandDigitalFiltersPart1,RenforsSaramaki_RecursiveNthBandDigitalFiltersPart2} as
\begin{align}
H\left(z\right) &= \frac{1}{R}\sum_{k=0}^{R-1}z^{-k}A_{k}\left(z^R\right)
\label{eqn:Polyphase-allpass-transfer-function}  
\end{align}
Where the $A_{k}$ are all-pass filters. In the following I consider an example
with $R=2$, in other words, a half-band decimation filter suitable for use
in an efficient half-band filter-bank. The Octave functions
\emph{parallel\_allpassP} and \emph{parallel\_allpassAsq} support the calculation
of the phase and squared magnitude response, respectively, of the polyphase
combination of two all-pass filters with $R=2$. 

\subsubsection{Design of an IIR filter as the polyphase decomposition into two all-pass filters each represented in pole-zero form with no constraints on the group delay}
The Octave script \emph{polyphase\_allpass\_socp\_slb\_test.m} calls the Octave
function \emph{parallel\_allpass\_slb}
to design a low-pass filter composed of the polyphase combination of two parallel
all-pass filters in terms of the allpass filter 
pole locations. The response of the filter is optimised with the PCLS algorithm
described in Section~\ref{sub:Choice-of-Active-Constraints}. The filter
specification is:
\begin{small}
\verbatiminput{polyphase_allpass_socp_slb_test_spec.m}
\end{small}
As in Section~\ref{sec:Design-IIR-filter-sum-all-pass-filters-pole-zero-no-constraints-on-group-delay}, the script does not optimise for a flat filter group 
delay. 

At first, the initial parallel all-pass filters were designed by the
Octave script \emph{tarczynski\_polyphase\_allpass\_test.m} using the \emph{WISE}
method described in
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}. In this case
the script has $flat\_delay = false$. These initial allpass filters have $3$
real poles and $4$ complex pole pairs. I find that better stop-band attenuation
is obtained by modifying these initial allpass filters to use $5$ real poles
and $3$ complex pole pairs. The response after PCLS optimisation with the
\emph{SeDuMi} SOCP solver is shown in
Figure~\ref{fig:Polyphase-allpass-filter-PCLS-SOCP-response} and
Figure~\ref{fig:Polyphase-allpass-filter-PCLS-SOCP-detail-response}.
The denominator polynomials of the two all-pass filters are
\begin{small}
\verbatiminput{polyphase_allpass_socp_slb_test_Da1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{polyphase_allpass_socp_slb_test_Db1_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{polyphase_allpass_socp_slb_test_ab1}}
\caption{Polyphase combination of two allpass filters, response after PCLS SOCP
  optimisation.}
\label{fig:Polyphase-allpass-filter-PCLS-SOCP-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{polyphase_allpass_socp_slb_test_ab1dual}}
\caption{Polyphase combination of two allpass filters, detail of response after
  PCLS SOCP optimisation.}
\label{fig:Polyphase-allpass-filter-PCLS-SOCP-detail-response}
\end{figure}
\clearpage
\subsubsection{Design of an IIR filter as the polyphase decomposition into two all-pass filters each represented in pole-zero form with constraints on the group delay}
The Octave script \emph{polyphase\_allpass\_socp\_slb\_flat\_delay\_test.m} 
calls the Octave function \emph{parallel\_allpass\_slb}
to design a low-pass filter composed of the polyphase combination of two parallel
all-pass filters in terms of the all-pass filter 
pole locations. The response of the filter is optimised with the PCLS algorithm
described in Section~\ref{sub:Choice-of-Active-Constraints}. The filter
specification is:
\begin{small}
\verbatiminput{polyphase_allpass_socp_slb_flat_delay_test_spec.m}
\end{small}
In this case the script ignores the pass band amplitude, optimises the stop band
amplitude and optimises for a flat filter group delay across the pass band.

The initial parallel allpass filters were designed by the
Octave script \emph{tarczynski\_polyphase\_allpass\_test.m} with the \emph{WISE}
method described in
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}. In this case
that script has $flat\_delay = true$.
Figure~\ref{fig:Polyphase-allpass-filter-flat-delay-PCLS-SOCP-response}
shows the response after PCLS optimisation with the \emph{SeDuMi} SOCP solver.
Figure~\ref{fig:Polyphase-allpass-filter-flat-delay-PCLS-SOCP-passband-response}
shows the pass band response. The denominator polynomials of the all-pass
filters are
\begin{small}
\verbatiminput{polyphase_allpass_socp_slb_flat_delay_test_Da1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{polyphase_allpass_socp_slb_flat_delay_test_Db1_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{polyphase_allpass_socp_slb_flat_delay_test_ab1}}
\caption{Polyphase combination of two all-pass filters with flat pass-band
  delay, response after PCLS SOCP optimisation.}
\label{fig:Polyphase-allpass-filter-flat-delay-PCLS-SOCP-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{polyphase_allpass_socp_slb_flat_delay_test_ab1pass}}
\caption{Polyphase combination of two all-pass filters with flat pass-band
  delay, pass-band response after PCLS SOCP optimisation.}
\label{fig:Polyphase-allpass-filter-flat-delay-PCLS-SOCP-passband-response}
\end{figure}
\clearpage
\section{\label{sec:Design-of-IIR-Schur-lattice-filters}Design of IIR Schur lattice filters}
There is a large literature describing adaptive IIR lattice filters. For example,
\emph{Regalia}~\cite{Regalia_StableLatticeAdaptiveIIR} describes adaptive
IIR lattice filter algorithms with $\mathcal{O}\left(N\right)$ complexity.
The lattice structure has the advantage that the allpass
``reflection'' coefficients, $k_{i}$, have a simple filter stability
criterion: $\left|k_{i}\right|<1$ (see, for example, \emph{Vaidyanathan} and
\emph{Mitra}~\cite{VaidyanathanMitra_UnifiedStructuralInterpretationStability}).
This section describes the PCLS
design of the squared magnitude, phase and group delay responses of
one-multplier and normalised scaled IIR Schur lattice filters by SOCP and SQP
optimisation of the lattice coefficients. The calculation of the Schur lattice
filter squared-magnitude, phase and group delay responses and gradients is
calculated in three steps:
\begin{enumerate}
\item calculate the state variable representation of the lattice filter and the 
gradients of the state variable matrixes with respect to each of the lattice 
coefficients
\item calculate the lattice filter complex frequency response and gradients
\item calculate the lattice filter squared magnitude, phase and group delay responses and gradients 
\end{enumerate}

Chapter~\ref{sec:Schur-decomposition} reviews the Schur decomposition of an IIR
transfer function into an IIR tapped-lattice structure.
Algorithm~\ref{alg:Construction-state-variable-One-Multiplier-lattice} shows the
factorisation of the state variable description of the \emph{one-multiplier}
lattice filter.
Algorithm~\ref{alg:Construction-state-variable-Scaled-Normalised-lattice} shows
the factorisation of the state variable description of the
\emph{normalised-scaled} lattice filter.
Section~\ref{sec:Sensitivity-analysis-state-variable-transfer-function} reviews
the sensitivities of the complex transfer function with respect to the state
variable coefficients.
Appendix~\ref{app:Gradients-state-variable-filter-frequency-response} shows the
gradients of the squared-magnitude, phase and group delay responses with respect
to the components of the state variable matrixes.  The state-transition matrix,
$A$, generated by
Algorithm~\ref{alg:Construction-state-variable-One-Multiplier-lattice} or
Algorithm~\ref{alg:Construction-state-variable-Scaled-Normalised-lattice} is
lower Hessenberg. The matrix resolvent, $\left(zI-A\right)^{-1}$ is calculated
by direct matrix inversion rather than \emph{Le Verrier's} algorithm (see
Algorithm~\ref{alg:LeVerriers-algorithm-characteristic-polynomial}).  
\emph{Xu Zhong}~\cite{Zhong_InversesOfHessenbergMatrices} gives an algorithm that
calculates the inverse of a lower Hessenberg matrix. That algorithm is
implemented in Octave as the function \emph{zhong\_inverse.m} and, for a matrix
with complex elements, in the \emph{oct}-file \emph{complex\_zhong\_inverse.cc}.
The Octave function \emph{Abcd2H}, exercised by the Octave script 
\emph{Abcd2H\_test.m}, calculates the response of a state
variable filter and the gradients of the complex response with respect to
frequency and with respect to the components of the state variable matrixes. The
Octave function \emph{Abcd2H} assumes that the components of the state variable
matrixes are first order combinations of the lattice coefficients. In other
words, \emph{Abcd2H} does not support gradients with respect to the square-roots
of the $k$ lattice coefficients derived in
Chapter~\ref{sec:Schur-decomposition} for the normalised-scaled lattice. The
results of this section are intended to be used in the following
Part~\ref{part:IIR-filters-fixed-point-coefficients} to optimise the choice of
fixed-point lattice coefficients. 

\clearpage
\subsection{Design of one-multiplier IIR Schur lattice filters with SQP optimisation}
\subsubsection{\label{sec:Design-IIR-one-multiplier-Schur-lattice-low-pass-SQP}Design of a one-multiplier IIR Schur lattice low-pass filter using SQP}
The Octave script \emph{schurOneMlattice\_sqp\_slb\_lowpass\_test.m} implements
the design of a lowpass IIR one-multiplier Schur lattice filter with SQP and 
PCLS. The specification of the filter is:
\begin{small}
\verbatiminput{schurOneMlattice_sqp_slb_lowpass_test_spec.m}
\end{small}
The initial filter is the ``IPZS-1'' of Section~\ref{sub:Deczkys-Example-3}. As
for the examples of 
Chapter~\ref{sec:Constrained-Optimisation-of-IIR-by-Quadratic-Programming-Pole-Zero-Location}
the SQP BFGS update is initialised by the diagonal of the Hessian matrix of the
squared error. The diagonals of the Hessian matrixes of the 
squared-magnitude, phase and group delay are given in 
Appendix~\ref{app:Gradients-state-variable-filter-frequency-response}.

Figures~\ref{fig:Schur-one-multiplier-lattice-lowpass-filter-SQP-PCLS} 
and~\ref{fig:Schur-one-multiplier-lattice-lowpass-filter-SQP-PCLS-pass} 
show the overall and passband response of the filter after SQP PCLS optimisation.
Figure~\ref{fig:Schur-one-multiplier-lattice-lowpass-filter-SQP-PCLS-pz} shows
the pole-zero plot of the filter after SQP PCLS optimisation.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_sqp_slb_lowpass_test_pcls_k2c2}}
\caption{Schur one-multiplier lattice lowpass filter, response after SQP PCLS
  optimisation.}
\label{fig:Schur-one-multiplier-lattice-lowpass-filter-SQP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_sqp_slb_lowpass_test_pcls_k2c2pass}}
\caption{Schur one-multiplier lattice lowpass filter, passband response after
  SQP PCLS optimisation.}
\label{fig:Schur-one-multiplier-lattice-lowpass-filter-SQP-PCLS-pass}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_sqp_slb_lowpass_test_pcls_k2c2pz}}
\caption{Schur one-multiplier lattice lowpass filter, pole-zero plot after SQP
  PCLS optimisation.}
\label{fig:Schur-one-multiplier-lattice-lowpass-filter-SQP-PCLS-pz}
\end{figure}

The SQP PCLS optimised Schur one-multiplier all-pass lattice and numerator tap 
coefficients of the low-pass filter are:
\begin{small}
\verbatiminput{schurOneMlattice_sqp_slb_lowpass_test_k2_coef.m}
\verbatiminput{schurOneMlattice_sqp_slb_lowpass_test_epsilon2_coef.m}
\verbatiminput{schurOneMlattice_sqp_slb_lowpass_test_p2_coef.m}
\verbatiminput{schurOneMlattice_sqp_slb_lowpass_test_c2_coef.m}
\end{small}
The PCLS SQP optimised Schur one-multiplier low-pass filter numerator and
denominator polynomials are:
\begin{small}
\verbatiminput{schurOneMlattice_sqp_slb_lowpass_test_n2_coef.m}
\verbatiminput{schurOneMlattice_sqp_slb_lowpass_test_d2_coef.m}
\end{small}

\subsubsection{Design of a one-multiplier IIR Schur lattice band-pass filter using SQP\label{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-SQP}}
The Octave script \emph{schurOneMlattice\_sqp\_slb\_bandpass\_test.m} implements
the design of a band-pass IIR one-multiplier Schur lattice filter with SQP and 
PCLS. The specification of the filter is:
\begin{small}
\verbatiminput{schurOneMlattice_sqp_slb_bandpass_test_spec.m}
\end{small}
The initial filter is that of the Octave script 
\emph{iir\_sqp\_slb\_bandpass\_test.m}, as shown in 
Section~\ref{sec:Band-pass-R-2-decimation-filter}.
The denominator polynomial of the filter has coefficients in $z^{2}$ only.

Figure~\ref{fig:Schur-one-multiplier-lattice-band-pass-filter-SQP-MMSE} 
shows the overall response of the band-pass filter after SQP MMSE optimisation.
Figures~\ref{fig:Schur-one-multiplier-lattice-band-pass-filter-SQP-PCLS} 
and~\ref{fig:Schur-one-multiplier-lattice-band-pass-filter-SQP-PCLS-pass} 
show the overall and passband response of the band-pass filter after SQP PCLS
optimisation.
Figure~\ref{fig:Schur-one-multiplier-lattice-band-pass-filter-SQP-PCLS-pz} shows
the pole-zero plot of the band-pass filter after SQP PCLS optimisation.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_sqp_slb_bandpass_test_mmse_k1c1}}
\caption{Response of the Schur one-multiplier lattice band-pass filter after
  SQP MMSE optimisation.}
\label{fig:Schur-one-multiplier-lattice-band-pass-filter-SQP-MMSE}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_sqp_slb_bandpass_test_pcls_k2c2}}
\caption{Response of the Schur one-multiplier lattice band-pass filter after SQP
  PCLS optimisation.}
\label{fig:Schur-one-multiplier-lattice-band-pass-filter-SQP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_sqp_slb_bandpass_test_pcls_k2c2pass}}
\caption{Passband response of the Schur one-multiplier lattice band-pass filter
  after SQP PCLS optimisation.}
\label{fig:Schur-one-multiplier-lattice-band-pass-filter-SQP-PCLS-pass}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_sqp_slb_bandpass_test_pcls_k2c2pz}}
\caption{Pole-zero plot of the Schur one-multiplier lattice band-pass filter
  after SQP PCLS optimisation.}
\label{fig:Schur-one-multiplier-lattice-band-pass-filter-SQP-PCLS-pz}
\end{figure}

The SQP PCLS optimised Schur one-multiplier allpass lattice and numerator tap 
coefficients of the band-pass filter are:
\begin{small}
\verbatiminput{schurOneMlattice_sqp_slb_bandpass_test_k2_coef.m}
\verbatiminput{schurOneMlattice_sqp_slb_bandpass_test_epsilon2_coef.m}
\verbatiminput{schurOneMlattice_sqp_slb_bandpass_test_p2_coef.m}
\verbatiminput{schurOneMlattice_sqp_slb_bandpass_test_c2_coef.m}
\end{small}

The corresponding overall transfer function numerator and denominator
polynomial coefficients are:
\begin{small}
\verbatiminput{schurOneMlattice_sqp_slb_bandpass_test_N2_coef.m}
\verbatiminput{schurOneMlattice_sqp_slb_bandpass_test_D2_coef.m}
\end{small}

\subsubsection{\label{sec:Design-IIR-one-multiplier-Schur-lattice-hilbert-SQP}Design of a one-multiplier IIR Schur lattice Hilbert filter using SQP} 
The Octave script \emph{schurOneMlattice\_sqp\_slb\_hilbert\_test.m} implements
the design of an IIR one-multiplier Schur lattice Hilbert filter with SQP and 
PCLS. The specification of the filter is:
\begin{small}
\verbatiminput{schurOneMlattice_sqp_slb_hilbert_test_spec.m}
\end{small}
The initial filter is that of the Octave script 
\emph{iir\_sqp\_slb\_hilbert\_test.m} designed by
the method of \emph{Tarczynski et al.} with the Octave script 
\emph{tarczynski\_hilbert\_test.m}, as shown in 
Section~\ref{sec:Hilbert-transform-R-2-decimation-filter}.
The denominator polynomial of the filter has coefficients in $z^{2}$ only.
Figure~\ref{fig:Schur-one-multiplier-lattice-hilbert-filter-SQP-PCLS} 
shows the response of the Hilbert filter after SQP PCLS optimisation. The phase
response shown has been adjusted by the nominal group delay, $\omega{}\tau_{d}$.
The values shown on the phase axis of the phase response plot are multiples of
$\pi$ radians.
Figure~\ref{fig:Schur-one-multiplier-lattice-hilbert-filter-SQP-PCLS-pz} shows
the pole-zero plot of the Hilbert filter after SQP PCLS optimisation.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_sqp_slb_hilbert_test_pcls_response}}
\caption{Schur one-multiplier lattice Hilbert filter, response after SQP PCLS
  optimisation.}
\label{fig:Schur-one-multiplier-lattice-hilbert-filter-SQP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_sqp_slb_hilbert_test_pcls_pz}}
\caption{Schur one-multiplier lattice Hilbert filter, pole-zero plot after SQP
  PCLS optimisation.}
\label{fig:Schur-one-multiplier-lattice-hilbert-filter-SQP-PCLS-pz}
\end{figure}

The SQP PCLS optimised Schur one-multiplier all-pass lattice and numerator tap 
coefficients of the Hilbert filter are:
\begin{small}
\verbatiminput{schurOneMlattice_sqp_slb_hilbert_test_k2_coef.m}
\verbatiminput{schurOneMlattice_sqp_slb_hilbert_test_epsilon2_coef.m}
\verbatiminput{schurOneMlattice_sqp_slb_hilbert_test_p2_coef.m}
\verbatiminput{schurOneMlattice_sqp_slb_hilbert_test_c2_coef.m}
\end{small}

The corresponding denominator and numerator transfer function polynomial
coefficients are:
\begin{small}
\verbatiminput{schurOneMlattice_sqp_slb_hilbert_test_N2_coef.m}
\verbatiminput{schurOneMlattice_sqp_slb_hilbert_test_D2_coef.m}
\end{small}
\clearpage
\subsection{Design of one-multiplier IIR Schur lattice filters with SOCP optimisation}

\subsubsection{Design of a one-multiplier IIR Schur lattice low-pass filter using SOCP}
The Octave script \emph{schurOneMlattice\_socp\_slb\_lowpass\_test.m} implements
the design of a lowpass IIR one-multiplier Schur lattice filter using the 
\emph{SeDuMi} SOCP solver with PCLS constraints. The filter specification is 
similar to that of the \emph{Deczky3} gain-pole-zero SQP and SOCP optimisation
examples in Sections~\ref{sub:Deczkys-Example-3}
and~\ref{sec:Deczky3-IIR-filter-gain-zero-pole-with-SeDuMi}:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_test_spec.m}
\end{small}
The initial filter is a heavily modified version of the ``IPZS-1'' filter of 
Section~\ref{sub:Deczkys-Example-3}. 
Figures~\ref{fig:Schur-one-multiplier-lattice-lowpass-filter-SOCP-PCLS} 
and~\ref{fig:Schur-one-multiplier-lattice-lowpass-filter-SOCP-PCLS-pass} 
show the overall and passband response after SOCP PCLS optimisation.
Figure~\ref{fig:Schur-one-multiplier-lattice-lowpass-filter-SOCP-PCLS-pz} shows
the pole-zero plot of the resulting filter after SOCP PCLS optimisation.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_lowpass_test_pcls_k2c2}}
\caption{Response of the Schur one-multiplier lattice lowpass filter after PCLS
  SOCP optimisation.}
\label{fig:Schur-one-multiplier-lattice-lowpass-filter-SOCP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_lowpass_test_pcls_k2c2pass}}
\caption{Passband response of the Schur one-multiplier lattice lowpass filter
  after PCLS SOCP optimisation.}
\label{fig:Schur-one-multiplier-lattice-lowpass-filter-SOCP-PCLS-pass}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_lowpass_test_pcls_k2c2pz}}
\caption{Pole-zero plot of the Schur one-multiplier lattice lowpass filter after
  PCLS SOCP optimisation.}
\label{fig:Schur-one-multiplier-lattice-lowpass-filter-SOCP-PCLS-pz}
\end{figure}

The PCLS SOCP optimised Schur one-multiplier all-pass lattice and numerator tap 
coefficients of the low-pass filter are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_test_k2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_test_epsilon2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_test_p2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_test_c2_coef.m}
\end{small}
The PCLS SOCP optimised Schur one-multiplier low-pass filter numerator and
denominator polynomials are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_test_n2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_test_d2_coef.m}
\end{small}

\subsubsection{Design of a one-multiplier IIR Schur lattice band-pass filter using SOCP\label{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-SOCP}}
The Octave script \emph{schurOneMlattice\_socp\_slb\_bandpass\_test.m}
implements the design of a band-pass IIR one-multiplier Schur lattice filter
with SOCP and PCLS. The specification of the filter is:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_test_spec.m}
\end{small}
The initial filter is that found by the Octave script 
\emph{tarczynski\_bandpass\_R1\_test.m}.
Figure~\ref{fig:Schur-one-multiplier-lattice-band-pass-filter-SOCP-PCLS} 
shows the response of the band-pass filter after SOCP PCLS optimisation and
Figure~\ref{fig:Schur-one-multiplier-lattice-band-pass-filter-SOCP-PCLS-pz} 
shows the pole-zero plot of the band-pass filter.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_bandpass_test_pcls_response}}
\caption{Response of the Schur one-multiplier lattice band-pass filter after
  SOCP PCLS optimisation.}
\label{fig:Schur-one-multiplier-lattice-band-pass-filter-SOCP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_bandpass_test_pcls_pz}}
\caption{Pole-zero plot of the Schur one-multiplier lattice band-pass filter
  after SOCP PCLS optimisation.}
\label{fig:Schur-one-multiplier-lattice-band-pass-filter-SOCP-PCLS-pz}
\end{figure}

The SOCP PCLS optimised Schur one-multiplier
allpass lattice and numerator tap coefficients of the band-pass filter are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_test_k3_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_test_epsilon3_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_test_p3_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_test_c3_coef.m}
\end{small}

The corresponding overall transfer function numerator and denominator
polynomial coefficients are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_test_N3_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_test_D3_coef.m}
\end{small}
\subsubsection{Design of an R=2 one-multiplier IIR Schur lattice band-pass filter using SOCP\label{sec:Design-R2-IIR-one-multiplier-Schur-lattice-band-pass-SOCP}}
The Octave script \emph{schurOneMR2lattice\_socp\_slb\_bandpass\_test.m}
implements the design of an $R=2$ band-pass IIR one-multiplier Schur lattice
filter with SOCP and PCLS. The filter denominator polynomial has coefficients
only in $z^{-2}$. The specification of the filter is:
\begin{small}
\verbatiminput{schurOneMR2lattice_socp_slb_bandpass_test_spec.m}
\end{small}
The initial filter is that found by the Octave script 
\emph{tarczynski\_bandpass\_test.m}.
Figure~\ref{fig:R2-Schur-one-multiplier-lattice-band-pass-filter-SOCP-PCLS} 
shows the response of the band-pass filter after SOCP PCLS optimisation and
Figure~\ref{fig:R2-Schur-one-multiplier-lattice-band-pass-filter-SOCP-PCLS-pz} 
shows the pole-zero plot of the $R=2$ band-pass filter.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMR2lattice_socp_slb_bandpass_test_pcls_response}}
\caption{Response of the R=2 Schur one-multiplier lattice band-pass filter after
  SOCP PCLS optimisation.}
\label{fig:R2-Schur-one-multiplier-lattice-band-pass-filter-SOCP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMR2lattice_socp_slb_bandpass_test_pcls_pz}}
\caption{Pole-zero plot of the R=2 Schur one-multiplier lattice band-pass filter
  after SOCP PCLS optimisation.}
\label{fig:R2-Schur-one-multiplier-lattice-band-pass-filter-SOCP-PCLS-pz}
\end{figure}

The SOCP PCLS optimised Schur one-multiplier
allpass lattice and numerator tap coefficients of the $R=2$ band-pass filter are:
\begin{small}
\verbatiminput{schurOneMR2lattice_socp_slb_bandpass_test_k3_coef.m}
\verbatiminput{schurOneMR2lattice_socp_slb_bandpass_test_epsilon3_coef.m}
\verbatiminput{schurOneMR2lattice_socp_slb_bandpass_test_p3_coef.m}
\verbatiminput{schurOneMR2lattice_socp_slb_bandpass_test_c3_coef.m}
\end{small}

The corresponding overall transfer function numerator and denominator
polynomial coefficients are:
\begin{small}
\verbatiminput{schurOneMR2lattice_socp_slb_bandpass_test_N3_coef.m}
\verbatiminput{schurOneMR2lattice_socp_slb_bandpass_test_D3_coef.m}
\end{small}
\subsubsection{Design of a pipelined  IIR Schur one-multiplier lattice band-pass filter using SOCP}
The Octave script
\emph{schurOneMlatticePipelined\_socp\_slb\_bandpass\_test.m}
designs a band-pass Schur one-multiplier lattice filter implemented in the
pipelined form shown in
Section~\ref{sec:State-variable-pipelined-One-multiplier-Schur-lattice-filter}.
The initial filter is designed by the Octave script
\emph{tarczynski\_bandpass\_R1\_test.m}. The filter specification is:
\begin{small}
\verbatiminput{schurOneMlatticePipelined_socp_slb_bandpass_test_spec.m}
\end{small}

The PCLS SOCP optimised pipelined Schur one-multiplier lattice band-pass filter
coefficients are:
\begin{small}
\verbatiminput{schurOneMlatticePipelined_socp_slb_bandpass_test_k2_coef.m}
\verbatiminput{schurOneMlatticePipelined_socp_slb_bandpass_test_epsilon0_coef.m}
\verbatiminput{schurOneMlatticePipelined_socp_slb_bandpass_test_c2_coef.m}
\verbatiminput{schurOneMlatticePipelined_socp_slb_bandpass_test_kk2_coef.m}
\verbatiminput{schurOneMlatticePipelined_socp_slb_bandpass_test_ck2_coef.m}
\end{small}

The corresponding overall transfer function numerator and denominator
polynomials are:
\begin{small}
\verbatiminput{schurOneMlatticePipelined_socp_slb_bandpass_test_N2_coef.m}
\verbatiminput{schurOneMlatticePipelined_socp_slb_bandpass_test_D2_coef.m}
\end{small}

Figure~\ref{fig:Schur-OneM-lattice-pipelined-bandpass-SOCP-PCLS}
shows the response of the band-pass filter after PCLS optimisation and 
Figure~\ref{fig:Schur-OneM-lattice-pipelined-bandpass-SOCP-PCLS-pz}
shows the pole-zero plot of the band-pass filter after PCLS optimisation. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlatticePipelined_socp_slb_bandpass_test_pcls_response}}
\caption{PCLS optimised response of a pipelined Schur one-multiplier  lattice
  band-pass filter.}
\label{fig:Schur-OneM-lattice-pipelined-bandpass-SOCP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlatticePipelined_socp_slb_bandpass_test_pcls_pz}}
\caption{Pole-zero plot of the PCLS optimised pipelined Schur one-multiplier
  lattice band-pass filter.}
\label{fig:Schur-OneM-lattice-pipelined-bandpass-SOCP-PCLS-pz}
\end{figure}

\subsubsection{\label{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-hilbert-SOCP}Design of a one-multiplier IIR Schur lattice band-pass Hilbert filter using SOCP}
The Octave script \emph{schurOneMlattice\_socp\_slb\_bandpass\_hilbert\_test.m}
implements the design of a band-pass Hilbert IIR one-multiplier Schur lattice
filter with SOCP and PCLS. The specification of the filter is:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_hilbert_test_spec.m}
\end{small}
The initial filter is that found by the Octave script 
\emph{tarczynski\_bandpass\_hilbert\_test.m}.
Figure~\ref{fig:Schur-one-multiplier-lattice-band-pass-hilbert-filter-SOCP-PCLS} 
shows the response of the band-pass Hilbert filter after SOCP PCLS optimisation
and
Figure~\ref{fig:Schur-one-multiplier-lattice-band-pass-hilbert-filter-SOCP-PCLS-pz} 
shows the pole-zero plot of the band-pass Hilbert filter.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_bandpass_hilbert_test_response}}
\caption{Response of the Schur one-multiplier lattice band-pass Hilbert filter
  after SOCP PCLS optimisation.}
\label{fig:Schur-one-multiplier-lattice-band-pass-hilbert-filter-SOCP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_bandpass_hilbert_test_pz}}
\caption{Pole-zero plot of the Schur one-multiplier lattice band-pass Hilbert
  filter after SOCP PCLS optimisation.}
\label{fig:Schur-one-multiplier-lattice-band-pass-hilbert-filter-SOCP-PCLS-pz}
\end{figure}

The SOCP PCLS optimised Schur one-multiplier allpass lattice and numerator tap
coefficients of the band-pass Hilbert filter are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_hilbert_test_k2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_hilbert_test_epsilon2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_hilbert_test_p2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_hilbert_test_c2_coef.m}
\end{small}

The corresponding overall transfer function numerator and denominator
polynomial coefficients are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_hilbert_test_N1_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_hilbert_test_D1_coef.m}
\end{small}

\subsubsection{\label{sec:SOCP-Schur-OneM-lowpass-differentiator}Design of a low-pass differentiator filter with an IIR Schur one-multiplier lattice correction filter using SOCP}
The Octave script
\emph{schurOneMlattice\_socp\_slb\_lowpass\_differentiator\_test.m}
calls \emph{schurOneMlattice\_slb} to improve the filter designed with
\emph{tarczynski\_lowpass\_differentiator\_test.m}. The low-pass
differentiator filter consists of $1-z^{-1}$ and a Schur one-multiplier lattice
correction filter. The filter specification is similar to that of
Section~\ref{sec:iir-sqp-slb-lowpass-differentiator}:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_test_spec.m}
\end{small}

The PCLS SOCP optimised Schur one-multiplier lattice filter coefficients of the
correction filter are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_test_k2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_test_c2_coef.m}
\end{small}

The corresponding transfer function numerator and denominator
polynomials of the correction filter are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_test_N2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_test_D2_coef.m}
\end{small}

Figure~\ref{fig:Schur-OneM-lattice-correction-lowpass-differentiator-SOCP-PCLS}
shows the response of the low-pass differentiator filter after PCLS
optimisation and
Figure~\ref{fig:Schur-OneM-lattice-correction-lowpass-differentiator-SOCP-PCLS-pz}
shows the pole-zero plot of the low-pass differentiator filter after PCLS
optimisation. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_lowpass_differentiator_test_error_response}}
\caption{PCLS optimised error response of a low-pass differentiator filter
  composed of a Schur one-multiplier lattice correction filter and $1-z^{-1}$.}
\label{fig:Schur-OneM-lattice-correction-lowpass-differentiator-SOCP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_lowpass_differentiator_test_pz}}
\caption{Pole-zero plot of the PCLS optimised low-pass differentiator filter
  composed of a Schur one-multiplier lattice correction filter in series with
  $1-z^{-1}$.}
\label{fig:Schur-OneM-lattice-correction-lowpass-differentiator-SOCP-PCLS-pz}
\end{figure}
\clearpage
\subsubsection{Design of an alternative low-pass differentiator filter with an IIR Schur one-multiplier lattice correction filter using SOCP}
The Octave script
\emph{schurOneMlattice\_socp\_slb\_lowpass\_differentiator\_alternate\_test.m}
calls \emph{schurOneMlattice\_slb} to improve the filter designed with
\emph{tarczynski\_lowpass\_differentiator\_alternate\_test.m}. The low-pass
differentiator filter consists of $1-z^{-1}$ and a Schur one-multiplier lattice
correction filter. The filter specification is similar to that of
Section~\ref{sec:iir-sqp-slb-lowpass-differentiator-alt}:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_alternate_test_spec.m}
\end{small}

The PCLS SOCP optimised alternative Schur one-multiplier lattice filter
coefficients of the correction filter are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_alternate_test_k2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_alternate_test_c2_coef.m}
\end{small}

The corresponding transfer function numerator and denominator
polynomials of the correction filter are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_alternate_test_N2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_alternate_test_D2_coef.m}
\end{small}

Figure~\ref{fig:Schur-OneM-lattice-correction-lowpass-diff-alt-SOCP-PCLS}
shows the response of the alternative low-pass differentiator filter after PCLS
optimisation and
Figure~\ref{fig:Schur-OneM-lattice-correction-lowpass-differentiator-SOCP-PCLS-pz}
shows the pole-zero plot of the alternative low-pass differentiator filter after
PCLS optimisation. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_lowpass_differentiator_alternate_test_pcls_error_response}}
\caption{PCLS optimised error response of a low-pass differentiator filter
  composed of an alternative Schur one-multiplier lattice correction filter in
  series with $1-z^{-1}$.}
\label{fig:Schur-OneM-lattice-correction-lowpass-diff-alt-SOCP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_lowpass_differentiator_alternate_test_pcls_pz}}
\caption{Pole-zero plot of the PCLS optimised low-pass differentiator filter
  composed of an alternative Schur one-multiplier lattice correction filter in
  series with $1-z^{-1}$.}
\label{fig:Schur-OneM-lattice-correction-lowpass-diff-alt-SOCP-PCLS-pz}
\end{figure}
\clearpage
\subsubsection{\label{sec:SOCP-Schur-OneM-pipelined-lowpass-differentiator}Design of a low-pass differentiator filter with a pipelined  IIR Schur one-multiplier lattice correction filter using SOCP}
The Octave script
\emph{schurOneMlatticePipelined\_socp\_slb\_lowpass\_differentiator\_test.m}
calls \emph{schurOneMlatticePipelined\_slb} to improve the filter designed with
\emph{tarczynski\_lowpass\_differentiator\_test.m}. The low-pass
differentiator filter consists of $1-z^{-1}$ and a Schur one-multiplier lattice
correction filter implemented in the pipelined form shown in
Section~\ref{sec:State-variable-pipelined-One-multiplier-Schur-lattice-filter}.
The filter specification is similar to that of
Section~\ref{sec:iir-sqp-slb-lowpass-differentiator-alt}:
\begin{small}
\verbatiminput{schurOneMlatticePipelined_socp_slb_lowpass_differentiator_test_spec.m}
\end{small}

The PCLS SOCP optimised pipelined Schur one-multiplier lattice filter
coefficients of the correction filter are:
\begin{small}
\verbatiminput{schurOneMlatticePipelined_socp_slb_lowpass_differentiator_test_k2_coef.m}
\verbatiminput{schurOneMlatticePipelined_socp_slb_lowpass_differentiator_test_c2_coef.m}
\verbatiminput{schurOneMlatticePipelined_socp_slb_lowpass_differentiator_test_kk2_coef.m}
\verbatiminput{schurOneMlatticePipelined_socp_slb_lowpass_differentiator_test_ck2_coef.m}
\end{small}

The corresponding transfer function numerator and denominator
polynomials of the correction filter are:
\begin{small}
\verbatiminput{schurOneMlatticePipelined_socp_slb_lowpass_differentiator_test_N2_coef.m}
\verbatiminput{schurOneMlatticePipelined_socp_slb_lowpass_differentiator_test_D2_coef.m}
\end{small}

Figure~\ref{fig:Schur-OneM-lattice-pipelined-correction-lowpass-differentiator-SOCP-PCLS}
shows the response of the low-pass differentiator filter after PCLS
optimisation and
Figure~\ref{fig:Schur-OneM-lattice-pipelined-correction-lowpass-differentiator-SOCP-PCLS-pz}
shows the pole-zero plot of the low-pass differentiator filter after PCLS
optimisation. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlatticePipelined_socp_slb_lowpass_differentiator_test_pcls_error}}
\caption{PCLS optimised error response of a low-pass differentiator filter
  composed of a pipelined Schur one-multiplier lattice correction filter and
  $1-z^{-1}$.}
\label{fig:Schur-OneM-lattice-pipelined-correction-lowpass-differentiator-SOCP-PCLS}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlatticePipelined_socp_slb_lowpass_differentiator_test_pcls_pz}}
\caption{Pole-zero plot of the PCLS optimised low-pass differentiator filter
  composed of a pipelined Schur one-multiplier lattice correction filter in
  series with $1-z^{-1}$.}
\label{fig:Schur-OneM-lattice-pipelined-correction-lowpass-differentiator-SOCP-PCLS-pz}
\end{figure}

\subsubsection{\label{sec:SOCP-Schur-OneM-R2-lowpass-differentiator}Design of a low-pass differentiator filter with an IIR Schur one-multiplier lattice correction filter with R=2 using SOCP}
The Octave script
\emph{schurOneMlattice\_socp\_slb\_lowpass\_differentiator\_R2\_test.m}
designs a low-pass differentiator filter consisting of a Schur
one-multiplier lattice correction filter in series with $1-z^{-1}$ with
constraints on the squared-amplitude, phase, group delay and on the derivative
of the squared-amplitude with respect to angular frequency. The denominator of
the correction filter has terms only in $z^{-2}$ (ie: $R=2$). The filter
specification is:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_R2_test_spec.m}
\end{small}
The Schur one-multiplier lattice coefficients of the PCLS SOCP optimised
correction filter are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_R2_test_k2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_R2_test_epsilon2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_R2_test_c2_coef.m}
\end{small}
The corresponding correction filter numerator and denominator polynomial
coefficients are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_R2_test_N2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_lowpass_differentiator_R2_test_D2_coef.m}
\end{small}
Figure~\ref{fig:Schur-OneM-lattice-correction-lowpass-differentiator-R2}
shows the response error of the $R=2$ low-pass differentiator filter
after PCLS SOCP optimisation (with sample rate $f_{S}=1$).
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_lowpass_differentiator_R2_test_pcls_error}}
\caption{PCLS optimised response error of a low-pass differentiator
  filter composed of a Schur one-multiplier lattice correction filter with a
  denominator polynomial having terms only in $z^{-2}$ in series with $1-z^{-1}$.}
\label{fig:Schur-OneM-lattice-correction-lowpass-differentiator-R2}
\end{figure}
Figure~\ref{fig:Schur-OneM-lattice-correction-lowpass-differentiator-R2-corr}
shows the response of the $R=2$ correction filter for the low-pass
differentiator filter after PCLS SOCP optimisation (with sample rate $f_{S}=1$).
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_lowpass_differentiator_R2_test_pcls_correction}}
\caption{PCLS optimised response error of the correction filter of a low-pass
  differentiator filter composed of a Schur one-multiplier lattice 
  filter with a denominator polynomial having terms only in $z^{-2}$ in series
  with $1-z^{-1}$.}
\label{fig:Schur-OneM-lattice-correction-lowpass-differentiator-R2-corr}
\end{figure}
Figure~\ref{fig:Schur-OneM-lattice-correction-lowpass-differentiator-R2-pz} shows
the pole-zero plot of the $R=2$ low-pass differentiator filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_lowpass_differentiator_R2_test_pcls_pz}}
\caption{Pole-zero plot of the PCLS optimised low-pass differentiator
  filter composed of a Schur one-multiplier lattice correction filter with a
  denominator polynomial having terms only in $z^{-2}$ in series with $1-z^{-1}$.}
\label{fig:Schur-OneM-lattice-correction-lowpass-differentiator-R2-pz}
\end{figure}
\subsubsection{Design of a band-pass differentiator filter with an IIR Schur one-multiplier lattice correction filter using SOCP}
The Octave script
\emph{schurOneMlattice\_socp\_slb\_bandpass\_differentiator\_test.m}
calls \emph{schurOneMlattice\_slb} to improve the filter designed with
\emph{tarczynski\_bandpass\_differentiator\_test.m}. The band-pass
differentiator filter consists of $1-z^{-2}$ and a Schur one-multiplier lattice
correction filter. The filter specification is:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_differentiator_test_spec.m}
\end{small}

The PCLS SOCP optimised Schur one-multiplier lattice filter coefficients of the
correction filter are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_differentiator_test_k2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_differentiator_test_c2_coef.m}
\end{small}

The corresponding transfer function numerator and denominator polynomials of
the correction filter are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_differentiator_test_N1_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_bandpass_differentiator_test_D1_coef.m}
\end{small}

Figure~\ref{fig:Schur-OneM-lattice-correction-bandpass-differentiator-SOCP-PCLS}
shows the response error of the band-pass differentiator filter after PCLS
optimisation and
Figure~\ref{fig:Schur-OneM-lattice-correction-bandpass-differentiator-SOCP-PCLS-dAsqdw}
shows the pass-band \emph{dAsqdw} response of the band-pass differentiator
filter after PCLS optimisation. 
Figure~\ref{fig:Schur-OneM-lattice-correction-bandpass-differentiator-SOCP-PCLS-pz}
shows the pole-zero plot of the band-pass differentiator filter after PCLS
optimisation. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_bandpass_differentiator_test_error}}
\caption{PCLS optimised response error of a band-pass differentiator filter
  composed of a Schur one-multiplier lattice correction filter and $1-z^{-2}$.}
\label{fig:Schur-OneM-lattice-correction-bandpass-differentiator-SOCP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_bandpass_differentiator_test_dAsqdw}}
\caption{PCLS optimised pass-band dAsqdw response of a band-pass differentiator
  filter composed of a Schur one-multiplier lattice correction filter and
  $1-z^{-2}$.}
\label{fig:Schur-OneM-lattice-correction-bandpass-differentiator-SOCP-PCLS-dAsqdw}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_bandpass_differentiator_test_pz}}
\caption{Pole-zero plot of the PCLS optimised band-pass differentiator filter
  composed of a Schur one-multiplier lattice correction filter in series with
  $1-z^{-2}$.}
\label{fig:Schur-OneM-lattice-correction-bandpass-differentiator-SOCP-PCLS-pz}
\end{figure}
\clearpage
\subsubsection{\label{sec:Design-IIR-one-multiplier-Schur-lattice-hilbert-SOCP}Design of a one-multiplier IIR Schur lattice Hilbert filter with $R=2$ using SOCP}
The Octave script \emph{schurOneMlattice\_socp\_slb\_hilbert\_test.m} implements
the design of an IIR one-multiplier Schur lattice Hilbert filter with SOCP and 
PCLS. The specification of the filter is:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_hilbert_test_spec.m}
\end{small}
The initial filter is that of the Octave script 
\emph{iir\_sqp\_slb\_hilbert\_test.m} designed by
the method of \emph{Tarczynski et al.} with the Octave script 
\emph{tarczynski\_hilbert\_test.m}, as shown in 
Section~\ref{sec:Hilbert-transform-R-2-decimation-filter}.
The denominator polynomial of the filter has coefficients in $z^{2}$ only.
Figure~\ref{fig:Schur-one-multiplier-lattice-hilbert-filter-SOCP-PCLS} 
shows the response of the Hilbert filter after SOCP PCLS optimisation. The phase
response shown has been adjusted by the nominal group delay, $\omega{}\tau_{d}$.
The values shown on the phase axis of the phase response plot are multiples of
$\pi$ radians.
Figure~\ref{fig:Schur-one-multiplier-lattice-hilbert-filter-SOCP-PCLS-pz} shows
the pole-zero plot of the Hilbert filter after SOCP PCLS optimisation.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_hilbert_test_pcls_response}}
\caption{Schur one-multiplier lattice Hilbert filter, response after SOCP PCLS
  optimisation.}
\label{fig:Schur-one-multiplier-lattice-hilbert-filter-SOCP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_socp_slb_hilbert_test_pcls_pz}}
\caption{Schur one-multiplier lattice Hilbert filter, pole-zero plot after SOCP
  PCLS optimisation.}
\label{fig:Schur-one-multiplier-lattice-hilbert-filter-SOCP-PCLS-pz}
\end{figure}

The SOCP PCLS optimised Schur one-multiplier all-pass lattice and numerator tap 
coefficients of the Hilbert filter are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_hilbert_test_k2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_hilbert_test_epsilon2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_hilbert_test_p2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_hilbert_test_c2_coef.m}
\end{small}

The corresponding denominator and numerator transfer function polynomial
coefficients are:
\begin{small}
\verbatiminput{schurOneMlattice_socp_slb_hilbert_test_N2_coef.m}
\verbatiminput{schurOneMlattice_socp_slb_hilbert_test_D2_coef.m}
\end{small}
\clearpage
\subsection{Design of parallel one-multiplier IIR Schur all-pass lattice filters with SOCP optimisation}

\subsubsection{\label{sec:Design-parallel-Schur-one-mult-all-pass-lattice-low-pass-SOCP}Design of a low-pass filter with parallel IIR Schur one-multiplier all-pass lattice filters using SOCP}
The Octave script \emph{schurOneMPAlattice\_socp\_slb\_lowpass\_test.m}
implements the design of a low-pass IIR filter composed of the sum of two
parallel one-multiplier Schur lattice all-pass filters with SOCP and PCLS
optimisation. For such a filter the all-pass reflection coefficient sign
assignments can be recalculated without affecting the response. The
specification of the filter is:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_test_spec.m}
\end{small}
The initial parallel all-pass filters were designed by the Octave script 
\emph{tarczynski\_parallel\_allpass\_test.m} (with $flat\_delay=true$).
These initial filters are those used in
Section~\ref{sec:Design-IIR-filter-sum-all-pass-filters-pole-zero-constrained-group-delay}.

The low-pass filter SOCP PCLS optimised Schur one-multiplier all-pass lattice
coefficients are: 
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_test_A1k_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_test_A1epsilon_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_test_A2k_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_test_A2epsilon_coef.m}
\end{small}

The corresponding transfer function numerator and denominator polynomial
coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_test_N1_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_test_D1_coef.m}
\end{small}

Figures~\ref{fig:Parallel-Schur-OneMPA-lattice-lowpass-filter-SOCP-PCLS} 
and~\ref{fig:Parallel-Schur-OneMPA-lattice-lowpass-filter-SOCP-PCLS-pass}
show the overall and passband responses of the filter after SOCP PCLS
optimisation and
Figure~\ref{fig:Parallel-Schur-OneMPA-lattice-lowpass-filter-SOCP-PCLS-pz}
shows the pole-zero plot of the filter.
Figure~\ref{fig:Parallel-Schur-OneMPA-lattice-lowpass-filter-SOCP-PCLS-sens}
shows the coefficient sensitivity responses of the filter.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlattice_socp_slb_lowpass_test_response}}
\caption{Parallel Schur one-multiplier all-pass lattice low-pass filter,
  response after SOCP PCLS optimisation.}
\label{fig:Parallel-Schur-OneMPA-lattice-lowpass-filter-SOCP-PCLS}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlattice_socp_slb_lowpass_test_passband_response}}
\caption{Parallel Schur one-multiplier all-pass lattice low-pass filter,
  passband response after SOCP PCLS optimisation.}
\label{fig:Parallel-Schur-OneMPA-lattice-lowpass-filter-SOCP-PCLS-pass}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlattice_socp_slb_lowpass_test_pz}}
\caption{Parallel Schur one-multiplier all-pass lattice low-pass filter,
  pole-zero plot after SOCP PCLS optimisation.}
\label{fig:Parallel-Schur-OneMPA-lattice-lowpass-filter-SOCP-PCLS-pz}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlattice_socp_slb_lowpass_test_sensitivity}}
\caption{Parallel Schur one-multiplier all-pass lattice low-pass filter,
  coefficient sensitivity responses after SOCP PCLS optimisation.}
\label{fig:Parallel-Schur-OneMPA-lattice-lowpass-filter-SOCP-PCLS-sens}
\end{figure}
\clearpage
\subsubsection{\label{sec:Design-parallel-delay-Schur-one-mult-all-pass-lattice-low-pass-SOCP}Design of a low-pass filter with a delay in parallel with a one-multiplier  IIR Schur all-pass lattice filter using SOCP}
The Octave script \emph{schurOneMPAlatticeDelay\_socp\_slb\_lowpass\_test.m}
implements the design of a low-pass IIR filter composed of the sum of a delay
and a one-multiplier Schur lattice all-pass filter with SOCP and PCLS
optimisation. For such a filter the all-pass reflection coefficient sign
assignments can be recalculated without affecting the response.
The filter specification is similar to that described in
Section~\ref{sec:Design-IIR-filter-sum-delay-all-pass-filter-pole-zero-SOCP}:
\begin{small}
\verbatiminput{schurOneMPAlatticeDelay_socp_slb_lowpass_test_m_12_spec.m}
\end{small}
The initial all-pass filter was designed with the Octave function
\emph{WISE\_DA.m} using the \emph{WISE} method described in
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier} and is the
same as that used in
Section~\ref{sec:Design-IIR-filter-sum-delay-all-pass-filter-pole-zero-SOCP}.
The low-pass filter SOCP PCLS optimised Schur one-multiplier all-pass lattice
coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlatticeDelay_socp_slb_lowpass_test_m_12_A1k_coef.m}
\end{small}

The corresponding all-pass denominator and overall transfer function 
denominator polynomial coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlatticeDelay_socp_slb_lowpass_test_m_12_Da1_coef.m}
\end{small}
The overall transfer function numerator polynomial coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlatticeDelay_socp_slb_lowpass_test_m_12_Na1_coef.m}
\end{small}

Figure~\ref{fig:Parallel-delay-Schur-OneMPA-lattice-lowpass-filter-SOCP-PCLS} 
shows the passband and stopband responses of the filter after SOCP PCLS
optimisation and 
Figure~\ref{fig:Parallel-delay-Schur-OneMPA-lattice-lowpass-filter-SOCP-PCLS-pz}
shows the pole-zero plot of the filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDelay_socp_slb_lowpass_test_m_12_response}}
\caption{Parallel delay and Schur one-multiplier all-pass lattice low-pass
  filter, response after SOCP PCLS optimisation.}
\label{fig:Parallel-delay-Schur-OneMPA-lattice-lowpass-filter-SOCP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDelay_socp_slb_lowpass_test_m_12_pz}}
\caption{Parallel delay and Schur one-multiplier all-pass lattice low-pass
  filter, pole-zero plot after SOCP PCLS optimisation.}
\label{fig:Parallel-delay-Schur-OneMPA-lattice-lowpass-filter-SOCP-PCLS-pz}
\end{figure}
\clearpage
Similarly, the Octave script
\emph{schurOneMPAlatticeDelay\_socp\_slb\_lowpass\_flat\_delay\_test.m}
implements the design of a low-pass IIR filter with flat pass-band delay
composed of the sum of a delay
and a one-multiplier Schur lattice all-pass filter with SOCP and PCLS
optimisation. The filter specification is:
\begin{small}
\verbatiminput{schurOneMPAlatticeDelay_socp_slb_lowpass_flat_delay_test_m_12_spec.m}
\end{small}

Figure~\ref{fig:Parallel-delay-Schur-OneMPA-lowpass-flat-delay-SOCP-PCLS} 
shows the passband and stopband amplitude and passband delay responses of the
filter after SOCP PCLS optimisation and
Figure~\ref{fig:Parallel-delay-Schur-OneMPA-lowpass-flat-delay-SOCP-PCLS-pz}
shows the pole-zero plot of the filter.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDelay_socp_slb_lowpass_flat_delay_test_m_12_response}}
\caption{Parallel delay and Schur one-multiplier all-pass lattice low-pass
  filter with flat pass-band delay, amplitude and delay responses after SOCP PCLS optimisation.}
\label{fig:Parallel-delay-Schur-OneMPA-lowpass-flat-delay-SOCP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDelay_socp_slb_lowpass_flat_delay_test_m_12_pz}}
\caption{Parallel delay and Schur one-multiplier all-pass lattice low-pass
  filter with flat pass-band delay, pole-zero plot after SOCP PCLS optimisation.}
\label{fig:Parallel-delay-Schur-OneMPA-lowpass-flat-delay-SOCP-PCLS-pz}
\end{figure}

The low-pass filter SOCP PCLS optimised Schur one-multiplier all-pass lattice
filter coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlatticeDelay_socp_slb_lowpass_flat_delay_test_m_12_A1k_coef.m}
\end{small}

The overall transfer function and all-pass filter denominator polynomial
coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlatticeDelay_socp_slb_lowpass_flat_delay_test_m_12_Da1_coef.m}
\end{small}

The overall transfer function numerator polynomial coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlatticeDelay_socp_slb_lowpass_flat_delay_test_m_12_Na1_coef.m}
\end{small}
\clearpage
\subsubsection{\label{sec:Design-parallel-Schur-one-mult-all-pass-lattice-band-pass-SOCP}Design of a parallel one-multiplier IIR Schur  all-pass lattice band-pass filter using SOCP}
The Octave script \emph{schurOneMPAlattice\_socp\_slb\_bandpass\_test.m}
implements the design of a band-pass IIR filter composed of the difference of
two parallel one-multiplier Schur lattice all-pass filters with SOCP and PCLS
optimisation. The specification of the filter is:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_test_spec.m}
\end{small}
The initial parallel all-pass filters were designed by the Octave script 
\emph{tarczynski\_parallel\_allpass\_bandpass\_test.m}.
These initial filters are those used in
Section~\ref{sec:Design-IIR-filter-difference-all-pass-filters-pole-zero-constrained-group-delay}.
Figures~\ref{fig:Parallel-Schur-one-m-lattice-all-pass-bandpass-filter-SOCP-PCLS} 
and~\ref{fig:Parallel-Schur-one-m-lattice-all-pass-bandpass-filter-SOCP-PCLS-pass}
show the overall and passband responses of the filter after SOCP PCLS
optimisation.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlattice_socp_slb_bandpass_test_response}}
\caption{Parallel Schur one-multiplier all-pass lattice band-pass filter,
  response after SOCP PCLS optimisation.}
\label{fig:Parallel-Schur-one-m-lattice-all-pass-bandpass-filter-SOCP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlattice_socp_slb_bandpass_test_passband_response}}
\caption{Parallel Schur one-multiplier all-pass lattice band-pass filter,
  passband response after SOCP PCLS optimisation.}
\label{fig:Parallel-Schur-one-m-lattice-all-pass-bandpass-filter-SOCP-PCLS-pass}
\end{figure}

The band-pass filter SOCP PCLS optimised Schur one-multiplier
all-pass lattice coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_test_A1k_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_test_A1epsilon_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_test_A2k_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_test_A2epsilon_coef.m}
\end{small}

The corresponding coefficients of the all-pass filter denominator polynomial
coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_test_A1d_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_test_A2d_coef.m}
\end{small}

The corresponding coefficients of the overall filter transfer function
numerator and denominator polynomial coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_test_N2_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_test_D2_coef.m}
\end{small}
\clearpage
\subsubsection{\label{sec:Design-parallel-Schur-one-mult-all-pass-lattice-band-pass-Hilbert-SOCP}Design of a parallel one-multiplier IIR Schur all-pass lattice band-pass Hilbert filter using SOCP}
The Octave script \emph{schurOneMPAlattice\_socp\_slb\_bandpass\_hilbert\_test.m}
implements the design of a band-pass IIR Hilbert filter composed of the
difference of two parallel one-multiplier Schur lattice all-pass filters with
SOCP and PCLS optimisation. The specification of the filter is:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_hilbert_test_spec.m}
\end{small}
The initial parallel all-pass filters were designed by the Octave script 
\emph{tarczynski\_parallel\_allpass\_bandpass\_hilbert\_test.m}.
Figure~\ref{fig:Parallel-Schur-one-m-lattice-all-pass-bandpass-hilbert-filter-SOCP-PCLS} 
shows the overall and passband responses of the filter after SOCP PCLS
optimisation. The phase response shown is adjusted for the nominal delay.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlattice_socp_slb_bandpass_hilbert_test_response}}
\caption{Response of a parallel Schur one-multiplier all-pass lattice band-pass
  Hilbert filter after SOCP PCLS optimisation. The phase response shown is
  adjusted for the nominal delay.} 
\label{fig:Parallel-Schur-one-m-lattice-all-pass-bandpass-hilbert-filter-SOCP-PCLS}
\end{figure}

The band-pass filter PCLS SOCP optimised Schur one-multiplier
all-pass lattice coefficients are: 
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_hilbert_test_A1k_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_hilbert_test_A1epsilon_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_hilbert_test_A2k_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_hilbert_test_A2epsilon_coef.m}
\end{small}

The corresponding overall transfer function denominator and numerator polynomial
coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_hilbert_test_N2_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_bandpass_hilbert_test_D2_coef.m}
\end{small}
\clearpage
\subsubsection{\label{sec:Design-parallel-Schur-one-mult-all-pass-lattice-multi-band-pass-SOCP}Design of a parallel one-multiplier IIR Schur lattice multi-band-pass filter using SOCP}
The Octave script
\emph{schurOneMPAlattice\_socp\_slb\_lowpass\_to\_multiband\_test.m}
implements the design of a multi-band-pass IIR filter composed of the difference
of two parallel one-multiplier Schur lattice all-pass filters with SOCP and PCLS
optimisation. The specification of the filter is:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_to_multiband_test_spec.m}
\end{small}
The initial parallel all-pass filters are designed by the frequency
transformation of a prototype elliptic low-pass filter. The parallel all-pass
multi-band filter orders are $12$ and $8$. The SOCP PCLS optimised lattice coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_to_multiband_test_A1k_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_to_multiband_test_A1epsilon_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_to_multiband_test_A2k_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_to_multiband_test_A2epsilon_coef.m}
\end{small}

The corresponding all-pass lattice denominator polynomial coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_to_multiband_test_A1d_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_to_multiband_test_A2d_coef.m}
\end{small}

The overall transfer function numerator and denominator polynomial coefficients
are:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_to_multiband_test_N2_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_lowpass_to_multiband_test_D2_coef.m}
\end{small}

Figure~\ref{fig:Schur-one-multiplier-parallel-allpass-low-multiband-PCLS}
shows the amplitude and delay response of the PCLS SOCP optimised parallel
all-pass filter.
Figure~\ref{fig:Schur-one-multiplier-parallel-allpass-low-multiband-PCLS-pass}
shows the pass-band response of the filter.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlattice_socp_slb_lowpass_to_multiband_test_pcls}}
\caption{Schur one-multiplier parallel all-pass lattice low-pass to multi-band filter,
  response after SOCP PCLS optimisation. The initial filter is designed by a
  low-pass to multi-band frequency transformation.}
\label{fig:Schur-one-multiplier-parallel-allpass-low-multiband-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlattice_socp_slb_lowpass_to_multiband_test_pcls_pass}}
\caption{Schur one-multiplier parallel all-pass lattice low-pass to multi-band filter,
  pass-band response after SOCP PCLS optimisation. The initial filter is
  designed by a low-pass to multi-band frequency transformation.}
\label{fig:Schur-one-multiplier-parallel-allpass-low-multiband-PCLS-pass}
\end{figure}
\clearpage
Similarly, the Octave script
\emph{schurOneMPAlattice\_socp\_slb\_multiband\_test.m}
implements the design of a multi-band-pass IIR filter composed of the difference
of two parallel one-multiplier Schur lattice all-pass filters with SOCP and PCLS
optimisation. The specification of the filter is:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_multiband_test_spec.m}
\end{small}
The initial parallel all-pass filters are designed by the Octave script
\emph{tarczynski\_parallel\_allpass\_multiband\_test.m}. The SOCP PCLS optimised
lattice coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_multiband_test_A1k_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_multiband_test_A1epsilon_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_multiband_test_A2k_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_multiband_test_A2epsilon_coef.m}
\end{small}

The corresponding all-pass lattice denominator polynomial coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_multiband_test_A1d_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_multiband_test_A2d_coef.m}
\end{small}

The overall transfer function numerator and denominator polynomial coefficients
are:
\begin{small}
\verbatiminput{schurOneMPAlattice_socp_slb_multiband_test_N2_coef.m}
\verbatiminput{schurOneMPAlattice_socp_slb_multiband_test_D2_coef.m}
\end{small}

Figure~\ref{fig:Schur-one-multiplier-parallel-allpass-multiband-PCLS} shows the
amplitude and delay response of the PCLS SOCP optimised parallel all-pass filter.
Figure~\ref{fig:Schur-one-multiplier-parallel-allpass-multiband-PCLS-pass} shows
the pass-band response of the filter. 

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlattice_socp_slb_multiband_test_pcls}}
\caption{Schur one-multiplier parallel all-pass lattice multi-band filter, response after SOCP PCLS optimisation.}
\label{fig:Schur-one-multiplier-parallel-allpass-multiband-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlattice_socp_slb_multiband_test_pcls_pass}}
\caption{Schur one-multiplier parallel all-pass lattice multi-band filter,
  pass-band response after SOCP PCLS optimisation.}
\label{fig:Schur-one-multiplier-parallel-allpass-multiband-PCLS-pass}
\end{figure}
\clearpage
\subsection{Design of normalised-scaled IIR Schur lattice filters with SQP optimisation}
\subsubsection{Design of an approximately normalised-scaled IIR Schur lattice low-pass filter using SQP}
The Octave script \emph{schurNSlattice\_sqp\_slb\_lowpass\_test.m} implements
the design of a lowpass approximately normalised-scaled IIR Schur lattice filter
with PCLS and SQP. The filter coefficients are allowed to vary independently 
and the resulting filter is not, in fact, normalised-scaled. 
The initial filter is the ``IPZS-1'' of Section~\ref{sub:Deczkys-Example-3}. As
for the examples of 
Chapter~\ref{sec:Constrained-Optimisation-of-IIR-by-Quadratic-Programming-Pole-Zero-Location}
the SQP BFGS update is initialised by the diagonal of the Hessian matrix of the
squared error. The SQP loop for this example is called from the Octave
function \emph{schurNSlattice\_sqp\_mmse} exercised by the 
Octave script \emph{schurNSlattice\_sqp\_mmse\_test.m}. 
The \emph{schurNSlattice\_sqp\_mmse} function includes code that forces 
$s_{02}=-s_{20}$ and $s_{22}=s_{00}$. In neither case does this function
enforce normalised-scaling with the relations $s_{02}=\sqrt{1-s_{00}^{2}}$ and
$s_{22}=\sqrt{1-s_{20}^{2}}$. For simplicity, I have assumed that all
relationships between coefficients are linear.

The specification of the filter is:
\begin{small}
\verbatiminput{schurNSlattice_sqp_slb_lowpass_test_spec.m}
\end{small}

Figures~\ref{fig:Schur-normalised-scaled-lattice-lowpass-filter-SQP-PCLS} 
and~\ref{fig:Schur-normalised-scaled-lattice-lowpass-filter-SQP-PCLS-pass} 
show the overall and passband response of the filter after PCLS SQP optimisation.
Figure~\ref{fig:Schur-normalised-scaled-lattice-lowpass-filter-SQP-PCLS-pz} shows
the pole-zero plot of the filter after PCLS SQP optimisation.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurNSlattice_sqp_slb_lowpass_test_pcls_sxx_2}}
\caption{Schur approximately normalised-scaled lattice lowpass filter response
  after SQP PCLS optimisation.}
\label{fig:Schur-normalised-scaled-lattice-lowpass-filter-SQP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurNSlattice_sqp_slb_lowpass_test_pcls_sxx_2pass}}
\caption{Schur approximately normalised-scaled lattice lowpass filter passband
  response after SQP PCLS optimisation.}
\label{fig:Schur-normalised-scaled-lattice-lowpass-filter-SQP-PCLS-pass}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurNSlattice_sqp_slb_lowpass_test_pcls_sxx_2pz}}
\caption{Schur approximately normalised-scaled lattice lowpass filter, pole-zero
  plot after SQP PCLS optimisation.}
\label{fig:Schur-normalised-scaled-lattice-lowpass-filter-SQP-PCLS-pz}
\end{figure}

The PCLS SQP optimised Schur normalised-scaled all-pass lattice and numerator 
tap coefficients of the low-pass filter are:
\begin{small}
\verbatiminput{schurNSlattice_sqp_slb_lowpass_test_s10_2_coef.m}
\verbatiminput{schurNSlattice_sqp_slb_lowpass_test_s11_2_coef.m}
\verbatiminput{schurNSlattice_sqp_slb_lowpass_test_s20_2_coef.m}
\verbatiminput{schurNSlattice_sqp_slb_lowpass_test_s00_2_coef.m}
\verbatiminput{schurNSlattice_sqp_slb_lowpass_test_s02_2_coef.m}
\verbatiminput{schurNSlattice_sqp_slb_lowpass_test_s22_2_coef.m}
\end{small}

The corresponding transfer function numerator and denominator polynomial
coefficients are:
\begin{small}
\verbatiminput{schurNSlattice_sqp_slb_lowpass_test_N2_coef.m}
\verbatiminput{schurNSlattice_sqp_slb_lowpass_test_D2_coef.m}
\end{small}

The diagonal of the state covariance matrix, $K$, of the optimised filter is:
\begin{small}
\verbatiminput{schurNSlattice_sqp_slb_lowpass_test.diagK.val}
\end{small}

\clearpage
\subsubsection{\label{sec:Design-IIR-noralised-scaled-Schur-lattice-band-pass-SQP}Design of a normalised-scaled IIR Schur lattice band-pass filter with SQP optimisation}
The Octave script \emph{schurNSlattice\_sqp\_slb\_bandpass\_test.m} implements
the design of a band-pass IIR normalised-scaled Schur lattice filter with PCLS
and SQP. The specification of the filter is:
\begin{small}
\verbatiminput{schurNSlattice_sqp_slb_bandpass_test_spec.m}
\end{small}
The initial filter is that of the Octave script 
\emph{iir\_sqp\_slb\_bandpass\_test.m}, as shown in 
Section~\ref{sec:Band-pass-R-2-decimation-filter}.
The denominator polynomial of the filter has coefficients in $z^{2}$ only.

Figures~\ref{fig:Schur-normalised-scaled-lattice-band-pass-filter-SQP-PCLS} 
and~\ref{fig:Schur-normalised-scaled-lattice-band-pass-filter-SQP-PCLS-pass} 
show the overall and passband response of the band-pass filter after PCLS SQP
optimisation.
Figure~\ref{fig:Schur-normalised-scaled-lattice-band-pass-filter-SQP-PCLS-pz}
shows the pole-zero plot of the band-pass filter after PCLS SQP optimisation.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurNSlattice_sqp_slb_bandpass_test_pcls_sxx_2}}
\caption{Schur normalised-scaled lattice band-pass filter, response after SQP
  PCLS optimisation.} 
\label{fig:Schur-normalised-scaled-lattice-band-pass-filter-SQP-PCLS}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurNSlattice_sqp_slb_bandpass_test_pcls_sxx_2pass}}
\caption{Schur normalised-scaled lattice band-pass filter, passband response
  after SQP PCLS optimisation.}
\label{fig:Schur-normalised-scaled-lattice-band-pass-filter-SQP-PCLS-pass}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurNSlattice_sqp_slb_bandpass_test_pcls_sxx_2pz}}
\caption{Pole-zero plot of a Schur normalised-scaled lattice band-pass filter
  after PCLS SQP optimisation.}
\label{fig:Schur-normalised-scaled-lattice-band-pass-filter-SQP-PCLS-pz}
\end{figure}

The SQP PCLS optimised Schur normalised-scaled allpass lattice and numerator tap 
coefficients of the band-pass filter are:
\begin{small}
\verbatiminput{schurNSlattice_sqp_slb_bandpass_test_s00_2_coef.m}
\verbatiminput{schurNSlattice_sqp_slb_bandpass_test_s02_2_coef.m}
\verbatiminput{schurNSlattice_sqp_slb_bandpass_test_s22_2_coef.m}
\verbatiminput{schurNSlattice_sqp_slb_bandpass_test_s20_2_coef.m}
\verbatiminput{schurNSlattice_sqp_slb_bandpass_test_s10_2_coef.m}
\verbatiminput{schurNSlattice_sqp_slb_bandpass_test_s11_2_coef.m}
\end{small}

The corresponding transfer function denominator and numerator polynomial
coefficients are:
\begin{small}
\verbatiminput{schurNSlattice_sqp_slb_bandpass_test_N2_coef.m}
\verbatiminput{schurNSlattice_sqp_slb_bandpass_test_D2_coef.m}
\end{small}
\clearpage
\subsection{Design of parallel all-pass normalised-scaled IIR Schur lattice filters with SOCP optimisation}

\subsubsection{\label{sec:Design-parallel-Schur-norm-scaled-all-pass-lattice-low-pass-SOCP}Design of a parallel all-pass approximately normalised scaled IIR Schur lattice low-pass filter with SOCP optimisation}
The Octave script \emph{schurNSPAlattice\_socp\_slb\_lowpass\_test.m}
implements the design of a low-pass IIR filter composed of the
difference of two parallel approximately normalised scaled Schur lattice
all-pass filters with PCLS and SOCP optimisation. This design is only
approximately normalised-scaled since the s20 and s00 coefficients are
assumed to be independent rather than related by
$\sigma_{00}=\sqrt{1-\sigma_{20}^{2}}$. The design enforces
$\sigma_{02}=-\sigma_{20}$ and $\sigma_{s22}=\sigma_{00}$.
The initial parallel all-pass filters were designed by the Octave script 
\emph{tarczynski\_parallel\_allpass\_test.m}.
The specification of the filter is:
\begin{small}
\verbatiminput{schurNSPAlattice_socp_slb_lowpass_test_spec.m}
\end{small}

The low-pass filter SOCP PCLS optimised Schur
approximately normalised scaled all-pass lattice coefficients are: 
\begin{small}
\verbatiminput{schurNSPAlattice_socp_slb_lowpass_test_A1s20_coef.m}
\verbatiminput{schurNSPAlattice_socp_slb_lowpass_test_A1s00_coef.m}
\verbatiminput{schurNSPAlattice_socp_slb_lowpass_test_A2s20_coef.m}
\verbatiminput{schurNSPAlattice_socp_slb_lowpass_test_A2s00_coef.m}
\end{small}

\begin{comment}
The coefficients of the denominator polynomials of the parallel all-pass
lattice filters are:
\begin{small}
\verbatiminput{schurNSPAlattice_socp_slb_lowpass_test_A1d_coef.m}
\verbatiminput{schurNSPAlattice_socp_slb_lowpass_test_A2d_coef.m}
\end{small}

The coefficients of the overall filter transfer function
numerator and denominator polynomial coefficients are:
\begin{small}
\verbatiminput{schurNSPAlattice_socp_slb_lowpass_test_N2_coef.m}
\verbatiminput{schurNSPAlattice_socp_slb_lowpass_test_D2_coef.m}
\end{small}
\end{comment}

Figure~\ref{fig:Parallel-Schur-norm-scaled-lattice-all-pass-lowpass-filter-SOCP-PCLS} 
shows the overall and passband amplitude and group delay responses of the filter
after PCLS SOCP optimisation.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurNSPAlattice_socp_slb_lowpass_test_response}}
\caption{Response of a parallel all-pass approximately normalised-scaled Schur
  lattice low-pass filter after SOCP PCLS optimisation.} 
\label{fig:Parallel-Schur-norm-scaled-lattice-all-pass-lowpass-filter-SOCP-PCLS}
\end{figure}
\clearpage
\subsubsection{\label{sec:Design-parallel-Schur-norm-scaled-all-pass-lattice-band-pass-Hilbert-SOCP}Design of a parallel all-pass approximately normalised scaled IIR Schur  lattice band-pass Hilbert filter using SOCP}
The Octave script \emph{schurNSPAlattice\_socp\_slb\_bandpass\_hilbert\_test.m}
implements the design of a band-pass IIR Hilbert filter composed of the
difference of two parallel normalised scaled Schur lattice
all-pass filters with SOCP and PCLS optimisation. In fact, this design is only
approximately normalised-scaled since the s20 and s00 coefficients are
assumed to be independent rather than related by
$\sigma_{00}=\sqrt{1-\sigma_{20}^{2}}$. The design enforces
$\sigma_{02}=-\sigma_{20}$ and $\sigma_{s22}=\sigma_{00}$.
The specification of the filter is:
\begin{small}
\verbatiminput{schurNSPAlattice_socp_slb_bandpass_hilbert_test_spec.m}
\end{small}
The initial parallel all-pass filters were designed by the Octave script 
\emph{tarczynski\_parallel\_allpass\_bandpass\_hilbert\_test.m}.
Figure~\ref{fig:Parallel-Schur-norm-scaled-lattice-all-pass-bandpass-hilbert-filter-SOCP-PCLS} 
shows the overall and passband responses of the filter after SOCP PCLS
optimisation. The phase response shown is adjusted for the nominal delay.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurNSPAlattice_socp_slb_bandpass_hilbert_test_response}}
\caption{Response of a parallel Schur approximately normalised scaled all-pass
  lattice band-pass Hilbert filter after SOCP PCLS optimisation. The phase
  response shown is adjusted for the nominal delay.} 
\label{fig:Parallel-Schur-norm-scaled-lattice-all-pass-bandpass-hilbert-filter-SOCP-PCLS}
\end{figure}

The band-pass Hilbert filter SOCP PCLS optimised approximately normalised
scaled Schur all-pass lattice filter coefficients are: 
\begin{small}
\verbatiminput{schurNSPAlattice_socp_slb_bandpass_hilbert_test_A1s20_coef.m}
\verbatiminput{schurNSPAlattice_socp_slb_bandpass_hilbert_test_A1s00_coef.m}
\verbatiminput{schurNSPAlattice_socp_slb_bandpass_hilbert_test_A2s20_coef.m}
\verbatiminput{schurNSPAlattice_socp_slb_bandpass_hilbert_test_A2s00_coef.m}
\end{small}

The script simulates this filter with a uniform random noise input to the
\emph{schurNSlatticeFilter} function. The standard deviations of the all-pass
filter state variables are:

\begin{small}
\verbatiminput{schurNSPAlattice_socp_slb_bandpass_hilbert_test_A1stdx.m}
\verbatiminput{schurNSPAlattice_socp_slb_bandpass_hilbert_test_A2stdx.m}
\end{small}

Figure~\ref{fig:Parallel-Schur-norm-scaled-lattice-all-pass-bandpass-hilbert-filter-sim} 
shows the amplitude, phase and group delay responses of the simulated filter.
The phase response shown is adjusted for the nominal delay. The responses are
smoothed by a moving window filter. This may explain the shift in the phase
response shown.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurNSPAlattice_socp_slb_bandpass_hilbert_test_sim}}
\caption{Simulated response of a parallel all-pass approximately
  normalised-scaled Schur lattice band-pass Hilbert filter. The phase response
  shown is adjusted for the nominal delay.} 
\label{fig:Parallel-Schur-norm-scaled-lattice-all-pass-bandpass-hilbert-filter-sim}
\end{figure}
\clearpage
\section{\label{sec:Design-of-an-IIR-filters-with-a-sharp-transition-band-by-frequency-response-masking}Design of IIR filters with a sharp transition band by frequency response masking}
\subsection{\label{sec:Review-FRM-digital-filters}Review of Frequency Response Masking digital filters}
\emph{Frequency response masking} (FRM) is a technique for designing digital 
filters with sharp transition bands. Given a prototype or ``model'' low-pass 
filter, $G\left(z\right)$, the filter $G\left(z^M\right)$ has a pass-band width
and pass-band to stop-band transition width that is reduced by a factor $M$
compared to the model low-pass filter and also has $M$ images across the whole
frequency band. The ``masking'' filter, $F\left(z\right)$ selects the required 
filter image frequency response. The resulting filter is 
$G\left(z^M\right)F\left(z\right)$, illustrated in 
Figure~\ref{fig:Simple-frequency-response-masking-filter}.
\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{simple_frm_response}
\caption{Simple frequency response masking filter.}
\label{fig:Simple-frequency-response-masking-filter}
\end{figure}
This simple frequency response masking filter technique is only suitable for
designing narrow-band filters.
Lim~\cite{Lim_FrequencyResponseMaskingSharpDigitalFilters} describes the design 
of digital filters with sharp transition bands with wider bandwidths using
FIR model and masking filters.
Lu and Hinamoto~\cite{LuHinamoto_IIRFrequencyMaskingFiltersConeProgramming}
describe the design of digital filters with an IIR model filter and FIR masking
filters using a structure, shown in
Figure~\ref{fig:Lims-frequency-response-masking-filter-structure}, that is
similar to Lim's. The passband delay of $F_{a}\left(z\right)$ is $D$ so that
$F_{c}=z^{-D}-F_{a}\left(z\right)$ is complementary to $F_{a}\left(z\right)$.
\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{lim_frm_structure}
\caption{Lim's frequency response masking filter structure.}
\label{fig:Lims-frequency-response-masking-filter-structure}
\end{figure}

Johansson and
Wanhammar~\cite{JohanssonWanhammar_RecursiveDigitalFiltersFrequencyMasking}
describe design of frequency response masking filters with a model filter
consisting of parallel all-pass filters, FIR masking filters and the structure
shown in 
Figure~\ref{fig:Johansson-and-Wanhammar-frequency-response-masking-structure}.
Johansson and Wanhammar specify a delay line in one arm of the model filter
if approximately linear phase response is desired.
\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{johansson_frm_structure}
\caption{Johansson and Wanhammar's frequency response masking filter structure.}
\label{fig:Johansson-and-Wanhammar-frequency-response-masking-structure}
\end{figure}

In the following I use Lim's description of frequency response masking for the
two cases shown in 
Figure~\ref{fig:Frequency-response-masking-with-Lims-filter-structure}~\cite[Section
III, Figure 4]{Lim_FrequencyResponseMaskingSharpDigitalFilters}.
Figure~\ref{fig:Frequency-response-masking-with-Lims-filter-structure_a} shows
the response of a prototype filter a with frequency response,
$F_{a}\left(\omega\right)$, having
passband and stopband edge frequencies of $\theta$ and $\phi$ respectively. 
Figure~\ref{fig:Frequency-response-masking-with-Lims-filter-structure_b} shows
the response of the \emph{complementary} filter 
$F_{c}\left(z\right)=z^{-D}-F_{a}\left(z\right)$. 
Figure~\ref{fig:Frequency-response-masking-with-Lims-filter-structure_c} shows
the responses of the filters 
$F_{a}^{\prime}\left(z\right)=F_{a}\left(z^{M}\right)$ and 
$F_{c}^{\prime}\left(z\right)=F_{c}\left(z^{M}\right)$. Each response is
aliased into M images across the frequency band. The aliased response of the
model filter is masked by $F_{M_{a}}$ and the aliased response of the complement
to the model filter is masked by $F_{M_{c}}$. For example, in
Figure~\ref{fig:Frequency-response-masking-with-Lims-filter-structure_d}, 
$F_{M_{a}}$ has passband and stopband edge frequencies of 
$\omega_{M_{ap}}=\frac{2m\pi+\theta}{M}$ and 
$\omega_{M_{as}}=\frac{2\left(m+1\right)\pi-\phi}{M}$ respectively. Here 
$\omega_{M_{ap}}$ includes the $m$'th image band of the model filter and 
$\omega_{M_{as}}$ excludes the $m+1$'th image band of the model filter. The 
complementary masking filter, $F_{M_{c}}$, has passband and stopband edge 
frequencies of $\omega_{M_{cp}}=\frac{2m\pi-\theta}{M}$ and 
$\omega_{M_{cs}}=\frac{2m\pi+\phi}{M}$ respectively so that the $m-1$'th
image of the complementary filter is included and the $m$'th image is excluded.
The resulting frequency response masking filter, shown in 
Figure~\ref{fig:Frequency-response-masking-with-Lims-filter-structure_e}, has 
passband edge $\omega_{p}=\frac{2m\pi+\theta}{M}$ and stopband edge 
$\omega_{s}=\frac{2m\pi+\phi}{M}$. Alternatively,  
Figures~\ref{fig:Frequency-response-masking-with-Lims-filter-structure_f}
and~\ref{fig:Frequency-response-masking-with-Lims-filter-structure_g} show the 
frequency response masking filter for which the passband edge is 
$\omega_{p}=\frac{2m\pi-\phi}{M}$ and the stopband edge is
$\omega_{s}=\frac{2m\pi-\theta}{M}$. In this case the filter includes $m-1$
images of the model filter and $m-1$ images of the complementary filter.
\begin{figure}
\centering
\begin{subfigure}[b]{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{lim_frm_response_a}
\caption{}
\label{fig:Frequency-response-masking-with-Lims-filter-structure_a}
\end{subfigure}
\begin{subfigure}[b]{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{lim_frm_response_b}
\caption{}
\label{fig:Frequency-response-masking-with-Lims-filter-structure_b}
\end{subfigure}
\begin{subfigure}[b]{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{lim_frm_response_c}
\caption{}
\label{fig:Frequency-response-masking-with-Lims-filter-structure_c}
\end{subfigure}
\begin{subfigure}[b]{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{lim_frm_response_d}
\caption{}
\label{fig:Frequency-response-masking-with-Lims-filter-structure_d}
\end{subfigure}
\begin{subfigure}[b]{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{lim_frm_response_e}
\caption{}
\label{fig:Frequency-response-masking-with-Lims-filter-structure_e}
\end{subfigure}
\begin{subfigure}[b]{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{lim_frm_response_f}
\caption{}
\label{fig:Frequency-response-masking-with-Lims-filter-structure_f}
\end{subfigure}
\begin{subfigure}[b]{\textwidth}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{lim_frm_response_g}
\caption{}
\label{fig:Frequency-response-masking-with-Lims-filter-structure_g}
\end{subfigure}
\vspace{0.5cm}
\caption{Frequency response masking with Lim's filter structure.}
\label{fig:Frequency-response-masking-with-Lims-filter-structure}
\end{figure}

In order that $0<\theta<\phi<\pi$ in 
Figure~\ref{fig:Frequency-response-masking-with-Lims-filter-structure_a},
for Figure~\ref{fig:Frequency-response-masking-with-Lims-filter-structure_e}
\begin{align*}
m &= \lfloor\frac{\omega_{p}M}{2\pi}\rfloor\\
\theta &= \omega_{p}M-2m\pi\\
\phi &= \omega_{s}M-2m\pi
\end{align*}
and for Figure~\ref{fig:Frequency-response-masking-with-Lims-filter-structure_g}
\begin{align*}
m &= \lceil\frac{\omega_{s}M}{2\pi}\rceil\\
\theta &= 2m\pi-\omega_{s}M\\
\phi &= 2m\pi-\omega_{p}M
\end{align*}
where $\lfloor x \rfloor$ and $\lceil x \rceil$ represent the largest integer
less than $x$ and the smallest integer larger than $x$ respectively.
\clearpage
\subsection{\label{sec:FRM-IIR-model-2nd-Order-Cascade}Design of  an FRM digital filter with an IIR model filter consisting of a cascade of second-order sections using SOCP}
In this section I follow Lu and 
Hinamoto~\cite[Section V]{LuHinamoto_IIRFrequencyMaskingFiltersConeProgramming}
The FRM filter structure is shown in 
Figure~\ref{fig:Lims-frequency-response-masking-filter-structure}. The model
filter is an IIR filter of the form
\begin{align*}
F_{a}\left(z\right) &= \frac{a\left(z\right)}{d\left(z\right)}
\end{align*}
where
\begin{align*}
a\left(z\right) &= \sum^{n}_{k=0}a_{k}z^{-k}
\end{align*}
and $d\left(z\right)$ is a product of second order sections (with one first 
order section if $r$ is odd)
\begin{align*}
d\left(z\right) &= \begin{cases}
\left(1+d_{0}z^{-1}\right)
\prod^{\frac{r-1}{2}}_{k=1}\left(1+d_{k1}z^{-1}+d_{k2}z^{-2}\right),
&\text{if $r$ odd}\\
\prod^{\frac{r}{2}}_{k=1}\left(1+d_{k1}z^{-1}+d_{k2}z^{-2}\right),&\text{if $r$ even}
\end{cases}
\end{align*}
Define the two model filter coefficient vectors as
\begin{align*}
\boldsymbol{a}&=\left[\begin{array}{cccc}
a_{0} & a_{1} & \hdots & a_{n}\\
\end{array}\right]^{\top}
\end{align*}
and
\begin{align*}
\boldsymbol{d}&=\left[\begin{array}{c}
d_{0}\\
\boldsymbol{d}_{1}\\
\vdots\\
\boldsymbol{d}_{L}
\end{array}\right]\\
\boldsymbol{d}_{k}&=\left[\begin{array}{c}
d_{k1}\\
d_{k2}
\end{array}\right],\quad\text{for } 1\le k\le L\\
L&=\begin{cases}
\frac{r-1}{2},&\text{if $r$ odd}\\
\frac{r}{2},&\text{if $r$ even}
\end{cases}
\end{align*}
The masking filters are 
\begin{align*}
F_{M_{a}}\left(z\right)&=\sum_{k=0}^{n_{a}-1}p_{k}z^{-k}\\
F_{M_{c}}\left(z\right)&=\sum_{k=0}^{n_{c}-1}q_{k}z^{-k}
\end{align*}
$F_{M_{a}}\left(z\right)$ and $F_{M_{c}}\left(z\right)$ are assumed to have linear
phase responses; the lengths $n_{a}$ and $n_{c}$ are assumed to be both even
or odd; and the group delays of $F_{M_{a}}\left(z\right)$ and 
$F_{M_{c}}\left(z\right)$ are both 
$d=\max\left\{\frac{n_{a}-1}{2},\frac{n_{c}-1}{2}\right\}$ (if necessary, one 
filter is padded with extra delays).

The frequency response of the symmetric, linear phase, FIR masking filters
is (in the case of $F_{M_{a}}$)
\begin{align*}
F_{M_{a}} \left(\omega\right) &= \sum _{k=0}^{n_{a}-1}p_{k}e^{-\imath\omega k}\\
&= e^{-\imath\omega\frac{n_{a}-1}{2}}\begin{cases}
p_{\frac{n_{a}-1}{2}}+2\sum_{k=1}^{\frac{n_{a}-1}{2}}
p_{k+\frac{n_{a}-1}{2}}\cos k\omega,&\text{if $n_{a}$ odd}\\
2\sum_{k=1}^{\frac{n_{a}}{2}}
p_{k+\frac{n_{a}}{2}-1}\cos \left(k-\frac{1}{2}\right)\omega,
&\text{if $n_{a}$ even}
\end{cases}
\end{align*}

The desired passband group delay of the FRM filter is $D_{s}=d+MD$
where $D$ is the group delay of the model filter. The desired frequency
response of the FRM filter can be expressed as
\begin{align*}
e^{-\imath D_{s} \omega}H\left(\boldsymbol{x},\omega\right)
\end{align*}
where
\begin{align*}
H\left(\boldsymbol{x},\omega\right) &= \tilde{H}_{a}\left(M\omega\right)
\left[\boldsymbol{a}_{a}^{\top}\boldsymbol{c}_{a}\left(\omega\right)-
\boldsymbol{a}_{c}^{\top}\boldsymbol{c}_{c}\left(\omega\right)\right]+
\boldsymbol{a}_{c}^{\top}\boldsymbol{c}_{c}\left(\omega\right)\\
\tilde{H}_{a}\left(\omega\right) &= e^{\imath D\omega}
\frac{a\left(\omega\right)}{d\left(\omega\right)} = 
\frac{\boldsymbol{a}^{\top}\boldsymbol{v}\left(\omega\right)}
{d\left(\omega\right)}\\
\boldsymbol{v}\left(\omega\right) &= 
\boldsymbol{c}\left(\omega\right) + \imath\boldsymbol{s}\left(\omega\right)\\ 
\boldsymbol{c}\left(\omega\right) &= \left[\begin{array}{ccc}
\cos D\omega & \hdots & \cos \left(D-n\right)\omega
\end{array}\right]^{\top}\\
\boldsymbol{s}\left(\omega\right) &= \left[\begin{array}{ccc}
\sin D\omega & \hdots & \sin \left(D-n\right)\omega
\end{array}\right]^{\top}\\
v_{1}\left(\omega\right) &= \cos \omega - \imath \sin\omega \\
\boldsymbol{v}_{2}\left(\omega\right) &= \left[\begin{array}{c}
\cos \omega\\
\cos 2\omega
\end{array}\right]-\imath\left[\begin{array}{c}
\sin \omega\\
\sin 2\omega
\end{array}\right]
\end{align*}
and
\begin{align*}
d\left(\omega\right) &= \begin{cases}
\left[1 + d_{0}v_{1}\left(\omega\right)\right]
\prod^{L}_{k=1}\left[1 + \boldsymbol{d}_{k}^{\top}
\boldsymbol{v}_{2}\left(\omega\right)\right],&\text{if $r$ odd} \\
\prod^{L}_{k=1}\left[1 + \boldsymbol{d}_{k}^{\top}
\boldsymbol{v}_{2}\left(\omega\right)\right],&\text{if $r$ even}
\end{cases}\\
\boldsymbol{a}_{a}&=\begin{cases}
\left[ \begin{array}{cccc}
p_{\frac{n_{a}-1}{2}} & p_{\frac{n_{a}+1}{2}} & \hdots & p_{n_{a}-1}
\end{array}\right]^{\top}, &  \text{if $n_{a}$ odd} \\
\left[ \begin{array}{cccc}
p_{\frac{n_{a}}{2}} & p_{\frac{n_{a}}{2}+1} & \hdots & p_{n_{a}-1}
\end{array}\right]^{\top}, &  \text{if $n_{a}$ even} 
\end{cases}\\
\boldsymbol{c}_{a}\left(\omega\right) &= \begin{cases}
\left[\begin{array}{cccc}
1 & 2 \cos \omega & \hdots & 2 \cos \frac{\left(n_{a}-1\right)}{2}\omega
\end{array}\right]^{\top}, &  \text{if $n_{a}$ odd} \\
\left[\begin{array}{ccc}
2 \cos \frac{1}{2}\omega & \hdots & 2 \cos \frac{\left(n_{a}-1\right)}{2}\omega
\end{array}\right]^{\top}, &  \text{if $n_{a}$ even} \\
\end{cases}\\
\boldsymbol{a}_{c}&=\begin{cases}
\left[ \begin{array}{cccc}
q_{\frac{n_{c}-1}{2}} & q_{\frac{n_{c}+1}{2}} & \hdots & q_{n_{c}-1}
\end{array}\right]^{\top}, &  \text{if $n_{c}$ odd} \\
\left[ \begin{array}{cccc}
q_{\frac{n_{c}}{2}} & q_{\frac{n_{c}}{2}+1} & \hdots & q_{n_{c}-1}
\end{array}\right]^{\top}, &  \text{if $n_{c}$ even} 
\end{cases}\\
\boldsymbol{c}_{c}\left(\omega\right) &= \begin{cases}
\left[\begin{array}{cccc}
1 & 2 \cos \omega & \hdots & 2 \cos \frac{\left(n_{c}-1\right)}{2}\omega
\end{array}\right]^{\top}, &  \text{if $n_{c}$ odd} \\
\left[\begin{array}{ccc}
2 \cos \frac{1}{2}\omega & \hdots & 2 \cos \frac{\left(n_{c}-1\right)}{2}\omega
\end{array}\right]^{\top}, &  \text{if $n_{c}$ even} \\
\end{cases}
\end{align*}
The gradient of $H\left(\boldsymbol{x},\omega\right)$ is
\begin{align*}
\frac{\partial H\left(\boldsymbol{x},\omega\right)}{\partial \boldsymbol{x}} &=
\left[ \begin{array}{c}
y\left(\omega\right)\frac{\partial \tilde{H}_{a}\left(M\omega\right)}
{\partial \boldsymbol{a}}\\
y\left(\omega\right)\frac{\partial \tilde{H}_{a}\left(M\omega\right)}
{\partial \boldsymbol{d}}\\
\tilde{H}_{a}\left(M\omega\right)\boldsymbol{c}_{a}\left(\omega\right)\\
\left[ 1-\tilde{H}_{a}\left(M\omega\right)\right]
\boldsymbol{c}_{c}\left(\omega\right)\\
\end{array}\right]^{\top}
\end{align*}
where
\begin{align*}
y\left(\omega\right)&=\boldsymbol{a}_{a}^{\top}\boldsymbol{c}_{a}\left(\omega\right)-
\boldsymbol{a}_{c}^{\top}\boldsymbol{c}_{c}\left(\omega\right)\\
\frac{\partial \tilde{H}_{a}\left(\omega\right)}{\partial\boldsymbol{a}}&=
\frac{\boldsymbol{v}\left(\omega\right)}{d\left(\omega\right)}\\
\frac{\partial \tilde{H}_{a}\left(\omega\right)}{\partial\boldsymbol{d}}&=
\left[\begin{array}{cccc}
\frac{\partial \tilde{H}_{a}\left(\omega\right)}{\partial d_{0}}&
\frac{\partial \tilde{H}_{a}\left(\omega\right)}{\partial\boldsymbol{d_{1}}}&
\hdots&
\frac{\partial \tilde{H}_{a}\left(\omega\right)}{\partial\boldsymbol{d_{L}}}
\end{array}\right]
\end{align*}
with
\begin{align*}
\frac{\partial \tilde{H}_{a}\left(\omega\right)}{\partial d_{0}}&=
-\tilde{H}_{a}\left(\omega\right)\frac{v_{1}\left(\omega\right)}
{1+d_{0}v_{1}\left(\omega\right)}\\
\frac{\partial \tilde{H}_{a}\left(\omega\right)}{\partial \boldsymbol{d}_{k}}&=
-\tilde{H}_{a}\left(\omega\right)\frac{\boldsymbol{v}_{2}\left(\omega\right)}
{1+\boldsymbol{d}_{k}^{\top}\boldsymbol{v}_{2}\left(\omega\right)},\quad
\text{for $1\le k \le L$}
\end{align*}
The overall parameter vector is
\begin{align*}
\boldsymbol{x}&=\left[\begin{array}{c}
\boldsymbol{a}\phantom{_{a}}\\
\boldsymbol{d}\phantom{_{a}}\\
\boldsymbol{a}_{a}\\
\boldsymbol{a}_{c}
\end{array}\right]
\end{align*}
The calculation of the FRM zero-phase frequency response,
$H\left(\boldsymbol{x},\omega\right)$, and its gradient with respect to the 
coefficients is implemented in the Octave function \emph{frm2ndOrderCascade}.

The SOCP optimisation of an FRM filter is implemented in the Octave function
\emph{frm2ndOrderCascade\_socp}. The Octave script
\emph{frm2ndOrderCascade\_socp\_test.m} designs a FRM filter similar to that
of the example shown by Lu and 
Hinamoto~\cite[Section V.E]{LuHinamoto_IIRFrequencyMaskingFiltersConeProgramming}.
The specification of the FRM filter is:
\begin{small}
\verbatiminput{frm2ndOrderCascade_socp_test_spec.m}
\end{small}

For comparison, the example of Lu and Hinamoto uses $mn=14$, $n_{a}=41$ and $D=9$
and has a nominal passband delay of $101$ samples. The SOCP pass minimises the
combined error of the pass and stop bands at the constraint frequencies. Those 
frequencies are chosen so that half are concentrated in the union of the regions
$[0.9f_{p} \;\; f_{p}]$ and $[f_{s} \;\; 1.1f_{s}]$. I found during debugging that
the best results were obtained if the model filter denominator polynomial second
order sections are rearranged after each of the first few SOCP passes. The 
initial filter uses FIR filter and IIR model filter numerator polynomials 
calculated by the Octave \emph{remez} function and a model filter denominator 
polynomial of $\boldsymbol{d}=1$. This initial FRM filter results in a better 
FRM filter than the initial FRM filter calculated by the Octave script
\emph{tarczynski\_frm\_iir\_test.m}.

The model filter numerator polynomial is
\begin{small}
\verbatiminput{frm2ndOrderCascade_socp_test_a_coef.m}
\end{small}
The model filter denominator polynomial is
\begin{small}
\verbatiminput{frm2ndOrderCascade_socp_test_d_coef.m}
\end{small}
The masking filter polynomial is
\begin{small}
\verbatiminput{frm2ndOrderCascade_socp_test_aa_coef.m}
\end{small}
The complementary masking filter polynomial is
\begin{small}
\verbatiminput{frm2ndOrderCascade_socp_test_ac_coef.m}
\end{small}

Figure~\ref{fig:2nd-order-cascade-frequency-response-masking-filter-response} 
shows the overall response of the resulting FRM filter. 
Figure~\ref{fig:2nd-order-cascade-frequency-response-masking-filter-passband} 
shows the passband response of the FRM filter. 
Figure~\ref{fig:2nd-order-cascade-frequency-response-masking-filter-model} 
shows the decimated response of the FRM model filter. 
Figure~\ref{fig:2nd-order-cascade-frequency-response-masking-filter-masking} 
shows the responses of the FRM masking filters.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{frm2ndOrderCascade_socp_test_x1}}
\caption{Second order cascade FRM filter response.}
\label{fig:2nd-order-cascade-frequency-response-masking-filter-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{frm2ndOrderCascade_socp_test_x1pass}}
\caption{Second order cascade FRM filter passband response.}
\label{fig:2nd-order-cascade-frequency-response-masking-filter-passband}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{frm2ndOrderCascade_socp_test_x1model}}
\caption{Second order cascade FRM model filter response.}
\label{fig:2nd-order-cascade-frequency-response-masking-filter-model}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{frm2ndOrderCascade_socp_test_x1mask}}
\caption{Second order cascade FRM masking filter responses.}
\label{fig:2nd-order-cascade-frequency-response-masking-filter-masking}
\end{figure}
Figure~\ref{fig:2nd-order-cascade-frequency-response-remez-comparison} compares
the amplitude response of the FRM filter with that of a linear-phase FIR 
filter having a group delay of $79$ samples designed with the \emph{remez} 
function:
\begin{small}
\begin{verbatim}
br=remez(((M*D)+d)*2,[0 fpass fstop 0.5]*2,[1 1 0 0],[1 Was]);
\end{verbatim}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{frm2ndOrderCascade_socp_test_remez_comparison}}
\caption{Comparison of the second order cascade FRM filter with a linear-phase
  FIR filter designed with \emph{remez}.}
\label{fig:2nd-order-cascade-frequency-response-remez-comparison}
\end{figure}
\clearpage
\subsection{Design of  an FRM digital filter with an IIR model filter represented in gain-pole-zero form using SOCP and PCLS optimisation}
This section describes an FRM filter with the \emph{Lim} FRM filter structure
shown in Figure~\ref{fig:Lims-frequency-response-masking-filter-structure} in
which the model filter is represented in gain-pole-zero form and the FIR masking
filters are symmetric (ie: linear phase). The squared-amplitude and the group 
delay of the MMSE optimised FRM filter response are constrained by the PCLS 
algorithm of \emph{Selesnick}, \emph{Lang} and \emph{Burrus}, described in 
Section~\ref{sub:Choice-of-Active-Constraints}. 

Using the notation of Section~\ref{sec:FRM-IIR-model-2nd-Order-Cascade}, the
desired passband group delay of the FRM filter is 
$D_{s}=d_{mask}+M_{model}D_{model}$, where $D_{model}$ is the delay of the pure delay
branch of the FRM filter, $M_{model}$ is the decimation factor
of the IIR model filter and $d_{mask}$ is the group delay of the linear phase 
FIR masking filters. If $R\left(\omega\right)e^{\imath\phi_{R}\left(\omega\right)}$ 
is the frequency response of the IIR model filter then the \emph{zero phase} 
response of the FRM filter is 
\begin{align*}
H\left(\boldsymbol{x},\omega\right) &= 
A\left(\omega\right)R\left(M\omega\right)e^{\imath \phi_{Z}\left(M\omega\right)}
+ B\left(\omega\right)
\end{align*}
where
\begin{align*}
\phi_{Z}\left(\omega\right)&= D\omega + \phi_{R}\left(\omega\right)\\
A\left(\omega\right) &=
\boldsymbol{a}_{a}^{\top}\boldsymbol{c}_{a}\left(\omega\right)-
\boldsymbol{a}_{c}^{\top}\boldsymbol{c}_{c}\left(\omega\right) \\
B\left(\omega\right) &=
\boldsymbol{a}_{c}^{\top}\boldsymbol{c}_{c}\left(\omega\right)
\end{align*}

The squared-magnitude and phase responses of the zero phase response of the 
FRM filter are
\begin{align*}
\left|H\left(\omega\right)\right|^{2}&=
A^{2}\left(\omega\right)R^{2}\left(M\omega\right)+B^{2}\left(\omega\right) +
2A\left(\omega\right)B\left(\omega\right)
R\left(M\omega\right)\cos\phi_{Z}\left(M\omega\right)\\
\phi_{H}\left(\omega\right) &= \arctan 
\frac{A\left(\omega\right)R\left(M\omega\right)\sin\phi_{Z}\left(M\omega\right)}
{A\left(\omega\right)R\left(M\omega\right)\cos\phi_{Z}\left(M\omega\right) + 
B\left(\omega\right)}
\end{align*}

The group delay response, $T\left(\omega\right)$, of the zero phase response 
of the FRM filter (ie: the group delay error of the FRM 
filter, $-\frac{\partial \phi_{H}}{\partial\omega}$) is given by 
\begin{align*}
\left|H\left(\omega\right)\right|^{2}T\left(\omega\right) =&
  -\left(A^{2}\left(\omega\right)R^{2}\left(M\omega\right)+
   A\left(\omega\right)B\left(\omega\right)R\left(M\omega\right)
   \cos\phi_{Z}\left(M\omega\right)\right)
   \frac{\partial\phi_{Z}\left(M\omega\right)}{\partial\omega} \hdots \\
& -A\left(\omega\right)B\left(\omega\right)\sin\phi_{Z}\left(M\omega\right)
   \frac{\partial R\left(M\omega\right)}{\partial\omega} \hdots \\
& +R\left(M\omega\right)\sin\phi_{Z}\left(M\omega\right)
\left(A\left(\omega\right)\frac{\partial B\left(\omega\right)}{\partial\omega}
-B\left(\omega\right)\frac{\partial A\left(\omega\right)}{\partial\omega}\right)
\end{align*}
where
\begin{align*}
\frac{\partial \phi_{Z}\left(M\omega\right)}{\partial\omega} &=
DM+\frac{\partial \phi_{R}\left(M\omega\right)}{\partial\omega}\\
\frac{\partial A\left(\omega\right)}{\partial\omega} &=
\boldsymbol{a}_{a}^{\top}\boldsymbol{s}_{a}\left(\omega\right)-
\boldsymbol{a}_{c}^{\top}\boldsymbol{s}_{c}\left(\omega\right) \\
\frac{\partial B\left(\omega\right)}{\partial\omega} &=
\boldsymbol{a}_{c}^{\top}\boldsymbol{s}_{c}\left(\omega\right) \\
\boldsymbol{s}_{a}\left(\omega\right) &= \begin{cases}
-2\left[\begin{array}{cccc}
0 & \sin \omega & \hdots & \frac{\left(n_{a}-1\right)}{2}
                           \sin\frac{\left(n_{a}-1\right)}{2}\omega
\end{array}\right]^{\top}, & \text{if $n_{a}$ odd} \\
-2\left[\begin{array}{ccc}
\sin \frac{1}{2}\omega & \hdots & \frac{\left(n_{a}-1\right)}{2}
                           \sin\frac{\left(n_{a}-1\right)}{2}\omega
\end{array}\right]^{\top}, & \text{if $n_{a}$ even} \\
\end{cases}\\
\boldsymbol{s}_{c}\left(\omega\right) &= \begin{cases}
-2\left[\begin{array}{cccc}
0 & \sin \omega & \hdots & \frac{\left(n_{c}-1\right)}{2}
                           \sin\frac{\left(n_{c}-1\right)}{2}\omega
\end{array}\right]^{\top}, & \text{if $n_{c}$ odd} \\
-2\left[\begin{array}{ccc}
\sin \frac{1}{2}\omega & \hdots & \frac{\left(n_{c}-1\right)}{2}
                                  \sin\frac{\left(n_{c}-1\right)}{2}\omega
\end{array}\right]^{\top}, & \text{if $n_{c}$ even} \\
\end{cases}
\end{align*}
The gradients of $\left|H\left(\omega\right)\right|^{2}$ with respect to the 
coefficients are
\begin{align*}
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{r}}=
&\phantom{-}2\left(A^{2}\left(\omega\right)R\left(M\omega\right)
+A\left(\omega\right)B\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)\right)
\frac{\partial R\left(M\omega\right)}{\partial\boldsymbol{r}} \hdots \\
&-2A\left(\omega\right)B\left(\omega\right)R\left(M\omega\right)
\sin\phi_{Z}\left(M\omega\right)
\frac{\partial \phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}} \\
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{a}}=
&\phantom{+}2\left(A\left(\omega\right)R^{2}\left(M\omega\right)+
B\left(\omega\right)R\left(M\omega\right)\cos\phi_{Z}\left(M\omega\right)\right)
\frac{\partial A\left(\omega\right)}{\partial\boldsymbol{a}} \hdots \\
&+2\left(B\left(\omega\right)+
A\left(\omega\right)R\left(M\omega\right)\cos\phi_{Z}\left(M\omega\right)\right)
\frac{\partial B\left(\omega\right)}{\partial\boldsymbol{a}}
\end{align*}
where $\boldsymbol{r}$ represents the coefficients of the IIR model filter,
and $\boldsymbol{a}$ represents the coefficients of both the masking filter, 
$\boldsymbol{a}_{a}$, and the complementary masking filter, $\boldsymbol{a}_{c}$.

The gradients of $T\left(\omega\right)$ with respect to the coefficients are
given by
\begin{align*}
&\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{r}}
T\left(\omega\right)+\left|H\left(\omega\right)\right|^{2}
\frac{\partial T\left(\omega\right)}{\partial\boldsymbol{r}}=\hdots \\
& \quad -\left(A^{2}\left(\omega\right)R^{2}\left(M\omega\right) 
+A\left(\omega\right)B\left(\omega\right)R\left(M\omega\right)
\cos\phi_{Z}\left(M\omega\right)\right)
\frac{\partial^{2}\phi_{R}\left(M\omega\right)}
{\partial\omega\partial\boldsymbol{r}} \hdots \\
& \quad -\left(2A^{2}\left(\omega\right)R\left(M\omega\right)
+A\left(\omega\right)B\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)\right)
\frac{\partial\phi_{Z}\left(M\omega\right)}{\partial\omega} 
\frac{\partial R\left(M\omega\right)}{\partial\boldsymbol{r}} \hdots \\
& \quad +A\left(\omega\right)B\left(\omega\right)R\left(M\omega\right)
\sin\phi_{Z}\left(M\omega\right)
\frac{\partial\phi_{Z}\left(M\omega\right)}{\partial\omega}
\frac{\partial\phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}} \hdots \\
& \quad -A\left(\omega\right)B\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)
\frac{\partial R\left(M\omega\right)}{\partial\omega} 
\frac{\partial\phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}} \hdots \\
& \quad -A\left(\omega\right)B\left(\omega\right)\sin\phi_{Z}\left(M\omega\right)
\frac{\partial^{2}R\left(M\omega\right)}{\partial\omega\partial\boldsymbol{r}}
\hdots \\
& \quad +\sin\phi_{Z}\left(M\omega\right)
\frac{\partial R\left(M\omega\right)}{\partial\boldsymbol{r}}
\left(A\left(\omega\right)\frac{\partial B\left(\omega\right)}{\partial\omega}
-B\left(\omega\right)\frac{\partial A\left(\omega\right)}{\partial\omega}\right)
\hdots \\
& \quad +R\left(M\omega\right)\cos\phi_{Z}\left(M\omega\right)
\frac{\partial\phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}}
\left(A\left(\omega\right)\frac{\partial B\left(\omega\right)}{\partial\omega} 
-B\left(\omega\right)\frac{\partial A\left(\omega\right)}{\partial\omega}\right)
\end{align*}
and
\begin{align*}
&\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{a}}
T\left(\omega\right)+\left|H\left(\omega\right)\right|^{2}
\frac{\partial T\left(\omega\right)}{\partial\boldsymbol{a}}=\hdots \\
& \quad -\left(2A\left(\omega\right)R^{2}\left(M\omega\right)
+B\left(\omega\right)R\left(M\omega\right)\cos\phi_{Z}\left(M\omega\right)\right)
\frac{\partial\phi_{Z}\left(M\omega\right)}{\partial\omega} 
\frac{\partial A\left(\omega\right)}{\partial\boldsymbol{a}} \hdots \\
& \quad -A\left(\omega\right)R\left(M\omega\right)
\cos\phi_{Z}\left(M\omega\right)
\frac{\partial\phi_{Z}\left(M\omega\right)}{\partial\omega} 
\frac{\partial B\left(\omega\right)}{\partial\boldsymbol{a}} \hdots \\
& \quad -\sin\phi_{Z}\left(M\omega\right)
\frac{\partial R\left(M\omega\right)}{\partial\omega} \left(
A\left(\omega\right)\frac{\partial B\left(\omega\right)}{\partial\boldsymbol{a}} 
+B\left(\omega\right)\frac{\partial A\left(\omega\right)}{\partial\boldsymbol{a}}
\right) \hdots \\
& \quad -R\left(M\omega\right)\sin\phi_{Z}\left(M\omega\right)\left(
\frac{\partial A\left(\omega\right)}{\partial\omega} 
\frac{\partial B\left(\omega\right)}{\partial\boldsymbol{a}}
-\frac{\partial B\left(\omega\right)}{\partial\omega} 
\frac{\partial A\left(\omega\right)}{\partial\boldsymbol{a}} \right)\hdots \\
& \quad +R\left(M\omega\right)\sin\phi_{Z}\left(M\omega\right)\left(
A\left(\omega\right)
\frac{\partial^{2} B\left(\omega\right)}{\partial\omega\partial\boldsymbol{a}} 
-B\left(\omega\right)
\frac{\partial^{2} A\left(\omega\right)}{\partial\omega\partial\boldsymbol{a}}
\right)
\end{align*}
The amplitude, phase and group delay responses and gradients of the IIR model 
filter are calculated by the Octave functions \emph{iirA}, \emph{iirP} and
\emph{iirT}. The derivative with respect to frequency of the IIR model filter
amplitude response, $\frac{\partial R}{\partial\omega}$, is derived in
Appendix~\ref{app:Gradient-IIR-filter-amplitude-response-wrt-frequency} 
and calculated by the Octave function \emph{iirdelAdelw}. The Octave function
\emph{iir\_frm.m} returns the low pass FRM filter squared-magnitude and
group delay error responses and their gradients. 

The Octave function \emph{iir\_frm\_socp\_mmse.m} finds the SOCP solution that
optimises the coefficients of a filter response calculated by
\emph{iir\_frm.m} with the required linear amplitude and group delay
constraints. To avoid numerical problems, \emph{iir\_frm\_socp\_mmse.m} sets
the \emph{SeDuMi} parameter \emph{pars.eps} to $1e-6$ rather than the default
$1e-8$. The Octave function \emph{iir\_frm\_slb.m} implements the PCLS
algorithm for finding the constraint frequencies. The Octave script
\emph{iir\_frm\_socp\_slb\_test.m} designs an FRM filter with the following
specification:
\begin{small}
\verbatiminput{iir_frm_socp_slb_test_spec.m}
\end{small}
The passband edge frequency is the same as that of the design example given by 
Lu and Hinamoto~\cite[Section V.E]{LuHinamoto_IIRFrequencyMaskingFiltersConeProgramming},
namely $0.300$, but the stop band edge frequency is relaxed from $0.305$ to 
$0.31125$. Both FIR masking filters have length $41$. The initial filter is 
designed by the Octave script \emph{tarczynski\_frm\_iir\_test.m}
with the WISE method of \emph{Tarczynski et al.} (as shown in 
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}). 
Figure~\ref{fig:iir-frm-initial-response} shows the overall response of 
the initial FRM filter. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_socp_slb_test_initial_response}}
\caption{FRM gain-pole-zero format IIR model filter with WISE optimisation,
  initial response.}
\label{fig:iir-frm-initial-response}
\end{figure}
After SOCP and PCLS optimisation of the initial response
the resulting IIR model filter numerator polynomial is
\begin{small}
\verbatiminput{iir_frm_socp_slb_test_a_coef.m}
\end{small}
and the IIR model filter denominator polynomial is
\begin{small}
\verbatiminput{iir_frm_socp_slb_test_d_coef.m}
\end{small}
The FIR masking filter polynomial is
\begin{small}
\verbatiminput{iir_frm_socp_slb_test_aa_coef.m}
\end{small}
The complementary FIR masking filter polynomial is
\begin{small}
\verbatiminput{iir_frm_socp_slb_test_ac_coef.m}
\end{small}
Figure~\ref{fig:iir-frm-socp-pcls-response} 
shows the overall response of the resulting SOCP optimised, PCLS constrained
FRM filter. Figure~\ref{fig:iir-frm-socp-pcls-passband-response} 
shows the passband response of the resulting FRM filter. 
Figure~\ref{fig:iir-frm-socp-pcls-mask-response} 
shows the responses of the resulting FRM masking filters. 
Figure~\ref{fig:iir-frm-socp-pcls-model-response} 
shows the decimated response of the resulting FRM model filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_socp_slb_test_pcls_response}}
\caption{FRM gain-pole-zero format IIR model filter with SOCP and PCLS
  optimisation, overall response.}
\label{fig:iir-frm-socp-pcls-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_socp_slb_test_pcls_passband_response}}
\caption{FRM gain-pole-zero format IIR model filter with SOCP and PCLS
  optimisation, passband response.}
\label{fig:iir-frm-socp-pcls-passband-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_socp_slb_test_pcls_mask_response}}
\caption{FRM gain-pole-zero format IIR model filter with SOCP and PCLS
  optimisation, masking filter responses.}
\label{fig:iir-frm-socp-pcls-mask-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_socp_slb_test_pcls_model_response}}
\caption{FRM gain-pole-zero format IIR model filter with SOCP and PCLS
  optimisation, model filter response.}
\label{fig:iir-frm-socp-pcls-model-response}
\end{figure}
\clearpage
\subsection{\label{sec:FRM-filter-allpass-model-filter-gain-pole-zero-SOCP-PCLS}Design of  an FRM digital filter with an allpass model filter represented in gain-pole-zero form using SOCP and PCLS optimisation}
This section describes an FRM filter with the structure shown in
Figure~\ref{fig:Johansson-and-Wanhammar-frequency-response-masking-structure},
and an all-pass filter. For simplicity the model filters consist of an
allpass filter in parallel with a pure delay and the FIR masking filters are
of equal odd length and are symmetric (ie: the FIR masking filters are even
order and linear phase). The squared-amplitude and the group delay of the MMSE
optimised FRM filter response are constrained by the PCLS algorithm of
\emph{Selesnick}, \emph{Lang} and \emph{Burrus}, described in
Section~\ref{sub:Choice-of-Active-Constraints}.

Using the notation of Section~\ref{sec:FRM-IIR-model-2nd-Order-Cascade}, the
desired passband group delay of the FRM filter is $D_{s}=d+MD$,
where $D$ is the group delay of the model filter, $M$ is the decimation factor
of the model filter and $d$ is the group delay of the linear phase FIR masking
filters. The \emph{zero phase} response of the FRM filter is 
\begin{align*}
H\left(\boldsymbol{x},\omega\right) &= 
e^{\imath \left[DM\omega + \phi_{R}\left(M\omega\right)\right]}A\left(\omega\right) +
B\left(\omega\right)
\end{align*}
where $\phi_{R}\left(\omega\right)$ is the phase response of the allpass branch
of the model filter and:
\begin{align*}
A\left(\omega\right) &=
\frac{\boldsymbol{a}_{a}^{\top}\boldsymbol{c}_{a}\left(\omega\right)+
\boldsymbol{a}_{c}^{\top}\boldsymbol{c}_{c}\left(\omega\right)}{2} \\
B\left(\omega\right) &=
\frac{\boldsymbol{a}_{a}^{\top}\boldsymbol{c}_{a}\left(\omega\right)-
\boldsymbol{a}_{c}^{\top}\boldsymbol{c}_{c}\left(\omega\right)}{2}
\end{align*}

The squared-magnitude and phase responses of the zero phase response of the 
FRM filter are:
\begin{align*}
\left|H\left(\omega\right)\right|^{2}&=
A^{2}\left(\omega\right)+B^{2}\left(\omega\right) +
2A\left(\omega\right)B\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)\\
\phi_{H}\left(\omega\right) &= \arctan \frac{
A\left(\omega\right)\sin\phi_{Z}\left(M\omega\right)}{
A\left(\omega\right)\cos\phi_{Z}\left(M\omega\right) + B\left(\omega\right)}
\end{align*}
where $\phi_{Z}\left(\omega\right)=D\omega + \phi_{R}\left(\omega\right)$.

The group delay response, $T\left(\omega\right)$, of the zero phase response 
of the FRM filter (ie: the group delay error of the FRM filter) is
given by:
\begin{align*}
\left|H\left(\omega\right)\right|^{2}T\left(\omega\right) =&
 -\left(A^{2}\left(\omega\right)+A\left(\omega\right)B\left(\omega\right)
  \cos\phi_{Z}\left(M\omega\right)\right)
  \frac{\partial\phi_{Z}\left(M\omega\right)}{\partial\omega} \hdots \\
& -B\left(\omega\right)\sin\phi_{Z}\left(M\omega\right)
  \frac{\partial A\left(\omega\right)}{\partial\omega} \hdots \\
& +A\left(\omega\right)\sin\phi_{Z}\left(M\omega\right)
  \frac{\partial B\left(\omega\right)}{\partial\omega}
\end{align*}
where:
\begin{align*}
\frac{\partial \phi_{Z}\left(M\omega\right)}{\partial\omega} &=
DM+\frac{\partial \phi_{R}\left(M\omega\right)}{\partial\omega}\\
\frac{\partial A\left(\omega\right)}{\partial\omega} &=
\frac{\boldsymbol{a}_{a}^{\top}\boldsymbol{s}_{a}\left(\omega\right)+
\boldsymbol{a}_{c}^{\top}\boldsymbol{s}_{c}\left(\omega\right)}{2} \\
\frac{\partial B\left(\omega\right)}{\partial\omega} &=
\frac{\boldsymbol{a}_{a}^{\top}\boldsymbol{s}_{a}\left(\omega\right)-
\boldsymbol{a}_{c}^{\top}\boldsymbol{s}_{c}\left(\omega\right)}{2} \\
\boldsymbol{s}_{a}\left(\omega\right) &= 
-2\left[\begin{array}{cccc}
0 & \sin \omega & \hdots & \frac{\left(n_{a}-1\right)}{2}
                           \sin \frac{\left(n_{a}-1\right)}{2}\omega
\end{array}\right]^{\top} \\
\boldsymbol{s}_{c}\left(\omega\right) &= 
-2\left[\begin{array}{cccc}
0 & \sin \omega & \hdots & \frac{\left(n_{c}-1\right)}{2}
                           \sin \frac{\left(n_{c}-1\right)}{2}\omega
\end{array}\right]^{\top}
\end{align*}
The gradients of $\left|H\left(\omega\right)\right|^{2}$ with respect to the 
coefficients are:
\begin{align*}
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{r}}=&
-2A\left(\omega\right)B\left(\omega\right)\sin\phi_{Z}\left(M\omega\right)
\frac{\partial \phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}} \\
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{a}}=&
2\left(A\left(\omega\right)+B\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)
\right)\frac{\partial A\left(\omega\right)}{\partial\boldsymbol{a}}+
2\left(B\left(\omega\right)+A\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)
\right)\frac{\partial B\left(\omega\right)}{\partial\boldsymbol{a}}
\end{align*}
where $\boldsymbol{r}$ represents the coefficients of the allpass model filter,
and $\boldsymbol{a}$ represents the coefficients of both the masking filter, 
$\boldsymbol{a}_{a}$, and the complementary masking filter, $\boldsymbol{a}_{c}$.

The gradients of $\phi_{H}\left(\omega\right)$ with respect to the 
coefficients are:
\begin{align*}
\left|H\left(\omega\right)\right|^{2}
\frac{\partial \phi_{H}\left(\omega\right)}{\partial\boldsymbol{r}}=&
A\left(\omega\right)\left[A\left(\omega\right)+
 B\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)\right]
\frac{\partial \phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}} \\
\left|H\left(\omega\right)\right|^{2}
\frac{\partial \phi_{H}\left(\omega\right)}{\partial\boldsymbol{a}}=&
\sin\phi_{Z}\left(M\omega\right)\left[
B\left(\omega\right)\frac{\partial A\left(\omega\right)}{\partial\boldsymbol{a}}-
A\left(\omega\right)\frac{\partial B\left(\omega\right)}{\partial\boldsymbol{a}}
\right]
\end{align*}

The gradients of $T\left(\omega\right)$ with respect to the coefficients are
given by:
\begin{align*}
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{r}}
T\left(\omega\right)+\left|H\left(\omega\right)\right|^{2}
\frac{\partial T\left(\omega\right)}{\partial\boldsymbol{r}}=&
-\left(A^{2}\left(\omega\right)+A\left(\omega\right)B\left(\omega\right)
 \cos\phi_{Z}\left(M\omega\right)\right)
\frac{\partial^{2}\phi_{Z}\left(M\omega\right)}
     {\partial\boldsymbol{r}\partial\omega} \hdots \\
&+A\left(\omega\right)B\left(\omega\right)\sin\phi_{Z}\left(M\omega\right)
\frac{\partial\phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}}
\frac{\partial\phi_{Z}\left(M\omega\right)}{\partial\omega} \hdots \\
&+A\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)
\frac{\partial\phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}}
\frac{\partial B\left(\omega\right)}{\partial\omega} \hdots \\
&-B\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)
\frac{\partial\phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}}
\frac{\partial A\left(\omega\right)}{\partial\omega} \\
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{a}}
T\left(\omega\right)+\left|H\left(\omega\right)\right|^{2}
\frac{\partial T\left(\omega\right)}{\partial\boldsymbol{a}}=& 
-\left(2A\left(\omega\right)+
B\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)\right)
\frac{\partial A\left(\omega\right)}{\partial\boldsymbol{a}} 
\frac{\partial\phi_{Z}\left(M\omega\right)}{\partial\omega} \hdots \\
&-A\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)
\frac{\partial B\left(\omega\right)}{\partial\boldsymbol{a}} 
\frac{\partial\phi_{Z}\left(M\omega\right)}{\partial\omega} \hdots \\
&+\sin\phi_{Z}\left(M\omega\right)
\frac{\partial A\left(\omega\right)}{\partial\boldsymbol{a}} 
\frac{\partial B\left(\omega\right)}{\partial\omega} 
-\sin\phi_{Z}\left(M\omega\right)
\frac{\partial B\left(\omega\right)}{\partial\boldsymbol{a}} 
\frac{\partial A\left(\omega\right)}{\partial\omega} \hdots \\
&+A\left(\omega\right)\sin\phi_{Z}\left(M\omega\right)
\frac{\partial^{2}B\left(\omega\right)}{\partial\boldsymbol{a}\partial\omega}
-B\left(\omega\right)\sin\phi_{Z}\left(M\omega\right)
\frac{\partial^{2} A\left(\omega\right)}{\partial\boldsymbol{a}\partial\omega}
\end{align*}

The values and gradients of $\phi_{R}\left(\omega\right)$ are calculated by the
Octave \emph{allpassP} and \emph{allpassT} functions. 

The Octave function
\emph{iir\_frm\_allpass.m} returns the low pass FRM filter squared-magnitude and
group delay error responses and their gradients. It is exercised by the Octave
script \emph{iir\_frm\_allpass\_test.m}. The Octave function
\emph{iir\_frm\_allpass\_socp\_mmse} finds the SOCP solution that optimises 
the coefficients of a filter response calculated by \emph{iir\_frm\_allpass}
with the required amplitude and group delay constraints. The Octave 
function \emph{iir\_frm\_allpass\_slb} implements the PCLS algorithm for 
finding the constraint frequencies.

The Octave script \emph{iir\_frm\_allpass\_socp\_slb\_test.m} designs an FRM
filter with the following specification:
\begin{small}
\verbatiminput{iir_frm_allpass_socp_slb_test_spec.m}
\end{small}
The passband edge frequency is are the same as for the design example given by 
Lu and Hinamoto~\cite[Section V.E]{LuHinamoto_IIRFrequencyMaskingFiltersConeProgramming},
namely $0.300$, but the stop band edge frequency is relaxed slightly from 
$0.305$ to $0.31$. Both FIR masking filters have length $41$.
The initial filter is designed by the Octave script 
\emph{tarczynski\_frm\_allpass\_test.m} with the WISE method of
\emph{Tarczynski et al.} as shown in 
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}. 
Figure~\ref{fig:iir-frm-allpass-initial-response} shows the overall response of 
the initial FRM filter. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_allpass_socp_slb_test_initial_response}}
\caption{FRM gain-pole-zero format allpass model filter with WISE optimisation,
  initial response.}
\label{fig:iir-frm-allpass-initial-response}
\end{figure}
After SOCP and PCLS optimisation of the initial filter the resulting
model filter allpass filter denominator polynomial is
\begin{small}
\verbatiminput{iir_frm_allpass_socp_slb_test_r_coef.m}
\end{small}
The FIR masking filter polynomial is
\begin{small}
\verbatiminput{iir_frm_allpass_socp_slb_test_aa_coef.m}
\end{small}
The complementary FIR masking filter polynomial is
\begin{small}
\verbatiminput{iir_frm_allpass_socp_slb_test_ac_coef.m}
\end{small}
Figure~\ref{fig:iir-frm-allpass-socp-pcls-response} 
shows the overall response of the resulting SOCP optimised, PCLS constrained
FRM filter. 
Figure~\ref{fig:iir-frm-allpass-socp-pcls-passband-response} 
shows the passband response of the resulting FRM filter. 
Figure~\ref{fig:iir-frm-allpass-socp-pcls-mask-response} 
shows the responses of the resulting FRM masking filters. 
Figure~\ref{fig:iir-frm-allpass-socp-pcls-model-response} 
shows the response of the resulting FRM model filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_allpass_socp_slb_test_pcls_response}}
\caption{FRM gain-pole-zero format allpass model filter with SOCP and PCLS
  optimisation, overall response.}
\label{fig:iir-frm-allpass-socp-pcls-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_allpass_socp_slb_test_pcls_passband_response}}
\caption{FRM gain-pole-zero format allpass model filter, passband response with
  SOCP and PCLS optimisation.}
\label{fig:iir-frm-allpass-socp-pcls-passband-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_allpass_socp_slb_test_pcls_mask_response}}
\caption{FRM gain-pole-zero format allpass model filter with SOCP and PCLS
  optimisation, masking filter responses.}
\label{fig:iir-frm-allpass-socp-pcls-mask-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_allpass_socp_slb_test_pcls_model_response}}
\caption{FRM gain-pole-zero format allpass model filter with SOCP and PCLS
  optimisation, model filter response.}
\label{fig:iir-frm-allpass-socp-pcls-model-response}
\end{figure}
\clearpage
\subsection{Design of  an FRM digital filter with an IIR model filter consisting of parallel allpass filters}
Figure~\ref{fig:Johansson-and-Wanhammar-frequency-response-masking-structure}
shows an FRM filter with a model filter consisting of parallel allpass filters.
The filter transfer function is
\begin{align*}
H\left(z\right)&= 
\frac{1}{2}\left[R\left(z^{M}\right)+S\left(z^{M}\right)\right]
F_{M_{a}}\left(z\right) +
\frac{1}{2}\left[R\left(z^{M}\right)-S\left(z^{M}\right)\right]
F_{M_{c}}\left(z\right)\\
\end{align*}
where $R\left(z\right)$ and $S\left(z\right)$ are allpass filters and, as
previously, $F_{M_{a}}\left(z\right)$ and $F_{M_{c}}\left(z\right)$ are the masking
and complementary masking filters
\begin{align*}
F_{M_{a}}\left(z\right)&=\sum_{k=0}^{n_{a}-1}p_{k}z^{-k}\\
F_{M_{c}}\left(z\right)&=\sum_{k=0}^{n_{c}-1}q_{k}z^{-k}
\end{align*}
 
An equivalent filter is
\begin{align*}
H\left(z\right)&=R\left(z^{M}\right)A\left(z\right)+
                 S\left(z^{M}\right)B\left(z\right)
\end{align*}
where
\begin{align*}
A\left(z\right)&=
\frac{1}{2}\left[F_{M_{a}}\left(z\right)+F_{M_{c}}\left(z\right)\right] 
= \sum_{k=0}^{n_{m}-1}a_{k}z^{-k}\\
B\left(z\right)&=
\frac{1}{2}\left[F_{M_{a}}\left(z\right)-F_{M_{c}}\left(z\right)\right] 
=\sum_{k=0}^{n_{m}-1}b_{k}z^{-k}
\end{align*}
$n_{m}$ is the larger of $n_{a}$ and $n_{c}$ and the $a_{k}$ or $b_{k}$ are
zero-padded as required. If $\phi_{R}\left(\omega\right)$ and
$\phi_{S}\left(\omega\right)$ are the phase responses of the allpass filters 
$R\left(z\right)$ and $S\left(z\right)$, then 
\begin{align*}
H\left(\omega\right)&=
e^{\imath\phi_{R}\left(M\omega\right)}
\sum_{k=0}^{n_{m}-1}a_{k}e^{-\imath k\omega}+
e^{\imath\phi_{S}\left(M\omega\right)}
\sum_{k=0}^{n_{m}-1}b_{k}e^{-\imath k\omega}\\
&=\boldsymbol{c}_{R}\boldsymbol{a}+\boldsymbol{c}_{S}\boldsymbol{b}
-\imath\left(\boldsymbol{s}_{R}\boldsymbol{a}+
             \boldsymbol{s}_{S}\boldsymbol{b}\right)
\end{align*}
where
\begin{align*}
\boldsymbol{a}&=\left[a_{0} ... a_{n_{m}-1}\right]^{\top}\\
\boldsymbol{b}&=\left[b_{0} ... b_{n_{m}-1}\right]^{\top}\\
\boldsymbol{v}&=\left[0 ... n_{m}-1\right]\\
\boldsymbol{c}_{R}&=\cos\left[ \boldsymbol{v}\omega - 
                               \phi_{R}\left(M\omega\right)\right]\\
\boldsymbol{c}_{S}&=\cos\left[ \boldsymbol{v}\omega - 
                               \phi_{S}\left(M\omega\right)\right]\\
\boldsymbol{s}_{R}&=\sin\left[ \boldsymbol{v}\omega - 
                               \phi_{R}\left(M\omega\right)\right]\\
\boldsymbol{s}_{S}&=\sin\left[ \boldsymbol{v}\omega - 
                               \phi_{S}\left(M\omega\right)\right]
\end{align*}

The squared-amplitude and phase responses of $H\left(z\right)$ are
\begin{align*}
\left|H\left(\omega\right)\right|^{2}&=
\left(\boldsymbol{c}_{R}\boldsymbol{a}+
\boldsymbol{c}_{S}\boldsymbol{b}\right)^{2}+
\left(\boldsymbol{s}_{R}\boldsymbol{a}+
\boldsymbol{s}_{S}\boldsymbol{b}\right)^{2}\\
\phi_{H}\left(\omega\right)&=-\arctan 
\frac{\boldsymbol{s}_{R}\boldsymbol{a}+\boldsymbol{s}_{S}\boldsymbol{b}}
     {\boldsymbol{c}_{R}\boldsymbol{a}+\boldsymbol{c}_{S}\boldsymbol{b}}
\end{align*}
The group delay response is given by
\begin{align*}
\left|H\left(\omega\right)\right|^{2}T\left(\omega\right)&=
\left(\boldsymbol{c}_{R}\boldsymbol{a}+
      \boldsymbol{c}_{S}\boldsymbol{b}\right)
\left(\frac{\partial\boldsymbol{s}_{R}}{\partial\omega}\boldsymbol{a}+
      \frac{\partial\boldsymbol{s}_{S}}{\partial\omega}\boldsymbol{b}\right)-
\left(\boldsymbol{s}_{R}\boldsymbol{a}+
      \boldsymbol{s}_{S}\boldsymbol{b}\right)
\left(\frac{\partial\boldsymbol{c}_{R}}{\partial\omega}\boldsymbol{a}+
      \frac{\partial\boldsymbol{c}_{S}}{\partial\omega}\boldsymbol{b}\right)
\end{align*}
where
\begin{align*}
\frac{\partial\boldsymbol{c}_{R}}{\partial\omega}&=
-\left[\boldsymbol{v}-\frac{\partial\phi_{R}\left(M\omega\right)}{\partial\omega}
\right]\circ\boldsymbol{s}_{R}\\
\frac{\partial\boldsymbol{c}_{S}}{\partial\omega}&=
-\left[\boldsymbol{v}-\frac{\partial\phi_{S}\left(M\omega\right)}{\partial\omega}
\right]\circ\boldsymbol{s}_{S}\\
\frac{\partial\boldsymbol{s}_{R}}{\partial\omega}&=
\phantom{-}\left[\boldsymbol{v}-\frac{\partial\phi_{R}\left(M\omega\right)}
{\partial\omega}\right]\circ\boldsymbol{c}_{R}\\
\frac{\partial\boldsymbol{s}_{S}}{\partial\omega}&=
\phantom{-}\left[\boldsymbol{v}-\frac{\partial\phi_{S}\left(M\omega\right)}
{\partial\omega}\right]\circ\boldsymbol{c}_{S}
\end{align*}
The $\circ$ symbol represents the \emph{Hadamard} or element-wise product.

The gradients of the squared amplitude response are
\begin{align*}
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{r}}
&=\phantom{-} 2\left(\boldsymbol{c}_{R}\boldsymbol{a}+
\boldsymbol{c}_{S}\boldsymbol{b}\right)
\frac{\partial\boldsymbol{c}_{R}}{\partial\boldsymbol{r}}\boldsymbol{a}+
2\left(\boldsymbol{s}_{R}\boldsymbol{a}+
\boldsymbol{s}_{S}\boldsymbol{b}\right)
\frac{\partial\boldsymbol{s}_{R}}{\partial\boldsymbol{r}}\boldsymbol{a}\\
&=\phantom{-} 2\left(
\left(\boldsymbol{c}_{S}\boldsymbol{b}\right)
\left(\boldsymbol{s}_{R}\boldsymbol{a}\right)-
\left(\boldsymbol{s}_{S}\boldsymbol{b}\right)
\left(\boldsymbol{c}_{R}\boldsymbol{a}\right)\right)
\frac{\partial\phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}}\\
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{s}}
&=\phantom{-} 2\left(
\boldsymbol{c}_{R}\boldsymbol{a}+
\boldsymbol{c}_{S}\boldsymbol{b}\right)
\frac{\partial\boldsymbol{c}_{S}}{\partial\boldsymbol{s}}\boldsymbol{b}+
2\left(\boldsymbol{s}_{R}\boldsymbol{a}+
\boldsymbol{s}_{S}\boldsymbol{b}\right)
\frac{\partial\boldsymbol{s}_{S}}{\partial\boldsymbol{s}}\boldsymbol{b}\\
&=-2\left(
\left(\boldsymbol{c}_{S}\boldsymbol{b}\right)
\left(\boldsymbol{s}_{R}\boldsymbol{a}\right)-
\left(\boldsymbol{s}_{S}\boldsymbol{b}\right)
\left(\boldsymbol{c}_{R}\boldsymbol{a}\right)\right)
\frac{\partial\phi_{S}\left(M\omega\right)}{\partial\boldsymbol{s}}\\
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{a}}
&=\phantom{-} 2\left(\boldsymbol{c}_{R}\boldsymbol{a}+
         \boldsymbol{c}_{S}\boldsymbol{b}\right)\boldsymbol{c}_{R}+
  2\left(\boldsymbol{s}_{R}\boldsymbol{a}+
         \boldsymbol{s}_{S}\boldsymbol{b}\right)\boldsymbol{s}_{R}\\
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{b}}
&=\phantom{-} 2\left(\boldsymbol{c}_{R}\boldsymbol{a}+
         \boldsymbol{c}_{S}\boldsymbol{b}\right)\boldsymbol{c}_{S}+
  2\left(\boldsymbol{s}_{R}\boldsymbol{a}+
         \boldsymbol{s}_{S}\boldsymbol{b}\right)\boldsymbol{s}_{S}
\end{align*}

The gradients of the group delay response are given by
\begin{align*}
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{r}}
T\left(\omega\right)+\left|H\left(\omega\right)\right|^{2}
\frac{\partial T\left(\omega\right)}{\partial\boldsymbol{r}} =& 
\phantom{+}\boldsymbol{s}_{R}\boldsymbol{a}
\left(\frac{\partial\boldsymbol{s}_{R}}{\partial\omega}\boldsymbol{a}+
      \frac{\partial\boldsymbol{s}_{S}}{\partial\omega}\boldsymbol{b}\right)
\frac{\partial\phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}}
+\left(\boldsymbol{c}_{R}\boldsymbol{a}+
      \boldsymbol{c}_{S}\boldsymbol{b}\right)
\frac{\partial^{2}\boldsymbol{s}_{R}}{\partial\boldsymbol{r}\partial\omega}
\boldsymbol{a}\\
&+\boldsymbol{c}_{R}\boldsymbol{a}
\left(\frac{\partial\boldsymbol{c}_{R}}{\partial\omega}\boldsymbol{a}+
      \frac{\partial\boldsymbol{c}_{S}}{\partial\omega}\boldsymbol{b}\right)
\frac{\partial\phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}}
-\left(\boldsymbol{s}_{R}\boldsymbol{a}+
      \boldsymbol{s}_{S}\boldsymbol{b}\right)
\frac{\partial^{2}\boldsymbol{c}_{R}}{\partial\boldsymbol{r}\partial\omega}
\boldsymbol{a} \\
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{s}}
T\left(\omega\right)+\left|H\left(\omega\right)\right|^{2}
\frac{\partial T\left(\omega\right)}{\partial\boldsymbol{s}} =&
\phantom{+}\boldsymbol{s}_{S}\boldsymbol{b}
\left(\frac{\partial\boldsymbol{s}_{R}}{\partial\omega}\boldsymbol{a}+
      \frac{\partial\boldsymbol{s}_{S}}{\partial\omega}\boldsymbol{b}\right)
\frac{\partial\phi_{S}\left(M\omega\right)}{\partial\boldsymbol{s}}
+\left(\boldsymbol{c}_{R}\boldsymbol{a}+
      \boldsymbol{c}_{S}\boldsymbol{b}\right)
\frac{\partial^{2}\boldsymbol{s}_{S}}{\partial\boldsymbol{s}\partial\omega}
\boldsymbol{b}\\
&+\boldsymbol{c}_{S}\boldsymbol{b}
\left(\frac{\partial\boldsymbol{c}_{R}}{\partial\omega}\boldsymbol{a}+
      \frac{\partial\boldsymbol{c}_{S}}{\partial\omega}\boldsymbol{b}\right)
\frac{\partial\phi_{S}\left(M\omega\right)}{\partial\boldsymbol{s}}
-\left(\boldsymbol{s}_{R}\boldsymbol{a}+
      \boldsymbol{s}_{S}\boldsymbol{b}\right)
\frac{\partial^{2}\boldsymbol{c}_{S}}{\partial\boldsymbol{s}\partial\omega}
\boldsymbol{b} \\
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{a}}
T\left(\omega\right)+\left|H\left(\omega\right)\right|^{2}
\frac{\partial T\left(\omega\right)}{\partial\boldsymbol{a}} =& 
\phantom{-}\left(\frac{\partial\boldsymbol{s}_{R}}{\partial\omega}\boldsymbol{a}+
      \frac{\partial\boldsymbol{s}_{S}}{\partial\omega}\boldsymbol{b}\right)
\boldsymbol{c}_{R}+
\left(\boldsymbol{c}_{R}\boldsymbol{a}+
      \boldsymbol{c}_{S}\boldsymbol{b}\right)
\frac{\partial\boldsymbol{s}_{R}}{\partial\omega}\\
&-\left(\frac{\partial\boldsymbol{c}_{R}}{\partial\omega}\boldsymbol{a}+
\frac{\partial\boldsymbol{c}_{S}}{\partial\omega}\boldsymbol{b}\right)
\boldsymbol{s}_{R}
-\left(\boldsymbol{s}_{R}\boldsymbol{a}+\boldsymbol{s}_{S}\boldsymbol{b}\right)
\frac{\partial\boldsymbol{c}_{R}}{\partial\omega}\\
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial\boldsymbol{b}}
T\left(\omega\right)+\left|H\left(\omega\right)\right|^{2}
\frac{\partial T\left(\omega\right)}{\partial\boldsymbol{b}} =& 
\phantom{-}\left(\frac{\partial\boldsymbol{s}_{R}}{\partial\omega}\boldsymbol{a}+
      \frac{\partial\boldsymbol{s}_{S}}{\partial\omega}\boldsymbol{b}\right)
\boldsymbol{c}_{S}+
\left(\boldsymbol{c}_{R}\boldsymbol{a}+
      \boldsymbol{c}_{S}\boldsymbol{b}\right)
\frac{\partial\boldsymbol{s}_{S}}{\partial\omega}\\
&-\left(\frac{\partial\boldsymbol{c}_{R}}{\partial\omega}\boldsymbol{a}+
\frac{\partial\boldsymbol{c}_{S}}{\partial\omega}\boldsymbol{b}\right)
\boldsymbol{s}_{S}
-\left(\boldsymbol{s}_{R}\boldsymbol{a}+\boldsymbol{s}_{S}\boldsymbol{b}\right)
\frac{\partial\boldsymbol{c}_{S}}{\partial\omega}
\end{align*}
where
\begin{align*}
\frac{\partial^{2}\boldsymbol{c}_{R}}{\partial\boldsymbol{r}\partial\omega}
\boldsymbol{a}&=
\phantom{-}\left(\boldsymbol{s}_{R}\boldsymbol{a}\right)
\frac{\partial^{2}\phi_{R}\left(M\omega\right)}
{\partial\boldsymbol{r}\partial\omega}
+\left(\frac{\partial\boldsymbol{s}_{R}}{\partial\omega}\boldsymbol{a}\right)
\frac{\partial\phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}}\\
\frac{\partial^{2}\boldsymbol{c}_{S}}{\partial\boldsymbol{s}\partial\omega}
\boldsymbol{b}&=
\phantom{-}\left(\boldsymbol{s}_{S}\boldsymbol{b}\right)
\frac{\partial^{2}\phi_{S}\left(M\omega\right)}
{\partial\boldsymbol{s}\partial\omega}
+\left(\frac{\partial\boldsymbol{s}_{S}}{\partial\omega}\boldsymbol{b}\right)
\frac{\partial\phi_{S}\left(M\omega\right)}{\partial\boldsymbol{s}}\\
\frac{\partial^{2}\boldsymbol{s}_{R}}{\partial\boldsymbol{r}\partial\omega}
\boldsymbol{a}&= 
-\left(\boldsymbol{c}_{R}\boldsymbol{a}\right)
\frac{\partial^{2}\phi_{R}\left(M\omega\right)}
{\partial\boldsymbol{r}\partial\omega}
-\left(\frac{\partial\boldsymbol{c}_{R}}{\partial\omega}\boldsymbol{a}\right)
\frac{\partial\phi_{R}\left(M\omega\right)}{\partial\boldsymbol{r}}\\
\frac{\partial^{2}\boldsymbol{s}_{S}}{\partial\boldsymbol{s}\partial\omega}
\boldsymbol{b}&=
-\left(\boldsymbol{c}_{S}\boldsymbol{b}\right)
\frac{\partial^{2}\phi_{S}\left(M\omega\right)}
{\partial\boldsymbol{s}\partial\omega}
-\left(\frac{\partial\boldsymbol{c}_{S}}{\partial\omega}\boldsymbol{b}\right)
\frac{\partial\phi_{S}\left(M\omega\right)}{\partial\boldsymbol{s}}
\end{align*}

The calculation of the filter response and gradients is implemented in the 
Octave function \emph{iir\_frm\_parallel\_allpass.m} which is exercised by the 
Octave script \emph{iir\_frm\_parallel\_allpass\_test.m}.

The Octave script \emph{iir\_frm\_parallel\_allpass\_socp\_slb\_test.m} designs
an FRM filter with the following specification:
\begin{small}
\verbatiminput{iir_frm_parallel_allpass_socp_slb_test_spec.m}
\end{small}
In this example the FIR masking filters are not required to be linear phase 
and there is no constraint on the group delay of the filter. The Octave script
\emph{iir\_frm\_parallel\_allpass\_socp\_slb\_test.m} calls
the Octave function \emph{iir\_frm\_parallel\_allpass\_socp\_mmse} to minimise
the response error and the coefficient step size with the SeDuMi SOCP solver. 
The initial filter was calculated by the Octave script 
\emph{tarczynski\_frm\_parallel\_allpass\_test.m} with the WISE method of
Tarczynski et al.\ (see
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}). 
The response of the initial filter is shown in 
Figure~\ref{fig:iir-frm-parallel-allpass-initial-response}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_parallel_allpass_socp_slb_test_initial_response}}
\caption{FRM filter with gain-pole-zero format parallel allpass model filter,
  initial response with WISE optimisation.}
\label{fig:iir-frm-parallel-allpass-initial-response}
\end{figure}
The initial filter was SOCP and PCLS optimised with the Octave function
\emph{iir\_frm\_parallel\_allpass\_slb}. The resulting model filter parallel 
allpass filter denominator polynomials are
\begin{small}
\verbatiminput{iir_frm_parallel_allpass_socp_slb_test_r_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{iir_frm_parallel_allpass_socp_slb_test_s_coef.m}
\end{small}
The FIR masking filter polynomial is
\begin{small}
\verbatiminput{iir_frm_parallel_allpass_socp_slb_test_aa_coef.m}
\end{small}
and the complementary FIR masking filter polynomial is
\begin{small}
\verbatiminput{iir_frm_parallel_allpass_socp_slb_test_ac_coef.m}
\end{small}
Figure~\ref{fig:iir-frm-parallel-allpass-socp-slb-pcls-overall-response} 
shows the overall response of the resulting SOCP and PCLS optimised FRM filter. 
Figure~\ref{fig:iir-frm-parallel-allpass-socp-slb-pcls-passband-response} 
shows the passband response of the resulting FRM filter. 
Figure~\ref{fig:iir-frm-parallel-allpass-socp-slb-pcls-masking-filters} 
shows the impulse response of the resulting FRM masking filters. 
Figure~\ref{fig:iir-frm-parallel-allpass-socp-slb-pcls-masking-response} 
shows the responses of the resulting FRM masking filters. 
Figure~\ref{fig:iir-frm-parallel-allpass-socp-slb-pcls-model-response} 
shows the response of the resulting FRM model filter\footnote{The responses
 shown are calculated with the allpass filter polynomial derived from the
gain-pole-zero form.}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_parallel_allpass_socp_slb_test_pcls_response}}
\caption{FRM filter with gain-pole-zero format parallel allpass model filter,
  SOCP PCLS optimised overall response.}
\label{fig:iir-frm-parallel-allpass-socp-slb-pcls-overall-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_parallel_allpass_socp_slb_test_pcls_passband_response}}
\caption{FRM filter with gain-pole-zero format parallel allpass model filter,
  SOCP PCLS optimised passband response.}
\label{fig:iir-frm-parallel-allpass-socp-slb-pcls-passband-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_parallel_allpass_socp_slb_test_pcls_mask_filters}}
\caption{FRM filter with gain-pole-zero format parallel allpass model filter,
  SOCP PCLS optimised FIR masking filters.}
\label{fig:iir-frm-parallel-allpass-socp-slb-pcls-masking-filters}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_parallel_allpass_socp_slb_test_pcls_mask_response}}
\caption{FRM filter with gain-pole-zero format parallel allpass model filter,
  SOCP PCLS optimised FIR masking filter responses.}
\label{fig:iir-frm-parallel-allpass-socp-slb-pcls-masking-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{iir_frm_parallel_allpass_socp_slb_test_pcls_model_response}}
\caption{FRM filter with gain-pole-zero format parallel allpass model filter,
  SOCP PCLS optimised model filter response.}
\label{fig:iir-frm-parallel-allpass-socp-slb-pcls-model-response}
\end{figure}
\clearpage
\subsection{\label{sec:FRM-low-pass-Schur-lattice}Design of  an FRM low-pass digital filter with an all-pass Schur lattice model filter in parallel with a delay using SOCP and PCLS optimisation}
This section describes a low-pass FRM filter with the \emph{Johansson} and
\emph{Wanhammar} FRM filter structure shown in
Figure~\ref{fig:Johansson-and-Wanhammar-frequency-response-masking-structure} in
which the model filter is an all-pass Schur one-multiplier lattice filter in
parallel with a delay and the FIR masking filters are symmetric (ie: linear
phase) and even order. The squared-magnitude, phase and the group delay of the
MMSE optimised FRM filter response are constrained by the PCLS algorithm of
\emph{Selesnick}, \emph{Lang} and \emph{Burrus}, described in
Section~\ref{sub:Choice-of-Active-Constraints}. The calculations for this filter
are similar to those in
Section~\ref{sec:FRM-filter-allpass-model-filter-gain-pole-zero-SOCP-PCLS}
with the values and gradients of $\phi_{R}\left(\omega\right)$ calculated by
the Octave \emph{schurOneMAPlatticeP.m} and \emph{schurOneMAPlatticeT.m}
functions. The Octave function \emph{schurOneMAPlattice\_frmEsq.m}
returns the FRM filter squared-magnitude, phase and group delay error
responses and their gradients. The Octave function
\emph{schurOneMAPlattice\_frm\_socp\_mmse} finds the SOCP solution that
optimises the coefficients of a filter error response calculated by
\emph{schurOneMAPlattice\_frmEsq} with the required amplitude, phase and group
delay constraints. The Octave function
\emph{schurOneMAPlattice\_frm\_slb} implements the PCLS algorithm for
finding the constraint frequencies. The Octave script
\emph{schurOneMAPlattice\_frm\_socp\_slb\_test.m} designs an FRM
filter with the following specification:
\begin{small}
\verbatiminput{schurOneMAPlattice_frm_socp_slb_test_spec.m}
\end{small}
Both the FIR masking filters are symmetric and have length $41$.
The initial filter is designed by the Octave script 
\emph{tarczynski\_frm\_allpass\_test.m} with the WISE method of
\emph{Tarczynski et al.} as shown in 
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}. 
The response of the initial filter is shown in
Figure~\ref{fig:iir-frm-allpass-initial-response}.
After SOCP and PCLS optimisation of the initial filter the resulting
model filter all-pass Schur lattice filter has coefficients:
\begin{small}
\verbatiminput{schurOneMAPlattice_frm_socp_slb_test_k1_coef.m}
\verbatiminput{schurOneMAPlattice_frm_socp_slb_test_epsilon1_coef.m}
\end{small}
The distinct coefficients of the FIR masking filter polynomial are
\begin{small}
\verbatiminput{schurOneMAPlattice_frm_socp_slb_test_u1_coef.m}
\end{small}
The distinct coefficients of the complementary FIR masking filter polynomial are
\begin{small}
\verbatiminput{schurOneMAPlattice_frm_socp_slb_test_v1_coef.m}
\end{small}
Figure~\ref{fig:schurOneMAPlattice-frm-socp-pcls-response} 
shows the response of the resulting SOCP optimised, PCLS constrained
FRM filter. 
Figure~\ref{fig:schurOneMAPlattice-frm-socp-pcls-mask-response} 
shows the responses of the resulting FRM masking filters. 
Figure~\ref{fig:schurOneMAPlattice-frm-socp-pcls-model-response} 
shows the response of the resulting FRM model filter.
Figure~\ref{fig:schurOneMAPlattice-frm-socp-pcls-remez-response} 
compares the amplitude response of the FRM low-pass filter with that of a
linear-phase FIR filter designed with the Octave \emph{remez} function. The FIR
and FRM low-pass filters have a similar number of distinct coefficients.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMAPlattice_frm_socp_slb_test_pcls_response}}
\caption{FRM filter with Schur one-multiplier lattice filter allpass
  model filter, amplitude, delay and phase responses after SOCP and
  PCLS optimisation.}
\label{fig:schurOneMAPlattice-frm-socp-pcls-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMAPlattice_frm_socp_slb_test_pcls_mask_response}}
\caption{FRM filter with Schur one-multiplier lattice allpass model
  filter, masking filter responses after SOCP and PCLS optimisation.}
\label{fig:schurOneMAPlattice-frm-socp-pcls-mask-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMAPlattice_frm_socp_slb_test_pcls_model_response}}
\caption{FRM filter with Schur one-multiplier lattice allpass model
  filter, model filter response after SOCP and PCLS optimisation.}
\label{fig:schurOneMAPlattice-frm-socp-pcls-model-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMAPlattice_frm_socp_slb_test_remez}}
\caption{Comparison of the amplitude responses of an FRM filter with Schur
  one-multiplier lattice allpass model filter and a linear-phase FIR filter
  having a similar number of distinct coefficients.}
\label{fig:schurOneMAPlattice-frm-socp-pcls-remez-response}
\end{figure}

\clearpage
\subsection{\label{sec:Design-half-band-FRM-allpass-model-filter-Schur-lattice}Design of an FRM half-band digital filter with an allpass Schur lattice model filter using SOCP and PCLS optimisation}
\emph{Mili\'{c}} et al.\ describe the design of an FRM half-band filter with
the structure shown in
Figure~\ref{fig:Johansson-and-Wanhammar-frequency-response-masking-structure}.
In this case the model filters are synthesised as the parallel combination of
a pure delay, $S\left(z\right)=z^{-D}$ and an all-pass filter with
coefficients only in $z^{2}$, $R\left(z^{2}\right)$. The coefficients of the
denominator polynomial of $R\left(z^{2}\right)$ are $r_{k}$. The masking filters
are symmetric FIR filters with even order $N_{m}$, a multiple of $4$ and delay
$d=\frac{N_{m}}{2}$. The transfer function of the FRM half-band filter is:
\begin{align*}
H\left(z\right)&=
\frac{1}{2}\left[R\left(z^{2M}\right)+z^{-DM}\right]F_{M_{a}}\left(z\right)+
\frac{1}{2}\left[R\left(z^{2M}\right)-z^{-DM}\right]F_{M_{c}}\left(z\right) \\
&=\frac{1}{2}R\left(z^{2M}\right)
\left[F_{M_{a}}\left(z\right)+F_{M_{c}}\left(z\right)\right] +
\frac{1}{2}z^{-DM}\left[F_{M_{a}}\left(z\right)-F_{M_{c}}\left(z\right)\right]
\end{align*}
where $M$ is the decimation factor of the model filter. The nominal delay of
the FRM filter is $DM+d$.

The power-complementary branches of a half-band filter are symmetric in 
frequency. Section~\ref{sec:Review-FRM-digital-filters} shows the calculation
of the band edges of the masking filters required for the FRM filter 
corresponding to these model filters. \emph{Saram\"{a}ki} et 
al.~\cite[Figure 2]{SaramakiLimYang_SynthesisHalfBandFRM} show that the
masking filters of the FRM half-band filter are related by:
\begin{align*}
F_{M_{c}}\left(z\right)&=-z^{-d}+F_{M_{a}}\left(-z\right)
\end{align*}

The polyphase decomposition of $F_{M_{a}}\left(z\right)$ is:
\begin{align*}
F_{M_{a}}\left(z\right)&=U\left(z^{2}\right)+z^{-1}V\left(z^{2}\right)
\end{align*}
where $U\left(z\right)$ is a symmetric FIR filter with even order 
$\frac{N_{m}}{2}$ and $V\left(z\right)$ is a symmetric FIR filter with odd 
order $\frac{N_{m}}{2}-1$.

The transfer function of the FRM half-band filter is, in terms of the
polyphase decomposition of $F_{M_{a}}$:
\begin{align*}
F_{M_{a}}\left(z\right)+F_{M_{c}}\left(z\right)&=2U\left(z^{2}\right)-z^{-d} \\
F_{M_{a}}\left(z\right)-F_{M_{c}}\left(z\right)&=2z^{-1}V\left(z^{2}\right)+z^{-d}
\end{align*}
so that:
\begin{align*}
H\left(z\right)&=\frac{1}{2}z^{-DM-d}+
\frac{1}{2}\left[R\left(z^{2M}\right)
\left(2U\left(z^{2}\right)-z^{-d}\right)+
2z^{-DM}z^{-1}V\left(z^{2}\right)
\right]
\end{align*}

It is convenient to express $U\left(z^{2}\right)$ and
$z^{-1}V\left(z^{2}\right)$ in terms of the coefficients, $u_{k}$ and $v_{k}$:
\begin{align*}
  U\left(z^{2}\right)&=\sum_{k=0}^{d}u_{k}z^{-2k}\\
                 &=u_{\frac{d}{2}}z^{-d}+
                   \sum_{k=0}^{\frac{d}{2}-1}u_{k}z^{-2k}+
                   \sum_{k=\frac{d}{2}+1}^{d}u_{k}z^{-2k}\\
                 &=u_{\frac{d}{2}}z^{-d}+
                   \sum_{k=0}^{\frac{d}{2}-1}u_{k}
                   \left(z^{-2k}+z^{2k-2d}\right)\\
                 &=z^{-d}\left[u_{\frac{d}{2}}+
                   \sum_{k=0}^{\frac{d}{2}-1}u_{k}
                   \left(z^{-2k+d}+z^{2k-d}\right)\right]
\end{align*}
and:
\begin{align*}
  z^{-1}V\left(z^{2}\right) &=z^{-1}\sum_{k=0}^{d-1}v_{k}z^{-2k}\\
                           &=z^{-1}\sum_{k=0}^{\frac{d}{2}-1}v_{k}z^{-2k}+
                             z^{-1}\sum_{k=\frac{d}{2}}^{d-1}v_{k}z^{-2k}\\
                           &=z^{-1}\sum_{k=0}^{\frac{d}{2}-1}v_{k}
                             \left(z^{-2k}+z^{2k-2d+2}\right)\\
                           &=z^{-d}\sum_{k=0}^{\frac{d}{2}-1}v_{k}
                             \left(z^{-2k+d-1}+z^{2k-d+1}\right)
\end{align*}
Rearranging $H\left(z\right)$:
\begin{align*}
  H\left(z\right)&=z^{-DM-d}\left[
                   z^{DM}R\left(z^{2M}\right)\left(-\frac{1}{2}+
                   z^{d}U\left(z^{2}\right)\right)+
                   \left(\frac{1}{2}+
                   z^{d}z^{-1}V\left(z^{2}\right)\right)\right]
\end{align*}
so that the zero-phase frequency response of the half-band FRM filter, 
$H\left(z\right)$, is:
\begin{align*}
H\left(\omega\right)&=e^{\imath\left[DM\omega+\phi_{R}\left(2M\omega\right)\right]}
A\left(\omega\right)+B\left(\omega\right)
\end{align*}
where $\phi_{R}\left(2M\omega\right)$ is the phase response of the all-pass
filter $R\left(z^{2M}\right)$ and:
\begin{align*}
A\left(\omega\right)&=-\frac{1}{2}+u_{\frac{d}{2}}+\sum_{k=0}^{\frac{d}{2}-1}
2u_{k}\cos\left[\omega{}\left(2k-d\right)\right] \\
B\left(\omega\right)&=\frac{1}{2}+\sum_{k=0}^{\frac{d}{2}-1}
2v_{k}\cos\left[\omega{}\left(2k-d+1\right)\right]
\end{align*}

The squared-magnitude and phase responses of the zero phase response of the 
FRM half-band filter are similar to those shown in 
Section~\ref{sec:FRM-filter-allpass-model-filter-gain-pole-zero-SOCP-PCLS}:
\begin{align*}
\left|H\left(\omega\right)\right|^{2}&=
A^{2}\left(\omega\right)+B^{2}\left(\omega\right) +
2A\left(\omega\right)B\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)\\
\phi_{H}\left(\omega\right) &= \arctan \frac{
A\left(\omega\right)\sin\phi_{Z}\left(M\omega\right)}{
A\left(\omega\right)\cos\phi_{Z}\left(M\omega\right) + B\left(\omega\right)}
\end{align*}
where $\phi_{Z}\left(\omega\right)=D\omega + \phi_{R}\left(2\omega\right)$.

The group delay response, $T\left(\omega\right)$, of the zero phase response 
of the FRM half-band filter is given by:
\begin{align*}
  \left|H\left(\omega\right)\right|^{2}T\left(\omega\right)
  =& -\left(A^{2}\left(\omega\right)+A\left(\omega\right)B\left(\omega\right)
  \cos\phi_{Z}\left(M\omega\right)\right)
  \frac{\partial\phi_{Z}\left(M\omega\right)}{\partial\omega} \hdots \\
   & -\sin\phi_{Z}\left(M\omega\right)\left[
     B\left(\omega\right)\frac{\partial A\left(\omega\right)}{\partial\omega}-
     A\left(\omega\right)\frac{\partial B\left(\omega\right)}{\partial\omega}
     \right]
\end{align*}
where:
\begin{align*}
  \frac{\partial A\left(\omega\right)}{\partial\omega} =
  & -2\sum_{k=0}^{\frac{d}{2}-1}\left(2k-d\right)u_{k}
    \sin\left[\omega{}\left(2k-d\right)\right] \\
  \frac{\partial B\left(\omega\right)}{\partial\omega} =
  & -2\sum_{k=0}^{\frac{d}{2}-1}\left(2k-d+1\right)v_{k}
    \sin\left[\omega{}\left(2k-d+1\right)\right]
\end{align*}

The gradients of $\left|H\left(\omega\right)\right|^{2}$ with respect to the 
coefficients are:
\begin{align*}
  \frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial r_{k}}=
  &-2A\left(\omega\right)B\left(\omega\right)
    \sin\phi_{Z}\left(M\omega\right)
    \frac{\partial \phi_{R}\left(2M\omega\right)}{\partial r_{k}} \\
  \frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial u_{k}}=
  &\phantom{-} 2\left(A\left(\omega\right)+
    B\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)\right)
    \frac{\partial A\left(\omega\right)}{\partial u_{k}}\\
  \frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial v_{k}}=
  &\phantom{-} 2\left(B\left(\omega\right)+
    A\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)\right)
    \frac{\partial B\left(\omega\right)}{\partial v_{k}}
\end{align*}
and:
\begin{align*}
  \frac{\partial A\left(\omega\right)}{\partial u_{k}} =
  & \begin{cases}
    1 & k=\frac{d}{2} \\
    2\cos\left[\omega{}\left(2k-d\right)\right] & otherwise \\
    \end{cases}\\
  \frac{\partial B\left(\omega\right)}{\partial v_{k}} =
  &\; 2\cos\left[\omega{}\left(2k-d+1\right)\right]
\end{align*}

\begin{comment}
The gradients of $\phi_{H}\left(\omega\right)$ with respect to the coefficients
are given by:
\begin{align*}
  \left|H\left(\omega\right)\right|^{2}
  \frac{\partial\phi_{H}\left(\omega\right)}{\partial r_{k}}
  =& \left(A^{2}\left(\omega\right)+A\left(\omega\right)B\left(\omega\right)
  \cos\phi_{Z}\left(M\omega\right)\right)
     \frac{\partial\phi_{R}\left(2M\omega\right)}{\partial r_{k}} \\
  \left|H\left(\omega\right)\right|^{2} 
  \frac{\partial\phi_{H}\left(\omega\right)}{\partial u_{k}}
  =& \sin\phi_{Z}\left(M\omega\right)B\left(\omega\right)
     \frac{\partial A\left(\omega\right)}{\partial u_{k}} \\
  \left|H\left(\omega\right)\right|^{2} 
  \frac{\partial\phi_{H}\left(\omega\right)}{\partial v_{k}}
  =& -\sin\phi_{Z}\left(M\omega\right)A\left(\omega\right)
     \frac{\partial B\left(\omega\right)}{\partial v_{k}} 
\end{align*}
\end{comment}

The gradients of $T\left(\omega\right)$ with respect to the coefficients are
given by:
\begin{align*}
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial r_{k}}
T\left(\omega\right)+\left|H\left(\omega\right)\right|^{2}
\frac{\partial T\left(\omega\right)}{\partial r_{k}}=
  &\phantom{-}
    \left(A^{2}\left(\omega\right)+A\left(\omega\right)B\left(\omega\right)
 \cos\phi_{Z}\left(M\omega\right)\right)
\frac{\partial^{2}\phi_{R}\left(2M\omega\right)}
     {\partial\omega\partial r_{k}} \hdots \\
&+A\left(\omega\right)B\left(\omega\right)\sin\phi_{Z}\left(M\omega\right)
  \frac{\partial\phi_{Z}\left(M\omega\right)}{\partial\omega}
  \frac{\partial\phi_{R}\left(2M\omega\right)}{\partial r_{k}} \hdots \\
&-\cos\phi_{Z}\left(M\omega\right)\left[
  B\left(\omega\right)\frac{\partial A\left(\omega\right)}{\partial\omega}-
  A\left(\omega\right)\frac{\partial B\left(\omega\right)}{\partial\omega}
  \right]\frac{\partial\phi_{R}\left(2M\omega\right)}{\partial r_{k}}\\
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial u_{k}}
T\left(\omega\right)+\left|H\left(\omega\right)\right|^{2}
\frac{\partial T\left(\omega\right)}{\partial u_{k}}=
&-\left(2A\left(\omega\right)+
  B\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)\right)
  \frac{\partial\phi_{Z}\left(M\omega\right)}{\partial\omega}
  \frac{\partial A\left(\omega\right)}{\partial u_{k}} \hdots \\
&  -\sin\phi_{Z}\left(M\omega\right)\left[
  B\left(\omega\right)\frac{\partial^{2} A\left(\omega\right)}
  {\partial\omega\partial u_{k}} -
  \frac{\partial B\left(\omega\right)}{\partial\omega}
  \frac{\partial A\left(\omega\right)}{\partial u_{k}}\right] \\
\frac{\partial\left|H\left(\omega\right)\right|^{2}}{\partial v_{k}}
T\left(\omega\right)+\left|H\left(\omega\right)\right|^{2}
\frac{\partial T\left(\omega\right)}{\partial v_{k}}=
&-A\left(\omega\right)\cos\phi_{Z}\left(M\omega\right)
  \frac{\partial\phi_{Z}\left(M\omega\right)}{\partial\omega}
  \frac{\partial B\left(\omega\right)}{\partial v_{k}} \hdots \\
&  -\sin\phi_{Z}\left(M\omega\right)\left[
  \frac{\partial A\left(\omega\right)}{\partial\omega}
  \frac{\partial B\left(\omega\right)}{\partial v_{k}}
  -A\left(\omega\right)\frac{\partial^{2} B\left(\omega\right)}
  {\partial\omega\partial v_{k}}
  \right]
\end{align*}

The Octave script
\emph{schurOneMAPlattice\_frm\_halfband\_socp\_slb\_test.m} designs an FRM
half-band filter with a model filter implemented as a Schur
one-multiplier all-pass lattice. The filter specification is:
\begin{small}
\verbatiminput{schurOneMAPlattice_frm_halfband_socp_slb_test_spec.m}
\end{small}
The initial filter is designed by the Octave script
\emph{tarczynski\_frm\_halfband\_test.m} with the WISE method of
\emph{Tarczynski et al.} as shown in
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}.
Figure~\ref{fig:schurOneMAPlattice-frm-half-band-initial-response} shows the
overall response of the initial FRM filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMAPlattice_frm_halfband_socp_slb_test_initial_response}}
\caption{FRM half-band filter, initial response.}
\label{fig:schurOneMAPlattice-frm-half-band-initial-response}
\end{figure}

SOCP and PCLS optimisation of the initial filter results in a 
model filter allpass filter with following lattice coefficients:
\begin{small}
\verbatiminput{schurOneMAPlattice_frm_halfband_socp_slb_test_k2_coef.m}
\verbatiminput{schurOneMAPlattice_frm_halfband_socp_slb_test_epsilon2_coef.m}
\end{small}
The FIR masking filter polynomials are:
\begin{small}
\verbatiminput{schurOneMAPlattice_frm_halfband_socp_slb_test_u2_coef.m}
\verbatiminput{schurOneMAPlattice_frm_halfband_socp_slb_test_v2_coef.m}
\end{small}
Figure~\ref{fig:schurOneMAPlattice-frm-half-band-socp-pcls-response} 
shows the overall response of the resulting SOCP optimised, PCLS constrained
FRM filter. 
Figure~\ref{fig:schurOneMAPlattice-frm-half-band-socp-pcls-passband-response} 
shows the passband response of the resulting FRM filter. 
Figure~\ref{fig:schurOneMAPlattice-frm-half-band-socp-pcls-mask-response} 
shows the responses of the resulting FRM masking filters. 
Figure~\ref{fig:schurOneMAPlattice-frm-half-band-socp-pcls-model-response} 
shows the response of the resulting FRM model filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMAPlattice_frm_halfband_socp_slb_test_pcls_response}}
\caption{FRM half-band filter, overall response after SOCP and PCLS
  optimisation .}
\label{fig:schurOneMAPlattice-frm-half-band-socp-pcls-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMAPlattice_frm_halfband_socp_slb_test_pcls_passband_response}}
\caption{FRM half-band filter, passband response after SOCP and PCLS
  optimisation.}
\label{fig:schurOneMAPlattice-frm-half-band-socp-pcls-passband-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMAPlattice_frm_halfband_socp_slb_test_pcls_mask_response}}
\caption{FRM half-band filter with SOCP and PCLS optimisation, masking filter
  responses.}
\label{fig:schurOneMAPlattice-frm-half-band-socp-pcls-mask-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMAPlattice_frm_halfband_socp_slb_test_pcls_model_response}}
\caption{FRM half-band filter with SOCP and PCLS optimisation, model filter
  response.}
\label{fig:schurOneMAPlattice-frm-half-band-socp-pcls-model-response}
\end{figure}
\clearpage
\subsection{\label{sec:Design-Hilbert-FRM-allpass-model-filter-Schur-lattice}Design of an FRM Hilbert digital filter with an allpass Schur lattice model filter using SOCP and PCLS optimisation}
\emph{Mili\'{c}} et al.~\cite{Milic_FRMAllpassHilbert} point out that shifting
the transfer function of the FRM half-band filter, $H\left(z\right)$, of
Section~\ref{sec:Design-half-band-FRM-allpass-model-filter-Schur-lattice},
right-wards by $\frac{\pi}{2}$ along the frequency axis results in a filter,
$H_{A}\left(z\right)$, that generates the \emph{analytic} signal. Suppose the
half-band filter response is:
\begin{align*}
H\left(z\right)&=\frac{1}{2}z^{-N}+\frac{1}{2}Q\left(z^{2}\right)
\end{align*}
where $N+1$ is a multiple of $4$. The filter, $H_{A}\left(z\right)$,
that generates the analytic signal is:
\begin{align*}
H_{A}\left(z\right) &=2\imath H\left(-\imath z\right) \\
 &= z^{-N}+\imath Q\left(-z^{2}\right)
\end{align*}
In other words, $H_{H}\left(z\right)=Q\left(-z^{2}\right)$ is a Hilbert
transform filter. For convenience, assume that the masking filter order,
$N_{m}$, is a multiple of $8$, that $M$ and $D$ are odd and that $DM+1$ is a
multiple of $4$. Then:
\begin{align*}
H_{H}\left(z\right)&=R\left(-z^{2M}\right)
\left(2U\left(-z^{2}\right)-z^{-d}\right)+2z^{-DM-1}V\left(-z^{2}\right)
\end{align*}
where:
\begin{align*}
  U\left(-z^{2}\right)
  &=\sum_{k=0}^{d}u_{k}\left(-z^{2}\right)^{-k}\\
  &=\left(-1\right)^{-\frac{d}{2}}u_{\frac{d}{2}}z^{-d}+
    \sum_{k=0}^{\frac{d}{2}-1}\left(-1\right)^{-k}u_{k}z^{-2k}+
    \sum_{k=\frac{d}{2}+1}^{d}\left(-1\right)^{-k}u_{k}z^{-2k}\\
  &=u_{\frac{d}{2}}z^{-d}+
    \sum_{k=0}^{\frac{d}{2}-1}\left(-1\right)^{-k}u_{k}
    \left(z^{-2k}+z^{2k-2d}\right)\\
  &=z^{-d}\left[u_{\frac{d}{2}}+
    \sum_{k=0}^{\frac{d}{2}-1}\left(-1\right)^{-k}u_{k}
    \left(z^{-2k+d}+z^{2k-d}\right)\right]\\
\end{align*}
and:
\begin{align*}
  z^{-1}V\left(-z^{2}\right)
  &=z^{-1}\sum_{k=0}^{d-1}v_{k}\left(-z^{2}\right)^{-k}\\
  &=z^{-1}\sum_{k=0}^{\frac{d}{2}-1}\left(-1\right)^{-k}v_{k}z^{-2k}+
    z^{-1}\sum_{k=\frac{d}{2}}^{d-1}\left(-1\right)^{-k}v_{k}z^{-2k}\\
  &=z^{-d}\sum_{k=0}^{\frac{d}{2}-1}\left(-1\right)^{-k}v_{k}
    \left(z^{-2k+d-1}-z^{2k-d+1}\right)
\end{align*}
If $r\left(z^{2}\right)$ is the denominator polynomial of the prototype
all-pass filter prototype, $R\left(z^{2}\right)$, then:
\begin{align*}
  R\left(-z^{2}\right)
  =&\frac{\left(-z^{-2}\right)^{N_{model}}r\left(-z^{-2}\right)}
     {r\left(-z^{2}\right)}\\
  =&\left(-1\right)^{N_{model}}
     \frac{z^{-2N_{model}}r\left(-z^{-2}\right)}{r\left(-z^{2}\right)}
\end{align*}
where $N_{model}$ is the order of $r\left(z\right)$. If $N_{model}$ is odd
then the zero frequency gain of $R\left(-z^{2}\right)$ is $-1$.

For convenience, rename the FRM Hilbert filter coefficients in terms of the
coefficients of the FRM half-band filter as
$r^{\prime}_{k}=\left(-1\right)^{-k}r_{k}$,
$u^{\prime}_{k}=\left(-1\right)^{-k}u_{k}$ and
$v^{\prime}_{k}=\left(-1\right)^{-k}v_{k}$.  The zero-phase frequency response
of the Hilbert filter, $H_{H}\left(z\right)$, is:
\begin{align*}
  H_{H}\left(\omega\right)=
  &e^{\imath\left[DM\omega+\phi_{R_{H}}\left(2M\omega\right)\right]}
    A_{H}\left(\omega\right)+\imath B_{H}\left(\omega\right)
\end{align*}
where:
\begin{align*}
A_{H}\left(\omega\right)&=-1+2u^{\prime}_{\frac{d}{2}}+4\sum_{k=0}^{\frac{d}{2}-1}
u^{\prime}_{k}\cos\left[\omega{}\left(2k-d\right)\right] \\
B_{H}\left(\omega\right)&=-4\sum_{k=0}^{\frac{d}{2}-1}
v^{\prime}_{k}\sin\left[\omega{}\left(2k-d+1\right)\right]
\end{align*}
and $\phi_{R_{H}}\left(2M\omega\right)$ is the phase response of the modified
all-pass filter $R_{H}\left(z^{2M}\right)=R\left(-z^{2M}\right)$. 

The squared-magnitude and phase responses of the zero phase response of the 
FRM Hilbert filter are:
\begin{align*}
  \left|H_{H}\left(\omega\right)\right|^{2}
  &=A_{H}^{2}\left(\omega\right)+B_{H}^{2}\left(\omega\right) +
    2A_{H}\left(\omega\right)B_{H}\left(\omega\right)
    \sin\phi_{Z_{H}}\left(M\omega\right)
\end{align*}
and:
\begin{align*}
  \phi_{H_{H}}\left(\omega\right)
  &= \arctan \frac{A_{H}\left(\omega\right)
    \sin\phi_{Z_{H}}\left(M\omega\right)+B_{H}\left(\omega\right)}
    {A_{H}\left(\omega\right)\cos\phi_{Z_{H}}\left(M\omega\right)}
\end{align*}
where $\phi_{Z_{H}}\left(\omega\right)=D\omega+\phi_{R_{H}}\left(2\omega\right)$.

The group delay response, $T_{H}\left(\omega\right)$, of the zero phase response 
of the FRM Hilbert filter is given by:
\begin{align*}
  \left|H_{H}\left(\omega\right)\right|^{2}T_{H}\left(\omega\right)
  =& -\left(A_{H}^{2}\left(\omega\right)+
     A_{H}\left(\omega\right)B_{H}\left(\omega\right)
     \sin\phi_{Z_{H}}\left(M\omega\right)\right)
     \frac{\partial\phi_{Z_{H}}\left(M\omega\right)}{\partial\omega} \hdots \\
   & +\cos\phi_{Z_{H}}\left(M\omega\right)\left[
     B_{H}\left(\omega\right)
     \frac{\partial A_{H}\left(\omega\right)}{\partial\omega}-
     A_{H}\left(\omega\right)
     \frac{\partial B_{H}\left(\omega\right)}{\partial\omega}
     \right]
\end{align*}
where:
\begin{align*}
  \frac{\partial A_{H}\left(\omega\right)}{\partial\omega} =
  & -4\sum_{k=0}^{\frac{d}{2}-1}\left(2k-d\right)u^{\prime}_{k}
    \sin\left[\omega{}\left(2k-d\right)\right] \\
  \frac{\partial B_{H}\left(\omega\right)}{\partial\omega} =
  & -4\sum_{k=0}^{\frac{d}{2}-1}
    \left(2k-d+1\right)v^{\prime}_{k}\cos\left[\omega{}\left(2k-d+1\right)\right]
\end{align*}

The gradients of $\left|H_{H}\left(\omega\right)\right|^{2}$ with respect to
the coefficients are:
\begin{align*}
  \frac{\partial\left|H_{H}\left(\omega\right)\right|^{2}}{\partial r^{\prime}_{k}}=
  &2A_{H}\left(\omega\right)B_{H}\left(\omega\right)
    \cos\phi_{Z_{H}}\left(M\omega\right)
    \frac{\partial \phi_{R_{H}}\left(2M\omega\right)}{\partial r^{\prime}_{k}} \\
  \frac{\partial\left|H_{H}\left(\omega\right)\right|^{2}}{\partial u^{\prime}_{k}}=
  &2\left(A_{H}\left(\omega\right)+
    B_{H}\left(\omega\right)\sin\phi_{Z_{H}}\left(M\omega\right)\right)
    \frac{\partial A_{H}\left(\omega\right)}{\partial u^{\prime}_{k}}\\
  \frac{\partial\left|H_{H}\left(\omega\right)\right|^{2}}{\partial v^{\prime}_{k}}=
  &2\left(B_{H}\left(\omega\right)+
    A_{H}\left(\omega\right)\sin\phi_{Z_{H}}\left(M\omega\right)\right)
    \frac{\partial B_{H}\left(\omega\right)}{\partial v^{\prime}_{k}}
\end{align*}
where:
\begin{align*}
  \frac{\partial A_{H}\left(\omega\right)}{\partial u^{\prime}_{k}} =
  & \begin{cases}
    1 & k=\frac{d}{2} \\
    4\cos\left[\omega{}\left(2k-d\right)\right] & otherwise \\
    \end{cases}\\
  \frac{\partial B_{H}\left(\omega\right)}{\partial v^{\prime}_{k}} =
  &-4\sin\left[\omega{}\left(2k-d+1\right)\right]
\end{align*}

The gradients of $\phi_{H_{H}}\left(\omega\right)$ with respect to the coefficients
are given by:
\begin{align*}
  \left|H_{H}\left(\omega\right)\right|^{2}
  \frac{\partial\phi_{H_{H}}\left(\omega\right)}{\partial r^{\prime}_{k}}
  =& \left(A_{H}^{2}\left(\omega\right)+
     A_{H}\left(\omega\right)B_{H}\left(\omega\right)
     \sin\phi_{Z_{H}}\left(M\omega\right)\right)
     \frac{\partial\phi_{Z_{H}}\left(2M\omega\right)}{\partial\omega} \\
  \left|H_{H}\left(\omega\right)\right|^{2} 
  \frac{\partial\phi_{H_{H}}\left(\omega\right)}{\partial u^{\prime}_{k}}
  =&-B_{H}\left(\omega\right)\cos\phi_{Z_{H}}\left(M\omega\right)
     \frac{\partial A_{H}\left(\omega\right)}{\partial u^{\prime}_{k}} \\
  \left|H_{H}\left(\omega\right)\right|^{2} 
  \frac{\partial\phi_{H_{H}}\left(\omega\right)}{\partial v^{\prime}_{k}}
  =& \phantom{-}A_{H}\left(\omega\right)\cos\phi_{Z_{H}}\left(M\omega\right)
     \frac{\partial B_{H}\left(\omega\right)}{\partial v^{\prime}_{k}}
\end{align*}

The gradients of $T_{H}\left(\omega\right)$ with respect to the coefficients are
given by:
\begin{align*}
  \frac{\partial\left|H_{H}\left(\omega\right)\right|^{2}}{\partial r^{\prime}_{k}}
  T_{H}\left(\omega\right)+\left|H_{H}\left(\omega\right)\right|^{2}
  \frac{\partial T_{H}\left(\omega\right)}{\partial r^{\prime}_{k}}=
  &-A_{H}\left(\omega\right)B_{H}\left(\omega\right)
    \cos\phi_{Z_{H}}\left(M\omega\right)
    \frac{\partial\phi_{Z_{H}}\left(M\omega\right)}{\partial\omega}
    \frac{\partial\phi_{R_{H}}\left(2M\omega\right)}{\partial r^{\prime}_{k}}
    \hdots\\
  &-\left(A_{H}^{2}\left(\omega\right)+
    A_{H}\left(\omega\right)B_{H}\left(\omega\right)
    \sin\phi_{Z_{H}}\left(M\omega\right)\right)
    \frac{\partial^{2}\phi_{Z_{H}}\left(M\omega\right)}
    {\partial\omega\partial r^{\prime}_{k}} \hdots \\
  &-\sin\phi_{Z_{H}}\left(M\omega\right)\left[B_{H}\left(\omega\right)
    \frac{\partial A_{H}\left(\omega\right)}{\partial\omega}-
    A_{H}\left(\omega\right)\frac{\partial B_{H}\left(\omega\right)}
    {\partial\omega}\right]
    \frac{\partial\phi_{R_{H}}\left(2M\omega\right)}{\partial r^{\prime}_{k}}\\
  \frac{\partial\left|H_{H}\left(\omega\right)\right|^{2}}
  {\partial u^{\prime}_{k}}
  T_{H}\left(\omega\right)+\left|H_{H}\left(\omega\right)\right|^{2}
  \frac{\partial T_{H}\left(\omega\right)}{\partial u^{\prime}_{k}}=
  &-\left(2A_{H}\left(\omega\right)+
    B_{H}\left(\omega\right)\sin\phi_{Z_{H}}\left(M\omega\right)\right)
    \frac{\partial\phi_{Z_{H}}\left(M\omega\right)}{\partial\omega}
    \frac{\partial A_{H}\left(\omega\right)}{\partial u^{\prime}_{k}} \hdots \\
  & +\cos\phi_{Z_{H}}\left(M\omega\right)\left[
    B_{H}\left(\omega\right)\frac{\partial^{2} A_{H}\left(\omega\right)}
    {\partial\omega\partial u^{\prime}_{k}} -
    \frac{\partial B_{H}\left(\omega\right)}{\partial\omega}
    \frac{\partial A_{H}\left(\omega\right)}{\partial u^{\prime}_{k}}\right] \\
  \frac{\partial\left|H_{H}\left(\omega\right)\right|^{2}}
  {\partial v^{\prime}_{k}}
  T_{H}\left(\omega\right)+\left|H_{H}\left(\omega\right)\right|^{2}
  \frac{\partial T_{H}\left(\omega\right)}{\partial v^{\prime}_{k}}=
  &-A_{H}\left(\omega\right)\sin\phi_{Z_{H}}\left(M\omega\right)
    \frac{\partial\phi_{Z_{H}}\left(M\omega\right)}{\partial\omega}
    \frac{\partial B_{H}\left(\omega\right)}{\partial v^{\prime}_{k}} \hdots \\
  &  +\cos\phi_{Z_{H}}\left(M\omega\right)\left[
    \frac{\partial A_{H}\left(\omega\right)}{\partial\omega}
    \frac{\partial B_{H}\left(\omega\right)}{\partial v^{\prime}_{k}}
    -A_{H}\left(\omega\right)\frac{\partial^{2} B_{H}\left(\omega\right)}
    {\partial\omega\partial v^{\prime}_{k}}\right]
\end{align*}

where:
\begin{align*}
  \frac{\partial^{2} A_{H}\left(\omega\right)}
  {\partial\omega\partial u_{k}^{\prime}}
  &= -4\left(2k-d\right)\sin\left[\omega{}\left(2k-d\right)\right] \\
  \frac{\partial^{2} B_{H}\left(\omega\right)}
  {\partial\omega\partial v_{k}^{\prime}}
  &= -4\left(2k-d+1\right)\cos\left[\omega{}\left(2k-d+1\right)\right] 
\end{align*}

The Octave script
\emph{schurOneMAPlattice\_frm\_hilbert\_socp\_slb\_test.m} designs an FRM
Hilbert filter with an all-pass model filter implemented as a Schur
one-multiplier lattice. The filter specification is:
\begin{small}
\verbatiminput{schurOneMAPlattice_frm_hilbert_socp_slb_test_spec.m}
\end{small}

The initial filter is based on the half-band filter designed by the Octave
script \emph{tarczynski\_frm\_halfband\_test.m} with the WISE method of
\emph{Tarczynski et al.} as shown in
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}.
Figure~\ref{fig:schurOneMAPlattice-frm-Hilbert-initial-response} shows the
response of the initial FRM Hilbert filter.
SOCP and PCLS optimisation of the initial filter results in a 
model filter allpass filter with following lattice coefficients:
\begin{small}
\verbatiminput{schurOneMAPlattice_frm_hilbert_socp_slb_test_k2_coef.m}
\verbatiminput{schurOneMAPlattice_frm_hilbert_socp_slb_test_epsilon2_coef.m}
\end{small}
and FIR masking filter polynomials:
\begin{small}
\verbatiminput{schurOneMAPlattice_frm_hilbert_socp_slb_test_u2_coef.m}
\verbatiminput{schurOneMAPlattice_frm_hilbert_socp_slb_test_v2_coef.m}
\end{small}
Figure~\ref{fig:schurOneMAPlattice-frm-Hilbert-pcls-response} shows the
response of the FRM Hilbert filter after SOCP and PCLS optimisation.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMAPlattice_frm_hilbert_socp_slb_test_initial_response}}
\caption{FRM Hilbert filter, initial response.}
\label{fig:schurOneMAPlattice-frm-Hilbert-initial-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMAPlattice_frm_hilbert_socp_slb_test_pcls_response}}
\caption{FRM Hilbert filter, response after SOCP and PCLS optimisation.}
\label{fig:schurOneMAPlattice-frm-Hilbert-pcls-response}
\end{figure}

\cleardoublepage
\part{\label{part:IIR-filters-fixed-point-coefficients}Design of IIR filters with integer coefficients}
\cleardoublepage

This part describes the results of my experiments in optimising the response
of digital filters with integer  coefficients expressed in \emph{signed-digit}
form. A coefficient approximated with a small number of signed-digits can be
implemented with \emph{shift-and-add} operations.
Chapter~\ref{sec:Signed-digit-representation-filter-coefficients} describes
the conversion of coefficients to signed-digit form and two heuristics for
allocating the number of signed-digits used by each coefficient. The
remaining chapters in this part consider methods of searching for the 
signed-digit approximations to the coefficients that give an acceptable filter
response.

\chapter{\label{sec:Signed-digit-representation-filter-coefficients}Signed-digit representation of filter coefficients}
\emph{Hwang}~\cite[Section 1.5]{Hwang_ComputerArithmetic} defines 
\emph{signed-digit} numbers as follows:
\begin{quotation}
Given a radix $r$, each digit of a signed-digit number can assume the following
$2\alpha+1$ values:
\begin{align*}
\Sigma_{r}&=\left\{-\alpha,\hdots,-1,0,1,\hdots,\alpha\right\}
\end{align*}
where the maximum digit magnitude, $\alpha$, must be within the following
region:
\begin{align*}
\lceil\frac{r-1}{2}\rceil\le\alpha\le r-1
\end{align*}
Because integer $\alpha\ge 1$,$r\ge 2$ must be assumed. In order to yield
\emph{maximum redundancy} in the balanced digit set $\Sigma_{r}$, one can choose
the following value for the maximum magnitude
\begin{align*}
\alpha=\lfloor\frac{r}{2}\rfloor
\end{align*}
\end{quotation}
Further:
\begin{quotation}
The original motivation of using signed-digit number system is to eliminate
carry propagation chains in addition (or subtraction). To break the carry chain,
the lower bound on $\alpha$ should be made tighter as
\begin{align*}
\lceil\frac{r+1}{2}\rceil\le\alpha\le r-1
\end{align*}
\end{quotation}

\emph{Parhi}~\cite[Section 13.6]{Parhi_VLSIDigitalSignalProcessingSystems} lists
the following properties of the \emph{canonical} binary signed-digit (CSD)
representation of a binary signed-digit number $A=a_{W-1}a_{W-2}\cdots{}a_{1}a_{0}$
where each $a_{i}\in \left\{-1,0,1\right\}$:
\begin{itemize}
\item no 2 consecutive bits in a CSD number are non-zero
\item the CSD representation of a number contains the miniumum possible number
of non-zero bits, thus the name \emph{canonic}
\item the CSD representation of a number is unique
\item CSD numbers cover the range $\left(-\frac{4}{3},\frac{4}{3}\right)$, out
of which the values in the range $\left[-1,1\right)$ are of greatest interest
\item among the $W$-bit CSD numbers in the range $\left[-1,1\right)$, the
average number of nonzero bits is 
$\frac{W}{3}+\frac{1}{9}+\mathcal{O}\left(2^{-W}\right)$. Hence, on average, the
CSD representation contains about two-thirds the number of
non-zero bits of the equivalent two's complement representation.
\end{itemize}

\emph{Parhi}~\cite[Section 13.6.1]{Parhi_VLSIDigitalSignalProcessingSystems}
shows an algorithm that calculates the \emph{canonical} binary signed-digit 
representation from the two's complement representation, reproduced here as
Algorithm~\ref{alg:twos-complement-to-signed-digit-conversion}.

\begin{algorithm}[htbp]
Denote the two's complement representation of the number $A$ as 
$A=\hat{a}_{W-1}\hat{a}_{W-2}\cdots\hat{a}_{1}\hat{a}_{0}$. \\
Denote the CSD representation of $A$ as $A=a_{W-1}a_{W-2}\cdots{}a_{1}a_{0}$.

\begin{algorithmic}
\State $\hat{a}_{-1}=0$
\State $\gamma_{-1}=0$
\State $\hat{a}_{W}=\hat{a}_{W-1}$
\For{$k=0,\hdots,W-1$}
\State $\theta_{i}=\hat{a}_{i}\oplus\hat{a}_{i-1}$
\State $\gamma_{i}=\bar{\gamma}_{i-1}\theta_{i}$
\State $a_{i}=\left(1-2\hat{a}_{i+1}\right)\gamma_{i}$
\EndFor
\end{algorithmic}
\caption{Conversion of 2's complement numbers to the canonical signed-digit
  representation (\emph{Parhi}~\cite[Section
  13.6.1]{Parhi_VLSIDigitalSignalProcessingSystems}).}
\label{alg:twos-complement-to-signed-digit-conversion}
\end{algorithm}

The Octave function \emph{bin2SPT} converts a two's complement number to the
canonical signed-digit representation. The Octave function \emph{bin2SD} 
approximates an \emph{nbits} two's complement number by the \emph{ndigits}
signed-digit representation.

\section{\label{sec:Lim-allocation-signed-digits}Lim's method for allocating signed-digits to filter coefficients}
\emph{Lim et al.}~\cite{Lim_SignedPowerOfTwoAllocationDigitalFilters} describe
a method of allocating  a limited number of signed power-of-two digit terms 
to the fixed-point coefficients of a digital filter. The method is based 
on the belief that \emph{``allocating the SPT terms in such a way that all the 
coefficient values have the same quantisation step-size to coefficient
sensitivity ratio will lead to a good design''}. 

\emph{Lim et al.} first prove properties of the signed-digit
representation~\cite[Section II]{Lim_SignedPowerOfTwoAllocationDigitalFilters}.
In particular:

\emph{Property 1}: Define $S_{Q}$ as the set of contiguous integers that can be 
represented by up to $Q$ signed digits. The largest integer in $S_{Q}$ is
$J_{Q}=\sum_{l=0}^{Q-1}2^{2l+1}$.

\emph{Property 2}: For $n=\sum^{L-1}_{l=0}s_{l}2^{l}$ with 
$s_{l}\in\left\{-1,0,1\right\}$ it is always possible to 
find a representation for $n$ such that no two consecutive signed-digits are 
non-zero: $s_{l}s_{l+1}=0$ for all $l$.

\emph{Property 5}: On average, $0.72Q$ signed-digits are required to represent
the integers in $S_{Q}$.

\emph{Lim et al.} show that an estimate of the number of signed digits, $Q$, 
required to represent $J_{Q}$ is:
\begin{align*}
  Q \approx \frac{1}{2}\log_{2}J_{Q}+0.31
\end{align*}
Replacing $J_{Q}$ by an integer $n\in S_{Q}$, an estimate of the average number
of terms, $Q_{A}$, required to represent $n$ is:
\begin{align*}
  Q_{A}&\approx 0.72Q\\
      &\approx 0.36 \log_{2}n+0.22
\end{align*}

Now suppose that $R$ signed digits are available to represent two positive
integers $n_{1}$ and $n_{2}$. If $n_{1}\approx n_{2}$ then each integer is
allocated $\frac{R}{2}$ bits. If $n_{1}>n_{2}$ then \emph{Lim et al.} argue 
that the number of additional signed-digits, $Q_{E}$, required to represent 
$n_{1}$ is:
\begin{align*}
  Q_{E}&\approx 0.36\log_{2}\lfloor \frac{n_{1}}{n_{2}}\rfloor
\end{align*}
where $\lfloor x \rfloor$ represents the integer part of $x$. In general, 
$Q_{E}$ is not an integer.

\emph{Lim et al.} go on to consider the allocation of signed digits to the
coefficients of a symmetric FIR filter. The change in the frequency response,
$\Delta{} H\left(\omega\right)$ of a filter due to a change $\Delta{}x_{k}$ in
coefficient $x_{k}$ is:
\begin{align*}
\Delta{} H\left(\omega,k\right)&  \approx
\frac{\partial{}H\left(\omega\right)}{\partial{}x_{k}}\Delta{}x_{k}
\end{align*}
\emph{Lim et al.} use the average of the coefficient sensitivity to define a
cost, $c_{k}$, for the $k$'th coefficient:
\begin{align*}
c_{k}&=0.36\log_{2}\left|x_{k}\right| + 0.36\log_{2}\int^{\pi}_{0}
\left|\frac{\partial{}H\left(\omega\right)}{\partial{}x_{k}}\right|d\omega
\end{align*}

Given a total of $R$ signed-digits, \emph{Lim et al.} assign a single 
signed-digit at a time to the coefficient with the largest cost. After a 
coefficient is given a signed-digit, its cost is decreased by one. The
process is repeated until all $R$ digits have been allocated.
\section{\label{sec:Ito-allocation-signed-digits}Ito's method for allocating signed-digits to filter coefficients}
\emph{Ito et al.}~\cite{Ito_PowersOfTwoAllocationFIR} describe a heuristic for
allocating signed-digits to the coefficients of an FIR filter. Suppose 
$\boldsymbol{x}=\left\{x_{1},\hdots,x_{K}\right\}$ are the
floating-point coefficients of the filter and that each $x_{k}$ is approximated
by an $L$ signed-digit number, $\hat{x}_{k}$, and there are a total of $R$
signed digits to be allocated:
\begin{align*}
\hat{x}_{k}&=\sum^{n_{k}}_{l=1}b_{k,l}2^{-q_{k,l}} 
\end{align*} 
where
\begin{align*}
b_{k,l}&\in\left\{-1,1\right\}\\
q_{k,l}&\le L\\
R&\ge\sum^{K}_{k=1}n_{k}
\end{align*} 

The heuristic of \emph{Ito et al.} allocates the
$R$ available signed digits to the coefficients $\boldsymbol{x}$. 
$c\left(\boldsymbol{x}\right)$ is a cost function for the filter design and
$\boldsymbol{e_{k}}$ is the unit vector with a $1$ in the $k$'th position and
$0$ elsewhere. In this case, $\lceil{}x_{k}\rceil$ is defined to be the least 
CSD upper bound to $x_{k}$ and $\lfloor{}x_{k}\rfloor$ is defined to be the 
greatest CSD lower bound to $x_{k}$. I have modified the heuristic described by 
\emph{Ito et al.} to that shown in 
Algorithm~\ref{alg:Modified-Ito-signed-digit-allocation} by
beginning with an allocation of $2N$ signed digits to each non-zero coefficient 
(where $N$ is the desired average number of signed-digits per coefficient) and
then iteratively removing digits from coefficients with the lowest cost. At
each iteration the new cost for the coefficient is recalculated.

\begin{algorithm}[htbp]
Initialise $n_{k}$:
\begin{algorithmic}
\For{$k=1,\hdots,K$}
\If{$\left|x_{k}\right|<\epsilon$}
\State $n_{k}=0$
\Else
\State $n_{k}=2N$
\EndIf
\EndFor
\end{algorithmic}
Allocate $n_{k}$:
\begin{algorithmic}
\For{$r=2R,\hdots,R$}
\For{$k=1,\hdots,K$}
\If{$n_{k}\ge{}1$}
\State $c^{U}_{k}=c\left(\boldsymbol{x}+\left(\lceil{}x_{k}\rceil-x_{k}\right)
                        \boldsymbol{e_{k}}\right)$
\State $c^{L}_{k}=c\left(\boldsymbol{x}-\left(x_{k}-\lfloor{}x_{k}\rfloor\right)
                        \boldsymbol{e_{k}}\right)$
\State $c_{k}=\min\left\{c^{L}_{k},c^{U}_{k}\right\}$
\EndIf
\EndFor
\State $c_{k_{min}}=\min\left\{c_{k}\right\}$
\State $n_{k_{min}}-=1$
\EndFor
\end{algorithmic}
\caption{Modified signed-digit allocation heuristic of 
\emph{Ito et al.}~\cite{Ito_PowersOfTwoAllocationFIR}.}
\label{alg:Modified-Ito-signed-digit-allocation}
\end{algorithm}
\clearpage
\section{Signed-digit allocation of the coefficients of a Schur one-multiplier lattice filter}
This section compares the performance of the SQP optimised Schur
one-multiplier bandpass filter of
Section~\ref{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-SQP} with
coefficients that are floating-point rounded, approximated by two signed-digits
and approximated by an average of two and three signed-digits allocated by the
\emph{Lim} and \emph{Ito} heuristics. The filter is implemented in the Octave
script \emph{schurOneMlattice\_bandpass\_allocsd\_test.m}. That script designs
a Schur IIR tapped-lattice band-pass filter for which the denominator of the
transfer function has coefficients only in $z^{-2}$ the amplitude passband is
$[0.1,0.2]$, the lower amplitude stopband is $[0, 0.05]$, the upper amplitude
stopband is $[0.25,0.5)$ and the passband group delay is $t_{d}=16$ samples
over $[0.09,0.21]$. There are $31$ non-zero lattice coefficients to be
truncated. I assume that the internal state scaling for round-off noise
reduction is approximated by bit-shifts. The heuristic of \emph{Lim et al.} is
implemented in the Octave function \emph{schurOneMlattice\_allocsd\_Lim} and
the heuristic of \emph{Ito et al.} is implemented in the Octave function
\emph{schurOneMlattice\_allocsd\_Ito.m}. The function
\emph{schurOneMlattice\_allocsd\_Lim} allocates signed digits according to the
gradients of the \emph{un-weighted} sum of the squared-magnitude and
group-delay errors.

Figure~\ref{fig:schurOneMlattice-bandpass-2-allocsd-cost}
compares the cost for each allocation method,
Figure~\ref{fig:schurOneMlattice-bandpass-2-allocsd-sidelobe} compares the
maximum stopband response in the frequency range $[0.26,0.5)$,
Figure~\ref{fig:schurOneMlattice-bandpass-2-allocsd-used} compares the total
number of signed-digits required to implement the coefficient multipliers for
$2$ signed-digits allocated to each non-zero coefficient and
Figure~\ref{fig:schurOneMlattice-bandpass-2-allocsd-noise-gain} compares the
estimated filter noise-gain using word-sizes of $6$ to $16$ bits.
Figure~\ref{fig:schurOneMlattice-bandpass-allocsd-2-10-amplitude} compares the
responses for $10$-bit coefficients and
Figures~\ref{fig:schurOneMlattice-bandpass-allocsd-2-10-pass-amplitude}
and~\ref{fig:schurOneMlattice-bandpass-allocsd-2-10-pass-delay}
compare the passband responses for $10$-bit $2$-signed-digit coefficients.

Figures~\ref{fig:schurOneMlattice-bandpass-3-allocsd-cost},
~\ref{fig:schurOneMlattice-bandpass-3-allocsd-sidelobe},
~\ref{fig:schurOneMlattice-bandpass-3-allocsd-used},
~\ref{fig:schurOneMlattice-bandpass-3-allocsd-noise-gain},
~\ref{fig:schurOneMlattice-bandpass-allocsd-3-10-amplitude},
~\ref{fig:schurOneMlattice-bandpass-allocsd-3-10-pass-amplitude},
and~\ref{fig:schurOneMlattice-bandpass-allocsd-3-10-pass-delay} show the  
corresponding results for an allocation of $3$ signed-digits to each non-zero 
$10$-bit coefficient. For the heuristic of \emph{Ito et al.}, when $3$ bits are 
allocated to each non-zero coefficient approximately $2$ signed-digits per
coefficient are in fact used. 

This filter has been designed with denominator polynomial coefficients only
in powers of $z^{-2}$ so that the filter can be retimed with reduced latency for
the state update and filter output calculations. (As shown in 
Figure~\ref{fig:example-pipelining-a-one-multplier-Schur-lattice-filter}). The 
noise gain of the retimed filter is calculated by converting the lattice 
filter representation to state variable form with the Octave function
\emph{schurOneMR2lattice2Abcd}. The noise gain of the filter with floating-point
coefficients is $3.44804$. A fixed point implementation of the filter would
either scale the states with bit-shifts (ie: by a power of two) or by adding
bits to the state registers as required. In the results shown here the noise
gain calculated for the retimed filter with truncated coefficients does not
include the round-off noise due to state scaling.
\clearpage

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_2_ndigits_cost}}
\caption{Comparison of the cost function for a Schur one-multiplier lattice
bandpass filter with 6-bit to 16-bit integer coefficients found by rounding,
approximation by two signed-digits and approximation by an average of two signed
digits using the heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-2-allocsd-cost}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_2_ndigits_sidelobe}}
\caption{Comparison of the maximum stopband response in the region [0.26,0.5)
for a Schur one-multiplier lattice
bandpass filter with 6-bit to 16-bit integer coefficients found by rounding,
approximation by two signed-digits and approximation by an average of two signed
digits using the heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-2-allocsd-sidelobe}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_2_ndigits_digits}}
\caption{Comparison of the total number of signed-digits required to implement
the coefficients of a Schur one-multiplier lattice
bandpass filter with 6-bit to 16-bit integer coefficients found by rounding,
approximation by two signed-digits and approximation by an average of two signed
digits using the heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-2-allocsd-used}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_2_ndigits_ng}}
\caption{Comparison of the estimated noise gain of a Schur one-multiplier lattice
bandpass filter with 6-bit to 16-bit integer coefficients found by rounding,
approximation by two signed-digits and approximation by an average of two signed
digits using the heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-2-allocsd-noise-gain}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_2_ndigits_10_nbits_amplitude}}
\caption{Comparison of the amplitude responses for a Schur one-multiplier lattice
bandpass filter with 10-bit integer coefficients found by rounding,
approximation by two signed-digits and approximation by an average of two signed
digits using the heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-allocsd-2-10-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_2_ndigits_10_nbits_pass_amplitude}}
\caption{Comparison of the passband amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by rounding, approximation by two signed-digits and approximation by an
  average of two signed digits using the heuristics of \emph{Lim et al.} and
  \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-allocsd-2-10-pass-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_2_ndigits_10_nbits_pass_delay}}
\caption{Comparison of the passband delay responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by rounding, approximation by two signed-digits and approximation by an
  average of two signed digits using the heuristics of \emph{Lim et al.} and
  \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-allocsd-2-10-pass-delay}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_3_ndigits_cost}}
\caption{Comparison of the cost function for a Schur one-multiplier lattice
bandpass filter with 6-bit to 16-bit integer coefficients found by rounding,
approximation by three signed-digits and approximation by an average of three
signed digits using the heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-3-allocsd-cost}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_3_ndigits_sidelobe}}
\caption{Comparison of the maximum stopband response in the region [0.26,0.5)
for a Schur one-multiplier lattice
bandpass filter with 6-bit to 16-bit integer coefficients found by rounding,
approximation by three signed-digits and approximation by an average of three
signed digits using the heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-3-allocsd-sidelobe}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_3_ndigits_digits}}
\caption{Comparison of the total number of signed-digits required to implement
the coefficients of a Schur one-multiplier lattice
bandpass filter with 6-bit to 16-bit integer coefficients found by rounding,
approximation by three signed-digits and approximation by an average of three 
signed digits using the heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-3-allocsd-used}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_3_ndigits_ng}}
\caption{Comparison of the estimated noise gain of a Schur one-multiplier lattice
bandpass filter with 6-bit to 16-bit integer coefficients found by rounding,
approximation by three signed-digits and approximation by an average of two 
signed digits using the heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-3-allocsd-noise-gain}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_3_ndigits_10_nbits_amplitude}}
\caption{Comparison of the amplitude responses for a Schur one-multiplier lattice
bandpass filter with 10-bit integer coefficients found by rounding,
approximation by three signed-digits and approximation by an average of three
signed digits using the heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-allocsd-3-10-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_3_ndigits_10_nbits_pass_amplitude}}
\caption{Comparison of the passband amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by rounding, approximation by three signed-digits and approximation by an
  average of three signed digits using the heuristics of
  \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-allocsd-3-10-pass-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMlattice_bandpass_allocsd_test_3_ndigits_10_nbits_pass_delay}}
\caption{Comparison of the passband amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by rounding, approximation by three signed-digits and approximation by an
  average of three signed digits using the heuristics of
  \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:schurOneMlattice-bandpass-allocsd-3-10-pass-delay}
\end{figure}
\clearpage
\section{Signed-digit allocation of the coefficients of a symmetric FIR band-pass filter}
This section compares the performance of a direct-form even-order
symmetric FIR bandpass with coefficients that are floating-point, rounded,
approximated by two signed-digits and approximated by an average of two and
three signed-digits allocated by the \emph{Lim} and \emph{Ito} heuristics.  The
comparison is implemented in the Octave script
\emph{directFIRsymmetric\_bandpass\_allocsd\_test.m}. That script calls the
Octave function \emph{directFIRsymmetric\_slb} to design a symmetric FIR
band-pass filter polynomial of order $30$ with $16$ distinct coefficients. The
filter amplitude passband is $[0.1,0.2]$, the lower amplitude stopband is
$[0, 0.05]$ and the upper amplitude stopband is $[0.25,0.5)$. The heuristic of
\emph{Lim et al.} is implemented in the Octave function
\emph{directFIRsymmetric\_allocsd\_Lim}.  That function allocates signed
digits according to the gradients of the \emph{un-weighted} sum of the
magnitude errors. The heuristic of \emph{Ito et al.}  is implemented in the
Octave function \emph{directFIRsymmetric\_allocsd\_Ito.m}.

Figure~\ref{fig:directFIRsymmetric-bandpass-2-allocsd-cost} compares the cost
for each allocation method,
Figure~\ref{fig:directFIRsymmetric-bandpass-2-allocsd-sidelobe} compares the
maximum stopband response in the frequency range $[0.26,0.5)$,
Figure~\ref{fig:directFIRsymmetric-bandpass-2-allocsd-used} compares the total
number of signed-digits required to implement the coefficient multipliers for
$2$ signed-digits allocated to each non-zero coefficient and
Figures~\ref{fig:directFIRsymmetric-bandpass-allocsd-2-10-amplitude}
and~\ref{fig:directFIRsymmetric-bandpass-allocsd-2-10-pass-amplitude}
compare the responses for $10$-bit $2$-signed-digit coefficients.
Figures~\ref{fig:directFIRsymmetric-bandpass-3-allocsd-cost},
~\ref{fig:directFIRsymmetric-bandpass-3-allocsd-sidelobe},
~\ref{fig:directFIRsymmetric-bandpass-3-allocsd-used},
~\ref{fig:directFIRsymmetric-bandpass-allocsd-3-10-amplitude} and
~\ref{fig:directFIRsymmetric-bandpass-allocsd-3-10-pass-amplitude}
show the corresponding results for an allocation of $3$ signed-digits to each
non-zero $10$-bit coefficient.
\clearpage
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_bandpass_allocsd_test_2_ndigits_cost}}
\caption{Comparison of the cost function for a direct-form even-order
  symmetric FIR bandpass filter with 6-bit to 16-bit integer coefficients
  found by rounding, approximation by two signed-digits and approximation by
  an average of two signed digits using the heuristics of \emph{Lim et al.}
  and \emph{Ito et al.}\;.}
\label{fig:directFIRsymmetric-bandpass-2-allocsd-cost}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_bandpass_allocsd_test_2_ndigits_sidelobe}}
\caption{Comparison of the maximum stopband response in the region [0.26,0.5)
  for a direct-form even-order symmetric FIR bandpass filter with 6-bit to
  16-bit integer coefficients found by rounding, approximation by two
  signed-digits and approximation by an average of two signed digits using the
  heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:directFIRsymmetric-bandpass-2-allocsd-sidelobe}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_bandpass_allocsd_test_2_ndigits_digits}}
\caption{Comparison of the total number of signed-digits required to implement
  the coefficients of a direct-form even-order symmetric FIR bandpass filter
  with 6-bit to 16-bit integer coefficients found by rounding, approximation
  by two signed-digits and approximation by an average of two signed digits
  using the heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:directFIRsymmetric-bandpass-2-allocsd-used}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_bandpass_allocsd_test_2_ndigits_10_nbits_amplitude}}
\caption{Comparison of the amplitude responses for a direct-form even-order
  symmetric FIR bandpass filter with 10-bit integer coefficients found by
  rounding, approximation by two signed-digits and approximation by an average
  of two signed digits using the heuristics of \emph{Lim et al.} and
  \emph{Ito et al.}\;.}
\label{fig:directFIRsymmetric-bandpass-allocsd-2-10-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_bandpass_allocsd_test_2_ndigits_10_nbits_pass_amplitude}}
\caption{Comparison of the pass-band amplitude responses for a direct-form
  even-order symmetric FIR bandpass filter with 10-bit integer coefficients
  found by rounding, approximation by two signed-digits and approximation by an
  average of two signed digits using the heuristics of \emph{Lim et al.} and
  \emph{Ito et al.}\;.}
\label{fig:directFIRsymmetric-bandpass-allocsd-2-10-pass-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_bandpass_allocsd_test_3_ndigits_cost}}
\caption{Comparison of the cost function for a direct-form even-order
  symmetric FIR bandpass filter with 6-bit to 16-bit integer coefficients
  found by rounding, approximation by three signed-digits and approximation by
  an average of three signed digits using the heuristics of \emph{Lim et al.}
  and \emph{Ito et al.}\;.}
\label{fig:directFIRsymmetric-bandpass-3-allocsd-cost}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_bandpass_allocsd_test_3_ndigits_sidelobe}}
\caption{Comparison of the maximum stopband response in the region [0.26,0.5)
  for a direct-form even-order symmetric FIR bandpass filter with 6-bit to
  16-bit integer coefficients found by rounding, approximation by three
  signed-digits and approximation by an average of three signed digits using
  the heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:directFIRsymmetric-bandpass-3-allocsd-sidelobe}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_bandpass_allocsd_test_3_ndigits_digits}}
\caption{Comparison of the total number of signed-digits required to implement
  the coefficients of a direct-form even-order symmetric FIR bandpass filter
  with 6-bit to 16-bit integer coefficients found by rounding, approximation
  by three signed-digits and approximation by an average of three signed
  digits using the heuristics of \emph{Lim et al.} and \emph{Ito et al.}\;.}
\label{fig:directFIRsymmetric-bandpass-3-allocsd-used}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_bandpass_allocsd_test_3_ndigits_10_nbits_amplitude}}
\caption{Comparison of the amplitude responses for a direct-form even-order
  symmetric FIR bandpass filter with 10-bit integer coefficients found by
  rounding, approximation by three signed-digits and approximation by an average
  of three signed digits using the heuristics of \emph{Lim et al.} and
  \emph{Ito et al.}\;.}
\label{fig:directFIRsymmetric-bandpass-allocsd-3-10-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_bandpass_allocsd_test_3_ndigits_10_nbits_pass_amplitude}}
\caption{Comparison of the pass-band amplitude responses for a direct-form
  even-order symmetric FIR bandpass filter with 10-bit integer coefficients
  found by rounding, approximation by three signed-digits and approximation by
  an average of three signed digits using the heuristics of \emph{Lim et al.}
  and \emph{Ito et al.}\;.}
\label{fig:directFIRsymmetric-bandpass-allocsd-3-10-pass-amplitude}
\end{figure}

\chapter{\label{sec:Exhaustive-search-for-integer-signed-digit-filter-coefficients}Exhaustive search for integer and signed-digit filter coefficients}
The Octave script \emph{exhaustive\_schurOneMlattice\_bandpass\_test.m} implements
an exhaustive search for the best signed-digit approximation to the
floating-point coefficients of the Schur one-multiplier lattice band-pass filter
designed in
Section~\ref{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-SQP}. The
cost function for the search calculates the weighted root-squared-error of
the amplitude and group-delay responses of the filter when compared to an ideal
``brick-wall'' response. The band-pass filter has $31$ non-zero coefficients and
each coefficient is selected from an upper and lower bound on the exact value so
the exhaustive search will perform $2^{32}$ evaluations of the cost function.
Preliminary experiments showed that this script would require about a month of
processing time on my PC (which has an Intel i7-7700K CPU with 4 cores running
at 4.2GHz).

\chapter{\label{sec:bit-flip-searching-for-integer-signed-digit-filter-coefficients}Searching
  for integer and signed-digit filter coefficients with the
  \emph{bit-flipping} algorithm}
\emph{Krukowski and 
Kale}~\cite{KrukowskiKale_FixedPointFilterDesignBitFlippingSimplex}, describe
a ``bit-flipping'' algorithm for fixed-point filter design, shown in flow-graph
form in Figure~\ref{fig:krukowski-kale-bit-flipping-algorithm}
(from~\cite[Figure 2]{KrukowskiKale_FixedPointFilterDesignBitFlippingSimplex}).

\begin{figure}[!ht]
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{BitFlippingAlgorithm}
\caption{The bit-flipping algorithm of \emph{Krukowski and Kale}~\cite[Figure 2]{KrukowskiKale_FixedPointFilterDesignBitFlippingSimplex}.}
\label{fig:krukowski-kale-bit-flipping-algorithm}
\end{figure}

The bit-flipping algorithm searches for an improvement in a cost-function by 
testing each combination of bits within a window for each coefficient. When no 
further improvement is found the window is shifted toward the
least-significant-bits and the search is repeated. The bit-flipping algorithm 
is implemented in the Octave function \emph{bitflip}. 

In the following examples I apply the bit-flipping algoritm to direct-form,
Schur normalised-scaled lattice and Schur one-multiplier lattice IIR filter
implementations.

The initial IIR filter is that designed by the Octave script
\emph{iir\_sqp\_slb\_bandpass\_test.m} with:
\begin{small}
\begin{verbatim}
fapl=0.1           % Amplitude passband lower edge (fs=1)
faph=0.2           % Amplitude passband upper edge
dBap=1             % Amplitude passband ripple (dB)
ftpl=0.09          % Group delay passband lower edge
ftph=0.21          % Group delay passband upper edge
tp=16              % Passband group delay (samples)
tpr=0.08           % Passband group delay ripple
fasl=0.05          % Amplitude lower stopband upper edge
fasl=0.25          % Amplitude upper stopband lower edge
dBas=35            % Amplitude stopband attenuation
\end{verbatim}
\end{small}

For completeness, I also apply the bit-flipping algorithm to the coefficients
of a minimum-phase Schur FIR lattice band-pass filter and a direct-form
linear-phase symmetric FIR band-pass filter having the desired frequency
bands. The parallel allpass one-multiplier Schur lattice filter has amplitude
response constraints of $dBap=2$ and $dBas=53$. The Schur FIR lattice has
amplitude response constraints of $dBap=3$ and $dBas=25$. The direct-form
symmetric FIR filter has amplitude response constraints of $dBap=2$ and
$dBas=46$. 

For each example a cost function compares an ideal, ``brick-wall'' response 
with the responses for the floating-point filter coefficients and the filter
coefficients approximated by 8-bit rounded, 8-bit rounding optimised with the
bit-flipping algorithm, 8-bit 2-signed-digits and 8-bit 2-signed-digits 
optimised with the bit-flipping algorithm. The cost function weights the 
stop-band amplitude error by $W_{asl}=W_{asu}=30$. Bit-flipping starts at bit
6 of 8 bits and uses a mask size of 3 bits. 
\clearpage
\section{Bit-flipping search for the signed-digit coefficients of a
  direct-form bandpass IIR filter}
The Octave script \emph{bitflip\_directIIR\_bandpass\_test.m} applies the
bit-flipping algorithm to a direct-form IIR bandpass filter with the following
filter transfer function polynomials:
\begin{small}
\verbatiminput{bitflip_directIIR_bandpass_test_n_ex_coef.m}
\verbatiminput{bitflip_directIIR_bandpass_test_d_ex_coef.m}
\end{small}
There is no attempt to ensure that the bit-flipped filter transfer function is
stable.

Figures~\ref{fig:bitflip-bandpass-direct-iir-amplitude}
and~\ref{fig:bitflip-bandpass-direct-iir-delay} show the amplitude and group
delay responses.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_directIIR_bandpass_test_amplitude}}
\caption{Amplitude responses of a direct-form IIR band-pass
  filter with floating-point coefficients, 8-bit rounded coefficients, 8-bit
  rounded coefficients optimised with the bit-flipping algorithm, 8-bit
  2-signed-digit coefficients and 8-bit 2-signed-digit coefficients optimised
  with the bit-flipping algorithm.}
\label{fig:bitflip-bandpass-direct-iir-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_directIIR_bandpass_test_delay}}
\caption{Group-delay responses of a direct-form IIR band-pass
  filter with floating-point coefficients, 8-bit rounded coefficients, 8-bit
  rounded coefficients optimised with the bit-flipping algorithm, 8-bit
  2-signed-digit coefficients and 8-bit 2-signed-digit coefficients optimised
  with the bit-flipping algorithm.}
\label{fig:bitflip-bandpass-direct-iir-delay}
\end{figure}

Table~\ref{tab:bitflip-bandpass-direct-iir-cost-summary} compares the cost
result for each test.

\begin{table}
\centering
\begin{threeparttable}
  \begin{tabular}{lr}  \\ \toprule
    Band-pass direct form IIR & Cost \\ \midrule
    \input{bitflip_directIIR_bandpass_test_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the direct form bandpass filter
bit-flipping algorithm example] {Summary of the cost results for the direct
  form IIR bandpass filter with floating-point coefficients, 8-bit rounded
  coefficients, 8-bit rounded coefficients optimised with the bit-flipping
  algorithm, 8-bit 2-signed-digit coefficients and 8-bit 2-signed-digit
  coefficients optimised with the bit-flipping algorithm.}
\label{tab:bitflip-bandpass-direct-iir-cost-summary}
\end{table}

The \emph{bitflip} optimised 8-bit 2 signed-digit direct-form IIR transfer
function coefficients are:
\begin{small}
\verbatiminput{bitflip_directIIR_bandpass_test_n_bfsd_coef.m}
\verbatiminput{bitflip_directIIR_bandpass_test_d_bfsd_coef.m}
\end{small}

A total of \input{bitflip_directIIR_bandpass_test_adders.tab}adders is
required to implement these signed-digit coefficients.

\section{Bit-flipping search for the signed-digit coefficients of a
  normalised-scaled lattice bandpass IIR filter}
The Octave script \emph{bitflip\_schurNSlattice\_bandpass\_test.m} applies the
bit-flipping algorithm to the example bandpass filter implemented as a Schur
normalised-scaled lattice filter.

Figures~\ref{fig:bitflip-bandpass-NS-lattice-amplitude}
and~\ref{fig:bitflip-bandpass-NS-lattice-delay} show the amplitude and group
delay responses of the filter/

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurNSlattice_bandpass_test_amplitude}}
\caption{Amplitude responses of a band-pass filter synthesised
as a normalised-scaled lattice filter with floating-point coefficients,
8-bit rounded coefficients, 8-bit rounded coefficients optimised 
with the bit-flipping algorithm, 8-bit 2-signed-digit coefficients and 8-bit 
2-signed-digit coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip-bandpass-NS-lattice-amplitude}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurNSlattice_bandpass_test_delay}}
\caption{Group delay responses of a band-pass filter synthesised
as a normalised-scaled lattice filter with floating-point coefficients,
8-bit rounded coefficients, 8-bit rounded coefficients optimised 
with the bit-flipping algorithm, 8-bit 2-signed-digit coefficients and 8-bit 
2-signed-digit coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip-bandpass-NS-lattice-delay}
\end{figure}

Table~\ref{tab:bitflip-bandpass-NS-lattice-cost-summary} compares the cost
result for each test. 
\begin{table}
\centering
\begin{threeparttable}
\begin{tabular}{lr}  \\ \toprule
Band-pass Schur normalised-scaled & Cost \\ \midrule
\input{bitflip_schurNSlattice_bandpass_test_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the normalised-scaled bandpass
filter bit-flipping algorithm example]{Summary of the cost results for the
  bandpass filter synthesised as a normalised-scaled lattice filter with
  floating-point coefficients, 8-bit rounded coefficients, 8-bit rounded
  coefficients optimised with the bit-flipping algorithm, 8-bit 2-signed-digit
  coefficients and 8-bit 2-signed-digit coefficients optimised with the
  bit-flipping algorithm.}
\label{tab:bitflip-bandpass-NS-lattice-cost-summary}
\end{table}

The \emph{bitflip} optimised 8-bit 2 signed-digit lattice filter coefficients
are:
\begin{small}
\verbatiminput{bitflip_schurNSlattice_bandpass_test_s10_bfsd_coef.m}
\verbatiminput{bitflip_schurNSlattice_bandpass_test_s11_bfsd_coef.m}
\verbatiminput{bitflip_schurNSlattice_bandpass_test_s20_bfsd_coef.m}
\verbatiminput{bitflip_schurNSlattice_bandpass_test_s00_bfsd_coef.m}
\verbatiminput{bitflip_schurNSlattice_bandpass_test_s02_bfsd_coef.m}
\verbatiminput{bitflip_schurNSlattice_bandpass_test_s22_bfsd_coef.m}
A total of \input{bitflip_schurNSlattice_bandpass_test_adders.tab}adders is
required to implement these signed-digit coefficients.
\end{small}

\section{\label{sec:bit-flip-signed-digit-one-m-lattice-bandpass}Bit-flipping search for the signed-digit coefficients of a one-multiplier lattice bandpass IIR filter}
The Octave script \emph{bitflip\_schurOneMlattice\_bandpass\_test.m} applies the
bit-flipping algorithm to the example bandpass filter implemented as a Schur 
one-multiplier lattice filter. Note that, in this example, the one-multiplier 
state scaling coefficients are not truncated. 

Figures~\ref{fig:bitflip-bandpass-OneM-lattice-amplitude}
and~\ref{fig:bitflip-bandpass-OneM-lattice-delay} show the filter amplitude and
group delay responses.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurOneMlattice_bandpass_test_amplitude}}
\caption{Amplitude responses of a band-pass filter synthesised
as a one-multiplier lattice filter with floating-point coefficients,
8-bit rounded coefficients, 8-bit rounded coefficients optimised 
with the bit-flipping algorithm, 8-bit 2-signed-digit coefficients and 8-bit 
2-signed-digit coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip-bandpass-OneM-lattice-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurOneMlattice_bandpass_test_delay}}
\caption{Group-delay responses of a band-pass filter synthesised
as a one-multiplier lattice filter with floating-point coefficients,
8-bit rounded coefficients, 8-bit rounded coefficients optimised 
with the bit-flipping algorithm, 8-bit 2-signed-digit coefficients and 8-bit 
2-signed-digit coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip-bandpass-OneM-lattice-delay}
\end{figure}

Figures~\ref{fig:bitflip-bandpass-OneM-lattice-amplitude-allocsd}
and~\ref{fig:bitflip-bandpass-OneM-lattice-delay-allocsd}
show the filter amplitude and group delay responses for the signed-digit
coefficients with 2-signed-digits, 2-signed-digits allocated with Lim's
algorithm and 2-signed-digits allocated with Ito's algorithm.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurOneMlattice_bandpass_test_amplitude_allocsd}}
\caption{Amplitude responses of a band-pass filter synthesised
as a one-multiplier lattice filter with floating-point coefficients,
8-bit 2-signed-digit coefficients allocated with Lim's algorithm, 8-bit 
2-signed-digit coefficients allocated with Lim's algorithm and optimised with
the bit-flipping algorithm, 8-bit 2-signed-digit coefficients allocated with 
Ito's algorithm and 8-bit 2-signed-digit coefficients allocated with Ito's 
algorithm and optimised with the bit-flipping algorithm.}
\label{fig:bitflip-bandpass-OneM-lattice-amplitude-allocsd}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurOneMlattice_bandpass_test_delay_allocsd}}
\caption{Group-delay responses of a band-pass filter synthesised
as a one-multiplier lattice filter with floating-point coefficients,
8-bit 2-signed-digit coefficients allocated with Lim's algorithm, 8-bit 
2-signed-digit coefficients allocated with Lim's algorithm and optimised with
the bit-flipping algorithm, 8-bit 2-signed-digit coefficients allocated with 
Ito's algorithm and 8-bit 2-signed-digit coefficients allocated with Ito's 
algorithm and optimised with the bit-flipping algorithm.}
\label{fig:bitflip-bandpass-OneM-lattice-delay-allocsd}
\end{figure}

Table~\ref{tab:bitflip-bandpass-OneM-lattice-cost-summary} compares the cost
result for each test. 
\begin{table}[!ht]
\centering
\begin{threeparttable}
\begin{tabular}{lr}  \\ \toprule
Band-pass Schur one-multiplier & Cost \\ \midrule
\input{bitflip_schurOneMlattice_bandpass_test_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the one-multiplier bandpass
filter bit-flipping algorithm example]
{Summary of the cost results for the bandpass 
filter synthesised as a one-multiplier lattice filter with floating-point
coefficients, 8-bit rounded coefficients, 8-bit rounded coefficients 
optimised with the bit-flipping algorithm, 8-bit 2-signed-digit coefficients
and 8-bit 2-signed-digit coefficients optimised with the bit-flipping 
algorithm. The signed digits are allocated with 2 digits each, Lim's allocation
method with an average of 2-signed-digits each and Ito's allocation method
with an average of 2-signed-digits each.}
\label{tab:bitflip-bandpass-OneM-lattice-cost-summary}
\end{table}

The \emph{bitflip} optimised 8-bit, rounded, one-multiplier lattice
bandpass filter coefficients are: 
\begin{small}
\verbatiminput{bitflip_schurOneMlattice_bandpass_test_k_bf_coef.m}
\verbatiminput{bitflip_schurOneMlattice_bandpass_test_c_bf_coef.m}
\end{small}
A total of \input{bitflip_schurOneMlattice_bandpass_test_adders_bf.tab}adders
is required to implement these rounded coefficients.

The \emph{bitflip} optimised 8-bit, 2-signed-digit, one-multiplier lattice
bandpass filter coefficients are: 
\begin{small}
\verbatiminput{bitflip_schurOneMlattice_bandpass_test_k_bfsd_coef.m}
\verbatiminput{bitflip_schurOneMlattice_bandpass_test_c_bfsd_coef.m}
\end{small}
A total of \input{bitflip_schurOneMlattice_bandpass_test_adders_bfsd.tab}adders
is required to implement these signed-digit coefficients.
\section{Bit-flipping search for the signed-digit coefficients of
  a one-multiplier parallel-allpass lattice bandpass IIR filter}
The Octave script \emph{bitflip\_schurOneMPAlattice\_bandpass\_test.m} applies
the bit-flipping algorithm to the example bandpass filter implemented as a Schur 
parallel-allpass one-multiplier lattice filter. Note that, in this example, the
one-multiplier state scaling coefficients are not truncated. The IIR filter in
Section~\ref{sec:bit-flip-signed-digit-one-m-lattice-bandpass} has a denominator
polynomial decimated with $R=2$. The initial IIR filter in this example
is that designed by the Octave script
\emph{schurOneMPAlattice\_socp\_slb\_bandpass\_test.m}. 

Figures~\ref{fig:bitflip-bandpass-OneMPA-lattice-amplitude}
and~\ref{fig:bitflip-bandpass-OneMPA-lattice-delay}
show the filter amplitude and group delay responses with floating-point
coefficients, 8-bit rounded coefficients, 8-bit rounded coefficients optimised
with the bit-flipping algorithm, 8-bit 2-signed-digit coefficients and 8-bit
2-signed-digit coefficients optimised with the bit-flipping algorithm.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurOneMPAlattice_bandpass_test_amplitude}}
\caption{Amplitude responses of a band-pass filter synthesised
  as a parallel-allpass one-multiplier lattice filter with floating-point
  coefficients, 8-bit rounded coefficients, 8-bit rounded coefficients optimised 
  with the bit-flipping algorithm, 8-bit 2-signed-digit coefficients and 8-bit 
  2-signed-digit coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip-bandpass-OneMPA-lattice-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurOneMPAlattice_bandpass_test_delay}}
\caption{Group delay responses of a band-pass filter synthesised
  as a parallel-allpass one-multiplier lattice filter with floating-point
  coefficients, 8-bit rounded coefficients, 8-bit rounded coefficients optimised 
  with the bit-flipping algorithm, 8-bit 2-signed-digit coefficients and 8-bit 
  2-signed-digit coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip-bandpass-OneMPA-lattice-delay}
\end{figure}

Figures~\ref{fig:bitflip-bandpass-OneMPA-lattice-amplitude-allocsd}
and~\ref{fig:bitflip-bandpass-OneMPA-lattice-delay-allocsd}.
shoe the filter amplitude and group delay responses for the signed-digit
coefficients with 2-signed-digits, 2-signed-digits allocated with Lim's
algorithm and 2-signed-digits allocated with Ito's algorithm.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurOneMPAlattice_bandpass_test_amplitude_allocsd}}
\caption{Amplitude responses of a band-pass filter
  synthesised as a parallel-allpass one-multiplier lattice filter with
  floating-point coefficients, 8-bit 2-signed-digit coefficients allocated with
  Lim's algorithm, 8-bit 2-signed-digit coefficients allocated with Lim's
  algorithm and optimised with the bit-flipping algorithm, 8-bit 2-signed-digit
  coefficients allocated with Ito's algorithm and 8-bit 2-signed-digit
  coefficients allocated with Ito's algorithm and optimised with the
  bit-flipping algorithm.}
\label{fig:bitflip-bandpass-OneMPA-lattice-amplitude-allocsd}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurOneMPAlattice_bandpass_test_delay_allocsd}}
\caption{Group-delay responses of a band-pass filter
  synthesised as a parallel-allpass one-multiplier lattice filter with
  floating-point coefficients, 8-bit 2-signed-digit coefficients allocated with
  Lim's algorithm, 8-bit 2-signed-digit coefficients allocated with Lim's
  algorithm and optimised with the bit-flipping algorithm, 8-bit 2-signed-digit
  coefficients allocated with Ito's algorithm and 8-bit 2-signed-digit
  coefficients allocated with Ito's algorithm and optimised with the
  bit-flipping algorithm.}
\label{fig:bitflip-bandpass-OneMPA-lattice-delay-allocsd}
\end{figure}

Table~\ref{tab:bitflip-bandpass-OneMPA-lattice-cost-summary} compares the cost
result for each test. 
\begin{table}[!ht]
\centering
\begin{threeparttable}
\begin{tabular}{lr}  \\ \toprule
Band-pass Schur parallel-allpass one-multiplier & Cost \\ \midrule
\input{bitflip_schurOneMPAlattice_bandpass_test_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the parallel-allpass one-multiplier bandpass
filter bit-flipping algorithm example]
{Summary of the cost results for the bandpass 
filter synthesised as a parallel-allpass one-multiplier lattice filter with
floating-point coefficients, 8-bit rounded coefficients, 8-bit rounded
coefficients  optimised with the bit-flipping algorithm, 8-bit 2-signed-digit
coefficients and 8-bit 2-signed-digit coefficients optimised with the
bit-flipping algorithm. The signed digits are allocated with 2 digits each,
Lim's allocation method with an average of 2-signed-digits each and Ito's
allocation method with an average of 2-signed-digits each.}
\label{tab:bitflip-bandpass-OneMPA-lattice-cost-summary}
\end{table}

The \emph{bitflip} optimised 8-bit, rounded, parallel-allpass
one-multiplier lattice bandpass filter coefficients are: 
\begin{small}
\verbatiminput{bitflip_schurOneMPAlattice_bandpass_test_A1k_bf_coef.m}
\verbatiminput{bitflip_schurOneMPAlattice_bandpass_test_A2k_bf_coef.m}
\end{small}
A total of \input{bitflip_schurOneMPAlattice_bandpass_test_adders_bf.tab}adders
is required to implement these rounded coefficients.

The \emph{bitflip} optimised 8-bit, 2-signed-digit, parallel-allpass
one-multiplier lattice bandpass filter coefficients are: 
\begin{small}
\verbatiminput{bitflip_schurOneMPAlattice_bandpass_test_A1k_bfsd_coef.m}
\verbatiminput{bitflip_schurOneMPAlattice_bandpass_test_A2k_bfsd_coef.m}
\end{small}
A total of \input{bitflip_schurOneMPAlattice_bandpass_test_adders_bfsd.tab}adders
is required to implement these signed-digit coefficients.
\section{Bitflipping search for the signed-digit coefficients of a
  minimum-phase bandpass FIR filter}
Section~\ref{sec:Minimum-phase-FIR-bandpass-filter} shows the design of a
minimum-phase FIR bandpass filter with an amplitude response that is similar
to that of the IIR examples above. A minimum-phase FIR filter has all zeros
within the unit circle so that the filter polynomial has a Schur
decomposition. The filter is not linear phase and does not have a flat group
delay response. The FIR Schur lattice has two real multipliers for each
reflection coefficient~\cite{DogonataVaidyanathan_OneMultiplierLatticeFIR}.

The Octave script, \emph{bitflip\_schurFIRlattice\_bandpass\_test.m}
implements the band-pass filter as a minimum-phase Schur FIR lattice filter.
In contrast to the previous examples in this chapter, the cost function does 
not include the group-delay error. As for the Schur one-multiplier lattice IIR
filter example, the FIR state scaling coefficients are not truncated. The
initial bandpass Schur lattice FIR filter polynomial is that calculated by the
Octave script \emph{iir\_sqp\_slb\_fir\_17\_bandpass\_test.m}:
\begin{small}
\verbatiminput{bitflip_schurFIRlattice_bandpass_test_b0_coef.m}
\end{small}
The Schur FIR lattice multiplier coefficients of the initial filter are
\begin{small}
\verbatiminput{bitflip_schurFIRlattice_bandpass_test_k_ex_coef.m}
\end{small}
The initial FIR filter has order $17$, $16$ lattice coefficients and $32$ 
multiplies per sample which is similar to the one-multiplier Schur lattice 
bandpass filter of the previous example. 

Figures~\ref{fig:bitflip-bandpass-schur-FIR-lattice-amplitude}
and~\ref{fig:bitflip-bandpass-schur-FIR-lattice-delay}
show the initial filter amplitude and group delay responses and the filter
responses after coefficient truncation.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurFIRlattice_bandpass_test_amplitude}}
\caption{Amplitude responses of a minimum-phase band-pass filter
synthesised as a Schur FIR lattice filter with floating-point coefficients, 8-bit
rounded coefficients, 8-bit rounded coefficients optimised with the 
bit-flipping algorithm, 8-bit 2-signed-digit coefficients and 8-bit 
2-signed-digit coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip-bandpass-schur-FIR-lattice-amplitude}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurFIRlattice_bandpass_test_delay}}
\caption{Group-delay responses of a minimum-phase band-pass filter
synthesised as a Schur FIR lattice filter with floating-point coefficients, 8-bit
rounded coefficients, 8-bit rounded coefficients optimised with the 
bit-flipping algorithm, 8-bit 2-signed-digit coefficients and 8-bit 
2-signed-digit coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip-bandpass-schur-FIR-lattice-delay}
\end{figure}

Table~\ref{tab:bitflip-bandpass-schur-FIR-lattice-cost-summary} compares the
cost results for each truncation method. 
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lr}  \\ \toprule
Band-pass Schur FIR & Cost \\ \midrule
\input{bitflip_schurFIRlattice_bandpass_test_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the Schur FIR minimum-phase 
bandpass filter bit-flipping algorithm example]
{Summary of the cost results for the FIR
minimum-phase bandpass filter synthesised as a Schur FIR lattice filter with
floating-point coefficients, 8-bit rounded coefficients, 8-bit rounded
coefficients optimised with the bit-flipping algorithm, 8-bit 2-signed-digit
coefficients and 8-bit 2-signed-digit coefficients optimised with the
bit-flipping algorithm.}
\label{tab:bitflip-bandpass-schur-FIR-lattice-cost-summary}
\end{table}

The \emph{bitflip} optimised 8-bit 2-signed-digit Schur FIR lattice
coefficients are:
\begin{small}
\verbatiminput{bitflip_schurFIRlattice_bandpass_test_k_bfsd_coef.m}
\end{small}
A total of \input{bitflip_schurFIRlattice_bandpass_test_adders.tab}adders is
required to implement these signed-digit coefficients.
\section{Bit-flipping search for the signed-digit coefficients of a
  direct-form symmetric bandpass FIR filter}
Appendix~\ref{app:PCLS-design-non-symmetric-FIR-filters-SOCP}
shows the design of a direct-form symmetric FIR bandpass filter with an
amplitude response that is similar to that of the IIR examples above. The
filter is linear phase and consequently has a flat group delay response.
The Octave script \emph{bitflip\_directFIRsymmetric\_bandpass\_test.m} uses
the bit-flipping algorithm to optimise the coefficients when truncated to
8-bit integers. The initial filter polynomial is that designed by the Octave
script \emph{directFIRsymmetric\_slb\_bandpass\_test.m}.
The distinct initial coefficients are:
\begin{small}
\verbatiminput{bitflip_directFIRsymmetric_bandpass_test_hM_ex_coef.m}
\end{small}
The filter order is $30$ giving a filter delay of $15$ samples. The symmetric
direct-form implementation requires $16$ multipliers.
Figure~\ref{fig:bitflip-direct-form-symmetric-bandpass-FIR-response} shows the
initial filter response and the filter responses after coefficient truncation.
The bit-flipping algorithm does not improve the response obtained with 8-bit
rounded coefficients.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_directFIRsymmetric_bandpass_test_response}}
\caption{Amplitude and group-delay responses of a direct-form symmetric FIR
  band-pass filter with floating-point coefficients, 8-bit rounded coefficients,
  8-bit rounded coefficients optimised with the bit-flipping algorithm, 8-bit
  2-signed-digit coefficients and 8-bit 2-signed-digit coefficients optimised
  with the bit-flipping algorithm.}
\label{fig:bitflip-direct-form-symmetric-bandpass-FIR-response}
\end{figure}

The filter responses for the signed-digit coefficients with 2-signed-digits,
2-signed-digits allocated with Lim's algorithm and 2-signed-digits allocated
with Ito's algorithm are shown in 
Figure~\ref{fig:bitflip-direct-form-symmetric-bandpass-FIR-response-allocsd}.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_directFIRsymmetric_bandpass_test_response_allocsd}}
\caption{Amplitude and group-delay responses of a direct-form symmetric FIR
  band-pass filter with floating-point coefficients, 8-bit 2-signed-digit
  coefficients allocated with Lim's algorithm, 8-bit 2-signed-digit coefficients
  allocated with Lim's algorithm and optimised with the bit-flipping algorithm,
  8-bit 2-signed-digit coefficients allocated with Ito's algorithm and 8-bit
  2-signed-digit coefficients allocated with Ito's algorithm and optimised
  with the bit-flipping algorithm.}
\label{fig:bitflip-direct-form-symmetric-bandpass-FIR-response-allocsd}
\end{figure}

Table~\ref{tab:bitflip-direct-form-symmetric-bandpass-FIR-cost-summary}
compares the cost results for each truncation method. 

\begin{table}
\centering
 \begin{threeparttable}
\begin{tabular}{lr}  \\ \toprule
Band-pass direct-form symmetric FIR & Cost \\ \midrule
\input{bitflip_directFIRsymmetric_bandpass_test_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the direct-form symmetric FIR bandpass
filter bit-flipping algorithm example] {Summary of the cost results for the
  direct-form symmetric FIR bandpass filter with floating-point coefficients,
  8-bit rounded coefficients, 8-bit rounded coefficients optimised with the
  bit-flipping algorithm, 8-bit 2-signed-digit coefficients and 8-bit
  2-signed-digit coefficients optimised with the bit-flipping algorithm. The
  signed digits are allocated with 2 digits each, Lim's allocation method with
  an average of 2-signed-digits each and Ito's allocation method with an
  average of 2-signed-digits each.}
\label{tab:bitflip-direct-form-symmetric-bandpass-FIR-cost-summary}
\end{table}

The \emph{bitflip} optimised 8-bit 2-signed-digits (allocated with Lim's
algorithm) direct-form symmetric filter coefficients are:
\begin{small}
\verbatiminput{bitflip_directFIRsymmetric_bandpass_test_hM_bfsdl_coef.m}
\end{small}
The coefficients are scaled to make full use of the 8-bit range. A total of
\input{bitflip_directFIRsymmetric_bandpass_test_adders_Lim.tab}adders is
required to implement these signed-digit coefficients.

The \emph{bitflip} optimised 8-bit rounded direct-form symmetric FIR
coefficients are:
\begin{small}
\verbatiminput{bitflip_directFIRsymmetric_bandpass_test_hM_bf_coef.m}
\end{small}
A total of
\input{bitflip_directFIRsymmetric_bandpass_test_bf_adders.tab}adders is
required to implement these coefficient multiplications in the
direct-form symmetric FIR filter structure and
\input{bitflip_directFIRsymmetric_bandpass_test_bft_adders.tab}adders are
required to implement the coefficient multiplications in the transposed
(pipelined) direct-form FIR filter structure.

\chapter{\label{sec:branch-bound-search-signed-digit-coefficients}\emph{Branch-and-bound} search for signed-digit coefficients}
Given the $K$ coefficients, $x_{k}$, of a filter, an exhaustive search of the
upper and lower bounds on the integer or signed-digit approximations to these
coefficients would require $\mathcal{O}\left(2^{K}\right)$ comparisons of the
corresponding filter approximation error.
\emph{Branch-and-bound}~\cite{LandDoig_AutomaticMethodSolvingDiscreteProgrammingProblems},~\cite[p.627]{Sedgewick_AlgorithmsInCPlusPlus}
is a heuristic for reducing the 
number of branches searched in a binary decision tree. At each branch of the
binary tree the solution is compared to the estimated lower bounds on the cost
of the full path proceeding from that branch. If the cost of that full path is
greater than that of the best full path found so far then further search on
that path is abandoned.  Figure~\ref{fig:branch-bound-tree-search-algorithm}
shows a flow diagram of an implementation of the algorithm using a stack. The
floating-point filter coefficients $\boldsymbol{x}$ are approximated by the
signed-digit coefficients $\bar{\boldsymbol{x}}$. Each coefficient, $x_{k}$
and $\bar{x}_{k}$ is bounded by the corresponding signed-digit numbers $u_{k}$
and $l_{k}$ so that $l_{k}\le{}x_{k}\le{}u_{k}$ and
$l_{k}\le{}\bar{x}_{k}\le{}u_{k}$. The search for the set of coefficients with
minimum cost is ``depth-first'', starting at the root of the search tree and
fixing successive coefficients.  \emph{Ito et
  al.}~\cite{Ito_PowersOfTwoAllocationFIR} recommend choosing, at each branch,
the $x_{k}$ with the greatest difference $u_{k}-l_{k}$. The two sub-problems
at that branch fix $x_{k}$ to $l_{k}$ and $u_{k}$. One of the two sub-problems
is pushed onto a stack and the other is solved and the cost calculated. I
assume that this cost is the least possible for the remaining coefficients on
the current branch. If the cost of the current sub-problem is greater than the
current minimum cost then the current branch is abandoned and a new
sub-problem is popped off the problem stack. Otherwise, if the search has
reached the maximum depth of the tree then the current solution is a new
signed-digit minimum cost solution. If the current cost is less than the
minimum cost and the search has not reached the maximum depth then the search
continues with a new branch.

\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{BranchBoundTree}
\caption{The branch-and-bound tree search algorithm. }
\label{fig:branch-bound-tree-search-algorithm}
\end{figure}
\clearpage
\section{Branch-and-bound search for the 8-bit 3-signed-digit coefficients of a direct-form symmetric bandpass FIR filter}
The Octave script
\emph{branch\_bound\_directFIRsymmetric\_bandpass\_8\_nbits\_test.m} uses
the branch-and-bound algorithm to optimise the 8-bit 3-signed-digit coefficients
of a direct-form symmetric FIR bandpass filter.

The initial filter polynomial is that designed by the Octave
script \emph{directFIRsymmetric\_slb\_bandpass\_test.m}.
\begin{small}
\verbatiminput{branch_bound_directFIRsymmetric_bandpass_8_nbits_test_hM1_coef.m}
\end{small}

The filter specification is:
\begin{small}
\verbatiminput{branch_bound_directFIRsymmetric_bandpass_8_nbits_test_spec.m}
\end{small}

Figures~\ref{fig:branch-bound-direct-form-symmetric-bandpass-FIR-passband}
and~\ref{fig:branch-bound-direct-form-symmetric-bandpass-FIR-stopband}
show the initial filter pass-band and stop-band amplitude responses and the
filter responses after coefficient truncation to 8-bit 3-signed-digits and
branch-and-bound search.

Table~\ref{tab:branch-bound-direct-form-symmetric-bandpass-FIR-cost-summary}
compares the cost results. 

The \emph{branch-and-bound} optimised 8-bit 2-signed-digits direct-form
symmetric filter coefficients are:
\begin{small}
\verbatiminput{branch_bound_directFIRsymmetric_bandpass_8_nbits_test_hM_min_coef.m}
\end{small}
The coefficients are scaled to make full use of the 8-bit range. A total of
\input{branch_bound_directFIRsymmetric_bandpass_8_nbits_test_hM_min_adders.tab}adders
is required to implement these signed-digit coefficient multiplications.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_directFIRsymmetric_bandpass_8_nbits_test_passband_response}}
\caption{Pass-band amplitude responses of a direct-form symmetric
  FIR band-pass filter with floating-point coefficients, 8-bit 3-signed-digit
  coefficients and 8-bit 3-signed-digit coefficients optimised with the
  branch-and-bound algorithm.}
\label{fig:branch-bound-direct-form-symmetric-bandpass-FIR-passband}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_directFIRsymmetric_bandpass_8_nbits_test_stopband_response}}
\caption{Stop-band amplitude responses of a direct-form symmetric
  FIR band-pass filter with floating-point coefficients, 8-bit 3-signed-digit
  coefficients and 8-bit 3-signed-digit coefficients optimised with the
  branch-and-bound algorithm.}
\label{fig:branch-bound-direct-form-symmetric-bandpass-FIR-stopband}
\end{figure}

\begin{table}[htbp]
\centering
 \begin{threeparttable}
\begin{tabular}{lrcc}  \\ \toprule
Band-pass direct-form symmetric FIR & Cost & Signed-digits & Additions\\\midrule
\input{branch_bound_directFIRsymmetric_bandpass_8_nbits_test_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the direct-form symmetric FIR bandpass
filter branch-and-bound algorithm example] {Summary of the cost results for
  the direct-form symmetric FIR bandpass filter with floating-point
  coefficients, 8-bit 3-signed-digit coefficients and 8-bit 3-signed-digit
  coefficients optimised with the branch-and-bound algorithm.}
\label{tab:branch-bound-direct-form-symmetric-bandpass-FIR-cost-summary}
\end{table}

\clearpage
\section{Branch-and-bound search for the 8-bit 3-signed-digit
coefficients of a lattice band-pass IIR filter}
The Octave script \emph{branch\_bound\_schurOneMlattice\_bandpass\_8\_nbits\_test.m}
uses the branch-and-bound heuristic to optimise the response of the SQP
optimised band-pass Schur one-multiplier lattice filter of
Section~\ref{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-SQP} with 
coefficients truncated to $8$ bits and $3$ signed-digits. The filter 
specification is:
\begin{small}
\verbatiminput{branch_bound_schurOneMlattice_bandpass_8_nbits_test_spec.m}
\end{small}

The $31$ non-zero 8-bit 3-signed-digit one-multiplier lattice coefficients 
found by the branch-and-bound search are:
\begin{small}
\verbatiminput{branch_bound_schurOneMlattice_bandpass_8_nbits_test_k_min_coef.m}
\verbatiminput{branch_bound_schurOneMlattice_bandpass_8_nbits_test_c_min_coef.m}
\end{small}
The $c_{min}$ tap coefficients have been scaled to make full use of the range
of integers available. I assume that the internal filter state scaling is
approximated by bit-shifts. The $\epsilon$ one-multiplier lattice cofficients
are not recalculated since that would require rescaling the $c_{min}$ tap
coefficients.
Figure~\ref{fig:branch-bound-schurOneMlattice-bandpass-8-nbits-pass-response}
compares the pass-band responses of the filter with floating-point coefficients,
the initial 8-bit 3-signed-digit coefficients and 8-bit 3-signed-digit
coefficients found by branch-and-bound search.
Figure~\ref{fig:branch-bound-schurOneMlattice-bandpass-8-nbits-stop-response}
shows the filter stop-band response and
Figure~\ref{fig:branch-bound-schurOneMlattice-bandpass-8-nbits-delay-response}
shows the filter pass-band group delay response.
Table~\ref{tab:branch-bound-schurOneMlattice-bandpass-8-nbits-cost-summary}
compares the cost and number of $8$ bit shift-and-add operations required to
implement the $31$ coefficient multiplications for the initial signed-digit
coefficients and the coefficients found by the branch-and-bound search. A
further $41$ additions are required by the lattice filter structure\footnote{A
  one-multiplier lattice filter with order $21$ and denominator polynomial
  coefficients in $z^{2}$ would normally require $1$ multiplication and $3$
  additions for each of $10$ lattice sections and $21$ filter output tap
  multiplications and additions. In this case $1$ of the lattice filter
  coefficients and $7$ of the tap coefficients are zero. See
  Figure~\ref{fig:One-multiplier-lattice-structure}.}.  Although $3$
signed-digits are allocated to each coefficient, many of these signed-digits
are not used.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlattice_bandpass_8_nbits_test_pass}}
\caption{Comparison of the pass-band amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 8-bit 3-signed-digit
  coefficients found by branch-and-bound search.}
\label{fig:branch-bound-schurOneMlattice-bandpass-8-nbits-pass-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlattice_bandpass_8_nbits_test_stop}}
\caption{Comparison of the stop-band amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 8-bit 3-signed-digit 
  coefficients found by branch-and-bound search}
\label{fig:branch-bound-schurOneMlattice-bandpass-8-nbits-stop-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlattice_bandpass_8_nbits_test_delay}}
\caption{Comparison of the pass-band group delay responses for a Schur
  one-multiplier lattice bandpass filter with 8-bit 3-signed-digit 
  coefficients found by branch-and-bound search}
\label{fig:branch-bound-schurOneMlattice-bandpass-8-nbits-delay-response}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Additions\\ \midrule
\input{branch_bound_schurOneMlattice_bandpass_8_nbits_test_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the Schur one-multiplier lattice 
bandpass filter branch-and-bound algorithm example with 8 bit coefficients]
{Comparison of the cost and number of additions required to implement the
  coefficient multiplications for a Schur one-multiplier lattice bandpass filter
  with 8-bit 3-signed-digit coefficients found by branch-and-bound search.}
\label{tab:branch-bound-schurOneMlattice-bandpass-8-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:Branch-and-bound-search-10-bit-3-sd-one-mult-Schur-lattice}Branch-and-bound search for the 10-bit 3-signed-digit coefficients of a lattice band-pass IIR filter}
The Octave script 
\emph{branch\_bound\_schurOneMlattice\_bandpass\_10\_nbits\_test.m}
uses the branch-and-bound heuristic to optimise the response of the band-pass 
Schur one-multiplier lattice filter of
Section~\ref{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-SQP}.
The filter specification is:
\begin{small}
\verbatiminput{branch_bound_schurOneMlattice_bandpass_10_nbits_test_spec.m}
\end{small}
The filter coefficients are truncated to $10$ bits with an average of $3$
signed-digits allocated to each coefficient. The number of signed-digits
allocated to each coefficient is determined by the heuristic of \emph{Lim et
  al.} as shown in Section~\ref{sec:Lim-allocation-signed-digits}.  The
average number of non-zero signed-digits per coefficient is close to $2$. The
tap coefficients are scaled to make full use of the range of integers
available. I assume that the internal filter state scaling is approximated by
bit-shifts.

At each branch the script fixes the coefficient with the largest difference
between upper and lower $3$ signed-digit approximations to the floating-point
value. For each sub-problem the coefficients ``higher-up-the-tree'' are fixed
and the remaining free coefficients are PCLS SQP optimised with the filter 
specification given above. For this example the branch-and-bound search
makes thousands of branches and requires several hours CPU time on my PC.

The numbers of signed digits allocated to each coefficient by the heuristic of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{branch_bound_schurOneMlattice_bandpass_10_nbits_test_k_allocsd_digits.m}
\verbatiminput{branch_bound_schurOneMlattice_bandpass_10_nbits_test_c_allocsd_digits.m}
\end{small}

The filter coefficients found by the branch-and-bound search are:
\begin{small}
\verbatiminput{branch_bound_schurOneMlattice_bandpass_10_nbits_test_k_min_coef.m}
\verbatiminput{branch_bound_schurOneMlattice_bandpass_10_nbits_test_c_min_coef.m}
\end{small}

Figure~\ref{fig:branch-bound-schurOneMlattice-bandpass-10-nbits-pass-response}
compares the pass-band responses of the filter with floating-point coefficients,
10-bit signed-digit coefficients allocated with the algorithm of
\emph{Lim et al.} and 10-bit signed-digits allocated with the algorithm of
\emph{Lim et al.} and branch-and-bound search.
Figure~\ref{fig:branch-bound-schurOneMlattice-bandpass-10-nbits-stop-response}
shows the filter stop-band response and
Figure~\ref{fig:branch-bound-schurOneMlattice-bandpass-10-nbits-delay-response}
shows the filter pass-band group delay response.
Table~\ref{tab:branch-bound-schurOneMlattice-bandpass-10-nbits-cost-summary} 
compares the cost and the number of $10$ bit shift-and-add operations required to
implement the $31$ coefficient multiplications found by the signed-digit 
allocation heuristic of \emph{Lim et al.} with the branch-and-bound search. A 
further $51$ additions are required by the lattice filter structure. The
truncation of the last coefficient is, by necessity, not PCLS optimised so the
final set of coefficients may not meet the PCLS specifications.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlattice_bandpass_10_nbits_test_pass}}
\caption{Comparison of the pass-band amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing branch-and-bound search.}
\label{fig:branch-bound-schurOneMlattice-bandpass-10-nbits-pass-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlattice_bandpass_10_nbits_test_stop}}
\caption{Comparison of the stop-band amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing branch-and-bound search.}
\label{fig:branch-bound-schurOneMlattice-bandpass-10-nbits-stop-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlattice_bandpass_10_nbits_test_delay}}
\caption{Comparison of the pass-band group delay responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing branch-and-bound search.}
\label{fig:branch-bound-schurOneMlattice-bandpass-10-nbits-delay-response}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_schurOneMlattice_bandpass_10_nbits_test_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the Schur one-multiplier lattice 
bandpass filter branch-and-bound algorithm example with 10-bit coefficients]
{Comparison of the cost and number of 10-bit shift-and-add operations required 
  to implement the coefficient multiplications for a Schur one-multiplier 
  lattice bandpass filter with 10-bit integer coefficients found by allocating 
  an average of 3-signed-digits to each coefficient using the heuristic of 
  \emph{Lim et al.} and performing branch-and-bound search.}
\label{tab:branch-bound-schurOneMlattice-bandpass-10-nbits-cost-summary}
\end{table}
\clearpage
\section{Branch-and-bound search for the 10-bit 3-signed-digit coefficients
  of a one-multiplier pipelined lattice band-pass filter}
The Octave script 
\emph{branch\_bound\_schurOneMlatticePipelined\_bandpass\_10\_nbits\_test.m}
uses the branch-and-bound heuristic to optimise the response of the band-pass 
Schur one-multiplier lattice filter of
Section~\ref{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-SQP}
designed with SQP as described in
Section~\ref{sec:State-variable-pipelined-One-multiplier-Schur-lattice-filter}
and implemented in the pipelined form. The $k_{n-1}k_{n}$ and $c_{2n-1}k_{2n}$
coefficient combinations are treated as additional coefficients. The filter
specification is:
\begin{small}
\verbatiminput{branch_bound_schurOneMlatticePipelined_bandpass_10_nbits_test_spec.m}
\end{small}
The filter coefficients are truncated to $10$ bits with $3$
signed-digits. The tap coefficients are scaled to make full use of the range of
integers available. I assume that the internal filter state scaling
is approximated by bit-shifts.

The inputs to the branch-and-bound search are the upper and lower bounds of the
truncated exact coefficients. At each branch the script selects the coefficient
with the largest difference between upper and lower signed-digit approximations
and selects the branch with the lowest response error value.
The filter coefficients found by the branch-and-bound search are:
\begin{small}
\verbatiminput{branch_bound_schurOneMlatticePipelined_bandpass_10_nbits_test_k_min_coef.m}
\verbatiminput{branch_bound_schurOneMlatticePipelined_bandpass_10_nbits_test_c_min_coef.m}
\verbatiminput{branch_bound_schurOneMlatticePipelined_bandpass_10_nbits_test_kk_min_coef.m}
\verbatiminput{branch_bound_schurOneMlatticePipelined_bandpass_10_nbits_test_ck_min_coef.m}
\end{small}

Figure~\ref{fig:branch-bound-schurOneMlattice-pipelined-bandpass-10-nbits-pass-response}
compares the pass-band responses of the filter with floating-point coefficients,
10-bit signed-digit coefficients and 10-bit signed-digits found with
branch-and-bound search.
Figure~\ref{fig:branch-bound-schurOneMlattice-pipelined-bandpass-10-nbits-stop-response}
shows the filter stop-band response and
Figure~\ref{fig:branch-bound-schurOneMlattice-pipelined-bandpass-10-nbits-delay-response}
shows the filter pass-band group delay response.
Table~\ref{tab:branch-bound-schurOneMlattice-pipelined-bandpass-10-nbits-cost-summary} 
compares the cost and the number of $10$ bit shift-and-add operations required to
implement the coefficient multiplications found with the branch-and-bound
search. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlatticePipelined_bandpass_10_nbits_test_pass}}
\caption{Comparison of the pass-band amplitude responses for a Schur
  one-multiplier pipelined lattice bandpass filter with 10-bit 3 signed-digit
  coefficients found by branch-and-bound search.}
\label{fig:branch-bound-schurOneMlattice-pipelined-bandpass-10-nbits-pass-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlatticePipelined_bandpass_10_nbits_test_stop}}
\caption{Comparison of the stop-band amplitude responses for a Schur
  one-multiplier pipelined lattice bandpass filter with 10-bit 3 signed-digit
  coefficients found by branch-and-bound search.}
\label{fig:branch-bound-schurOneMlattice-pipelined-bandpass-10-nbits-stop-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlatticePipelined_bandpass_10_nbits_test_delay}}
\caption{Comparison of the pass-band group delay responses for a Schur
  one-multiplier pipelined lattice bandpass filter with 10-bit 3 signed-digit
  coefficients found by branch-and-bound search.}
\label{fig:branch-bound-schurOneMlattice-pipelined-bandpass-10-nbits-delay-response}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_schurOneMlatticePipelined_bandpass_10_nbits_test_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the pipelined Schur one-multiplier lattice 
bandpass filter branch-and-bound algorithm example with 10-bit coefficients]
{Comparison of the cost and number of 10 bit shift-and-add operations required 
  to implement the coefficient multiplications for a pipelined Schur
  one-multiplier pipelined lattice bandpass filter with 10-bit 3 signed-digit
  coefficients found by branch-and-bound search.}
\label{tab:branch-bound-schurOneMlattice-pipelined-bandpass-10-nbits-cost-summary}
\end{table}
\clearpage
\section{Branch-and-bound search for the 16-bit 4-signed-digit coefficients
  of a one-multiplier pipelined lattice low-pass filter}
The Octave script 
\emph{branch\_bound\_schurOneMlatticePipelined\_lowpass\_16\_nbits\_test.m}
performs branch-and-bound search to optimise the response of a Schur
one-multiplier pipelined lattice low-pass filter implemented in the pipelined
form shown in
Section~\ref{sec:State-variable-pipelined-One-multiplier-Schur-lattice-filter}
with $16$ bit $4$ signed-digit coefficients. The $k_{n-1}k_{n}$ and
$c_{2n-1}k_{2n}$ coefficient combinations are treated as additional coefficients.
The inputs to the branch-and-bound search are the upper and lower bounds of the
truncated exact coefficients. At each branch the script selects the coefficient
with the largest difference between upper and lower signed-digit approximations
and selects the branch with the lowest response error value.
The filter specification is:
\begin{small}
\verbatiminput{branch_bound_schurOneMlatticePipelined_lowpass_16_nbits_test_spec.m}
\end{small} 

The signed-digit lattice coefficients found by the branch-and-bound search are:
\begin{small}
\verbatiminput{branch_bound_schurOneMlatticePipelined_lowpass_16_nbits_test_k_min_coef.m}
\verbatiminput{branch_bound_schurOneMlatticePipelined_lowpass_16_nbits_test_c_min_coef.m}
\verbatiminput{branch_bound_schurOneMlatticePipelined_lowpass_16_nbits_test_kk_min_coef.m}
\verbatiminput{branch_bound_schurOneMlatticePipelined_lowpass_16_nbits_test_ck_min_coef.m}
\end{small}

Figure~\ref{fig:branch-bound-schurOneMlattice-pipelined-lowpass-16-nbits-pass}
shows the amplitude pass-band response of the filter with
$16$-bit $4$-signed-digit coefficients found by branch-and-bound search.
Figure~\ref{fig:branch-bound-schurOneMlattice-pipelined-lowpass-16-nbits-stop}
shows the corresponding filter stop-band amplitude response.
Table~\ref{tab:branch-bound-schurOneMlattice-pipelined-lowpass-16-nbits-cost}
compares the cost and the number of $16$ bit shift-and-add operations required
to implement the coefficient multiplications found by branch-and-bound search.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlatticePipelined_lowpass_16_nbits_test_pass}}
\caption{Pass band amplitude response for a Schur one-multiplier
  pipelined lattice low-pass filter with 16 bit 4 signed-digit coefficients
  found by branch-and-bound search.}
\label{fig:branch-bound-schurOneMlattice-pipelined-lowpass-16-nbits-pass}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlatticePipelined_lowpass_16_nbits_test_stop}}
\caption{Stop band amplitude response for a Schur one-multiplier pipelined
  lattice low-pass filter with 16 bit 4 signed-digit coefficients found by
  branch-and-bound search.}
\label{fig:branch-bound-schurOneMlattice-pipelined-lowpass-16-nbits-stop}
\end{figure}
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_schurOneMlatticePipelined_lowpass_16_nbits_test_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for a Schur one-multiplier pipelined
lattice lowpass filter with 16 bit 4 signed-digit coefficients]{Comparison of
  the cost and number of 16-bit shift-and-add operations required to implement
  the coefficient multiplications for a Schur one-multiplier pipelined lattice
  low-pass filter with 16 bit 4 signed-digit coefficients found by
  branch-and-bound search.}
\label{tab:branch-bound-schurOneMlattice-pipelined-lowpass-16-nbits-cost}
\end{table}
\clearpage
\section{Branch-and-bound search for the 12-bit 3-signed-digit coefficients
  of a one-multiplier lattice R=2 low-pass differentiator filter}
The Octave script 
\emph{branch\_bound\_schurOneMlattice\_lowpass\_differentiator\_R2\_12\_nbits\_test.m}
performs branch-and- bound search to optimise the response of a Schur
one-multiplier lattice low-pass differentiator filter implemented as a
$1-z^{-1}$ filter followed by a correction filter. The correction filter has
$12$ bit coefficients with an average of $3$ signed-digits, allocated with the
heuristic of \emph{Lim et al.}, and a denominator polynomial having only
terms in $z^{-2}$. The inputs to the branch-and-bound search are the upper and
lower bounds of the truncated exact coefficients. At each branch the script
selects the coefficient with the largest difference between upper and lower
signed-digit approximations and selects the branch with the lowest response
error value. The filter specification is:
\begin{small}
\verbatiminput{branch_bound_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_spec.m}
\end{small} 

The numbers of signed digits allocated to each coefficient by the heuristic of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{branch_bound_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_k_allocsd_digits.m}
\verbatiminput{branch_bound_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_c_allocsd_digits.m}
\end{small}

The correction filter signed-digit lattice coefficients found by the
branch-and-bound search are:
\begin{small}
\verbatiminput{branch_bound_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_k_min_coef.m}
\verbatiminput{branch_bound_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_c_min_coef.m}
\end{small}

The corresponding correction filter transfer function polynomials are:
\begin{small}
\verbatiminput{branch_bound_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_N_min_coef.m}
\verbatiminput{branch_bound_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_D_min_coef.m}
\end{small}

Figure~\ref{fig:branch-bound-schurOneMlattice-R2-lowpass-diff-12-nbits-response}
shows the pass-band amplitude error, stop-band amplitude, pass-band phase and
pass-band group-delay responses of the low-pass differentiator filter.
Figure~\ref{fig:branch-bound-schurOneMlattice-R2-lowpass-diff-12-nbits-corr}
shows the error in the gradient of the squared-amplitude response of the
correction filter.
Figure~\ref{fig:branch-bound-schurOneMlattice-R2-lowpass-diff-12-nbits-pz}
shows the pole-zero plot of the low-pass differentiator filter with signed-digit
coefficients found by branch-and-bound search.
Table~\ref{tab:branch-bound-schurOneMlattice-R2-lowpass-diff-12-nbits-cost}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the coefficient multiplications found by branch-and-bound search.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_response}}
\caption{Comparison of the pass-band amplitude error, stop-band amplitude,
  pass-band phase and pass-band group delay responses of a Schur one-multiplier
  lattice low-pass differentiator filter having denominator polynomial
  coefficients only in $z^{-2}$, with $12$ bit coefficients found by allocating
  an average of $3$-signed-digits to each coefficient using the heuristic of
  \emph{Lim et al.} and performing branch-and-bound search. The phase response
  shown is adjusted for the nominal delay.}
\label{fig:branch-bound-schurOneMlattice-R2-lowpass-diff-12-nbits-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_correction}}
\caption{Error in the gradient of the squared-amplitude response of the
  correction filter of a Schur one-multiplier lattice low-pass differentiator
  filter having denominator polynomial coefficients only in $z^{-2}$ with $12$
  bit, $3$ signed-digit coefficients found by performing branch-and-bound
  search.}
\label{fig:branch-bound-schurOneMlattice-R2-lowpass-diff-12-nbits-corr}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_pz}}
\caption{Pole-zero plot of the Schur one-multiplier lattice low-pass
  differentiator filter having denominator polynomial coefficients only in
  $z^{-2}$ with $12$ bit, $3$ signed-digit coefficients found by performing
  branch-and-bound search.}
\label{fig:branch-bound-schurOneMlattice-R2-lowpass-diff-12-nbits-pz}
\end{figure}
\begin{table}
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for a Schur one-multiplier R=2 lattice lowpass differentiator filter with 12 bit, 3 signed-digit coefficients]{Comparison of
  the cost and number of $12$-bit shift-and-add operations required to implement
  the coefficient multiplications for a Schur one-multiplier lattice
  low-pass differentiator filter, having denominator polynomial coefficients
  only in $z^{-2}$, with $12$-bit integer coefficients found by allocating an
  average of $3$ signed-digits to each coefficient using the heuristic of
  \emph{Lim et al.} found by performing branch-and-bound search.}
\label{tab:branch-bound-schurOneMlattice-R2-lowpass-diff-12-nbits-cost}
\end{table}
\clearpage
\section{\label{sec:Branch-and-bound-search-signed-digit-coefficients-parallel-allpass-one-M-lowpass}Branch-and-bound
  search for the 12-bit 3-signed-digit coefficients of a parallel all-pass one-multiplier lattice low-pass IIR filter}
The Octave script 
\emph{branch\_bound\_schurOneMPAlattice\_lowpass\_12\_nbits\_test.m} performs
branch-and-bound search to optimise the response of the parallel
Schur one-multiplier all-pass lattice low-pass filter of
Section~\ref{sec:Design-parallel-Schur-one-mult-all-pass-lattice-low-pass-SOCP}
with $12$-bit integer coefficients. The initial filter is found by the Octave
script \emph{schurOneMPAlattice\_socp\_slb\_lowpass\_test.m}. The filter
specification is:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_lowpass_12_nbits_test_spec.m}
\end{small} 

The filter coefficients are truncated to $12$ bits allocated with an average
of $3$ signed-digits by the heuristic of \emph{Ito et al.} as shown in
Section~\ref{sec:Ito-allocation-signed-digits}.
At each branch the script fixes the coefficient with the largest difference
between upper and lower $3$ signed-digit approximations to the floating-point
value. For each sub-problem the coefficients ``higher-up-the-tree'' are fixed
and the remaining free coefficients are SOCP PCLS optimised with the filter 
specification given above. In this case there are no filter tap coefficients
and the one-multiplier lattice $\epsilon$ coefficients can be recalculated.

The numbers of signed digits allocated to each coefficient by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_lowpass_12_nbits_test_A1k_allocsd_digits.m}
\verbatiminput{branch_bound_schurOneMPAlattice_lowpass_12_nbits_test_A2k_allocsd_digits.m}
\end{small}

The signed-digit lattice coefficients found by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_lowpass_12_nbits_test_A1k0_sd_coef.m}
\verbatiminput{branch_bound_schurOneMPAlattice_lowpass_12_nbits_test_A2k0_sd_coef.m}
\end{small}

The signed-digit lattice coefficients found by the branch-and-bound search are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_lowpass_12_nbits_test_A1k_min_coef.m}
\verbatiminput{branch_bound_schurOneMPAlattice_lowpass_12_nbits_test_A2k_min_coef.m}
\end{small}
The signed-digit lattice coefficients found by the branch-and-bound
search are implemented with 
\input{branch_bound_schurOneMPAlattice_lowpass_12_nbits_test_kmin_digits.tab}
signed-digits and 
\input{branch_bound_schurOneMPAlattice_lowpass_12_nbits_test_kmin_adders.tab}
shift-and-add operations.

Figure~\ref{fig:branch-bound-schurOneMPAlattice-lowpass-12-nbits-pass-response}
shows the amplitude pass-band response of the filter with
$12$-bit $3$-signed-digit coefficients allocated with the algorithm of
\emph{Ito et al.} and branch-and-bound search.
Figure~\ref{fig:branch-bound-schurOneMPAlattice-lowpass-12-nbits-delay-response}
shows the corresponding filter pass-band group-delay response.
Figure~\ref{fig:branch-bound-schurOneMPAlattice-lowpass-12-nbits-stop-response}
shows the corresponding filter stop-band amplitude response.
Table~\ref{tab:branch-bound-schurOneMPAlattice-lowpass-12-nbits-cost-summary}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the coefficient multiplications found by the signed-digit
allocation heuristic of \emph{Ito et al.} with the branch-and-bound search.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_lowpass_12_nbits_test_kmin_pass}}
\caption{Pass band amplitude response for a parallel Schur
  one-multiplier all-pass lattice low-pass filter with 12 bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-lowpass-12-nbits-pass-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_lowpass_12_nbits_test_kmin_delay}}
\caption{Pass band group delay response for a parallel Schur
  one-multiplier all-pass lattice low-pass filter with 12 bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-lowpass-12-nbits-delay-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_lowpass_12_nbits_test_kmin_stop}}
\caption{Stop band amplitude response for a parallel Schur one-multiplier
  all-pass lattice low-pass filter with 12 bit integer coefficients found by
  allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Ito et al.} and performing branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-lowpass-12-nbits-stop-response}
\end{figure}
\begin{table}
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_schurOneMPAlattice_lowpass_12_nbits_test_kmin_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the parallel Schur one-multiplier
all-pass lattice lowpass filter SOCP algorithm example with 12 bit
coefficients] {Comparison of the cost and number of 12-bit shift-and-add
  operations required to implement the coefficient multiplications for a
  parallel Schur one-multiplier all-pass lattice low-pass filter with 12 bit
  integer coefficients found by allocating an average of 3-signed-digits to
  each coefficient using the heuristic of \emph{Ito et al.} and performing
  branch-and-bound search.}
\label{tab:branch-bound-schurOneMPAlattice-lowpass-12-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:Branch-and-bound-search-signed-digit-coefficients-parallel-allpass-norm-scaled-lowpass}Branch-and-bound
  search for the 12-bit 3-signed-digit coefficients of a parallel all-pass normalised-scaled lattice low-pass IIR filter}
The Octave script 
\emph{branch\_bound\_schurNSPAlattice\_lowpass\_12\_nbits\_test.m} performs
branch-and-bound search to optimise the response of the parallel
approximately normalised-scaled all-pass Schur lattice low-pass filter of
Section~\ref{sec:Design-parallel-Schur-norm-scaled-all-pass-lattice-low-pass-SOCP}
with $12$-bit integer coefficients. The filter specification is:
\begin{small}
\verbatiminput{branch_bound_schurNSPAlattice_lowpass_12_nbits_test_spec.m}
\end{small} 

The filter coefficients are truncated to $12$ bits and $3$ signed-digits.
The script enforces the symmetric relations $s_{02}=-s_{20}$ and $s_{22}=s_{00}$.
The script does not enforce normalised-scaling with the relation
$s_{02}=\sqrt{1-s_{00}^{2}}$. At each branch the script fixes the coefficient
with the largest difference between upper and lower $3$ signed-digit
approximations to the floating-point value. For each sub-problem the
coefficients ``higher-up-the-tree'' are fixed and the remaining free
coefficients are SOCP PCLS optimised with the filter specification given above.
The signed-digit lattice coefficients are:
\begin{small}
\verbatiminput{branch_bound_schurNSPAlattice_lowpass_12_nbits_test_A1s20_sd_coef.m}
\verbatiminput{branch_bound_schurNSPAlattice_lowpass_12_nbits_test_A1s00_sd_coef.m}
\verbatiminput{branch_bound_schurNSPAlattice_lowpass_12_nbits_test_A2s20_sd_coef.m}
\verbatiminput{branch_bound_schurNSPAlattice_lowpass_12_nbits_test_A2s00_sd_coef.m}
\end{small}

The signed-digit lattice coefficients found by the branch-and-bound search are:
\begin{small}
\verbatiminput{branch_bound_schurNSPAlattice_lowpass_12_nbits_test_A1s20_min_coef.m}
\verbatiminput{branch_bound_schurNSPAlattice_lowpass_12_nbits_test_A1s00_min_coef.m}
\verbatiminput{branch_bound_schurNSPAlattice_lowpass_12_nbits_test_A2s20_min_coef.m}
\verbatiminput{branch_bound_schurNSPAlattice_lowpass_12_nbits_test_A2s00_min_coef.m}
\end{small}

Figures~\ref{fig:branch-bound-schurNSPAlattice-lowpass-12-nbits-pass-amplitude}
and~\ref{fig:branch-bound-schurNSPAlattice-lowpass-12-nbits-pass-delay}
show the pass-band amplitude and group delay responses of the filter with
floating-point coefficients and with $12$-bit, $3$-signed-digit coefficients
found by simple truncation and by branch-and-bound search.
Figure~\ref{fig:branch-bound-schurNSPAlattice-lowpass-12-nbits-stop-amplitude}
shows the corresponding stop-band amplitude response.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurNSPAlattice_lowpass_12_nbits_test_sxx_min_pass_amplitude}}
\caption{Pass-band amplitude responses for a parallel all-pass
  approximately normalised-scaled Schur lattice low-pass filter with 12 bit
  3 signed-digit integer coefficients found by direct truncation and by
  performing branch-and-bound search.}
\label{fig:branch-bound-schurNSPAlattice-lowpass-12-nbits-pass-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurNSPAlattice_lowpass_12_nbits_test_sxx_min_pass_delay}}
\caption{Pass-band group delay responses for a parallel all-pass
  approximately normalised-scaled Schur lattice low-pass filter with 12 bit
  3 signed-digit integer coefficients found by direct truncation and by
  performing branch-and-bound search.}
\label{fig:branch-bound-schurNSPAlattice-lowpass-12-nbits-pass-delay}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurNSPAlattice_lowpass_12_nbits_test_sxx_min_stop_amplitude}}
\caption{Stop-band amplitude responses for a parallel all-pass
  approximately normalised-scaled Schur lattice low-pass filter with 12 bit
  3 signed-digit integer coefficients found by direct truncation and by
  performing branch-and-bound search.}
\label{fig:branch-bound-schurNSPAlattice-lowpass-12-nbits-stop-amplitude}
\end{figure}

Table~\ref{tab:branch-bound-schurNSPAlattice-lowpass-12-nbits-cost-summary}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the signed-digit coefficient multiplications.
\begin{table}
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_schurNSPAlattice_lowpass_12_nbits_test_sxx_min_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the parallel all-pass approximately
normalised scaled Schur lattice filter SOCP algorithm example with 12 bit
coefficients] {Comparison of the cost and number of 12-bit shift-and-add
  operations required to implement the coefficient multiplications for a
  parallel all-pass approximately normalised-scaled Schur lattice low-pass
  filter with 12 bit, 3 signed-digit integer coefficients found by direct
  truncation and by performing branch-and-bound search.}
\label{tab:branch-bound-schurNSPAlattice-lowpass-12-nbits-cost-summary}
\end{table}
\clearpage
\section{Branch-and-bound search for the 8-bit 3-signed-digit coefficients of a parallel all-pass lattice IIR elliptic low-pass filter}
The Octave script
\emph{branch\_bound\_schurOneMPAlattice\_elliptic\_lowpass\_8\_nbits\_test.m}
performs branch-and-bound search to optimise the response of a parallel
Schur one-multiplier all-pass lattice elliptic approximation low-pass filter
with $8$-bit integer coefficients. The filter specification is:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_elliptic_lowpass_8_nbits_test_spec.m}
\end{small} 

The filter coefficients are truncated to $8$ bits and $2$ signed-digits. At each
branch the script fixes the coefficient with the largest difference between
upper and lower $2$ signed-digit approximations to the floating-point value. For
each sub-problem the coefficients ``higher-up-the-tree'' are fixed and the
remaining free coefficients are SOCP PCLS optimised with the filter
specification given above.

The $8$ bit, $2$ signed-digit lattice coefficients are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_elliptic_lowpass_8_nbits_test_A1k0_sd_coef.m}
\verbatiminput{branch_bound_schurOneMPAlattice_elliptic_lowpass_8_nbits_test_A2k0_sd_coef.m}
\end{small}

The signed-digit lattice coefficients found by the branch-and-bound
search are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_elliptic_lowpass_8_nbits_test_A1k_min_coef.m}
\verbatiminput{branch_bound_schurOneMPAlattice_elliptic_lowpass_8_nbits_test_A2k_min_coef.m}
\end{small}
The signed-digit lattice coefficients found by the branch-and-bound
search are implemented with 
\input{branch_bound_schurOneMPAlattice_elliptic_lowpass_8_nbits_test_kmin_digits.tab}
signed-digits and 
\input{branch_bound_schurOneMPAlattice_elliptic_lowpass_8_nbits_test_kmin_adders.tab}
shift-and-add operations.

Figure~\ref{fig:branch-bound-schurOneMPAlattice-elliptic-lowpass-8-nbits-response}
shows the amplitude response of the filter with $8$-bit, $2$-signed-digit
coefficients and branch-and-bound search. 
Figure~\ref{fig:branch-bound-schurOneMPAlattice-elliptic-lowpass-8-nbits-pass-response}
shows the filter pass-band amplitude response.
Table~\ref{tab:branch-bound-schurOneMPAlattice-elliptic-lowpass-8-nbits-cost-summary}
compares the cost and the number of $8$ bit shift-and-add operations required
to implement the coefficient multiplications found with the branch-and-bound
search. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_elliptic_lowpass_8_nbits_test_kmin}}
\caption{Amplitude response for a parallel Schur one-multiplier all-pass
  lattice elliptic approximation low-pass filter with 8 bit, 2-signed-digits
  integer coefficients found performing branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-elliptic-lowpass-8-nbits-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_elliptic_lowpass_8_nbits_test_kmin_pass}}
\caption{Pass band amplitude response for a parallel Schur one-multiplier
  all-pass lattice elliptic approximation low-pass filter with 8 bit, 2
  signed-digit integer coefficients found by performing branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-elliptic-lowpass-8-nbits-pass-response}
\end{figure}
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_schurOneMPAlattice_elliptic_lowpass_8_nbits_test_kmin_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the parallel Schur one-multiplier
all-pass lattice elliptic approximation lowpass filter SOCP algorithm example
with 8 bit, 2 signed-digit coefficients] {Comparison of the cost and number of
  8-bit shift-and-add operations required to implement the coefficient
  multiplications for a parallel Schur one-multiplier all-pass lattice
  elliptic approximation low-pass filter with 8 bit, 2 signed-digit integer
  coefficients found by performing branch-and-bound search.} 
\label{tab:branch-bound-schurOneMPAlattice-elliptic-lowpass-8-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:Branch-and-bound-search-signed-digit-coefficients-parallel-allpass-elliptic-lowpass}Branch-and-bound search for the 16-bit 4-signed-digit coefficients of a parallel all-pass lattice IIR elliptic low-pass filter}
The Octave script
\emph{branch\_bound\_schurOneMPAlattice\_elliptic\_lowpass\_16\_nbits\_test.m}
performs branch-and-bound search to optimise the response of the parallel
Schur one-multiplier all-pass lattice elliptic low-pass filter
with $16$-bit integer coefficients. The filter specification is:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_elliptic_lowpass_16_nbits_test_spec.m}
\end{small} 
The initial parallel all-pass filters are those for the filter designed by the
Octave function \emph{ellip(11,0.02,84,2*0.15)}.
The filter coefficients are truncated to $16$ bits allocated with an average
of $4$ signed-digits by the heuristic of \emph{Ito et al.} as shown in
Section~\ref{sec:Ito-allocation-signed-digits}.

The numbers of signed digits allocated to each coefficient by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_elliptic_lowpass_16_nbits_test_A1k_allocsd_digits.m}
\verbatiminput{branch_bound_schurOneMPAlattice_elliptic_lowpass_16_nbits_test_A2k_allocsd_digits.m}
\end{small}

The signed-digit lattice coefficients found by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_elliptic_lowpass_16_nbits_test_A1k0_sd_coef.m}
\verbatiminput{branch_bound_schurOneMPAlattice_elliptic_lowpass_16_nbits_test_A2k0_sd_coef.m}
\end{small}

The signed-digit lattice coefficients found by the branch-and-bound
search are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_elliptic_lowpass_16_nbits_test_A1k_min_coef.m}
\verbatiminput{branch_bound_schurOneMPAlattice_elliptic_lowpass_16_nbits_test_A2k_min_coef.m}
\end{small}
The signed-digit lattice coefficients found by the branch-and-bound
search are implemented with 
\input{branch_bound_schurOneMPAlattice_elliptic_lowpass_16_nbits_test_kmin_digits.tab}
signed-digits and 
\input{branch_bound_schurOneMPAlattice_elliptic_lowpass_16_nbits_test_kmin_adders.tab}
shift-and-add operations.

Figure~\ref{fig:branch-bound-schurOneMPAlattice-elliptic-lowpass-16-nbits-pass-response}
shows the amplitude pass-band response of the filter with $16$-bit
$4$-signed-digit coefficients allocated with the algorithm of \emph{Ito et al.}
and branch-and-bound search.
Figure~\ref{fig:branch-bound-schurOneMPAlattice-elliptic-lowpass-16-nbits-stop-response}
shows the amplitude stop-band response.
Table~\ref{tab:branch-bound-schurOneMPAlattice-elliptic-lowpass-16-nbits-cost-summary}
compares the cost and the number of $16$ bit shift-and-add operations required
to implement the coefficient multiplications found by the signed-digit
allocation heuristic of \emph{Ito et al.} with the branch-and-bound search.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_elliptic_lowpass_16_nbits_test_kmin_pass}}
\caption{Pass band amplitude response of a parallel Schur one-multiplier
  all-pass lattice elliptic approximation low-pass filter with 16 bit integer
  coefficients found by allocating an average of 4-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-elliptic-lowpass-16-nbits-pass-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_elliptic_lowpass_16_nbits_test_kmin_stop}}
\caption{Stop band amplitude response of a parallel Schur one-multiplier
  all-pass lattice elliptic approximation low-pass filter with 16 bit integer
  coefficients found by allocating an average of 4-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-elliptic-lowpass-16-nbits-stop-response}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_schurOneMPAlattice_elliptic_lowpass_16_nbits_test_kmin_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results of a parallel all-pass Schur one-multiplier
lattice elliptic approximation lowpass filter SOCP algorithm example
with 16 bit coefficients] {Comparison of the cost and number of 16-bit
  shift-and-add operations required to implement the coefficient
  multiplications for a parallel Schur one-multiplier all-pass lattice
  elliptic approximation low-pass filter with 16 bit integer coefficients
  found by allocating an average of 4-signed-digits to each coefficient using
  the heuristic of \emph{Ito et al.} and performing branch-and-bound
  search.}
\label{tab:branch-bound-schurOneMPAlattice-elliptic-lowpass-16-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:Branch-and-bound-search-signed-digit-coefficients-parallel-allpass-bandpass}Branch-and-bound
  search for the 12-bit 3-signed-digit coefficients of a parallel all-pass lattice band-pass IIR filter}
The Octave script
\emph{branch\_bound\_schurOneMPAlattice\_bandpass\_12\_nbits\_test.m} performs
branch-and-bound search to optimise the response of the parallel
Schur one-multiplier all-pass lattice band-pass filter of
Section~\ref{sec:Design-parallel-Schur-one-mult-all-pass-lattice-band-pass-SOCP}
with $12$-bit integer coefficients. The filter specification is:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_12_nbits_test_spec.m}
\end{small} 

The filter coefficients are truncated to $12$ bits allocated with an average
of $3$ signed-digits by the heuristic of \emph{Ito et al.} as shown in
Section~\ref{sec:Ito-allocation-signed-digits}.
At each branch the script fixes the coefficient with the largest difference
between upper and lower $3$ signed-digit approximations to the floating-point
value. For each sub-problem the coefficients ``higher-up-the-tree'' are fixed
and the remaining free coefficients are SOCP PCLS optimised with the filter
specification given above.

The numbers of signed digits allocated to each coefficient by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_12_nbits_test_A1k_allocsd_digits.m}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_12_nbits_test_A2k_allocsd_digits.m}
\end{small}

The signed-digit lattice coefficients found by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_12_nbits_test_A1k0_sd_coef.m}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_12_nbits_test_A2k0_sd_coef.m}
\end{small}

The signed-digit lattice coefficients found by the branch-and-bound search are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_12_nbits_test_A1k_min_coef.m}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_12_nbits_test_A2k_min_coef.m}
\end{small}
The signed-digit lattice coefficients found by the branch-and-bound
search are implemented with 
\input{branch_bound_schurOneMPAlattice_bandpass_12_nbits_test_kmin_digits.tab}
signed-digits and 
\input{branch_bound_schurOneMPAlattice_bandpass_12_nbits_test_kmin_adders.tab}
shift-and-add operations.

Figure~\ref{fig:branch-bound-schurOneMPAlattice-bandpass-12-nbits-pass-response}
shows the amplitude pass-band response of the filter with
$12$-bit $3$-signed-digit coefficients allocated with the algorithm of
\emph{Ito et al.} and branch-and-bound search.
Figure~\ref{fig:branch-bound-schurOneMPAlattice-bandpass-12-nbits-delay-response}
shows the corresponding filter pass-band group-delay response.
Figure~\ref{fig:branch-bound-schurOneMPAlattice-bandpass-12-nbits-stop-response}
shows the corresponding filter stop-band amplitude response.
Table~\ref{tab:branch-bound-schurOneMPAlattice-bandpass-12-nbits-cost-summary}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the coefficient multiplications found by the signed-digit
allocation heuristic of \emph{Ito et al.} with the branch-and-bound search.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_bandpass_12_nbits_test_kmin_pass}}
\caption{Pass band amplitude response for a parallel Schur
  one-multiplier all-pass lattice band-pass filter with 12 bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-bandpass-12-nbits-pass-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_bandpass_12_nbits_test_kmin_delay}}
\caption{Pass band group delay response for a parallel Schur
  one-multiplier all-pass lattice band-pass filter with 12 bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-bandpass-12-nbits-delay-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_bandpass_12_nbits_test_kmin_stop}}
\caption{Stop band amplitude response for a parallel Schur one-multiplier
  all-pass lattice band-pass filter with 12 bit integer coefficients found by
  allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Ito et al.} and performing branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-bandpass-12-nbits-stop-response}
\end{figure}
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_schurOneMPAlattice_bandpass_12_nbits_test_kmin_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the parallel Schur one-multiplier
all-pass lattice bandpass filter SOCP algorithm example with 12 bit
coefficients] {Comparison of the cost and number of 12-bit shift-and-add
  operations required to implement the coefficient multiplications for a
  parallel Schur one-multiplier all-pass lattice band-pass filter with 12 bit
  integer coefficients found by allocating an average of 3-signed-digits to
  each coefficient using the heuristic of \emph{Ito et al.} and performing
  branch-and-bound search.}
\label{tab:branch-bound-schurOneMPAlattice-bandpass-12-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:Branch-and-bound-search-signed-digit-coefficients-parallel-allpass-bandpass-Hilbert-10-bit}Branch-and-bound search for the 10-bit 3-signed-digit coefficients of a parallel all-pass lattice band-pass Hilbert IIR filter}
The Octave script
\emph{branch\_bound\_schurOneMPAlattice\_bandpass\_hilbert\_10\_nbits\_test.m}
performs branch-and-bound search to optimise the response of the parallel
Schur one-multiplier all-pass lattice band-pass Hilbert filter of
Section~\ref{sec:Design-parallel-Schur-one-mult-all-pass-lattice-band-pass-Hilbert-SOCP}
with $10$-bit integer coefficients. The filter specification is:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_hilbert_10_nbits_test_spec.m}
\end{small} 

The filter coefficients are truncated to $10$ bits with $3$ signed-digits.
At each branch the script fixes the coefficient with the largest difference
between upper and lower $3$ signed-digit approximations to the floating-point
value. For each sub-problem the coefficients ``higher-up-the-tree'' are fixed
and the remaining free coefficients are SOCP PCLS optimised with the filter
specification given above.

The $12$-bit, $3$-signed-digit, lattice coefficients found by the
branch-and-bound search are: 
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_hilbert_10_nbits_test_A1k_min_coef.m}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_hilbert_10_nbits_test_A2k_min_coef.m}
\end{small}

The signed-digit lattice coefficients found by the branch-and-bound
search are implemented with 
\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_10_nbits_test_kmin_digits.tab}
signed-digits and 
\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_10_nbits_test_kmin_adders.tab}
shift-and-add operations.

Figure~\ref{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-10-nbits-pass-response}
shows the amplitude pass-band response of the filter with
$10$-bit, $3$-signed-digit coefficients. 
Figure~\ref{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-10-nbits-phase-response}
shows the corresponding filter pass-band phase response (in multiples of $\pi$
and adjusted for the nominal delay).
Figure~\ref{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-10-nbits-delay-response}
shows the corresponding filter pass-band group-delay response.
Figure~\ref{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-10-nbits-stop-response}
shows the corresponding filter stop-band amplitude response.
Table~\ref{tab:branch-bound-schurOneMPAlattice-band-pass-Hilbert-10-nbits-cost-summary}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the coefficient multiplications found with the branch-and-bound
search. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_10_nbits_test_kmin_pass}}
\caption{Pass band amplitude response for a parallel Schur
  one-multiplier all-pass lattice band-pass Hilbert filter with 10 bit 
  3-signed-digit coefficients found by branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-10-nbits-pass-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_10_nbits_test_kmin_phase}}
\caption{Pass band phase response for a parallel
  Schur one-multiplier all-pass lattice band-pass Hilbert filter with 10 bit 
  3-signed-digit coefficients found by performing branch-and-bound search. The
  phase response shown is adjusted for the nominal delay.}
\label{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-10-nbits-phase-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_10_nbits_test_kmin_delay}}
\caption{Pass band group delay response for a parallel Schur
  one-multiplier all-pass lattice band-pass Hilbert filter with 10 bit 
  3-signed-digit coefficients found by branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-10-nbits-delay-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_10_nbits_test_kmin_stop}}
\caption{Stop band amplitude response for a parallel Schur
  one-multiplier all-pass lattice band-pass Hilbert filter with 10 bit 
  3-signed-digit coefficients found by branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-10-nbits-stop-response}
\end{figure}
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_10_nbits_test_kmin_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption{Summary of cost results for the parallel Schur
  one-multiplier all-pass lattice band-pass Hilbert filter with 10 bit 
  3-signed-digit coefficients found by branch-and-bound search.}
\label{tab:branch-bound-schurOneMPAlattice-band-pass-Hilbert-10-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:Branch-and-bound-search-signed-digit-coefficients-parallel-allpass-bandpass-Hilbert-12-bit}Branch-and-bound search for the 12-bit 3-signed-digit coefficients of a parallel all-pass lattice band-pass Hilbert IIR filter}
The Octave script
\emph{branch\_bound\_schurOneMPAlattice\_bandpass\_hilbert\_12\_nbits\_test.m}
performs branch-and-bound search to optimise the response of the parallel
Schur one-multiplier all-pass lattice band-pass Hilbert filter of
Section~\ref{sec:Design-parallel-Schur-one-mult-all-pass-lattice-band-pass-Hilbert-SOCP}
with $12$-bit integer coefficients. The filter specification is:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_spec.m}
\end{small} 

The filter coefficients are truncated to $12$ bits allocated with an average
of $3$ signed-digits by the heuristic of \emph{Ito et al.} as shown in
Section~\ref{sec:Ito-allocation-signed-digits}.
At each branch the script fixes the coefficient with the largest difference
between upper and lower signed-digit approximations to the floating-point
value. For each sub-problem the coefficients ``higher-up-the-tree'' are fixed
and the remaining free coefficients are SOCP PCLS optimised with the filter
specification given above.

The numbers of signed-digits allocated to each lattice coefficient by the
heuristic of \emph{Ito et al.} are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_A1k_allocsd_digits.m}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_A2k_allocsd_digits.m}
\end{small}

The $12$-bit, average of $3$-signed-digit, lattice coefficients allocated with
the algorithm of \emph{Ito et al.} are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_A1k0_sd_coef.m}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_A2k0_sd_coef.m}
\end{small}

The $12$-bit, average of $3$-signed-digit, lattice coefficients allocated with
the algorithm of \emph{Ito et al.} found by the branch-and-bound search are:
\begin{small}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_A1k_min_coef.m}
\verbatiminput{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_A2k_min_coef.m}
\end{small}

The signed-digit lattice coefficients found by the branch-and-bound
search are implemented with 
\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_kmin_digits.tab}
signed-digits and 
\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_kmin_adders.tab}
shift-and-add operations.

Figure~\ref{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-12-nbits-pass-response}
shows the amplitude pass-band response of the filter with
$12$-bits $3$-signed-digit coefficients allocated with the
algorithm of \emph{Ito et al.} and branch-and-bound search.
Figure~\ref{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-12-nbits-phase-response}
shows the corresponding filter pass-band phase response (in multiples of $\pi$
and adjusted for the nominal delay).
Figure~\ref{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-12-nbits-delay-response}
shows the corresponding filter pass-band group-delay response.
Figure~\ref{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-12-nbits-stop-response}
shows the corresponding filter stop-band amplitude response.
Table~\ref{tab:branch-bound-schurOneMPAlattice-band-pass-Hilbert-12-nbits-cost-summary}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the coefficient multiplications found by the signed-digit
allocation heuristic of \emph{Ito et al.} with the branch-and-bound search.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_kmin_pass}}
\caption{Pass band amplitude response for a parallel Schur
  one-multiplier all-pass lattice band-pass Hilbert filter with 12 bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-12-nbits-pass-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_kmin_phase}}
\caption{Pass band phase response for a parallel
  Schur one-multiplier all-pass lattice band-pass Hilbert filter with 12 bit
  integer coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  branch-and-bound search. The phase response shown is adjusted for the nominal
  delay.}
\label{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-12-nbits-phase-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_kmin_delay}}
\caption{Pass band group-delay response for a parallel Schur
  one-multiplier all-pass lattice band-pass Hilbert filter with 12 bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-12-nbits-delay-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_kmin_stop}}
\caption{Stop band amplitude response for a parallel Schur one-multiplier
  all-pass lattice band-pass Hilbert filter with 12 bit integer coefficients
  found by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Ito et al.} and performing branch-and-bound search.}
\label{fig:branch-bound-schurOneMPAlattice-band-pass-Hilbert-12-nbits-stop-response}
\end{figure}
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_schurOneMPAlattice_bandpass_hilbert_12_nbits_test_kmin_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the parallel Schur one-multiplier
all-pass lattice bandpass Hilbert filter SOCP algorithm example with 12 bit
coefficients] {Comparison of the cost and number of 12-bit shift-and-add
  operations required to implement the coefficient multiplications for a
  parallel Schur one-multiplier all-pass lattice band-pass Hilbert filter with
  12 bit integer coefficients found by allocating an average of
  3-signed-digits to  each coefficient using the heuristic of \emph{Ito et
  al.} and performing branch-and-bound search.}
\label{tab:branch-bound-schurOneMPAlattice-band-pass-Hilbert-12-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:Branch-and-bound-search-one-mult-FRM-low-pass-Schur-lattice}Branch-and-bound search for the coefficients of an FRM low-pass filter implemented with 12-bits and an average of 3-signed-digits}
The Octave script
\emph{branch\_bound\_schurOneMAPlattice\_frm\_12\_nbits\_test.m} uses
the branch-and-bound heuristic to optimise the response of the FRM low-pass
filter of Section~\ref{sec:FRM-low-pass-Schur-lattice} with
$12$-bit coefficients each having an average of $3$ signed-digits allocated by
the heuristic of \emph{Lim et al.}. The numbers of signed-digits allocated to
the coefficients of the all-pass lattice filter are:
\begin{small}
  \verbatiminput{branch_bound_schurOneMAPlattice_frm_12_nbits_test_k_allocsd_digits.m}
\end{small}
The numbers of signed-digits allocated to the distinct coefficients of the
FIR masking filter are:
\begin{small}
\verbatiminput{branch_bound_schurOneMAPlattice_frm_12_nbits_test_u_allocsd_digits.m}
\end{small}
The numbers of signed-digits allocated to the distinct coefficients of the
FIR complementary masking filter are:
\begin{small}
\verbatiminput{branch_bound_schurOneMAPlattice_frm_12_nbits_test_v_allocsd_digits.m}
\end{small}
The filter specification is:
\begin{small}
\verbatiminput{branch_bound_schurOneMAPlattice_frm_12_nbits_test_spec.m}
\end{small}
The filter coefficients found by the branch-and-bound search\footnote{The search
was stopped after about $36$ hours.} are:
\begin{small}
  \verbatiminput{branch_bound_schurOneMAPlattice_frm_12_nbits_test_k_min_coef.m}
  \verbatiminput
  {branch_bound_schurOneMAPlattice_frm_12_nbits_test_epsilon_min_coef.m}
  \verbatiminput{branch_bound_schurOneMAPlattice_frm_12_nbits_test_u_min_coef.m}
  \verbatiminput{branch_bound_schurOneMAPlattice_frm_12_nbits_test_v_min_coef.m}
\end{small}
Figures~\ref{fig:branch-bound-schurOneMAPlattice-frm-12-nbits-amplitude},
~\ref{fig:branch-bound-schurOneMAPlattice-frm-12-nbits-pass-phase},
and~\ref{fig:branch-bound-schurOneMAPlattice-frm-12-nbits-pass-delay}
compare the amplitude, phase and group delay responses of the FRM low-pass
filter with floating-point coefficients and 12-bit coefficients with an average
of 3-signed-digits allocated by the method of \emph{Lim et al.} and with the
coefficients found by branch-and-bound search. 
Table~\ref{tab:branch-bound-schurOneMAPlattice-frm-12-nbits-cost}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the coefficient multiplications found by branch-and-bound search.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMAPlattice_frm_12_nbits_test_amplitude}}
\caption{Comparison of the amplitude responses of an FRM
  low-pass filter with floating-point coefficients, with 12 bit coefficients
  having an average of 3-signed-digits allocated by the method of
  \emph{Lim et al.} and with the coefficients found by branch-and-bound search.}
\label{fig:branch-bound-schurOneMAPlattice-frm-12-nbits-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMAPlattice_frm_12_nbits_test_pass_phase}}
\caption{Comparison of the pass-band phase responses of an FRM
  low-pass filter with floating-point coefficients, with 12 bit coefficients
  having an average of 3-signed-digits allocated by the method of
  \emph{Lim et al.} and with the coefficients found by branch-and-bound search.}
\label{fig:branch-bound-schurOneMAPlattice-frm-12-nbits-pass-phase}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMAPlattice_frm_12_nbits_test_pass_delay}}
\caption{Comparison of the pass-band delay responses of an FRM
  low-pass filter with floating-point coefficients, with 12 bit coefficients
  having an average of 3-signed-digits allocated by the method of
  \emph{Lim et al.} and with the coefficients found by branch-and-bound search.}
\label{fig:branch-bound-schurOneMAPlattice-frm-12-nbits-pass-delay}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_schurOneMAPlattice_frm_12_nbits_test_cost.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the FRM low-pass filter with floating-point
coefficients and 12-bit 3-signed-digit coefficients found by the
branch-and-bound algorithm]
{Comparison of the cost and number of 12-bit shift-and-add operations required 
  to implement the coefficient multiplications for an FRM low-pass filter
  with 12-bit coefficients having an average of 3-signed-digits allocated by the
  method of \emph{Lim et al.} and with the coefficients found by
  branch-and-bound search.} 
\label{tab:branch-bound-schurOneMAPlattice-frm-12-nbits-cost}
\end{table}
\clearpage
\section{Branch-and-bound search for the 12-bit 2-signed-digit
  coefficients of a FRM Hilbert filter}
The Octave script
\emph{branch\_bound\_schurOneMAPlattice\_frm\_hilbert\_12\_nbits\_test.m} uses
the branch-and-bound heuristic to optimise the response of the FRM Hilbert
filter of
Section~\ref{sec:Design-Hilbert-FRM-allpass-model-filter-Schur-lattice} with
12-bit 2-signed-digit coefficients. The filter specification is:
\begin{small}
\verbatiminput{branch_bound_schurOneMAPlattice_frm_hilbert_12_nbits_test_spec.m}
\end{small}
The truncation of the last coefficient is, by
necessity, not PCLS optimised so the final set of coefficients may not meet
the PCLS specifications. The filter coefficients found by the branch-and-bound search are:
\begin{small}
  \verbatiminput
  {branch_bound_schurOneMAPlattice_frm_hilbert_12_nbits_test_k_min_coef.m}
  \verbatiminput
  {branch_bound_schurOneMAPlattice_frm_hilbert_12_nbits_test_u_min_coef.m}
  \verbatiminput
  {branch_bound_schurOneMAPlattice_frm_hilbert_12_nbits_test_v_min_coef.m}
\end{small}
Figures~\ref{fig:branch-bound-schurOneMAPlattice-frm-Hilbert-12-nbits-A},~\ref{fig:branch-bound-schurOneMAPlattice-frm-Hilbert-12-nbits-P}
and~\ref{fig:branch-bound-schurOneMAPlattice-frm-Hilbert-12-nbits-T} compare
the amplitude, phase
and delay responses of the FRM Hilbert filter with floating-point coefficients,
with 12-bit 2-signed-digit coefficients and with the 12-bit 2-signed-digit
coefficients found by branch-and-bound search.
Figure~\ref{fig:branch-bound-schurOneMAPlattice-frm-Hilbert-12-nbits-remez}
compares the amplitude and phase responses of a linear phase FIR Hilbert
filter with 12-bit 2-signed-digit coefficients and the FRM Hilbert filter with
12 bit 2-signed digit integer coefficients found by branch-and-bound
search. The phase responses shown are adjusted for the nominal delay. The group
delay of the FIR Hilbert filter is the nominal delay of the FRM Hilbert filter:
\begin{small}
\begin{verbatim}
b=remez(2*tp,2*[fap fas],[1 1],1,"hilbert");
\end{verbatim}
\end{small}
The FIR Hilbert filter coefficients have not been optimised.
Table~\ref{tab:branch-bound-schurOneMAPlattice-frm-Hilbert-12-nbits-cost}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the coefficient multiplications found by the branch-and-bound
search.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMAPlattice_frm_hilbert_12_nbits_test_kuv_minAsq}}
\caption{Comparison of the amplitude response of an FRM Hilbert filter with
  floating-point coefficients and with 12 bit 2-signed digit integer
  coefficients found by branch-and-bound search}
\label{fig:branch-bound-schurOneMAPlattice-frm-Hilbert-12-nbits-A}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMAPlattice_frm_hilbert_12_nbits_test_kuv_minP}}
\caption{Comparison of the phase response of an
  FRM Hilbert filter with floating-point coefficients and with 12 bit 2-signed
  digit integer coefficients found by branch-and-bound search. The phase
  response shown is adjusted for the nominal delay.}
\label{fig:branch-bound-schurOneMAPlattice-frm-Hilbert-12-nbits-P}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMAPlattice_frm_hilbert_12_nbits_test_kuv_minT}}
\caption{Comparison of the delay response of an FRM Hilbert filter with
  floating-point coefficients and with 12 bit 2-signed digit integer
  coefficients found by branch-and-bound search.}
\label{fig:branch-bound-schurOneMAPlattice-frm-Hilbert-12-nbits-T}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_schurOneMAPlattice_frm_hilbert_12_nbits_test_remez}}
\caption{Comparison of the amplitude and phase
responses of an FIR Hilbert filter with 12-bit 2-signed-digit coefficients and
an FRM Hilbert filter with 12 bit 2-signed digit integer coefficients found by
branch-and-bound search. The phase response shown is adjusted for the nominal
delay.} 
\label{fig:branch-bound-schurOneMAPlattice-frm-Hilbert-12-nbits-remez}
\end{figure}
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_schurOneMAPlattice_frm_hilbert_12_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the FRM Hilbert filter with 12-bit 2-signed-digit coefficients found by the branch-and-bound algorithm]
{Comparison of the cost and number of 12-bit shift-and-add operations required 
  to implement the coefficient multiplications for an FRM Hilbert filter
  with 12-bit 2-signed-digit coefficients found by branch-and-bound search.}
\label{tab:branch-bound-schurOneMAPlattice-frm-Hilbert-12-nbits-cost}
\end{table}
\clearpage
\section{Branch-and-bound search for the 12-bit 2-signed-digit
  coefficients of a FIR Hilbert filter}
The Octave script
\emph{branch\_bound\_directFIRhilbert\_12\_nbits\_test.m} uses
the branch-and-bound heuristic to optimise the response of a direct-form FIR
Hilbert filter with 12-bit 2-signed-digit coefficients having a similar
specification to the FIR Hilbert filter of 
Appendix~\ref{app:Design-even-order-FIR-Hilbert-filter}.
An average of $2$ signed-digits are allocated to each non-zero coefficient with
the heuristic of \emph{Ito et al.}. The Octave script
  \emph{directFIRhilbert\_allocsd\_test.m} compares the heuristics of \emph{Lim
    et al.} and \emph{Ito et al.} for coefficient wordlengths from $6$ to
  $16$ bits. The direct-form FIR Hilbert filter specification is:
\begin{small}
\verbatiminput{branch_bound_directFIRhilbert_12_nbits_test_spec.m}
\end{small}

The filter has $40$ distinct non-zero coefficients and the filter group-delay
is $79$ samples. The numbers of signed-digits allocated to each coefficient with
the heuristic of \emph{Ito et al.} are:
\begin{small}
\verbatiminput{branch_bound_directFIRhilbert_12_nbits_test_hM_allocsd_digits.m}
\end{small}
The distinct non-zero filter coefficients found by the
branch-and-bound search are:
\begin{small}
  \verbatiminput{branch_bound_directFIRhilbert_12_nbits_test_hM_min_coef.m}
\end{small}

Figure~\ref{fig:branch-bound-direct-FIR-Hilbert-12-nbits-response},
compares the amplitude responses of the FIR Hilbert filter with floating-point
coefficients, 12-bit 2-signed-digit coefficients, 12-bit 2-signed-digit
coefficients with signed-digits allocated by the heuristic of \emph{Ito et al.}
and with the 12-bit 2-signed-digit coefficients found by branch-and-bound search.
Table~\ref{tab:branch-bound-direct-FIR-Hilbert-12-nbits-cost}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the coefficient multiplications found by the branch-and-bound
search. The FIR filter structure requires an extra $80$ additions.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_directFIRhilbert_12_nbits_test_response}}
\caption{Comparison of the amplitude response of a direct-form FIR Hilbert
  filter with floating-point coefficients and with 12-bit 2-signed digit integer
  coefficients found by branch-and-bound search.}
\label{fig:branch-bound-direct-FIR-Hilbert-12-nbits-response}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_directFIRhilbert_12_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the direct-form FIR Hilbert filter with
floating-point and 12-bit 2-signed-digit coefficients found by the
branch-and-bound algorithm]{Comparison of the cost and number of 12-bit
  shift-and-add operations required to implement the coefficient multiplications
  for a direct-form FIR Hilbert filter with 12-bit 2-signed-digit coefficients
  found by branch-and-bound search.}
\label{tab:branch-bound-direct-FIR-Hilbert-12-nbits-cost}
\end{table}
\clearpage
\section{\label{sec:Branch-and-bound-search-12-bit-2-sd-FIR-Hilbert-bandpass}Branch-and-bound search for the 12-bit 2-signed-digit
  coefficients of a FIR Hilbert band-pass filter}
The Octave script
\emph{branch\_bound\_directFIRhilbert\_bandpass\_12\_nbits\_test.m} uses
the branch-and-bound heuristic to optimise the response of a direct-form FIR
Hilbert band-pass filter with 12-bit 2-signed-digit coefficients having a
similar bandwidth specification to the FIR Hilbert band-pass filter of 
Appendix~\ref{app:Design-even-order-FIR-Hilbert-bandpass-filter}.
An average of $2$ signed-digits are allocated to each non-zero coefficient with
the heuristic of \emph{Ito et al.} .The direct-form FIR Hilbert filter
specification is: 
\begin{small}
\verbatiminput{branch_bound_directFIRhilbert_bandpass_12_nbits_test_spec.m}
\end{small}
The filter has $8$ distinct non-zero coefficients and the filter group-delay
is $15$ samples.

The numbers of signed-digits allocated to each coefficient by
the heuristic of \emph{Ito et al.} are:
\begin{small}
\verbatiminput{branch_bound_directFIRhilbert_bandpass_12_nbits_test_hM_allocsd_digits.m}
\end{small}
The distinct non-zero filter coefficients found by the
allocation of signed-digits with the heuristic of \emph{Ito et al.} are:
\begin{small}
\verbatiminput{branch_bound_directFIRhilbert_bandpass_12_nbits_test_hM_sd_coef.m}
\end{small}
and by branch-and-bound search are:
\begin{small}
\verbatiminput{branch_bound_directFIRhilbert_bandpass_12_nbits_test_hM_min_coef.m}
\end{small}

Figure~\ref{fig:branch-bound-direct-FIR-Hilbert-bandpass-12-nbits-response},
compares the amplitude responses of the FIR Hilbert band-pass filter with
floating-point coefficients, 12-bit 2-signed-digit coefficients, 12-bit
2-signed-digit coefficients with signed-digits allocated by the heuristic of
\emph{Ito et al.} and with the 12-bit 2-signed-digit coefficients found by
branch-and-bound search. 
Table~\ref{tab:branch-bound-direct-FIR-Hilbert-bandpass-12-nbits-cost}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the coefficient multiplications found by the branch-and-bound
search. The FIR filter structure requires an extra $16$ additions.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_directFIRhilbert_bandpass_12_nbits_test_response}}
\caption{Comparison of the amplitude response of a direct-form FIR Hilbert
  bandpass filter with floating-point coefficients and with 12-bit 2-signed
  digit integer coefficients found by branch-and-bound search.}
\label{fig:branch-bound-direct-FIR-Hilbert-bandpass-12-nbits-response}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{branch_bound_directFIRhilbert_bandpass_12_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the direct-form FIR Hilbert band-pass
filter with 12-bit 2-signed-digit coefficients found by the branch-and-bound
algorithm]{Comparison of the cost and number of 12-bit
  shift-and-add operations required to implement the coefficient multiplications
  for a direct-form FIR Hilbert band-pass filter with 12-bit 2-signed-digit
  coefficients found by branch-and-bound search.}
\label{tab:branch-bound-direct-FIR-Hilbert-bandpass-12-nbits-cost}
\end{table}

\chapter{\label{sec:successive-coefficient-relaxation-signed-digit-coefficients}Successive coefficient relaxation search for signed-digit filter coefficients}
This section describes the results of experiments in which I fix one
coefficient and minimise the objective function over the
remaining free coefficients. This is called a \emph{relaxation} of the
optimisation. The relaxation is repeated until all the coefficients are fixed.
\section{\label{sec:SOCP-relaxation-search-signed-digit-coefficients-symmetric-FIR-bandpass}SOCP-relaxation search for the signed-digit coefficients of a direct-form symmetric bandpass FIR filter}
The Octave script 
\emph{socp\_relaxation\_directFIRsymmetric\_bandpass\_12\_nbits\_test.m}
performs successive SOCP relaxations to optimise the response of a direct-form
symmetric band-pass FIR filter. The 
filter specification is:
\begin{small}
\verbatiminput{socp_relaxation_directFIRsymmetric_bandpass_12_nbits_test_spec.m}
\end{small} 
The filter coefficients are truncated to $12$ bits allocated with an average of
$3$ signed-digits by the heuristic of \emph{Ito et al.} as shown in
Section~\ref{sec:Ito-allocation-signed-digits}. 

At each coefficient relaxation step the script finds the upper and lower
signed-digit approximations to the current set of active coefficients and
selects the coefficient with the largest difference in those approximations. The
corresponding bounds are set in the bounds for that coefficient passed to the
Octave function \emph{directFIRsymmetric\_socp\_mmse}. The results of this MMSE
optimisation are then passed to \emph{directFIRsymmetric\_slb} for PCLS
optimisation. The resulting PCLS coefficient value selects the closer of the
upper or lower signed-digit values as the final choice for that coefficient. The
truncation of the last coefficient is, by necessity, not PCLS optimised so the
final set of coefficients may not meet the PCLS specifications.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_directFIRsymmetric_bandpass_12_nbits_test_hM_allocsd_digits.m}
\end{small}
The distinct direct-form symmetric FIR bandpass filter coefficients found by
the SOCP-relaxation search are:
\begin{small}
\verbatiminput{socp_relaxation_directFIRsymmetric_bandpass_12_nbits_test_hM_min_coef.m}
\end{small}

Figures~\ref{fig:socp-relax-direct-FIR-symmetric-bandpass-12-nbits-passband}
and~\ref{fig:socp-relax-direct-FIR-symmetric-bandpass-12-nbits-stopband}
compares the responses of the filter with floating-point coefficients, 12-bit
signed-digit coefficients allocated with the algorithm of \emph{Ito et al.} and
12-bit signed-digit coefficients allocated with the algorithm of
\emph{Ito et al.} and SOCP-relaxation search.
Table~\ref{tab:socp-relax-direct-FIR-symmetric-bandpass-12-nbits-cost-summary} 
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the $16$ distinct coefficient multiplications found by the
signed-digit allocation heuristic of \emph{Ito et al.} with the
SOCP-relaxation search.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_directFIRsymmetric_bandpass_12_nbits_test_passband_response}}
\caption{Comparison of the pass-band amplitude responses for a
  direct-form symmetric FIR bandpass filter with 12-bit integer coefficients
  found by allocating an average of 3-signed-digits to each coefficient using
  the heuristic of \emph{Ito et al.} and performing SOCP-relaxation search.}
\label{fig:socp-relax-direct-FIR-symmetric-bandpass-12-nbits-passband}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_directFIRsymmetric_bandpass_12_nbits_test_stopband_response}}
\caption{Comparison of the stop-band amplitude responses for a
  direct-form symmetric FIR bandpass filter with 12-bit integer coefficients
  found by allocating an average of 3-signed-digits to each coefficient using
  the heuristic of \emph{Ito et al.} and performing SOCP-relaxation search.}
\label{fig:socp-relax-direct-FIR-symmetric-bandpass-12-nbits-stopband}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{socp_relaxation_directFIRsymmetric_bandpass_12_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the direct-form symmetric FIR 
bandpass filter SOCP-relaxation algorithm example with 12-bit coefficients]
{Comparison of the cost and number of 12-bit shift-and-add operations required 
  to implement the coefficient multiplications for a direct-form symmetric FIR
  bandpass filter with 12-bit integer coefficients found by allocating 
  an average of 3-signed-digits to each coefficient using the heuristic of 
  \emph{Ito et al.} and performing SOCP-relaxation search.}
\label{tab:socp-relax-direct-FIR-symmetric-bandpass-12-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:SQP-relaxation-search-signed-digit-coefficients-bandpass}SQP-relaxation search for the signed-digit coefficients of a lattice bandpass IIR filter}
The Octave script 
\emph{sqp\_relaxation\_schurOneMlattice\_bandpass\_10\_nbits\_test.m} performs
successive SQP relaxations to optimise the response of the SQP optimised
band-pass Schur one-multiplier lattice filter of
Section~\ref{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-SQP}. The 
filter specification is:
\begin{small}
\verbatiminput{sqp_relaxation_schurOneMlattice_bandpass_10_nbits_test_spec.m}
\end{small} 
The filter coefficients are truncated to $10$ bits allocated with an average of
$3$ signed-digits by the heuristic of \emph{Ito et al.} as shown in
Section~\ref{sec:Ito-allocation-signed-digits}. 

At each coefficient relaxation step the script finds the upper and lower
signed-digit approximations to the current set of active coefficients and
selects the coefficient with the largest difference in those approximations. The
corresponding bounds are set in the bounds for that coefficient passed to the
Octave function \emph{schurOneMlattice\_sqp\_mmse}. The results of this MMSE
optimisation are then passed to \emph{schurOneMlattice\_slb} for PCLS
optimisation. The resulting PCLS coefficient value selects the closer of the
upper or lower signed-digit values as the final choice for that coefficient. The
truncation of the last coefficient is, by necessity, not PCLS optimised so the
final set of coefficients may not meet the PCLS specifications.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{sqp_relaxation_schurOneMlattice_bandpass_10_nbits_test_k_allocsd_digits.m}
\verbatiminput{sqp_relaxation_schurOneMlattice_bandpass_10_nbits_test_c_allocsd_digits.m}
\end{small}
The filter coefficients found by the SQP-relaxation search are:
\begin{small}
\verbatiminput{sqp_relaxation_schurOneMlattice_bandpass_10_nbits_test_k_min_coef.m}
\verbatiminput{sqp_relaxation_schurOneMlattice_bandpass_10_nbits_test_c_min_coef.m}
\end{small}

Figure~\ref{fig:sqp-relax-schurOneMlattice-bandpass-10-nbits-pass-response}
compares the pass-band responses of the filter with floating-point coefficients,
10-bit signed-digit coefficients allocated with the algorithm of
\emph{Ito et al.} and 10-bit signed-digit coefficients allocated with the
algorithm of \emph{Ito et al.} and SQP-relaxation search.
Figure~\ref{fig:sqp-relax-schurOneMlattice-bandpass-10-nbits-stop-response}
shows the filter stop-band response and
Figure~\ref{fig:sqp-relax-schurOneMlattice-bandpass-10-nbits-delay-response}
shows the filter pass-band group delay response.
Table~\ref{tab:sqp-relax-schurOneMlattice-bandpass-10-nbits-cost-summary} 
compares the cost and the number of $10$ bit shift-and-add operations required to
implement the $31$ coefficient multiplications found by the signed-digit 
allocation heuristic of \emph{Ito et al.} with the SQP-relaxation search. A 
further $51$ additions are required by the lattice filter structure.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sqp_relaxation_schurOneMlattice_bandpass_10_nbits_test_pass}}
\caption{Comparison of the pass-band amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Ito et al.} and performing SQP-relaxation search.}
\label{fig:sqp-relax-schurOneMlattice-bandpass-10-nbits-pass-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sqp_relaxation_schurOneMlattice_bandpass_10_nbits_test_stop}}
\caption{Comparison of the stop-band amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Ito et al.} and performing SQP-relaxation search.}
\label{fig:sqp-relax-schurOneMlattice-bandpass-10-nbits-stop-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sqp_relaxation_schurOneMlattice_bandpass_10_nbits_test_delay}}
\caption{Comparison of the pass-band group delay responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Ito et al.} and performing SQP-relaxation search.}
\label{fig:sqp-relax-schurOneMlattice-bandpass-10-nbits-delay-response}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{sqp_relaxation_schurOneMlattice_bandpass_10_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the Schur one-multiplier lattice 
bandpass filter SQP-relaxation algorithm example with 10-bit coefficients]
{Comparison of the cost and number of 10-bit shift-and-add operations required 
  to implement the coefficient multiplications for a Schur one-multiplier 
  lattice bandpass filter with 10-bit integer coefficients found by allocating 
  an average of 3-signed-digits to each coefficient using the heuristic of 
  \emph{Ito et al.} and performing SQP-relaxation search.}
\label{tab:sqp-relax-schurOneMlattice-bandpass-10-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:SQP-relaxation-search-signed-digit-coefficients-lowpass}SQP-relaxation search for the signed-digit coefficients of a lattice lowpass IIR filter}
The Octave script
\emph{sqp\_relaxation\_schurOneMlattice\_lowpass\_10\_nbits\_test.m} performs
successive SQP relaxations to optimise the response of the low-pass Schur
one-multiplier lattice filter of
Section~\ref{sec:Design-IIR-one-multiplier-Schur-lattice-low-pass-SQP} with
$10$-bit signed-digit coefficients. The filter specification is:
\begin{small}
\verbatiminput{sqp_relaxation_schurOneMlattice_lowpass_10_nbits_test_spec.m}
\end{small} 

The filter coefficients are truncated to $10$ bits allocated with an average of
$3$ signed-digits by the heuristic of \emph{Lim et al.} as shown in
Section~\ref{sec:Lim-allocation-signed-digits}.  At each coefficient relaxation
step the script finds the upper and lower signed-digit approximations to the
current set of active coefficients and selects the coefficient with the largest
difference in those approximations. The corresponding bounds are set in the
bounds for that coefficient passed to the Octave function
\emph{schurOneMlattice\_sqp\_mmse}. The results of this MMSE optimisation are
then passed to \emph{schurOneMlattice\_slb} for PCLS optimisation. The resulting
PCLS coefficient value selects the closer of the upper or lower signed-digit
values as the final choice for that coefficient. The truncation of the last
coefficient is, by necessity, not PCLS optimised so the final set of
coefficients may not meet the PCLS specifications.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{sqp_relaxation_schurOneMlattice_lowpass_10_nbits_test_k_allocsd_digits.m}
\verbatiminput{sqp_relaxation_schurOneMlattice_lowpass_10_nbits_test_c_allocsd_digits.m}
\end{small}
The filter coefficients found by the SQP-relaxation search are:
\begin{small}
\verbatiminput{sqp_relaxation_schurOneMlattice_lowpass_10_nbits_test_k_min_coef.m}
\verbatiminput{sqp_relaxation_schurOneMlattice_lowpass_10_nbits_test_c_min_coef.m}
\end{small}

Figure~\ref{fig:sqp-relax-schurOneMlattice-lowpass-10-nbits-amplitude}
shows the amplitude and group-delay responses of the filter with $10$-bit 
$3$-signed-digit coefficients allocated with the algorithm of \emph{Lim et al.}
and SQP-relaxation search.
Figures~\ref{fig:sqp-relax-schurOneMlattice-lowpass-10-nbits-pass-amplitude}
and~\ref{fig:sqp-relax-schurOneMlattice-lowpass-10-nbits-pass-delay}
show the corresponding filter pass-band response.
Figure~\ref{fig:sqp-relax-schurOneMlattice-lowpass-10-nbits-pz}
shows the filter pole-zero plot.
Table~\ref{tab:sqp-relax-schurOneMlattice-lowpass-10-nbits-cost-summary} 
compares the cost and the number of $10$ bit shift-and-add operations required 
to implement the coefficient multiplications found by the signed-digit 
allocation heuristic of \emph{Lim et al.} with the SQP-relaxation search.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sqp_relaxation_schurOneMlattice_lowpass_10_nbits_test_kc_min_amplitude}}
\caption{Amplitude responses for a Schur
  one-multiplier lattice low-pass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SQP-relaxation search.}
\label{fig:sqp-relax-schurOneMlattice-lowpass-10-nbits-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sqp_relaxation_schurOneMlattice_lowpass_10_nbits_test_kc_min_pass_amplitude}}
\caption{Pass-band amplitude responses for a Schur
  one-multiplier lattice low-pass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SQP-relaxation search.}
\label{fig:sqp-relax-schurOneMlattice-lowpass-10-nbits-pass-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sqp_relaxation_schurOneMlattice_lowpass_10_nbits_test_kc_min_pass_delay}}
\caption{Pass-band group delay responses for a Schur
  one-multiplier lattice low-pass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SQP-relaxation search.}
\label{fig:sqp-relax-schurOneMlattice-lowpass-10-nbits-pass-delay}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sqp_relaxation_schurOneMlattice_lowpass_10_nbits_test_kc_min_pz}}
\caption{Pole-zero plot for a Schur
  one-multiplier lattice low-pass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SQP-relaxation search.}
\label{fig:sqp-relax-schurOneMlattice-lowpass-10-nbits-pz}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{sqp_relaxation_schurOneMlattice_lowpass_10_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the Schur one-multiplier lattice 
low-pass filter SQP-relaxation algorithm example with 10-bit coefficients]
{Comparison of the cost and number of 10-bit shift-and-add operations required 
  to implement the coefficient multiplications for a Schur one-multiplier 
  lattice low-pass filter with 10-bit integer coefficients found by allocating 
  an average of 3-signed-digits to each coefficient using the heuristic of 
  \emph{Lim et al.} and performing SQP-relaxation search.}
\label{tab:sqp-relax-schurOneMlattice-lowpass-10-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:SOCP-relaxation-search-signed-digit-coefficients-bandpass-lattice-IIR}SOCP-relaxation search for the signed-digit coefficients of a lattice bandpass IIR filter}
The Octave script 
\emph{socp\_relaxation\_schurOneMlattice\_bandpass\_10\_nbits\_test.m} performs
successive SOCP relaxations to optimise the response of the SQP optimised
band-pass Schur one-multiplier lattice filter of
Section~\ref{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-SQP} with
$10$-bit signed-digit coefficients. The filter specification is:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_bandpass_10_nbits_test_spec.m}
\end{small} 
The filter coefficients are truncated to $10$ bits allocated with an average of
$3$ signed-digits by the heuristic of \emph{Lim et al.} as shown in
Section~\ref{sec:Lim-allocation-signed-digits}. 

At each coefficient relaxation step the script finds the upper and lower
signed-digit approximations to the current set of active coefficients and
selects the coefficient with the largest difference in those approximations. The
corresponding bounds are set in the bounds for that coefficient passed to the
Octave function \emph{schurOneMlattice\_socp\_mmse}. The results of this MMSE
optimisation are then passed to \emph{schurOneMlattice\_slb} for PCLS
optimisation. The resulting PCLS coefficient value selects the closer of the
upper or lower signed-digit values as the final choice for that coefficient. The
truncation of the last coefficient is, by necessity, not PCLS optimised so the
final set of coefficients may not meet the PCLS specifications.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_bandpass_10_nbits_test_k_allocsd_digits.m}
\verbatiminput{socp_relaxation_schurOneMlattice_bandpass_10_nbits_test_c_allocsd_digits.m}
\end{small}
The filter coefficients found by the SOCP-relaxation search are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_bandpass_10_nbits_test_k_min_coef.m}
\verbatiminput{socp_relaxation_schurOneMlattice_bandpass_10_nbits_test_c_min_coef.m}
\end{small}
Figure~\ref{fig:socp-relax-schurOneMlattice-bandpass-10-nbits-pass-response}
compares the pass-band responses of the filter with floating-point coefficients,
10-bit signed-digit coefficients allocated with the algorithm of
\emph{Lim et al.} and 10-bit signed-digit coefficients allocated with the
algorithm of \emph{Lim et al.} and SOCP-relaxation search.
Figure~\ref{fig:socp-relax-schurOneMlattice-bandpass-10-nbits-stop-response}
shows the filter stop-band response and
Figure~\ref{fig:socp-relax-schurOneMlattice-bandpass-10-nbits-delay-response}
shows the filter pass-band group delay response.
Table~\ref{tab:socp-relax-schurOneMlattice-bandpass-10-nbits-cost}
compares the cost and the number of $10$ bit shift-and-add operations required to
implement the coefficient multiplications found by the signed-digit 
allocation heuristic of \emph{Lim et al.} with the SOCP-relaxation search.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_bandpass_10_nbits_test_pass}}
\caption{Comparison of the pass-band amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMlattice-bandpass-10-nbits-pass-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_bandpass_10_nbits_test_stop}}
\caption{Comparison of the stop-band amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMlattice-bandpass-10-nbits-stop-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_bandpass_10_nbits_test_delay}}
\caption{Comparison of the pass-band group delay responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMlattice-bandpass-10-nbits-delay-response}
\end{figure}
\begin{table}
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{socp_relaxation_schurOneMlattice_bandpass_10_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the Schur one-multiplier lattice 
bandpass filter SOCP-relaxation algorithm example with 10-bit coefficients]
{Comparison of the cost and number of 10-bit shift-and-add operations required 
 to implement the coefficient multiplications for a Schur one-multiplier 
 lattice bandpass filter with 10-bit integer coefficients found by allocating 
 an average of 3-signed-digits to each coefficient using the heuristic of 
 \emph{Lim et al.} and performing SOCP-relaxation search.}
\label{tab:socp-relax-schurOneMlattice-bandpass-10-nbits-cost}
\end{table}
\clearpage
\section{\label{sec:SOCP-relaxation-search-signed-digit-coefficients-bandpass-hilbert-lattice-IIR}SOCP-relaxation search for the signed-digit coefficients of a lattice bandpass Hilbert IIR filter}
The Octave script 
\emph{socp\_relaxation\_schurOneMlattice\_bandpass\_hilbert\_13\_nbits\_test.m}
performs successive SOCP relaxations to optimise the response of the SOCP
optimised band-pass Hilbert Schur one-multiplier lattice filter of
Section~\ref{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-hilbert-SOCP}
with $13$-bit signed-digit coefficients. The filter specification is:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_spec.m}
\end{small} 
The filter coefficients are truncated to $13$ bits allocated with an average of
$3$ signed-digits by the heuristic of \emph{Ito et al.} as shown in
Section~\ref{sec:Ito-allocation-signed-digits}. 
At each coefficient relaxation step the script finds the upper and lower
signed-digit approximations to the current set of active coefficients and
selects the coefficient with the largest difference in those approximations.
The Octave function \emph{schurOneMlattice\_slb} PCLS optimises the remaining
active coefficient values. The script selects the closer of the upper or
lower signed-digit values as the final choice for that coefficient.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_k_allocsd_digits.m}
\verbatiminput{socp_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_c_allocsd_digits.m}
\end{small}
The $13$-bit $3$-signed-digit filter coefficients found by the SOCP-relaxation
search are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_k_sd_min_coef.m}
\verbatiminput{socp_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_c_sd_min_coef.m}
\end{small}

Figure~\ref{fig:socp-relax-schurOneMlattice-bandpass-hilbert-13-nbits-pass}
compares the pass-band responses of the band-pass Hilbert filter with
floating-point coefficients, $13$-bit, $3$-signed-digit coefficients allocated
with the algorithm of \emph{Ito et al.} and $13$-bit $3$-signed-digit
coefficients allocated with the algorithm of \emph{Ito et al.} found with
SOCP-relaxation search.
Figure~\ref{fig:socp-relax-schurOneMlattice-bandpass-hilbert-13-nbits-stop}
shows the band-pass Hilbert filter stop-band response.
Figure~\ref{fig:socp-relax-schurOneMlattice-bandpass-hilbert-13-nbits-phase}
shows the band-pass Hilbert filter pass-band phase response.
Figure~\ref{fig:socp-relax-schurOneMlattice-bandpass-hilbert-13-nbits-delay}
shows the band-pass Hilbert filter pass-band group delay response.
Table~\ref{tab:socp-relax-schurOneMlattice-bandpass-hilbert-13-nbits-cost} 
compares the cost and the number of $13$-bit shift-and-add operations required to
implement the coefficient multiplications found by the signed-digit 
allocation heuristic of \emph{Ito et al.} with the SOCP-relaxation search.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_pass}}
\caption{Comparison of the pass-band amplitude responses for a Schur
  one-multiplier lattice band-pass Hilbert filter with 13-bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMlattice-bandpass-hilbert-13-nbits-pass}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_stop}}
\caption{Comparison of the stop-band amplitude responses for a Schur
  one-multiplier lattice band-pass Hilbert filter with 13-bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMlattice-bandpass-hilbert-13-nbits-stop}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_phase}}
\caption{Comparison of the pass-band phase responses for a Schur
  one-multiplier lattice band-pass Hilbert filter with 13-bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMlattice-bandpass-hilbert-13-nbits-phase}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_delay}}
\caption{Comparison of the pass-band group delay responses for a Schur
  one-multiplier lattice band-pass Hilbert filter with 13-bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMlattice-bandpass-hilbert-13-nbits-delay}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lcccc}  \\ \toprule
&Cost&Signed-digits&Stop-band response(dB)&Shift-and-adds\\ \midrule
\input{socp_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the Schur one-multiplier lattice 
bandpass Hilbert filter SOCP-relaxation algorithm example with 13-bit
coefficients]{Comparison of the cost and number of 13-bit shift-and-add
  operations required to implement the coefficient multiplications for a Schur
  one-multiplier lattice band-pass Hilbert filter with 13-bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  SOCP-relaxation search.}
\label{tab:socp-relax-schurOneMlattice-bandpass-hilbert-13-nbits-cost}
\end{table}
\clearpage
\section{\label{sec:SOCP-relaxation-search-signed-digit-coefficients-lowpass-parallel-allpass-lowpass}SOCP-relaxation search for the signed-digit coefficients of a parallel all-pass lattice low-pass IIR filter}
The Octave script
\emph{socp\_relaxation\_schurOneMPAlattice\_lowpass\_12\_nbits\_test.m}
performs successive SOCP relaxations to optimise the response of the parallel
Schur one-multiplier all-pass lattice low-pass filter of
Section~\ref{sec:Design-parallel-Schur-one-mult-all-pass-lattice-low-pass-SOCP}
with $12$-bit integer coefficients. The filter specification is:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMPAlattice_lowpass_12_nbits_test_spec.m}
\end{small} 
The filter weights differ from those used in
Section~\ref{sec:Branch-and-bound-search-signed-digit-coefficients-parallel-allpass-one-M-lowpass}.

The filter coefficients are truncated to $12$ bits allocated with an average
of $3$ signed-digits by the heuristic of \emph{Lim et al.} as shown in
Section~\ref{sec:Lim-allocation-signed-digits}.  At each coefficient
relaxation step the script finds the upper and lower signed-digit
approximations to the current set of active coefficients and selects the
coefficient with the largest difference in those approximations. The
corresponding bounds are set in the bounds for that coefficient passed to the
Octave function \emph{schurOneMPAlattice\_socp\_mmse}. The results of this
MMSE optimisation are then passed to \emph{schurOneMPAlattice\_slb} for PCLS
optimisation. The resulting PCLS coefficient value selects the closer of the
upper or lower signed-digit values as the final choice for that
coefficient. The truncation of the last coefficient is, by necessity, not PCLS
optimised so the final set of coefficients may not meet the PCLS
specifications.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMPAlattice_lowpass_12_nbits_test_A1k_allocsd_digits.m}
\verbatiminput{socp_relaxation_schurOneMPAlattice_lowpass_12_nbits_test_A2k_allocsd_digits.m}
\end{small}
The signed-digit lattice coefficients found by the heuristic of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMPAlattice_lowpass_12_nbits_test_A1k_sd_coef.m}
\verbatiminput{socp_relaxation_schurOneMPAlattice_lowpass_12_nbits_test_A2k_sd_coef.m}
\end{small}

The signed-digit lattice coefficients found by the SOCP-relaxation search are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMPAlattice_lowpass_12_nbits_test_A1k_min_coef.m}
\verbatiminput{socp_relaxation_schurOneMPAlattice_lowpass_12_nbits_test_A2k_min_coef.m}
\end{small}
The signed-digit lattice coefficients found by the SOCP-relaxation search are
implemented with 
\input{socp_relaxation_schurOneMPAlattice_lowpass_12_nbits_test_kmin_digits.tab}
signed-digits and 
\input{socp_relaxation_schurOneMPAlattice_lowpass_12_nbits_test_kmin_adders.tab}
shift-and-add operations.

Figures~\ref{fig:socp-relax-schurOneMPAlattice-lowpass-12-nbits-pass-amplitude}
and~\ref{fig:socp-relax-schurOneMPAlattice-lowpass-12-nbits-pass-delay}
shows the pass-band amplitude and group-delay responses of the filter with
$12$-bit $3$-signed-digit coefficients allocated with the algorithm of
\emph{Lim et al.} and SOCP-relaxation search.
Figure~\ref{fig:socp-relax-schurOneMPAlattice-lowpass-12-nbits-stop-amplitude}
shows the corresponding filter stop-band amplitude response.
Table~\ref{tab:socp-relax-schurOneMPAlattice-lowpass-12-nbits-cost-summary}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the coefficient multiplications found by the signed-digit
allocation heuristic of \emph{Lim et al.} with the SOCP-relaxation search.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMPAlattice_lowpass_12_nbits_test_kmin_pass_amplitude}}
\caption{Pass-band amplitude responses for a parallel Schur
  one-multiplier all-pass lattice low-pass filter with 12 bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Lim et al.} and performing
  SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMPAlattice-lowpass-12-nbits-pass-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMPAlattice_lowpass_12_nbits_test_kmin_pass_delay}}
\caption{Pass-band group delay responses for a parallel Schur
  one-multiplier all-pass lattice low-pass filter with 12 bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Lim et al.} and performing
  SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMPAlattice-lowpass-12-nbits-pass-delay}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMPAlattice_lowpass_12_nbits_test_kmin_stop_amplitude}}
\caption{Stop band amplitude responses for a parallel Schur one-multiplier
  all-pass lattice low-pass filter with 12 bit integer coefficients found by
  allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMPAlattice-lowpass-12-nbits-stop-amplitude}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{socp_relaxation_schurOneMPAlattice_lowpass_12_nbits_test_kmin_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the parallel Schur one-multiplier
all-pass lattice lowpass filter SOCP algorithm example with 12 bit
coefficients] {Comparison of the cost and number of 12-bit shift-and-add
  operations required to implement the coefficient multiplications for a
  parallel Schur one-multiplier all-pass lattice low-pass filter with 12 bit
  integer coefficients found by allocating an average of 3-signed-digits to
  each coefficient using the heuristic of \emph{Lim et al.} and performing
  SOCP-relaxation search.}
\label{tab:socp-relax-schurOneMPAlattice-lowpass-12-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:SOCP-relaxation-search-signed-digit-coefficients-parallel-allpass-bandpass}SOCP-relaxation search for the signed-digit coefficients of a parallel all-pass lattice band-pass IIR filter}
The Octave script 
\emph{socp\_relaxation\_schurOneMPAlattice\_bandpass\_12\_nbits\_test.m} performs
successive SOCP relaxations to optimise the response of the parallel Schur
one-multiplier all-pass lattice band-pass filter of
Section~\ref{sec:Design-parallel-Schur-one-mult-all-pass-lattice-band-pass-SOCP}
with $12$-bit integer coefficients. The filter specification is:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMPAlattice_bandpass_12_nbits_test_spec.m}
\end{small} 

The filter coefficients are truncated to $12$ bits allocated with an average
of $3$ signed-digits by the heuristic of \emph{Lim et al.} as shown in
Section~\ref{sec:Lim-allocation-signed-digits}.  At each coefficient
relaxation step the script finds the upper and lower signed-digit
approximations to the current set of active coefficients and selects the
coefficient with the largest difference in those approximations. The
corresponding bounds are set in the bounds for that coefficient passed to the
Octave function \emph{schurOneMPAlattice\_socp\_mmse}. The results of this
MMSE optimisation are then passed to \emph{schurOneMPAlattice\_slb} for PCLS
optimisation. The resulting PCLS coefficient value selects the closer of the
upper or lower signed-digit values as the final choice for that
coefficient. The truncation of the last coefficient is, by necessity, not PCLS
optimised so the final set of coefficients may not meet the PCLS
specifications.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMPAlattice_bandpass_12_nbits_test_A1k_allocsd_digits.m}
\verbatiminput{socp_relaxation_schurOneMPAlattice_bandpass_12_nbits_test_A2k_allocsd_digits.m}
\end{small}
The signed-digit lattice coefficients found by the heuristic of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMPAlattice_bandpass_12_nbits_test_A1k_sd_coef.m}
\verbatiminput{socp_relaxation_schurOneMPAlattice_bandpass_12_nbits_test_A2k_sd_coef.m}
\end{small}

The signed-digit lattice coefficients found by the SOCP-relaxation search are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMPAlattice_bandpass_12_nbits_test_A1k_min_coef.m}
\verbatiminput{socp_relaxation_schurOneMPAlattice_bandpass_12_nbits_test_A2k_min_coef.m}
\end{small}
The signed-digit lattice coefficients found by the SOCP-relaxation search are
implemented with 
\input{socp_relaxation_schurOneMPAlattice_bandpass_12_nbits_test_kmin_digits.tab}
signed-digits and 
\input{socp_relaxation_schurOneMPAlattice_bandpass_12_nbits_test_kmin_adders.tab}
shift-and-add operations.

Figures~\ref{fig:socp-relax-schurOneMPAlattice-bandpass-12-nbits-pass-amplitude}
and~\ref{fig:socp-relax-schurOneMPAlattice-bandpass-12-nbits-pass-delay}
show the pass-band amplitude and group-delay responses of the filter with
$12$-bit $3$-signed-digit coefficients allocated with the algorithm of
\emph{Lim et al.} and SOCP-relaxation search.
Figure~\ref{fig:socp-relax-schurOneMPAlattice-bandpass-12-nbits-stop-amplitude}
shows the corresponding filter stop-band amplitude response.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMPAlattice_bandpass_12_nbits_test_kmin_pass_amplitude}}
\caption{Pass-band mplitude responses for a parallel Schur
  one-multiplier all-pass lattice band-pass filter with 12 bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Lim et al.} and performing
  SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMPAlattice-bandpass-12-nbits-pass-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMPAlattice_bandpass_12_nbits_test_kmin_pass_delay}}
\caption{Pass-band group-delay responses for a parallel Schur
  one-multiplier all-pass lattice band-pass filter with 12 bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Lim et al.} and performing
  SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMPAlattice-bandpass-12-nbits-pass-delay}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMPAlattice_bandpass_12_nbits_test_kmin_stop_amplitude}}
\caption{Stop band amplitude responses for a parallel Schur one-multiplier
  all-pass lattice band-pass filter with 12 bit integer coefficients found by
  allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMPAlattice-bandpass-12-nbits-stop-amplitude}
\end{figure}

Table~\ref{tab:socp-relax-schurOneMPAlattice-bandpass-12-nbits-cost-summary}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the coefficient multiplications found by the signed-digit
allocation heuristic of \emph{Lim et al.} with the SOCP-relaxation search.
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{socp_relaxation_schurOneMPAlattice_bandpass_12_nbits_test_kmin_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the parallel Schur one-multiplier
all-pass lattice bandpass filter SOCP algorithm example with 12 bit
coefficients] {Comparison of the cost and number of 12-bit shift-and-add
  operations required to implement the coefficient multiplications for a
  parallel Schur one-multiplier all-pass lattice band-pass filter with 12 bit
  integer coefficients found by allocating an average of 3-signed-digits to
  each coefficient using the heuristic of \emph{Lim et al.} and performing
  SOCP-relaxation search.}
\label{tab:socp-relax-schurOneMPAlattice-bandpass-12-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:SOCP-relaxation-search-signed-digit-coefficients-hilbert}SOCP-relaxation search for the signed-digit coefficients of a lattice Hilbert IIR filter}
The Octave script 
\emph{socp\_relaxation\_schurOneMlattice\_hilbert\_10\_nbits\_test.m} performs
successive SOCP relaxations to optimise the response of the band-pass Schur
one-multiplier lattice filter of
Section~\ref{sec:Design-IIR-one-multiplier-Schur-lattice-hilbert-SQP} with
$10$-bit integer coefficients. The filter specification is:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_hilbert_10_nbits_test_spec.m}
\end{small} 
The filter coefficients are truncated to $10$ bits allocated with an average
of $3$ signed-digits by the heuristic of \emph{Lim et al.} as shown in
Section~\ref{sec:Lim-allocation-signed-digits}. In this example, the group
delay response is not constrained. I did not succeed in finding a Hilbert
filter with integer coefficients using the SQP solver or using the
signed-digit allocation heuristic of \emph{Ito et al.}.

As in
Section~\ref{sec:SQP-relaxation-search-signed-digit-coefficients-bandpass}, at
each coefficient relaxation step the script finds the upper and lower
signed-digit approximations to the current set of active coefficients and
selects the coefficient with the largest difference in those
approximations. The corresponding bounds are set in the bounds for that
coefficient passed to the Octave function
\emph{schurOneMlattice\_socp\_mmse}. The results of this MMSE optimisation are
then passed to \emph{schurOneMlattice\_slb} for PCLS optimisation. The
resulting PCLS coefficient value selects the closer of the upper or lower
signed-digit values as the final choice for that coefficient. The truncation
of the last coefficient is, by necessity, not PCLS optimised so the final set
of coefficients may not meet the PCLS specifications.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_hilbert_10_nbits_test_k_allocsd_digits.m}
\verbatiminput{socp_relaxation_schurOneMlattice_hilbert_10_nbits_test_c_allocsd_digits.m}
\end{small}
The signed-digit filter coefficients found by the heuristic of 
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_hilbert_10_nbits_test_k0_sd_coef.m}
\verbatiminput{socp_relaxation_schurOneMlattice_hilbert_10_nbits_test_c0_sd_coef.m}
\end{small}

The signed-digit filter coefficients found by the SOCP-relaxation search are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_hilbert_10_nbits_test_k_min_coef.m}
\verbatiminput{socp_relaxation_schurOneMlattice_hilbert_10_nbits_test_c_min_coef.m}
\end{small}

Figures~\ref{fig:socp-relax-hilbert-schurOneMlattice-10-nbits-amplitude},
~\ref{fig:socp-relax-hilbert-schurOneMlattice-10-nbits-phase} and
\ref{fig:socp-relax-hilbert-schurOneMlattice-10-nbits-delay}
compare the amplitude, phase and delay responses of the filter with
floating-point coefficients, 10-bit signed-digit coefficients allocated by the
heuristic of \emph{Lim et al.} and 10-bit signed-digit coefficients allocated
by the heuristic of \emph{Lim et al.} with SOCP-relaxation search. The phase
responses shown are adjusted for the nominal filter delay.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_hilbert_10_nbits_test_kc_min_amplitude}}
\caption{Comparison of the amplitude responses for a
  Schur one-multiplier lattice Hilbert filter with 10-bit integer coefficients
  found by allocating an average of 3-signed-digits to each coefficient using
  the heuristic of \emph{Lim et al.} and performing SOCP-relaxation
  search.}
\label{fig:socp-relax-hilbert-schurOneMlattice-10-nbits-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_hilbert_10_nbits_test_kc_min_phase}}
\caption{Comparison of the phase responses for a
  Schur one-multiplier lattice Hilbert filter with 10-bit integer coefficients
  found by allocating an average of 3-signed-digits to each coefficient using
  the heuristic of \emph{Lim et al.} and performing SOCP-relaxation
  search. The phase responses shown are adjusted for the nominal delay.}
\label{fig:socp-relax-hilbert-schurOneMlattice-10-nbits-phase}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_hilbert_10_nbits_test_kc_min_delay}}
\caption{Comparison of the delay responses for a
  Schur one-multiplier lattice Hilbert filter with 10-bit integer coefficients
  found by allocating an average of 3-signed-digits to each coefficient using
  the heuristic of \emph{Lim et al.} and performing SOCP-relaxation
  search.}
\label{fig:socp-relax-hilbert-schurOneMlattice-10-nbits-delay}
\end{figure}

Table~\ref{tab:socp-relax-hilbert-schurOneMlattice-10-nbits-cost-summary}
compares the cost, the number of signed-digits and the number of $10$-bit
shift-and-add operations required to implement the coefficient multiplications
found by the signed-digit allocation heuristic of \emph{Lim et al.} with
SOCP-relaxation search.
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{socp_relaxation_schurOneMlattice_hilbert_10_nbits_test_kc_min_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the Schur one-multiplier lattice 
Hilbert filter SOCP-relaxation example with 10-bit coefficients]
{Comparison of the cost and number of 10-bit shift-and-add operations required 
  to implement the coefficient multiplications for a Schur one-multiplier 
  lattice Hilbert filter with 10-bit integer coefficients found by allocating 
  an average of 3-signed-digits to each coefficient using the heuristic of 
  \emph{Lim et al.} and performing SOCP-relaxation search.}
\label{tab:socp-relax-hilbert-schurOneMlattice-10-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:SOCP-relaxation-search-signed-digit-coefficients-lowpass-differentiator}SOCP-relaxation search for the signed-digit coefficients of a one-multiplier lattice low-pass differentiator IIR filter}
The Octave script 
\emph{socp\_relaxation\_schurOneMlattice\_lowpass\_differentiator\_12\_nbits\_test.m}
performs successive SOCP relaxations to optimise the response of
an implementation of the low-pass differentiator filter shown in
Section~\ref{sec:iir-sqp-slb-lowpass-differentiator} as the series combination
of $1-z^{-1}$ and a Schur one-multiplier lattice correction filter with $12$-bit
integer signed-digit coefficients. The filter specification is:  
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_12_nbits_test_spec.m}
\end{small} 
The filter coefficients are truncated to $12$ bits allocated with an average
of $3$ signed-digits allocated by the heuristic of \emph{Lim et al.} as shown in
Section~\ref{sec:Ito-allocation-signed-digits}. At each coefficient relaxation
step the script finds the upper and lower signed-digit approximations to the
current set of active coefficients and selects the coefficient with the largest
difference in those approximations. The corresponding bounds are set in the
bounds for that coefficient passed to the Octave function
\emph{schurOneMlattice\_socp\_mmse}. The results of this MMSE optimisation are
then passed to \emph{schurOneMlattice\_slb} for PCLS optimisation. The
resulting PCLS coefficient value selects the closer of the upper or lower
signed-digit values as the final choice for that coefficient. 

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_12_nbits_test_k_allocsd_digits.m}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_12_nbits_test_c_allocsd_digits.m}
\end{small}
  
The corresponding signed-digit coefficients of the Schur one-multiplier lattice
correction filter are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_12_nbits_test_k0_sd_coef.m}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_12_nbits_test_c0_sd_coef.m}
\end{small}

The signed-digit filter coefficients  of the Schur one-multiplier lattice
correction filter found by the SOCP-relaxation search are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_12_nbits_test_k_min_coef.m}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_12_nbits_test_c_min_coef.m}
\end{small}

Figure~\ref{fig:socp-relax-schurOneMlattice-lowpass-differentiator-12-nbits-response}
compares the amplitude, phase and group delay error responses of the low-pass
differentiator filter with floating-point coefficients, 12-bit signed-digit
coefficients allocated with the algorithm of \emph{Lim et al.} and 12-bit
signed-digit coefficients allocated with the algorithm of \emph{Lim et al.} and
found by SOCP-relaxation search. The phase responses shown are adjusted for the
nominal filter delay.
Table~\ref{tab:socp-relax-schurOneMlattice-lowpass-differentiator-12-nbits-cost-summary}
compares the cost, the number of signed-digits and the number of $12$-bit
shift-and-add operations required to implement the coefficient multiplications
found by the signed-digit allocation heuristic of \emph{Lim et al.} and by
SOCP-relaxation search.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_lowpass_differentiator_12_nbits_test_kc_min}}
\caption{Comparison of the amplitude, phase and group delay error
  responses for a Schur one-multiplier lattice lowpass differentiator filter
  with 12-bit integer coefficients found by allocating an average of
  3-signed-digits to each coefficient using the heuristic of \emph{Lim et al.}
  and performing SOCP-relaxation search. The phase responses shown are adjusted
  for the nominal delay.} 
\label{fig:socp-relax-schurOneMlattice-lowpass-differentiator-12-nbits-response}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{llcc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{socp_relaxation_schurOneMlattice_lowpass_differentiator_12_nbits_test_kc_min_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the Schur one-multiplier lattice 
lowpass differentiator filter SOCP-relaxation example with 12-bit coefficients]
{Comparison of the cost and number of 12-bit shift-and-add operations required 
  to implement the coefficient multiplications for a Schur one-multiplier 
  lattice correction filter with 12-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SOCP-relaxation search.}
\label{tab:socp-relax-schurOneMlattice-lowpass-differentiator-12-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:SOCP-relaxation-search-signed-digit-coefficients-pipelined-lowpass-differentiator}SOCP-relaxation search for the signed-digit coefficients of a pipelined one-multiplier lattice low-pass differentiator IIR filter}
The Octave script 
\emph{socp\_relaxation\_schurOneMlatticePipelined\_lowpass\_differentiator\_12\_nbits\_test.m}
performs successive \\
SOCP relaxations to optimise the response of an implementation of the low-pass
differentiator filter shown in
Section~\ref{sec:SOCP-Schur-OneM-pipelined-lowpass-differentiator} as the series
combination of $1-z^{-1}$ and a pipelined Schur one-multiplier lattice
correction filter with $12$-bit integer signed-digit coefficients. The filter
specification is:  
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_spec.m}
\end{small} 
The filter coefficients are truncated to $12$ bits allocated with an average
of $3$ signed-digits allocated by the heuristic of \emph{Ito et al.} as shown in
Section~\ref{sec:Ito-allocation-signed-digits}. At each coefficient relaxation
step the script finds the upper and lower signed-digit approximations to the
current set of active coefficients and selects the coefficient with the largest
difference in those approximations. The corresponding bounds are set in the
bounds for that coefficient passed to the Octave function
\emph{schurOneMlatticePipelined\_socp\_mmse}. The results of this MMSE
optimisation are then passed to \emph{schurOneMlatticePipelined\_slb} for PCLS
optimisation. The resulting PCLS coefficient value selects the closer of the
upper or lower signed-digit values as the final choice for that coefficient. 

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_k_allocsd_digits.m}
\verbatiminput{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_c_allocsd_digits.m}
\verbatiminput{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_kk_allocsd_digits.m}
\verbatiminput{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_ck_allocsd_digits.m}
\end{small}
\begin{comment}
The signed-digit filter coefficients of the Schur one-multiplier lattice
correction filter with the number of digits allocated by the algorithm of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_k0_sd_coef.m}
\verbatiminput{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_c0_sd_coef.m}
\verbatiminput{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_kk0_sd_coef.m}
\verbatiminput{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_ck0_sd_coef.m}
\end{small}
\end{comment}
The signed-digit filter coefficients of the Schur one-multiplier lattice
correction filter found by the SOCP-relaxation search are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_k_min_coef.m}
\verbatiminput{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_c_min_coef.m}
\verbatiminput{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_kk_min_coef.m}
\verbatiminput{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_ck_min_coef.m}
\end{small}

Figure~\ref{fig:socp-relax-pipelined-schurOneMlattice-lowpass-differentiator-12-nbits-response}
compares the amplitude, phase and group delay error responses of the pipelined
low-pass differentiator filter with floating-point coefficients, 12-bit
signed-digit coefficients allocated with the algorithm of \emph{Ito et al.} and
12-bit signed-digit coefficients allocated with the algorithm of
\emph{Ito et al.} and found by SOCP-relaxation search. The phase responses shown
are adjusted for the nominal filter delay.
Table~\ref{tab:socp-relax-pipelined-schurOneMlattice-lowpass-differentiator-12-nbits-cost-summary}
compares the cost, the number of signed-digits and the number of $12$-bit
shift-and-add operations required to implement the coefficient multiplications
found by the signed-digit allocation heuristic of \emph{Ito et al.} and by
SOCP-relaxation search.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_kc_min}}
\caption{Comparison of the amplitude, phase and group delay error
  responses for a pipelined Schur one-multiplier lattice lowpass differentiator
  filter with 12-bit integer coefficients found by allocating an average of
  3-signed-digits to each coefficient using the heuristic of \emph{Ito et al.}
  and performing SOCP-relaxation search. The phase responses shown are adjusted
  for the nominal delay.} 
\label{fig:socp-relax-pipelined-schurOneMlattice-lowpass-differentiator-12-nbits-response}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{llcc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{socp_relaxation_schurOneMlatticePipelined_lowpass_differentiator_12_nbits_test_kc_min_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the pipelined Schur one-multiplier lattice 
lowpass differentiator filter SOCP-relaxation example with 12-bit coefficients]
{Comparison of the cost and number of 12-bit shift-and-add operations required 
  to implement the coefficient multiplications for a pipelined Schur
  one-multiplier lattice correction filter with 12-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Ito et al.} and performing SOCP-relaxation search.}
\label{tab:socp-relax-pipelined-schurOneMlattice-lowpass-differentiator-12-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:SOCP-relaxation-search-signed-digit-coefficients-R2-lowpass-differentiator}SOCP-relaxation search for the signed-digit
  coefficients of a one-multiplier lattice R=2 low-pass differentiator IIR
  filter}
The Octave script 
\emph{socp\_relaxation\_schurOneMlattice\_lowpass\_differentiator\_R2\_12\_nbits\_test.m}
performs successive SOCP relaxations to optimise the response of an
implementation of the low-pass differentiator filter shown in
Section~\ref{sec:SOCP-Schur-OneM-lowpass-differentiator} as the series
combination of $1-z^{-1}$ and a Schur one-multiplier lattice correction filter
having denominator polynomial coefficients only in $z^{-2}$ with $12$-bit
coefficients each having an average of $3$ signed-digits allocated by the
heuristic of \emph{Lim et al.} and found by SOCP-relaxation search.
The filter specification is:  
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_spec.m}
\end{small} 
The filter coefficients are truncated to $12$ bits allocated with an average
of $3$ signed-digits allocated by the heuristic of \emph{Lim et al.} as shown in
Section~\ref{sec:Lim-allocation-signed-digits}. At each coefficient relaxation
step the script finds the upper and lower signed-digit approximations to the
current set of active coefficients and selects the coefficient with the largest
difference in those approximations. The corresponding bounds are set in the
bounds for that coefficient passed to the Octave function
\emph{schurOneMlattice\_socp\_mmse}. The results of this MMSE
optimisation are then passed to \emph{schurOneMlattice\_slb} for PCLS
optimisation. The resulting PCLS coefficient value selects the closer of the
upper or lower signed-digit values as the final choice for that coefficient. 

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_k_allocsd_digits.m}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_c_allocsd_digits.m}
\end{small}
\begin{comment}
The signed-digit filter coefficients of the Schur one-multiplier lattice
correction filter with the number of digits allocated by the algorithm of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_k0_sd_coef.m}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_c0_sd_coef.m}
\end{small}
\end{comment}
The signed-digit filter coefficients of the Schur one-multiplier lattice
correction filter found by the SOCP-relaxation search are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_k_min_coef.m}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_c_min_coef.m}
\end{small}
The corresponding coefficients of the filter transfer function polynomials are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_N_min_coef.m}
\verbatiminput{socp_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_D_min_coef.m}
\end{small}

Figure~\ref{fig:socp-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-response}
compares the pass-band amplitude error (compared to a desired response of
$\frac{\omega}{2}$), stop-band amplitude, pass-band phase (adjusted for the
nominal filter delay) and pass-band group delay responses.
Figure~\ref{fig:socp-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-corr}
compares the error in the correction filter pass-band squared-amplitude gradient.
Figure~\ref{fig:socp-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-pz}
shows the pole-zero plot of the filter found by SOCP-relaxation search.
Table~\ref{tab:socp-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-cost}
compares the cost, the number of signed-digits and the number of $12$-bit
shift-and-add operations required to implement the coefficient multiplications.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_response}}
\caption{Comparison of the pass-band amplitude error, stop-band amplitude,
  pass-band phase and pass-bandgroup delay responses for a Schur one-multiplier
  lattice lowpass differentiator filter, having denominator polynomial
  coefficients only in $z^{-2}$, with $12$-bit integer coefficients found
  by allocating an average of $3$-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SOCP-relaxation search. The
  phase response shown is adjusted for the nominal delay.} 
\label{fig:socp-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_correction}}
\caption{Error in the gradient of the squared-amplitude response of the
  correction filter of a Schur one-multiplier lattice low-pass differentiator
  filter with $12$ bit, $3$ signed-digit coefficients and denominator polynomial
  terms only in $z^{-2}$ found by performing SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-corr}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_pz}}
\caption{Pole-zero plot of the Schur one-multiplier lattice low-pass
  differentiator filter having denominator polynomial terms only in $z^{-2}$
  with $12$ bit, $3$ signed-digit coefficients, found by performing
  SOCP-relaxation search.}
\label{fig:socp-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-pz}
\end{figure}
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{llcc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{socp_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the $R=2$ Schur one-multiplier lattice 
lowpass differentiator filter SOCP-relaxation example with $12$-bit coefficients]
{Comparison of the cost and number of 12-bit shift-and-add operations required 
  to implement the coefficient multiplications for a Schur one-multiplier
  lattice low-pass differentiator correction filter having denominator
  polynomial coefficients only in $z^{-2}$, with $12$-bit integer
  coefficients found by allocating an average of $3$-signed-digits to each
  coefficient using the heuristic of \emph{Lim et al.} and performing
  SOCP-relaxation search.}
\label{tab:socp-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-cost}
\end{table}
\clearpage
\section{\label{sec:SOCP-relaxation-search-one-mult-FRM-low-pass-Schur-lattice}SOCP relaxation search for the 12-bit, 3-signed-digit coefficients of an FRM low-pass filter}
The Octave script
\emph{socp\_relaxation\_schurOneMAPlattice\_frm\_12\_nbits\_test.m} uses
socp-relaxation search to optimise the response of the FRM low-pass
filter of Section~\ref{sec:FRM-low-pass-Schur-lattice} with
$12$-bit, $3$ signed-digit coefficient. The filter specification is:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMAPlattice_frm_12_nbits_test_spec.m}
\end{small}
The filter coefficients found by the socp-relaxation search are:
\begin{small}
  \verbatiminput
  {socp_relaxation_schurOneMAPlattice_frm_12_nbits_test_k_min_coef.m}
  \verbatiminput
  {socp_relaxation_schurOneMAPlattice_frm_12_nbits_test_epsilon_min_coef.m}
  \verbatiminput
  {socp_relaxation_schurOneMAPlattice_frm_12_nbits_test_u_min_coef.m}
  \verbatiminput
  {socp_relaxation_schurOneMAPlattice_frm_12_nbits_test_v_min_coef.m}
\end{small}
Figures~\ref{fig:socp-relaxation-schurOneMAPlattice-frm-12-nbits-amplitude},
~\ref{fig:socp-relaxation-schurOneMAPlattice-frm-12-nbits-pass-phase}
and~\ref{fig:socp-relaxation-schurOneMAPlattice-frm-12-nbits-pass-delay}
compare the amplitude, phase and delay responses of the FRM low-pass
filter with floating-point coefficients and with 12-bit, 3-signed-digit
coefficients found by SOCP-relaxation search. The phase response shown is adjusted for the nominal delay.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMAPlattice_frm_12_nbits_test_amplitude}}
\caption{Comparison of the amplitude responses of an FRM
  low-pass filter with floating-point coefficients and with 12 bit,
  3-signed-digit coefficients found by SOCP-relaxation search.}
\label{fig:socp-relaxation-schurOneMAPlattice-frm-12-nbits-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMAPlattice_frm_12_nbits_test_pass_phase}}
\caption{Comparison of the pass-band phase responses of an FRM
  low-pass filter with floating-point coefficients and with 12 bit,
  3-signed-digit coefficients found by SOCP-relaxation search. The phase
  response shown is adjusted for the nominal delay.}
\label{fig:socp-relaxation-schurOneMAPlattice-frm-12-nbits-pass-phase}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMAPlattice_frm_12_nbits_test_pass_delay}}
\caption{Comparison of the pass-band delay responses of an FRM
  low-pass filter with floating-point coefficients and with 12 bit,
  3-signed-digit coefficients found by SOCP-relaxation search.}
\label{fig:socp-relaxation-schurOneMAPlattice-frm-12-nbits-pass-delay}
\end{figure}

Table~\ref{tab:socp-relaxation-schurOneMAPlattice-frm-12-nbits-cost}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the coefficient multiplications found by SOCP-relaxation search.
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{socp_relaxation_schurOneMAPlattice_frm_12_nbits_test_kuv_min_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the FRM low-pass filter with floating-point
coefficients and with 12-bit 3-signed-digit coefficients found by
socp-relaxation search]
{Comparison of the cost and number of 12-bit shift-and-add operations required 
  to implement the coefficient multiplications for an FRM low-pass filter
  with 12-bit, 3-signed-digit coefficients found by SOCP-relaxation search.} 
\label{tab:socp-relaxation-schurOneMAPlattice-frm-12-nbits-cost}
\end{table}
\clearpage
\section{SOCP relaxation search for the 16-bit, 3-signed-digit coefficients of an FRM low-pass filter}
The Octave script
\emph{socp\_relaxation\_schurOneMAPlattice\_frm\_16\_nbits\_test.m} uses
socp-relaxation search to optimise the response of the FRM low-pass
filter of Section~\ref{sec:FRM-low-pass-Schur-lattice} with
$16$-bit coefficients each having an average of $3$ signed-digits allocated by
the method of \emph{Ito et al.}. The filter specification is:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMAPlattice_frm_16_nbits_test_spec.m}
\end{small}

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Ito et al.} are:
\begin{small}
  \verbatiminput
  {socp_relaxation_schurOneMAPlattice_frm_16_nbits_test_k_allocsd_digits.m}
  \verbatiminput
  {socp_relaxation_schurOneMAPlattice_frm_16_nbits_test_u_allocsd_digits.m}
  \verbatiminput
  {socp_relaxation_schurOneMAPlattice_frm_16_nbits_test_v_allocsd_digits.m}
\end{small}

Section~\ref{sec:Branch-and-bound-search-one-mult-FRM-low-pass-Schur-lattice}.
The filter coefficients found by the socp-relaxation search are:
\begin{small}
  \verbatiminput
  {socp_relaxation_schurOneMAPlattice_frm_16_nbits_test_k_min_coef.m}
  \verbatiminput
  {socp_relaxation_schurOneMAPlattice_frm_16_nbits_test_epsilon_min_coef.m}
  \verbatiminput
  {socp_relaxation_schurOneMAPlattice_frm_16_nbits_test_u_min_coef.m}
  \verbatiminput
  {socp_relaxation_schurOneMAPlattice_frm_16_nbits_test_v_min_coef.m}
\end{small}
Figures~\ref{fig:socp-relaxation-schurOneMAPlattice-frm-16-nbits-amplitude},
~\ref{fig:socp-relaxation-schurOneMAPlattice-frm-16-nbits-pass-phase},
Figures~\ref{fig:socp-relaxation-schurOneMAPlattice-frm-16-nbits-pass-delay},
compare the amplitude, phase and delay responses of the FRM low-pass
filter with floating-point coefficients, with $16$-bit coefficients having an
average of $3$-signed-digits allocated by the method of \emph{Ito et al.} and
with the coefficients found by SOCP-relaxation search. The phase response shown
is adjusted for the nominal delay.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMAPlattice_frm_16_nbits_test_amplitude}}
\caption{Comparison of the amplitude responses of an FRM
  low-pass filter with floating-point coefficients, with 16 bit coefficients
  having an average of 3-signed-digits allocated by the method of
  \emph{Ito et al.} and with the coefficients found by SOCP-relaxation search.}
\label{fig:socp-relaxation-schurOneMAPlattice-frm-16-nbits-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMAPlattice_frm_16_nbits_test_pass_phase}}
\caption{Comparison of the pass-band phase responses of an FRM
  low-pass filter with floating-point coefficients, with 16 bit coefficients
  having an average of 3-signed-digits allocated by the method of
  \emph{Ito et al.} and with the coefficients found by SOCP-relaxation search.
  The phase response shown is adjusted for the nominal delay.}
\label{fig:socp-relaxation-schurOneMAPlattice-frm-16-nbits-pass-phase}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMAPlattice_frm_16_nbits_test_pass_delay}}
\caption{Comparison of the pass-band delay responses of an FRM
  low-pass filter with floating-point coefficients, with 16 bit coefficients
  having an average of 3-signed-digits allocated by the method of
  \emph{Ito et al.} and with the coefficients found by SOCP-relaxation search.}
\label{fig:socp-relaxation-schurOneMAPlattice-frm-16-nbits-pass-delay}
\end{figure}

Table~\ref{tab:socp-relaxation-schurOneMAPlattice-frm-16-nbits-cost}
compares the cost and the number of $16$ bit shift-and-add operations required
to implement the coefficient multiplications found by SOCP-relaxation search.
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{socp_relaxation_schurOneMAPlattice_frm_16_nbits_test_kuv_min_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the FRM low-pass filter with floating-point
coefficients and with 16-bit 3-signed-digit coefficients found by socp-relaxation
search]
{Comparison of the cost and number of 16-bit shift-and-add operations required 
  to implement the coefficient multiplications for an FRM low-pass filter
  with 16-bit coefficients with an average of 3-signed-digits allocated by the
  method of \emph{Ito et al.} and with the coefficients found by
  SOCP-relaxation search.} 
\label{tab:socp-relaxation-schurOneMAPlattice-frm-16-nbits-cost}
\end{table}
\clearpage
\section{\label{sec:SOCP-relaxation-search-signed-digit-coefficients-FRM-hilbert}SOCP-relaxation search for the signed-digit coefficients of an FRM Hilbert IIR filter with an all-pass lattice model filter}

The Octave script
\emph{socp\_relaxation\_schurOneMAPlattice\_frm\_hilbert\_12\_nbits\_test.m}
performs successive SOCP relaxations to optimise the response of the FRM
Hilbert filter of
Section~\ref{sec:Design-Hilbert-FRM-allpass-model-filter-Schur-lattice} with
$12$-bit integer coefficients. The FRM model filter is implemented as a
Schur one-multiplier all-pass lattice filter. The filter specification is:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_spec.m}
\end{small} 
The filter coefficients are truncated to $12$ bits allocated with an average
of $2$ signed-digits by the heuristic of \emph{Lim et al.} shown in
Section~\ref{sec:Lim-allocation-signed-digits}. 

As in Section~\ref{sec:SQP-relaxation-search-signed-digit-coefficients-bandpass},
at each coefficient relaxation step the script finds the upper and lower
signed-digit approximations to the current set of active coefficients and
selects the coefficient with the largest difference in those approximations.
The corresponding filter is PCLS optimised by the function
\emph{schurOneMAPlattice\_frm\_hilbert\_slb}. The resulting PCLS coefficient
value selects the nearer of the upper or lower signed-digit values as the
final choice for that coefficient. The truncation of the last coefficient is
necessarily not PCLS optimised so the final set of coefficients may not meet
the PCLS specifications.

The numbers of signed-digits allocated to the coefficients of the all-pass
lattice filter, FIR masking filter and FIR complementary masking filter by the
heuristic of \emph{Lim et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_k_allocsd_digits.m}
\verbatiminput{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_u_allocsd_digits.m}
\verbatiminput{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_v_allocsd_digits.m}
\end{small}
The signed-digit filter coefficients found by the heuristic of 
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_k0_sd_coef.m}
\verbatiminput{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_u0_sd_coef.m}
\verbatiminput{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_v0_sd_coef.m}
\end{small}

The signed-digit filter coefficients found by the SOCP-relaxation search are:
\begin{small}
\verbatiminput{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_k_min_coef.m}
\verbatiminput{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_u_min_coef.m}
\verbatiminput{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_v_min_coef.m}
\end{small}

Table~\ref{tab:socp-relax-FRM-hilbert-schurOneMAPlattice-12-nbits-cost-summary}
compares the cost, the number of signed-digits and the number of $12$-bit
shift-and-add operations required to implement the coefficient multiplications
found by the signed-digit allocation heuristic of \emph{Lim et al.} optimised
by SOCP-relaxation search. The one-multiplier lattice implementation requires
a further $15$ additions ($3$ per coefficient) and the FIR masking filter
requires a further $33$ additions.
Figures~\ref{fig:socp-relax-FRM-hilbert-schurOneMAPlattice-12-nbits-amplitude-response},
~\ref{fig:socp-relax-FRM-hilbert-schurOneMAPlattice-12-nbits-delay-response}
~and~\ref{fig:socp-relax-FRM-hilbert-schurOneMAPlattice-12-nbits-phase-response}
compare the amplitude, delay and phase responses of the filter with
floating-point coefficients, 12 bit 2 signed-digit coefficients allocated with
the algorithm of \emph{Lim et al.} and 12-bit 2-signed-digit coefficients
allocated with the algorithm of \emph{Lim et al.} and optimised by
SOCP-relaxation search. The phase response shown is adjusted for the nominal
delay and normalised to $\pi$ radians. 
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_kuv_min_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the FRM Schur one-multiplier lattice 
Hilbert filter SOCP-relaxation example with 12 bit 2 signed digit coefficients]
{Comparison of the cost and number of 12-bit shift-and-add operations required
  to implement the coefficient multiplications for an FRM Hilbert filter with
  with 12 bit integer coefficients found by allocating an average of 2
  signed-digits to each coefficient using the heuristic of \emph{Lim et al.}
  and performing SOCP-relaxation search. The FRM model filter is
  implemented as a Schur one-multiplier all-pass lattice filter.}
\label{tab:socp-relax-FRM-hilbert-schurOneMAPlattice-12-nbits-cost-summary}
\end{table}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_kuv_minAsq}}
\caption{Comparison of the amplitude responses for an FRM Hilbert filter with
  with 12 bit integer coefficients found by allocating an average of 2
  signed-digits to each coefficient using the heuristic of \emph{Lim et al.}
  and performing SOCP-relaxation search. The FRM model filter is
  implemented as a Schur one-multiplier all-pass lattice filter.}
\label{fig:socp-relax-FRM-hilbert-schurOneMAPlattice-12-nbits-amplitude-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_kuv_minP}}
\caption{Comparison of the phase responses for an FRM Hilbert filter with
  with 12 bit integer coefficients found by allocating an average of 2
  signed-digits to each coefficient using the heuristic of \emph{Lim et al.}
  and performing SOCP-relaxation search. The phase response shown is adjusted
  for the nominal delay and normalised to $\pi$ radians. The FRM model
  filter is implemented as a Schur one-multiplier all-pass lattice filter.}
\label{fig:socp-relax-FRM-hilbert-schurOneMAPlattice-12-nbits-phase-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurOneMAPlattice_frm_hilbert_12_nbits_test_kuv_minT}}
\caption{Comparison of the delay responses for an FRM Hilbert filter with
  with 12 bit integer coefficients found by allocating an average of 2
  signed-digits to each coefficient using the heuristic of \emph{Lim et al.}
  and performing SOCP-relaxation search. The FRM model filter is
  implemented as a Schur one-multiplier all-pass lattice filter.}
\label{fig:socp-relax-FRM-hilbert-schurOneMAPlattice-12-nbits-delay-response}
\end{figure}

\clearpage
\section{\label{sec:SOCP-relaxation-search-signed-digit-coefficients-FIR_Hilbert}SOCP-relaxation search for the signed-digit coefficients of a direct-form FIR Hilbert filter}
The Octave script \emph{socp\_relaxation\_directFIRhilbert\_12\_nbits\_test.m}
performs successive SOCP relaxations to optimise the response of a direct-form
FIR Hilbert filter having a response similar to that of
Section~\ref{sec:SOCP-relaxation-search-signed-digit-coefficients-FRM-hilbert}.
The filter specification is:
\begin{small}
\verbatiminput{socp_relaxation_directFIRhilbert_12_nbits_test_spec.m}
\end{small} 
The filter has $M$ distinct non-zero coefficients, the filter polynomial order
is $4M-2$, the filter group-delay is $2M-1$ samples. The filter coefficients are
truncated to $12$ bits allocated with an average of $2$ signed-digits by the
heuristic of \emph{Ito et al.}, as shown in
Section~\ref{sec:Ito-allocation-signed-digits}. At each coefficient relaxation 
step the script finds the upper and lower signed-digit approximations to the
current set of active coefficients and selects the coefficient with the
largest difference in those approximations. The corresponding bounds are set
in the bounds for that coefficient passed to the Octave function
\emph{directFIRhilbert\_socp\_mmse}. The results of this MMSE optimisation
are then passed to \emph{directFIRhilbert\_slb} for PCLS optimisation. The
resulting PCLS coefficient value selects the closer of the upper or lower
signed-digit values as the final choice for that coefficient. The truncation
of the last coefficient is, by necessity, not PCLS optimised so the final
set of coefficients may not meet the PCLS specifications.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_directFIRhilbert_12_nbits_test_hM_allocsd_digits.m}
\end{small}
The 12-bit signed-digit filter coefficients found by the heuristic of 
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{socp_relaxation_directFIRhilbert_12_nbits_test_hM0_Ito_sd_coef.m}
\end{small}

The 12-bit signed-digit filter coefficients found by the SOCP-relaxation
search are:
\begin{small}
\verbatiminput{socp_relaxation_directFIRhilbert_12_nbits_test_hM_min_coef.m}
\end{small}

Figure~\ref{fig:socp-relax-direct-FIR-hilbert-12-nbits-response}
compares the amplitude responses of the filter with floating-point coefficients,
12-bit 2-signed-digit coefficients, 12-bit signed-digit coefficients allocated
with the algorithm of \emph{Ito et al.} and 12-bit signed-digit coefficients
allocated with the algorithm of \emph{Ito et al.} and SOCP-relaxation search.
Table~\ref{tab:socp-relax-direct-FIR-hilbert-12-nbits-cost}
compares the cost, the number of signed-digits and the number of $12$-bit
shift-and-add operations required to implement the coefficient multiplications
found by the signed-digit allocation heuristic of \emph{Ito et al.} with
SOCP-relaxation search. The FIR filter structure requires an extra $80$
additions.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_directFIRhilbert_12_nbits_test_response}}
\caption{Comparison of the amplitude responses for a
  direct-form FIR Hilbert filter with 12-bit integer coefficients
  found by allocating an average of 2-signed-digits to each coefficient using
  the heuristic of \emph{Ito et al.} and performing SOCP-relaxation
  search.}
\label{fig:socp-relax-direct-FIR-hilbert-12-nbits-response}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{socp_relaxation_directFIRhilbert_12_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the direct-form FIR Hilbert filter
  SOCP-relaxation example with 12-bit coefficients]
{Comparison of the cost and number of 12-bit shift-and-add operations required 
  to implement the coefficient multiplications for a direct-form FIR Hilbert
  filter with 12-bit integer coefficients found by allocating 
  an average of 2-signed-digits to each coefficient using the heuristic of 
  \emph{Ito et al.} and performing SOCP-relaxation search.}
\label{tab:socp-relax-direct-FIR-hilbert-12-nbits-cost}
\end{table}
\clearpage
\section{\label{sec:SOCP-relaxation-search-signed-digit-coefficients-bandpass-lattice-FIR}SOCP-relaxation search for the signed-digit coefficients of a lattice FIR filter}
The Gaussian function in the continuous angular frequency domain is:
\begin{align*}
  G\left(\omega\right)&=e^{-\left(\frac{\omega}{\alpha}\right)^{2}}
\end{align*}
Appendix~\ref{app:Fourier-transform-of-the-Gaussian-function} shows that
the corresponding time domain Fourier transform pair function is:
\begin{align*}
  g\left(t\right)&=\frac{\alpha}{2\sqrt{\pi}}e^{-\left(\frac{t\alpha}{2}\right)^{2}}
\end{align*}
If the symbol interval is $T_{S}$ then the normalised one-sided half-power
bandwidth-symbol time product, $BT_{S}$, is given by:
\begin{align*}
  e^{-\left(\frac{2\pi{}BT_{S}}{T_{S}\alpha}\right)^{2}}&=\frac{1}{\sqrt{2}}
\end{align*}
so:                                                          
\begin{align*}
  \alpha&=\frac{2\pi{}BT_{S}}{T_{S}}\sqrt{\frac{2}{\ln{}2}}
\end{align*}
Assume that the Gaussian filter has a length of $N_{S}$ symbols and an
over-sampling rate of $R$ samples per symbol. After shifting and truncation
the sampled filter coefficients of an odd length filter are:
\begin{align*}
  g\left(k\right)
  &=\frac{T_{S}}{R}\frac{1}{2\sqrt{\pi}}
    \frac{2\pi{}BT_{S}}{T_{S}}\sqrt{\frac{2}{\ln{}2}}
    e^{-\left[\left(\frac{\pi{}BT_{S}}{T_{S}}\sqrt{\frac{2}{\ln{}2}}\right)
    \frac{T_{S}}{R}\left(k-\frac{RN_{S}}{2}\right)\right]^{2}}
\end{align*}
where $k=0,\ldots{},RN_{S}$.  Assume that the modulation scheme uses
$BT_{S}=0.3$, that the Gaussian filter has a length of $N_{S}=4$ symbols and
that the over-sampling rate is $R=8$ samples per symbol. The filter
coefficients are:
\begin{small}
\verbatiminput{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_g0_coef.m}
\end{small} 
Figure~\ref{fig:socp-relaxation-gaussian-FIR-lattice-16-nbits-g0-impulse}
shows the impulse response of the filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_g0_impulse}}
\caption{Impulse response of a sampled Gaussian filter with half-power
  bandwidth-symbol-interval product $BT_{S}=0.3$,length $N_{S}=4$ symbols and
  $R=8$ samples per symbol}
\label{fig:socp-relaxation-gaussian-FIR-lattice-16-nbits-g0-impulse}
\end{figure}

The Octave script
\emph{socp\_relaxation\_schurFIRlattice\_gaussian\_16\_nbits\_test.m} performs
SOCP relaxation to find the 16-bit coefficients of the Gaussian filter
implemented as a complementary FIR lattice. (See
Appendix~\ref{app:Low-passband-sensitivity-FIR-digital-filters} for a
description of the complementary FIR lattice filter). The response of this
filter is compared with filters using 16-bit 3-signed-digit coefficients of
the direct form implementation and the 16-bit signed-digit coefficients of the
lattice implementation. The coefficients of the lattice filters are allocated
an average of 3-signed-digits with the algorithm of \emph{Lim et al.} shown in
Section~\ref{sec:Ito-allocation-signed-digits}.  The script does not implement
signed-digit allocation or SOCP-relaxation optimisation of the direct-form
coefficients. The filter specification is:
\begin{small}
\verbatiminput{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_spec.m}
\end{small}
The amplitude response in the ``pass-band'' (up to \emph{dBas}) found by
SOCP-relaxation is required to be within \emph{$\pm{}\frac{dBap}{2}$} of the
floating-point response and below \emph{dBasu} in the ``stop-band''.

The 16-bit 3-signed-digit direct form coefficients are:
\begin{small}
\verbatiminput{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_g0_sd_coef.m}
\end{small}
The floating-point lattice coefficients are:
\begin{small}
\verbatiminput{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_k0_coef.m}
\verbatiminput{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_khat0_coef.m}
\end{small}
The 16-bit lattice coefficients with an average of 3-signed-digits each are:
\begin{small}
\verbatiminput{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_k0_sd_coef.m}
\verbatiminput{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_khat0_sd_coef.m}
\end{small}
The 16-bit lattice coefficients with an average of 3-signed-digits optimised
by SOCP-relaxation are:
\begin{small}
\verbatiminput{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_k_min_coef.m}
\verbatiminput{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_khat_min_coef.m}
\end{small}

Table~\ref{tab:socp-relaxation-gaussian-FIR-lattice-16-nbits-cost-comparison}
compares the total number of signed-digits and 16-bit shift-and-add operations
required to implement the coefficient multiplications. The values for the
direct form filter assume that the implementation makes use of the symmetry
of the impulse response, in which case the direct form filter has $17$
multiplier scompared to the $130$ required by the lattice
implementation (though a number of the latter multipliers are $1$ or $0$).
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lcc}  \\ \toprule
&Signed-digits&Shift-and-adds\\ \midrule
\input{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_kkhat_min_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Comparison of signed-digit and shift-and-add requirements for a
direct form and a complementary FIR lattice Gaussian filter with 16 bit,
3-signed-digit coefficients] {Comparison of the number of 16-bit shift-and-add
  operations required to implement the coefficient multiplications for a
  direct form and a complementary FIR lattice implementation of a Gaussian
  filter with 16-bit 3-signed-digit coefficients.}
\label{tab:socp-relaxation-gaussian-FIR-lattice-16-nbits-cost-comparison}
\end{table}

Figure~\ref{fig:socp-relaxation-gaussian-FIR-lattice-16-nbits-min-response}
compares the overall amplitude response of the filter for floating-point
direct-form coefficients, direct-form coefficients implemented with 16-bit
3-signed-digits, complementary FIR lattice coefficients implemented with 16-bit,
3-signed-digits having an average of 3-signed-digits per coefficient allocated
with the algorithm of \emph{Lim et al.} and lattice coefficients optimised
with SOCP-relaxation.
Figure~\ref{fig:socp-relaxation-gaussian-FIR-lattice-16-nbits-min-pass-response}
compares the amplitude responses in the ``pass-band'' (up to \emph{dBas}).
Figure~\ref{fig:socp-relaxation-gaussian-FIR-lattice-16-nbits-min-delay-response}
compares the group delay responses in the ``pass-band'' (up to \emph{dBas}).
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_kkhat_min}}
\caption{Comparison of the amplitude response of the FIR Gaussian filter for
  floating-point direct-form coefficients, 16-bit 3-signed-digit direct-form
  coefficients, 16-bit coefficients with an average of 3-signed-digits per
  coefficient and 16-bit coefficients with an average of 3-signed-digits per
  coefficient optimised by SOCP-relaxation.}
\label{fig:socp-relaxation-gaussian-FIR-lattice-16-nbits-min-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_kkhat_min_pass}}
\caption{Comparison of the pass-band amplitude
  response of the FIR Gaussian filter for 16-bit coefficients with an average
  of 3-signed-digits per coefficient and 16-bit coefficients with an average
  of 3-signed-digits per coefficient optimised by SOCP-relaxation.}
\label{fig:socp-relaxation-gaussian-FIR-lattice-16-nbits-min-pass-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{socp_relaxation_schurFIRlattice_gaussian_16_nbits_test_kkhat_min_delay}}
\caption{Comparison of the ``pass-band'' (up to \emph{dBas}) group-delay
  response of the FIR Gaussian filter for 16-bit coefficients with an average
  of 3-signed-digits per coefficient and 16-bit coefficients with an average
  of 3-signed-digits per coefficient optimised by SOCP-relaxation.}
\label{fig:socp-relaxation-gaussian-FIR-lattice-16-nbits-min-delay-response}
\end{figure}
\clearpage

\chapter{\label{sec:POP-search-for-integer-signed-digit-filter-coefficients}POP programming search for integer and signed-digit filter coefficients}
\emph{Lu}~\cite{Lu_DigitalFilterGlobalPolynomialOptimization} and \emph{Lu} and 
\emph{Hinamoto}~\cite{LuHinamoto_FIRDiscreteCoefficientsPolynomialProgramming} 
point out that the integer programming optimisation of the truncated filter 
coefficients shown in 
Equation~\ref{eqn:integer-programming-coefficient-truncation} can be rewritten 
as a \emph{polynomial optimisation problem} (POP) in SOCP form as:
\begin{align*}
\textbf{minimise}\quad&
\mathcal{E}\left(\boldsymbol{x_{k}}\right)+
\nabla_{x}\mathcal{E}\left(\boldsymbol{x_{k}}\right)^{\top}\Delta\boldsymbol{x}+
\frac{1}{2}\Delta\boldsymbol{x}^{\top}
\nabla^{2}_{x}\mathcal{E}\left(\boldsymbol{x_{k}}\right)\Delta\boldsymbol{x} \\
\textbf{subject to}\quad&
\left(\boldsymbol{x_{k}}+\Delta\boldsymbol{x}-\boldsymbol{x}_{u}\right)^{\top}
\left(\boldsymbol{x_{k}}+\Delta\boldsymbol{x}-\boldsymbol{x}_{l}\right)
=\boldsymbol{0}
\end{align*}
where $\Delta\boldsymbol{x}$ is the coefficient update vector, $\mathcal{E}$ 
is the weighted response error at $\boldsymbol{x_{k}}$ and $\boldsymbol{x}_{u}$
and $\boldsymbol{x}_{l}$ are the upper and lower bounds on the truncated 
coefficients, $\boldsymbol{x_{k}}+\Delta\boldsymbol{x}$. 

\emph{Lasserre}~\cite{Lasserre_GlobalOptimizationPolynomialsMoments} and 
\emph{Waki et al.}~\cite{Waki_SumsSquaresSDPRelaxationsPolynomialOptSparsity}
show that polynomial optimisation can be reduced to the solution of ``an often 
finite sequence of convex linear matrix inequality problems''. 
\emph{Waki et al.} have written \emph{SparsePOP}~\cite{SparsePOP}, a ``Matlab 
implementation of sparse semidefinite programming (SDP) relaxation for 
polynomial optimization problems''. SparsePOP runs under Octave with minor 
modifications. SparsePOP converts the POP problem to a larger SOCP problem that
is solved by SeDuMi.

\section{\label{sec:POP-relaxation-search-signed-digit-coefficients-bandpass}POP relaxation search for the signed-digit coefficients of a one-multiplier lattice bandpass filter}
The Octave script
\emph{pop\_relaxation\_schurOneMlattice\_bandpass\_10\_nbits\_test.m}
performs SparsePOP optimisation of the truncated coefficients of the SQP
optimised band-pass Schur one-multiplier lattice filter described in
Section~\ref{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-SQP}. The
filter specification is:
\begin{small}
\verbatiminput{pop_relaxation_schurOneMlattice_bandpass_10_nbits_test_spec.m}
\end{small} 

The filter coefficients are truncated to $10$ bits and an average of $3$
signed-digits allocated by the heuristic of \emph{Ito et al.}. At each
coefficient relaxation step the script finds the upper and lower signed-digit
approximations to the current set of active coefficients, selects those
coefficients for which the floating-point values are are closer than a threshold
value to those
bounds~\cite[Section II.C]{Lu_FIRDiscreteCoefficientsConvexRelaxation}. The
Octave function \emph{schurOneMlattice\_pop\_socp\_mmse.m} calls \emph{SparsePOP}
with a second order polynomial equality constraint requiring that the previously
selected coefficients be equal to the corresponding signed-digit coefficient
upper or lower bound. The remaining active coefficients are allowed to vary
within the corresponding initial upper and lower bounds.

The Schur lattice filter coefficients found by the SparsePOP relaxation search
are:
\begin{small}
\verbatiminput{pop_relaxation_schurOneMlattice_bandpass_10_nbits_test_k_min_coef.m}
\verbatiminput{pop_relaxation_schurOneMlattice_bandpass_10_nbits_test_c_min_coef.m}
\end{small}

Table~\ref{tab:pop-relax-bandpass-OneM-lattice-SparsePOP-10-nbits-cost-summary}
compares the cost, the number of signed-digits and the number of $10$ bit
shift-and-add operations required to implement the coefficient multiplications.
Figure~\ref{fig:pop-relax-bandpass-OneM-lattice-SparsePOP-10-nbits-pass-response}
compares the pass-band responses of the filter with floating-point coefficients
and with $10$ bit $3$ signed-digit coefficients optimised with POP-relaxation
search. Similarly,
Figure~\ref{fig:pop-relax-bandpass-OneM-lattice-SparsePOP-10-nbits-stop-response}
shows the filter stop-band response and
Figure~\ref{fig:pop-relax-bandpass-OneM-lattice-SparsePOP-10-nbits-delay-response}
shows the filter pass-band group delay response.

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lccc}  \\ \toprule
& Cost&Signed-digits&Shift-and-adds\\ \midrule
\input{pop_relaxation_schurOneMlattice_bandpass_10_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the Schur one-multiplier lattice bandpass
filter POP-relaxation example with 10-bit 3 signed digit coefficients]
{Comparison of the cost and number of 10 bit shift-and-add operations required
  to implement the coefficient multiplications for a Schur one-multiplier
  lattice bandpass filter with 10 bit 3 signed-digit integer coefficients.}
\label{tab:pop-relax-bandpass-OneM-lattice-SparsePOP-10-nbits-cost-summary}
\end{table}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{pop_relaxation_schurOneMlattice_bandpass_10_nbits_test_pass}}
\caption{Comparison of the pass-band amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 10 bit 3 signed-digit coefficients
  optimised with POP-relaxation search.}
\label{fig:pop-relax-bandpass-OneM-lattice-SparsePOP-10-nbits-pass-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{pop_relaxation_schurOneMlattice_bandpass_10_nbits_test_stop}}
\caption{Comparison of the stop-band amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 10 bit 3 signed-digit coefficients
  optimised with POP-relaxation search.}
\label{fig:pop-relax-bandpass-OneM-lattice-SparsePOP-10-nbits-stop-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{pop_relaxation_schurOneMlattice_bandpass_10_nbits_test_delay}}
\caption{Comparison of the pass-band group delay responses for a Schur
  one-multiplier lattice bandpass filter with 10 bit 3 signed-digit coefficients
  optimised with POP-relaxation search.}
\label{fig:pop-relax-bandpass-OneM-lattice-SparsePOP-10-nbits-delay-response}
\end{figure}
\clearpage
\section{\label{sec:POP-relaxation-search-signed-digit-coefficients-bandpass-hilbert}POP relaxation search for the signed-digit coefficients of a one-multiplier lattice bandpass Hilbert filter}
The Octave script
\emph{pop\_relaxation\_schurOneMlattice\_bandpass\_hilbert\_13\_nbits\_test.m}
performs SparsePOP optimisation of the truncated coefficients of the SOCP
optimised band-pass Hilbert Schur one-multiplier lattice filter described in
Section~\ref{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-hilbert-SOCP}.
The filter specification is:
\begin{small}
\verbatiminput{pop_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_spec.m}
\end{small} 

The filter coefficients are truncated to $13$ bits and an average of $4$
signed-digits allocated by the heuristic of \emph{Ito et al.}. At each
coefficient relaxation
step the script finds the upper and lower signed-digit approximations to the
current set of active coefficients, selects those coefficients for which the
floating-point values are are closer than a threshold value to those
bounds~\cite[Section II.C]{Lu_FIRDiscreteCoefficientsConvexRelaxation}. The
Octave function \emph{schurOneMlattice\_pop\_socp\_mmse.m} calls \emph{SparsePOP}
with a second order polynomial equality constraint requiring that the previously
selected coefficients be equal to the corresponding signed-digit coefficient
upper or lower bound. The remaining active coefficients are allowed to vary
within the corresponding initial upper and lower bounds.

The signed-digits allocated by the heuristic of \emph{Ito et al.} are:
\begin{small}
\verbatiminput{pop_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_k_allocsd_digits.m}
\verbatiminput{pop_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_c_allocsd_digits.m}
\end{small}

The Schur lattice filter coefficients found by the SparsePOP relaxation search
are:
\begin{small}
\verbatiminput{pop_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_k_sd_min_coef.m}
\verbatiminput{pop_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_c_sd_min_coef.m}
\end{small}

The corresponding transfer function polynomial coefficients are:
\begin{small}
\verbatiminput{pop_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_N_sd_min_coef.m}
\verbatiminput{pop_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_D_sd_min_coef.m}
\end{small}

Table~\ref{tab:pop-relax-bandpass-hilbert-OneM-lattice-13-nbits-cost}
compares the cost, the number of signed-digits and the number of $13$ bit
shift-and-add operations required to implement the coefficient multiplications.
Figure~\ref{fig:pop-relax-bandpass-hilbert-OneM-lattice-13-nbits-pass}
compares the pass-band responses of the filter with floating-point coefficients
and with $13$ bit $4$ signed-digit coefficients optimised with POP-relaxation
search. Similarly,
Figure~\ref{fig:pop-relax-bandpass-hilbert-OneM-lattice-13-nbits-stop}
shows the filter stop-band amplitude response,
Figure~\ref{fig:pop-relax-bandpass-hilbert-OneM-lattice-13-nbits-phase}
shows the filter pass-band phase response and
Figure~\ref{fig:pop-relax-bandpass-hilbert-OneM-lattice-13-nbits-delay}
shows the filter pass-band group delay response.

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lcccc}  \\ \toprule
& Cost&Stop-band response(dB) & Signed-digits & Shift-and-adds\\ \midrule
\input{pop_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the Schur one-multiplier lattice bandpass
Hilbert filter POP-relaxation example with 13-bit 4 signed digit coefficients]
{Comparison of the cost and number of 13 bit shift-and-add operations required
  to implement the coefficient multiplications for a Schur one-multiplier
  lattice bandpass Hilbert filter with 13 bit 4 signed-digit integer
  coefficients.}
\label{tab:pop-relax-bandpass-hilbert-OneM-lattice-13-nbits-cost}
\end{table}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{pop_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_pass}}
\caption{Comparison of the pass-band amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 13 bit 4 signed-digit coefficients
  optimised with POP-relaxation search.}
\label{fig:pop-relax-bandpass-hilbert-OneM-lattice-13-nbits-pass}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{pop_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_stop}}
\caption{Comparison of the stop-band amplitude responses for a Schur
  one-multiplier lattice bandpass Hilbert filter with 13 bit 4 signed-digit
  coefficients optimised with POP-relaxation search.}
\label{fig:pop-relax-bandpass-hilbert-OneM-lattice-13-nbits-stop}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{pop_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_phase}}
\caption{Comparison of the pass-band phase responses for a Schur
  one-multiplier lattice bandpass Hilbert filter with 13 bit 4 signed-digit
  coefficients optimised with POP-relaxation search.}
\label{fig:pop-relax-bandpass-hilbert-OneM-lattice-13-nbits-phase}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{pop_relaxation_schurOneMlattice_bandpass_hilbert_13_nbits_test_delay}}
\caption{Comparison of the pass-band group delay responses for a Schur
  one-multiplier lattice bandpass Hilbert filter with 13 bit 4 signed-digit
  coefficients optimised with POP-relaxation search.}
\label{fig:pop-relax-bandpass-hilbert-OneM-lattice-13-nbits-delay}
\end{figure}
\clearpage
\section{\label{sec:POP-relaxation-search-signed-digit-coefficients-R2-lowpass-differentiator}POP-relaxation search for the signed-digit
  coefficients of a one-multiplier lattice R=2 low-pass differentiator IIR
  filter}
The Octave script 
\emph{pop\_relaxation\_schurOneMlattice\_lowpass\_differentiator\_R2\_12\_nbits\_test.m}
performs successive POP relaxations to optimise the response of an
implementation of the low-pass differentiator filter shown in
Section~\ref{sec:SOCP-Schur-OneM-R2-lowpass-differentiator} as the series
combination of $1-z^{-1}$ and a Schur one-multiplier lattice correction filter
having denominator polynomial coefficients only in $z^{-2}$ with $12$-bit
coefficients each having an average of $3$ signed-digits allocated by the
heuristic of \emph{Ito et al.} and found by POP-relaxation search.
The filter specification is:  
\begin{small}
\verbatiminput{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_spec.m}
\end{small} 
The filter coefficients are truncated to $12$ bits allocated with an average
of $3$ signed-digits allocated by the heuristic of \emph{Ito et al.} as shown in
Section~\ref{sec:Ito-allocation-signed-digits}.
At each coefficient relaxation step the script finds the upper and lower
signed-digit approximations to the current set of active coefficients, selects
those coefficients for which the floating-point values are are closer than a
threshold value to those
bounds~\cite[Section II.C]{Lu_FIRDiscreteCoefficientsConvexRelaxation}. The
Octave function \emph{schurOneMlattice\_slb} performs PCLS optimisation. The
Octave function \emph{schurOneMlattice\_pop\_socp\_mmse.m} calls \emph{SparsePOP}
with a second order polynomial equality constraint requiring that the previously
selected coefficients be equal to the corresponding signed-digit coefficient
upper or lower bound. The remaining active coefficients are allowed to vary
within the corresponding initial upper and lower bounds.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_k_allocsd_digits.m}
\verbatiminput{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_c_allocsd_digits.m}
\end{small}
\begin{comment}
The signed-digit filter coefficients of the Schur one-multiplier lattice
correction filter with the number of digits allocated by the algorithm of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_k0_sd_Ito_coef.m}
\verbatiminput{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_c0_sd_Ito_coef.m}
\end{small}
\end{comment}
The signed-digit filter coefficients of the Schur one-multiplier lattice
correction filter found by the POP-relaxation search are:
\begin{small}
\verbatiminput{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_k_sd_min_coef.m}
\verbatiminput{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_c_sd_min_coef.m}
\end{small}
The corresponding coefficients of the correction filter transfer function
polynomials are:
\begin{small}
\verbatiminput{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_N_sd_min_coef.m}
\verbatiminput{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_D_sd_min_coef.m}
\end{small}

Figure~\ref{fig:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-pass-error}
shows the pass-band amplitude error compared to a desired response of
$\frac{\omega}{2}$ for exact coefficients, $12$-bit $3$-signed-digit
coefficients, coefficient with an average of $12$-bit $3$-signed-digits
allocated with the heuristic of \emph{Ito et al.} and coefficients found
by POP-relaxation search.
Similarly,
Figure~\ref{fig:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-stop}
shows the stop-band amplitude response, 
Figure~\ref{fig:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-phase}
shows the pass-band phase response, adjusted for the nominal delay, and
Figure~\ref{fig:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-delay}
shows the pass-band group delay response of the low-pass differentiator filter.
Figure~\ref{fig:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-corr}
shows the pass-band amplitude error of the correction filter.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_pass_error}}
\caption{Plot of the pass-band amplitude error response of a Schur
  one-multiplier lattice lowpass differentiator filter, having denominator
  polynomial coefficients only in $z^{-2}$, with $12$-bit integer coefficients
  found by allocating an average of $3$-signed-digits to each coefficient using
  the heuristic of \emph{Ito et al.} and performing POP-relaxation search.} 
\label{fig:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-pass-error}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_stop}}
\caption{Plot of the stop-band amplitude response of a Schur
  one-multiplier lattice lowpass differentiator filter, having denominator
  polynomial coefficients only in $z^{-2}$, with $12$-bit integer coefficients
  found by allocating an average of $3$-signed-digits to each coefficient using
  the heuristic of \emph{Ito et al.} and performing POP-relaxation search.} 
\label{fig:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-stop}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_phase}}
\caption{Plot of the pass-band phase response of a Schur
  one-multiplier lattice lowpass differentiator filter, having denominator
  polynomial coefficients only in $z^{-2}$, with $12$-bit signed-digit
  coefficients found by allocating an average of $3$-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  POP-relaxation search. The phase response shown is adjusted for the nominal
  delay.} 
\label{fig:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-phase}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_delay}}
\caption{Plot of the pass-band delay response of a Schur
  one-multiplier lattice lowpass differentiator filter, having denominator
  polynomial coefficients only in $z^{-2}$, with $12$-bit integer coefficients
  found by allocating an average of $3$-signed-digits to each coefficient using
  the heuristic of \emph{Ito et al.} and performing POP-relaxation search.} 
\label{fig:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-delay}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_correction_pass}}
\caption{Error in the pass-band squared-amplitude response of the
  correction filter of a Schur one-multiplier lattice low-pass differentiator
  filter with $12$ bit, $3$ signed-digit coefficients and denominator polynomial
  terms only in $z^{-2}$ found by performing POP-relaxation search.}
\label{fig:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-corr}
\end{figure}

Figure~\ref{fig:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-pz}
shows the pole-zero plot of the correction filter with coefficients found by
POP-relaxation search.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_pz}}
\caption{Pole-zero plot of the Schur one-multiplier lattice low-pass
  differentiator filter having denominator polynomial terms only in $z^{-2}$
  with $12$ bit, $3$ signed-digit coefficients found by performing
  POP-relaxation search.}
\label{fig:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-pz}
\end{figure}

Table~\ref{tab:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-cost}
compares the cost, the maximum stop-band response, the number of signed-digits
and the number of $12$-bit shift-and-add operations required to implement the
coefficient multiplications.

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lcccc}  \\ \toprule
& Cost & Stop-band response(dB) &Signed-digits&Shift-and-adds\\ \midrule
\input{pop_relaxation_schurOneMlattice_lowpass_differentiator_R2_12_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the $R=2$ Schur one-multiplier lattice 
lowpass differentiator filter POP-relaxation example with $12$-bit coefficients]
{Comparison of the cost and number of 12-bit shift-and-add operations required 
  to implement the coefficient multiplications for a Schur one-multiplier
  lattice low-pass differentiator correction filter having denominator
  polynomial coefficients only in $z^{-2}$, with $12$-bit integer
  coefficients found by allocating an average of $3$-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  POP-relaxation search.}
\label{tab:pop-relax-schurOneMlattice-lowpass-diff-R2-12-nbits-cost}
\end{table}
\clearpage
\chapter{\label{sec:Semi-definite-programming-search-for-integer-signed-digit-filter-coefficients}Semi-definite programming search for integer and signed-digit filter coefficients}
This section follows the method introduced by
\emph{Lu}~\cite{Lu_FIRDiscreteCoefficientsSemidefiniteRelaxation} and
\emph{Ito et al.}~\cite{Ito_FIRSP2CoefficientsRelaxationTriangleInequalities}
to find the signed-digit coefficients of a direct-form FIR filter. The
branch-and-bound algorithm of
Section~\ref{sec:branch-bound-search-signed-digit-coefficients} and the
successive coefficient relaxation methods of
Section~\ref{sec:successive-coefficient-relaxation-signed-digit-coefficients}
perform SQP or SOCP optimisation at each coefficient optimisation relaxation
step. Alternatively, the optimisation problem can be converted to an overall
\emph{integer programming} problem as follows: Given a set of floating-point
coefficients, $\boldsymbol{x}$, and signed-power-of-two upper and lower
bounds, $\boldsymbol{u}$ and $\boldsymbol{l}$, corresponding to stable filter
implementations such that $u_{i} \ge x_{i} \ge l_{i}$ for each of the $N$
components of $\boldsymbol{x}$, define
\begin{align*}
\hat{\boldsymbol{x}}=\frac{\left(\boldsymbol{u}+\boldsymbol{l}\right)}{2} \\
\boldsymbol{\delta}=\frac{\left(\boldsymbol{u}-\boldsymbol{l}\right)}{2}
\end{align*}
Then $u_{i}=\hat{x}_{i}+y_{i}\delta_{i}$ if $y_{i}=1$ and
$l_{i}=\hat{x}_{i}+y_{i}\delta_{i}$ if $y_{i}=-1$. Define the filter
coefficient vector as
$\boldsymbol{x}=\hat{\boldsymbol{x}}+\boldsymbol{y}\circ\boldsymbol{\delta}$,
where $\circ$ represents the element-by-element product, and approximate the
filter amplitude response by
$A\left(\omega\right)\approx\hat{A}\left(\omega\right)+A_{\delta}\left(\omega\right)$\footnote{This is an equality for an FIR filter transfer function.}.
The weighted mean-squared-error of the filter amplitude response is
approximately:
\begin{align*}
  \mathcal{E} &\approx \frac{1}{\pi}\int_{0}^{\pi}W\left(\omega\right)
                \left[\hat{A}\left(\omega\right)+ A_{\delta}\left(\omega\right)-
                A_{d}\left(\omega\right)\right]^{2}d\omega
\end{align*}

The weighted mean-squared-error of the amplitude response,
$\mathcal{E}$, of an IIR filter with signed-digit coefficients,
$\hat{\boldsymbol{x}}+\left(\boldsymbol{y}\circ\boldsymbol{\delta}\right)$, is
approximately:
\begin{align}
\label{eqn:integer-programming-coefficient-truncation}
\mathcal{E} &\approx
    \mathcal{E}\left(\hat{\boldsymbol{x}}\right)+
    \nabla_{x}\mathcal{E}\left(\hat{\boldsymbol{x}}\right)^{\top}
    \left(\boldsymbol{y}\circ\boldsymbol{\delta}\right) + 
    \frac{1}{2}\left(\boldsymbol{y}\circ\boldsymbol{\delta}\right)^{\top}
    \nabla_{x}^{2}\mathcal{E}\left(\hat{\boldsymbol{x}}\right)
    \left(\boldsymbol{y}\circ\boldsymbol{\delta}\right)
\end{align}

If $\boldsymbol{Y}=\boldsymbol{y}\boldsymbol{y}^{\top}$ and
$\boldsymbol{\Delta}=\boldsymbol{\delta}\boldsymbol{\delta}^{\top}$, then the
mean-squared-error can be expressed in the form\footnote{The \emph{trace} of
a matrix is defined in Appendix~\ref{app:Linear-algebra-trace-of-matrix}.}:
\begin{align*}
  \mathcal{E}&\approx
               \frac{1}{2}\mathtrace\left(
               \left(\boldsymbol{Q}\circ\boldsymbol{\Delta}\right)
               \boldsymbol{Y}\right)+
          \left(\boldsymbol{q}\circ\boldsymbol{\delta}\right)^{\top}\boldsymbol{y}
               +\text{const}
\end{align*}

The approximate minimum mean-squared-error is found by the integer programming
optimisation:
\begin{align*}
  \begin{split}
  \textbf{minimise}\quad&
  \mathtrace\left(\hat{\boldsymbol{Q}}\boldsymbol{Y}\right)+
  2\hat{\boldsymbol{q}}^{\top}\boldsymbol{y}\\
  \textbf{subject to}\quad& y_{i}\in \left\{-1,1\right\}
  \end{split}
\end{align*}
The integer programming constraints are equivalent to:
\begin{align*}
  Y_{ii}=1 \text{,}\quad
  \mathrank\left[\begin{array}{cc}
                     \boldsymbol{Y} & \boldsymbol{y} \\
                     \boldsymbol{y}^{\top} & 1\\
                   \end{array}\right]=1 \text{,}\quad
  \left[\begin{array}{cc}
          \boldsymbol{Y} & \boldsymbol{y} \\
          \boldsymbol{y}^{\top} & 1\\
        \end{array}\right]\succeq \boldsymbol{0}
\end{align*}
where $\succeq 0$ means that the array is positive semi-definite.
\emph{Lu}~\cite[Section 2.3]{Lu_FIRDiscreteCoefficientsSemidefiniteRelaxation}
suggests a relaxation of the integer programming problem by discarding the rank
constraint. The resulting constraints are simplified by defining a symmetric
matrix $\hat{\boldsymbol{Y}}$ with ones on the diagonal:
\begin{align*}
  \begin{split}
  \textbf{minimise}\quad
  & \mathtrace\left(\hat{\boldsymbol{Q}}\hat{\boldsymbol{Y}}\right)+
  2\hat{\boldsymbol{q}}^{\top}\boldsymbol{y}\\
  \textbf{subject to}\quad&
  \bar{\boldsymbol{Y}}=
  \left[\begin{array}{cc}
          \hat{\boldsymbol{Y}} & \boldsymbol{y} \\
          \boldsymbol{y}^{\top} & 1
        \end{array}\right]\succeq \boldsymbol{0}
  \end{split}
\end{align*}
Define a length $P=\frac{M\left(M-1\right)}{2}+M$ augmented variable,
$\bar{\boldsymbol{y}}$, consisting of the $M$ elements of $\boldsymbol{y}$
and the $\frac{M\left(M-1\right)}{2}$ distinct off-diagonal elements of
$\hat{\boldsymbol{Y}}$. The relaxed optimisation problem becomes:
\begin{align*}
  \begin{split}
  \textbf{minimise}\quad & \boldsymbol{c}^{\top}\bar{\boldsymbol{y}} \\
  \textbf{subject to}\quad &
  \bar{\boldsymbol{Y}} \succeq \boldsymbol{0}
  \end{split}
\end{align*}

\emph{Murumatsu} and \emph{Suzuki}~\cite[Section 3.3]
{MurumatsuSuzuki_SecondOrderConeRelaxationMaxCut} and
\emph{Ito et al.}~\cite{Ito_FIRSP2CoefficientsRelaxationTriangleInequalities},
\cite[Equation 19]{Ito_FIRSP2CoefficientsLinearProgrammingTriangleInequalities}
add \emph{triangle inequality} constraints:
\begin{align}
  \begin{split}
  \phantom{-} y_{i} + y_{j} + \hat{Y}_{ij} \ge -1 \\
  \phantom{-} y_{i} - y_{j} - \hat{Y}_{ij} \ge -1 \\
           -  y_{i} - y_{j} + \hat{Y}_{ij} \ge -1 \\
           -  y_{i} + y_{j} - \hat{Y}_{ij} \ge -1
  \end{split}
  \label{eqn:triangle-inequality-yyY}
\end{align}
for $i<j$.

Also~\cite[Equation 20]
{Ito_FIRSP2CoefficientsLinearProgrammingTriangleInequalities}:
\begin{align}
  \begin{split}
  \phantom{-} \hat{Y}_{ij} + \hat{Y}_{ik} + \hat{Y}_{jk} \ge -1 \\
  \phantom{-} \hat{Y}_{ij} - \hat{Y}_{ik} - \hat{Y}_{jk} \ge -1 \\
           -  \hat{Y}_{ij} - \hat{Y}_{ik} + \hat{Y}_{jk} \ge -1 \\
           -  \hat{Y}_{ij} + \hat{Y}_{ik} - \hat{Y}_{jk} \ge -1
  \end{split}
  \label{eqn:triangle-inequality-YYY}
\end{align}
for $i<j<k$. In practice, I have found that
Equation~\ref{eqn:triangle-inequality-yyY} is sufficient.

\emph{Lu}~\cite[Section V]{Lu_SedumiRemarks} shows how to solve this
\emph{semidefinite programming} optimisation problem with the
\emph{SeDuMi}~\cite{Sturm_SeDuMi_GitHub} SOCP solver by representing it in the
form:
\begin{align*}
  \begin{split}
  \textbf{minimise}\quad & \boldsymbol{c}^{\top}\bar{\boldsymbol{y}} \\
  \textbf{subject to}\quad&\boldsymbol{A}\bar{\boldsymbol{y}}\ge\boldsymbol{b}\\
  & \bar{\boldsymbol{Y}}=\boldsymbol{F}_{0} +
  \bar{y}_{1}\boldsymbol{F}_{1}
  + \hdots + \bar{y}_{P}\boldsymbol{F}_{P} \succeq \boldsymbol{0}
  \end{split}
\end{align*}
where $P$ is the number of distinct components of $\bar{\boldsymbol{Y}}$, and
the $\boldsymbol{F}_{k}$ are the symmetric matrixes that select the two
off-diagonal elements of $\bar{\boldsymbol{Y}}$ corresponding to $\bar{y}_{k}$.
If the SDP solution is $\boldsymbol{y}^{\ast}$ and $\hat{\boldsymbol{Y}}^{\ast}$,
then $\text{sign}\left(\boldsymbol{y}^{\ast}\right)$ is a reasonable solution to
the original integer programming problem.
\emph{Lu}~\cite{Lu_FIRDiscreteCoefficientsSemidefiniteRelaxation} points out
that, given the singular-value decomposition
\begin{align*}
  Z^{\ast} =  \left[\begin{array}{cc}
          \hat{\boldsymbol{Y}}^{\ast}&\boldsymbol{y}^{\ast} \\
          \boldsymbol{y}^{\ast\top}  & 1
        \end{array}\right]=U\Sigma U^{\top}
\end{align*}
an alternative solution is $\text{sign}\left(u_{N+1,l}u_{1\hdots N,l}\right)$,
where $u_{1\hdots N,l}$ is the first column vector in $U$ that corresponds to
the largest singular value, $\sigma_{l}$. ``\emph{The motivation ... is that a
  perfect solution $\hat{\boldsymbol{Y}}^{\ast}$ ... would imply that matrix
  $Z^{\ast}$ has rank one, hence
  $\sigma_{l}u_{1\hdots N+1,l}u_{1\hdots N+1,l}^{\top}$ is the best rank-one
  approximation of $Z^{\ast}$ in the 2-norm sense.}''

\emph{Ito et al.}~\cite[Equation 23]
{Ito_FIRSP2CoefficientsLinearProgrammingTriangleInequalities} suggest the
following relaxation of the SDP problem to a linear programming (LP) problem:
\begin{align*}
  \begin{split}
    \textbf{minimise}\quad & 2\sum_{i<j}\hat{Q}_{ij}\hat{Y}_{ij} +
                             \sum_{i}\hat{Q}_{ii} +
                             2\hat{\boldsymbol{q}}^{\top}\boldsymbol{y} \\
    \textbf{subject to}\quad&\text{Equation~\ref{eqn:triangle-inequality-yyY}}\\
                            &\text{Equation~\ref{eqn:triangle-inequality-YYY}}\\
                            & -1 \le y_{i}\le 1
  \end{split}
\end{align*}

For successive coefficient optimisation, the components of the coefficient
vector may be either \emph{inactive} (possibly already optimised) or
\emph{active}. The \emph{active} coefficients may further divided into
those that are to be \emph{fixed} to a signed-digit value, corresponding to
the $\boldsymbol{y}$ above, and those that are \emph{not fixed} and are
optimised to a floating point value. In the latter case an additional term
is added to the objective function, as shown in
Chapter~\ref{sec:IIR-Design-Using-SOCP}.

\begin{comment}
\section{The \emph{maximum-cut} problem of graph theory}
\emph{Ito et al.}~\cite{Ito_FIRSP2CoefficientsRelaxationTriangleInequalities}
point out that optimisation of a filter response with integer
coefficients is equivalent to the \emph{weighted-maximum-cut} problem of graph
theory. \emph{Goemans} and
\emph{Williamson}~\cite{GoemansWilliamson_ImprovedApproximationMaximumCut}
describe a randomised approximation algorithm for the weighted-maximum-cut
problem, shown as Algorithm~\ref{alg:Maximum-cut}.

\begin{algorithm}[hbpt]
Given a uni-directed graph, $G$, with a set of $N$ vertexes, $V$, a set of 
edges, $E$, and non-negative weights $w_{ij}=w_{ji}$ on the edges 
$\left(ij\right)\in E$, the \emph{maximum cut} problem is that of finding the 
set of vertexes, $S$, that maximises the weight of the edges in the \emph{cut} 
$\left(S,\bar{S}\right)$; that is, the weight of the edges with one endpoint 
in $S$ and the  other in $\bar{S}$. The weight of the maximum cut, $W_{MC}$, 
is given by the integer quadratic program:
\begin{align*}
\textbf{maximise}\quad&\frac{1}{2}\sum_{i<j}w_{ij}\left(1-y_{i}y_{j}\right)\\
\textbf{subject to}\quad&y_{i}\in\left\{1,-1\right\} \quad\forall i \in V
\end{align*}
where $S=\left\{i|y_{i}=1\right\}$ and $\bar{S}=\left\{j|y_{j}=-1\right\}$.
This optimisation restricts $y_{i}$ to be a 1-dimensional vector with unit
Euclidean norm. The optimisation can be relaxed to a quadratic program by 
allowing the $y_{i}$ to be replaced by $N$-dimensional vectors
$\boldsymbol{v_{i}}$ lying on the $N$-dimensional unit sphere, $\mathcal{S}_{N}$:
\begin{align*}
\textbf{maximise}\quad&
\frac{1}{2}\sum_{i<j}w_{ij}\left(1-\boldsymbol{v}_{i}^{\top}\boldsymbol{v}_{j}\right)\\
\textbf{subject to}\quad&\boldsymbol{v}_{i}\in \mathcal{S}_{N}\quad\forall i \in V
\end{align*}
Given a set of solution vectors, $\boldsymbol{v}_{i}$, and a vector, 
$\boldsymbol{r}$, uniformly distributed on $\mathcal{S}_{N}$, set 
$S=\left\{i|\boldsymbol{v}_{i}^{\top}\boldsymbol{r}\ge 0\right\}$. 
The cut, $W$, defined by the random hyperplane with normal $\boldsymbol{r}$, 
has the expected weight $E[W]\ge\alpha W_{MC}$ where:
\begin{align*}
\alpha=\min_{0\le\theta\le\pi}\frac{2}{\pi}\frac{\theta}{1-\cos\theta} > 0.87856
\end{align*}
\caption{The maximum-cut algorithm of \emph{Goemans} and 
\emph{Williamson}~\cite{GoemansWilliamson_ImprovedApproximationMaximumCut}}
\label{alg:Maximum-cut}
\end{algorithm}
\end{comment}

\section{\label{sec:SDP-signed-digit-coefficients-direct-form-symmetricFIR}SDP optimisation of the signed-digit coefficients of a direct-form symmetric FIR filter}
Following Appendix~\ref{app:PCLS-design-non-symmetric-FIR-filters-SOCP},
the components of the amplitude responses of a direct-form symmetic FIR filter
with signed-digit coefficients are:
\begin{align*}
  \hat{A}\left(\omega\right)
  &=  \hat{x}_{M}+2\sum_{n=0}^{M-1}\hat{x}_{n}\cos\left(M-n\right)\omega\\
  A_{\delta}\left(\omega\right)
  &=  y_{M}\delta_{M}+2\sum_{n=0}^{M-1}y_{n}\delta_{n}\cos\left(M-n\right)\omega
\end{align*}
The Octave script 
\emph{sdp\_relaxation\_directFIRsymmetric\_bandpass\_10\_nbits\_test.m}
performs SDP optimisation of the response of a direct-form symmetric
band-pass FIR filter. The filter specification is:
\begin{small}
\verbatiminput{sdp_relaxation_directFIRsymmetric_bandpass_10_nbits_test_spec.m}
\end{small} 
The filter coefficients are truncated to $10$ bits allocated with an average
of $3$ signed-digits by the heuristic of \emph{Lim et al.} as shown in
Section~\ref{sec:Lim-allocation-signed-digits}. The Octave function
\emph{directFIRsymmetric\_sdp\_mmsePW} implements SDP optimisation with the
triangle inequalities of Equation~\ref{eqn:triangle-inequality-yyY}. The
resulting $\boldsymbol{y}$ values were all very close to $-1$ or $1$. Attempts
at PCLS optimisation with \emph{directFIRsymmetric\_slb} failed.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{sdp_relaxation_directFIRsymmetric_bandpass_10_nbits_test_hM_allocsd_digits.m}
\end{small}
The distinct direct-form symmetric FIR bandpass filter coefficients found by
the SDP optimisation with triangle inequalities are:
\begin{small}
\verbatiminput{sdp_relaxation_directFIRsymmetric_bandpass_10_nbits_test_hM1_sd_sdp_coef.m}
\end{small}

Figures~\ref{fig:sdp-direct-FIR-symmetric-bandpass-10-nbits-pass-amplitude}
and~\ref{fig:sdp-direct-FIR-symmetric-bandpass-10-nbits-stop-amplitude}
compare the pass-band and stop-band responses of the filter with floating-point
coefficients, 10-bit signed-digit coefficients, 10-bit signed-digit coefficients
allocated with the algorithm of \emph{Lim et al.} and 10-bit signed-digit
coefficients allocated with the algorithm of \emph{Lim et al.} and SDP
optimisation.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_directFIRsymmetric_bandpass_10_nbits_test_pass_amplitude}}
\caption{Comparison of the pass-band amplitude responses for a direct-form
  symmetric FIR bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SDP optimisation with
  triangle inequalities.}
\label{fig:sdp-direct-FIR-symmetric-bandpass-10-nbits-pass-amplitude}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_directFIRsymmetric_bandpass_10_nbits_test_stop_amplitude}}
\caption{Comparison of the stop-band amplitude responses for a direct-form
  symmetric FIR bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SDP optimisation with
  triangle inequalities.}
\label{fig:sdp-direct-FIR-symmetric-bandpass-10-nbits-stop-amplitude}
\end{figure}

Table~\ref{tab:sdp-direct-FIR-symmetric-bandpass-10-nbits-cost-summary}
compares the cost and the number of $10$ bit shift-and-add operations required
to implement the $16$ distinct coefficient multiplications found by the
signed-digit allocation heuristic of \emph{Lim et al.} with the
SDP optimisation and triangle inequalities.
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lcccc}  \\ \toprule
& Cost&Stop-band response(dB)&Signed-digits&Shift-and-adds\\ \midrule
\input{sdp_relaxation_directFIRsymmetric_bandpass_10_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the direct-form symmetric FIR bandpass
  filter SDP optimisation example with 10-bit coefficients]
  {Comparison of the cost, maximum stop-band response and number of
    10-bit shift-and-add operations required to implement the
    coefficient multiplications for a direct-form symmetric FIR bandpass
    filter with 10-bit integer coefficients found by allocating an
    average of 3-signed-digits to each coefficient using the heuristic
    of \emph{Lim et al.} and performing SDP optimisation with triangle
    inequalities.}
\label{tab:sdp-direct-FIR-symmetric-bandpass-10-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:SDP-signed-digit-coefficients-direct-form-HilbertFIR}SDP optimisation of the signed-digit coefficients of an FIR Hilbert filter}

The Octave script \emph{sdp\_relaxation\_directFIRhilbert\_12\_nbits\_test.m}
performs SDP optimisation of the response of a direct-form Hilbert FIR
filter. The filter specification is: 
\begin{small}
\verbatiminput{sdp_relaxation_directFIRhilbert_12_nbits_test_spec.m}
\end{small} 
The filter coefficients are truncated to $12$ bits allocated with an average
of $2$ signed-digits by the heuristic of \emph{Ito et al.} as shown in
Section~\ref{sec:Ito-allocation-signed-digits}. The Octave function
\emph{directFIRhilbert\_sdp\_mmsePW} implements SDP optimisation with the
triangle inequalities of Equation~\ref{eqn:triangle-inequality-yyY}. The
resulting $\boldsymbol{y}$ values were all very close to $-1$ or $1$.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{sdp_relaxation_directFIRhilbert_12_nbits_test_hM_allocsd_digits.m}
\end{small}
The distinct direct-form Hilbert FIR filter coefficients found by
signed-digit allocation with the heuristic of \emph{Ito et al.} are:
\begin{small}
\verbatiminput{sdp_relaxation_directFIRhilbert_12_nbits_test_hM1_sd_Ito_coef.m}
\end{small}
and by SDP optimisation with triangle inequalities are: 
\begin{small}
\verbatiminput{sdp_relaxation_directFIRhilbert_12_nbits_test_hM1_sd_sdp_coef.m}
\end{small}
The corresponding FIR filter is:
\begin{small}
\begin{verbatim}
h=[kron(hM1_sd_sdp,[1;0]);-flipud(kron(hM1_sd_sdp,[0;1]))](1:end-1);
\end{verbatim}
\end{small}

Figure~\ref{fig:sdp-direct-FIR-hilbert-12-nbits-response} compares the
responses of the filter with floating-point coefficients, 12-bit signed-digit
coefficients, 12-bit signed-digit coefficients allocated with the algorithm of
\emph{Ito et al.} and 12-bit signed-digit coefficients allocated with the
algorithm of \emph{Ito et al.} and SDP optimisation.
Table~\ref{tab:sdp-direct-FIR-hilbert-12-nbits-cost-summary} compares
the cost, maximum pass-band response error and the number of $12$ bit
shift-and-add operations required to implement the $40$ distinct coefficient
multiplications found by the signed-digit allocation heuristic of \emph{Ito et
 al.} and performing SDP optimisation with triangle inequalities.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_directFIRhilbert_12_nbits_test_response}}
\caption{Comparison of the amplitude responses for a direct-form Hilbert FIR
  filter with 12-bit integer coefficients found by allocating an average of
  2-signed-digits to each coefficient using the heuristic of \emph{Ito et al.}
  and performing SDP optimisation with triangle inequalities.}
\label{fig:sdp-direct-FIR-hilbert-12-nbits-response}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lcccc}  \\ \toprule
& Cost&Pass-band response&Signed-digits&Shift-and-adds\\ \midrule
\input{sdp_relaxation_directFIRhilbert_12_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the direct-form Hilbert FIR filter SDP
  optimisation example with 12-bit coefficients] {Comparison of the
  cost, maximum pass-band response error (in dB) and number of 12-bit
  shift-and-add operations required to implement the coefficient
  multiplications for a direct-form Hilbert FIR filter with 12-bit integer
  coefficients found by allocating an average of 2-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing SDP
  optimisation with triangle inequalities.}
\label{tab:sdp-direct-FIR-hilbert-12-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:SDP-signed-digit-coefficients-direct-form-Hilbert-bandpass-FIR}SDP optimisation of the signed-digit coefficients of an FIR Hilbert band-pass filter}

The Octave script
\emph{sdp\_relaxation\_directFIRhilbert\_bandpass\_12\_nbits\_test.m} 
performs SDP optimisation of the response of a direct-form Hilbert
band-pass FIR filter. The initial filter is that shown in
Appendix~\ref{app:Design-even-order-FIR-Hilbert-bandpass-filter}. The filter
specification is: 
\begin{small}
\verbatiminput{sdp_relaxation_directFIRhilbert_bandpass_12_nbits_test_spec.m}
\end{small} 
The group-delay of the filter is $2M-1$ samples. The filter coefficients are
truncated to $12$ bits allocated with an average of $2$ signed-digits by the
heuristic of \emph{Ito et al.} as shown in 
Section~\ref{sec:Ito-allocation-signed-digits}. The Octave function
\emph{directFIRhilbert\_sdp\_mmsePW} implements SDP optimisation with the
triangle inequalities of Equation~\ref{eqn:triangle-inequality-yyY}.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{sdp_relaxation_directFIRhilbert_bandpass_12_nbits_test_hM_allocsd_digits.m}
\end{small}
The distinct direct-form Hilbert band-pass FIR filter coefficients found by
signed-digit allocation with the heuristic of \emph{Ito et al.} are:
\begin{small}
\verbatiminput{sdp_relaxation_directFIRhilbert_bandpass_12_nbits_test_hM2_sd_Ito_coef.m}
\end{small}
and by SDP optimisation with triangle inequalities are:
\begin{small}
\verbatiminput{sdp_relaxation_directFIRhilbert_bandpass_12_nbits_test_hM2_sd_sdp_coef.m}
\end{small}

Figure~\ref{fig:sdp-direct-FIR-hilbert-bandpass-12-nbits-response} compares the
responses of the filter with floating-point coefficients, 12-bit signed-digit
coefficients, 12-bit signed-digit coefficients allocated with the algorithm of
\emph{Ito et al.} and 12-bit signed-digit coefficients allocated with the
algorithm of \emph{Ito et al.} and SDP optimisation.
Figure~\ref{fig:sdp-direct-FIR-hilbert-bandpass-12-nbits-passband-response}
compares the pass-band responses.
Table~\ref{tab:sdp-direct-FIR-hilbert-bandpass-12-nbits-cost-summary} compares
the cost, maximum stop-band response error and the number of $12$ bit
shift-and-add operations required to implement the $8$ distinct coefficient
multiplications found by the signed-digit allocation heuristic of \emph{Ito et
  al.} with the SDP reaxation optimisation and triangle inequalities.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_directFIRhilbert_bandpass_12_nbits_test_response}}
\caption{Comparison of the amplitude responses for a direct-form Hilbert
  band-pass FIR filter with 12-bit integer coefficients found
  by allocating an average of 2-signed-digits to each coefficient using the
  heuristic of \emph{Ito et al.} and performing SDP optimisation with triangle
  inequalities.}
\label{fig:sdp-direct-FIR-hilbert-bandpass-12-nbits-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_directFIRhilbert_bandpass_12_nbits_test_passband_response}}
\caption{Comparison of the pass-band amplitude responses for a direct-form Hilbert
  band-pass FIR filter with 12-bit integer coefficients found
  by allocating an average of 2-signed-digits to each coefficient using the
  heuristic of \emph{Ito et al.} and performing SDP optimisation with triangle
  inequalities.}
\label{fig:sdp-direct-FIR-hilbert-bandpass-12-nbits-passband-response}
\end{figure}
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lcccc}  \\ \toprule
& Cost&Stop-band response(dB)&Signed-digits&Shift-and-adds\\ \midrule
\input{sdp_relaxation_directFIRhilbert_bandpass_12_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the direct-form Hilbert band-pass FIR filter SDP
optimisation example with 12-bit coefficients] {Comparison of the
  cost, maximum stop-band response error and number of 12-bit shift-and-add
  operations required to implement the coefficient multiplications for a
  direct-form Hilbert band-pass FIR filter with 12-bit integer coefficients
  found by allocating an average of 2-signed-digits to each coefficient using
  the heuristic of \emph{Ito et al.} and performing SDP optimisation with
  triangle inequalities.}
\label{tab:sdp-direct-FIR-hilbert-bandpass-12-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:SDP-relaxation-search-signed-digit-coefficients-IIR-lattice-bandpass}SDP-relaxation search for the signed-digit coefficients of a lattice bandpass IIR filter}
The Octave script 
\emph{sdp\_relaxation\_schurOneMlattice\_bandpass\_10\_nbits\_test.m} performs
successive SDP relaxations to optimise the response of the SQP optimised
band-pass Schur one-multiplier lattice filter of
Section~\ref{sec:Design-IIR-one-multiplier-Schur-lattice-band-pass-SQP}. The 
filter specification is:
\begin{small}
\verbatiminput{sdp_relaxation_schurOneMlattice_bandpass_10_nbits_test_spec.m}
\end{small} 
The filter coefficients are truncated to $10$ bits allocated with an average of
$3$ signed-digits by the heuristic of \emph{Lim et al.} as shown in
Section~\ref{sec:Lim-allocation-signed-digits}. 

The script compares the filter designed by a single call to the Octave
function \emph{schurOneMlattice\_sdp\_mmse} with that designed by successively
fixing the value of the remaining active coefficients to the SDP coefficient
corresponding to that with the largest difference between the upper and lower
signed-digit approximations as in
Section~\ref{sec:SQP-relaxation-search-signed-digit-coefficients-bandpass}.
At each coefficient relaxation step the script finds the upper and lower
signed-digit approximations to the current set of active coefficients and
selects the coefficient with the largest difference in those
approximations. Then the active coefficients are optimised with
\emph{schurOneMlattice\_sdp\_mmse}, the set of active coefficients is updated
and the remaining active coefficients are optimised with the Octave function
\emph{schurOneMlattice\_socp\_mmse} and the \emph{Selesnick-Lang-Burrus}
constraint algorithm implemented in the Octave function
\emph{schurOneMlattice\_slb}. The truncation of the last coefficient is, by
necessity, not PCLS optimised so the final set of coefficients may not meet
the PCLS specifications.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Lim et al.} are:
\begin{small}
\verbatiminput{sdp_relaxation_schurOneMlattice_bandpass_10_nbits_test_k_allocsd_digits.m}
\verbatiminput{sdp_relaxation_schurOneMlattice_bandpass_10_nbits_test_c_allocsd_digits.m}
\end{small}
The filter coefficients found by a single ``global'' SDP optimisation are:
\begin{small}
\verbatiminput{sdp_relaxation_schurOneMlattice_bandpass_10_nbits_test_k0_sd_sdp_coef.m}
\verbatiminput{sdp_relaxation_schurOneMlattice_bandpass_10_nbits_test_c0_sd_sdp_coef.m}
\end{small}

The filter coefficients found by the SDP-relaxation search are:
\begin{small}
\verbatiminput{sdp_relaxation_schurOneMlattice_bandpass_10_nbits_test_k0_sd_min_coef.m}
\verbatiminput{sdp_relaxation_schurOneMlattice_bandpass_10_nbits_test_c0_sd_min_coef.m}
\end{small}

Figure~\ref{fig:sdp-relax-schurOneMlattice-bandpass-10-nbits-pass-response}
compares the pass-band responses of the filter with floating-point coefficients,
10-bit signed-digit coefficients allocated with the algorithm of
\emph{Lim et al.} and 10-bit signed-digit coefficients allocated with the
algorithm of \emph{Lim et al.} and SDP-relaxation search.
Figure~\ref{fig:sdp-relax-schurOneMlattice-bandpass-10-nbits-stop-response}
shows the filter stop-band response and
Figure~\ref{fig:sdp-relax-schurOneMlattice-bandpass-10-nbits-delay-response}
shows the filter pass-band group delay response. The ``global'' unconstrained
SDP optimisation gives a poor delay response. Application of the
\emph{Selesnick-Lang-Burrus} PCLS algorithm to that ``global'' signed-digit SDP
optimisation failed by entering a loop of constraints. 
Figure~\ref{fig:sdp-relax-schurOneMlattice-bandpass-10-nbits-coef-hist}
shows the history of the difference of the successive relaxed signed-digit
coefficients from the initial floating-point values. 
Table~\ref{tab:sdp-relax-schurOneMlattice-bandpass-10-nbits-cost-summary}
compares the cost and the number of $10$ bit shift-and-add operations required
to implement the coefficient multiplications found by the signed-digit
allocation heuristic of \emph{Lim et al.} with the SDP-relaxation search.
For comparison,
Table~\ref{tab:sdp-relax-schurOneMlattice-bandpass-12-nbits-cost-summary}
compares the cost and the number of $12$ bit shift-and-add operations required
to implement the coefficient multiplications found by the signed-digit
allocation heuristic of \emph{Lim et al.} with the SDP-relaxation search with
the Octave script
\emph{sdp\_relaxation\_schurOneMlattice\_bandpass\_12\_nbits\_test.m}.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_schurOneMlattice_bandpass_10_nbits_test_pass}}
\caption{Comparison of the pass-band amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SDP-relaxation search.}
\label{fig:sdp-relax-schurOneMlattice-bandpass-10-nbits-pass-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_schurOneMlattice_bandpass_10_nbits_test_stop}}
\caption{Comparison of the stop-band amplitude responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SDP-relaxation search.}
\label{fig:sdp-relax-schurOneMlattice-bandpass-10-nbits-stop-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_schurOneMlattice_bandpass_10_nbits_test_delay}}
\caption{Comparison of the pass-band group delay responses for a Schur
  one-multiplier lattice bandpass filter with 10-bit integer coefficients found
  by allocating an average of 3-signed-digits to each coefficient using the
  heuristic of \emph{Lim et al.} and performing SDP-relaxation search.}
\label{fig:sdp-relax-schurOneMlattice-bandpass-10-nbits-delay-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_schurOneMlattice_bandpass_10_nbits_test_coef_hist}}
\caption{History of the difference of the successive SDP relaxed signed-digit
coefficients from the initial floating-point values.}
\label{fig:sdp-relax-schurOneMlattice-bandpass-10-nbits-coef-hist}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lcccc}  \\ \toprule
& Cost&Stop-band response(dB)&Signed-digits&Shift-and-adds\\ \midrule
\input{sdp_relaxation_schurOneMlattice_bandpass_10_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the Schur one-multiplier lattice 
bandpass filter SDP-relaxation algorithm example with 10-bit coefficients]
{Comparison of the cost and number of 10-bit shift-and-add operations required 
  to implement the coefficient multiplications for a Schur one-multiplier 
  lattice bandpass filter with 10-bit integer coefficients found by allocating 
  an average of 3-signed-digits to each coefficient using the heuristic of 
  \emph{Lim et al.} and performing SDP-relaxation search.}
\label{tab:sdp-relax-schurOneMlattice-bandpass-10-nbits-cost-summary}
\end{table}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lcccc}  \\ \toprule
& Cost&Stop-band response(dB)&Signed-digits&Shift-and-adds\\ \midrule
\input{sdp_relaxation_schurOneMlattice_bandpass_12_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the Schur one-multiplier lattice 
bandpass filter SDP-relaxation algorithm example with 12-bit coefficients]
{Comparison of the cost and number of 12-bit shift-and-add operations required 
  to implement the coefficient multiplications for a Schur one-multiplier 
  lattice bandpass filter with 12-bit integer coefficients found by allocating 
  an average of 4-signed-digits to each coefficient using the heuristic of 
  \emph{Lim et al.} and performing SDP-relaxation search.}
\label{tab:sdp-relax-schurOneMlattice-bandpass-12-nbits-cost-summary}
\end{table}
\clearpage
\section{\label{sec:SDP-relaxation-search-signed-digit-coefficients-IIR-lattice-elliptic-lowpass}SDP-relaxation search for the signed-digit coefficients of a parallel allpass lattice elliptic low-pass IIR filter}
The Octave script 
\emph{sdp\_relaxation\_schurOneMPAlattice\_elliptic\_lowpass\_14\_nbits\_test.m}
performs successive SDP relaxations to optimise the response of an elliptic
low-pass filter implemented with $14$-bit coefficients. The filter specification
is:
\begin{small}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_elliptic_lowpass_14_nbits_test_spec.m}
\end{small} 
The filter specification is similar to that for the filter designed with
branch-and-bound search shown in Section~\ref{sec:Branch-and-bound-search-signed-digit-coefficients-parallel-allpass-elliptic-lowpass}.
For comparison, the  Octave script 
\emph{sdp\_relaxation\_schurOneMPAlattice\_elliptic\_lowpass\_16\_nbits\_test.m}
performs successive SDP relaxations to optimise the response of an elliptic
low-pass filter implemented with $16$-bit coefficients each having an average
of $5$ signed-digits. 

The initial parallel all-pass filters are those for the filter designed by the
Octave function \emph{ellip(11,0.02,84,2*0.15)}.
The filter coefficients are truncated to $14$-bit coefficients having $4$
signed-digits each.

The script compares the filter designed by a single call to the Octave
function \emph{schurOneMPAlattice\_sdp\_mmse} with that designed by successively
fixing the value of the remaining active coefficients to the SDP coefficient
corresponding to that with the largest difference between the upper and lower
signed-digit approximations as in
Section~\ref{sec:SQP-relaxation-search-signed-digit-coefficients-bandpass}.
At each coefficient relaxation step the script finds the upper and lower
signed-digit approximations to the current set of active coefficients and
selects the coefficient with the largest difference in those
approximations. Then the active coefficients are optimised with
\emph{schurOneMPAlattice\_sdp\_mmse}, the set of active coefficients is updated
and the remaining active coefficients are optimised with the Octave function
\emph{schurOneMPAlattice\_socp\_mmse} and the \emph{Selesnick-Lang-Burrus}
constraint algorithm implemented in the Octave function
\emph{schurOneMPAlattice\_slb}. The truncation of the last coefficient is, by
necessity, not PCLS optimised so the final set of coefficients may not meet
the PCLS specifications.

\begin{comment}
The filter coefficients found by $14$-bit $4$-signed-digit approximation are:
\begin{small}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_elliptic_lowpass_14_nbits_test_A1k0_sd_coef.m}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_elliptic_lowpass_14_nbits_test_A2k0_sd_coef.m}
\end{small}

The $14$-bit $4$-signed-digit filter coefficients found by a single ``global''
SDP optimisation are:
\begin{small}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_elliptic_lowpass_14_nbits_test_A1k0_sd_sdp_coef.m}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_elliptic_lowpass_14_nbits_test_A2k0_sd_sdp_coef.m}
\end{small}
\end{comment}

The $14$-bit $4$-signed-digit filter coefficients found by the SDP-relaxation
search are:
\begin{small}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_elliptic_lowpass_14_nbits_test_A1k0_sd_min_coef.m}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_elliptic_lowpass_14_nbits_test_A2k0_sd_min_coef.m}
\end{small}

Figures~\ref{fig:sdp-relax-schurOneMPAlattice-elliptic-lowpass-14-nbits-pass}
and~\ref{fig:sdp-relax-schurOneMPAlattice-elliptic-lowpass-14-nbits-stop}
compare the pass-band and stop-band responses of the filter with floating-point
coefficients, $14$-bit coefficients having $4$ signed-digits each, signed-digit
coefficients found with ``global'' SDP approximation and those found by
SDP-relaxation search.
Figure~\ref{fig:sdp-relax-schurOneMPAlattice-elliptic-lowpass-14-nbits-coef-hist}
shows the history of the difference of the successive relaxed signed-digit
coefficients from the initial floating-point values.
Table~\ref{tab:sdp-relax-schurOneMPAlattice-elliptic-lowpass-14-nbits-cost}
compares the cost and the number of $14$ bit shift-and-add operations required
to implement the $11$ coefficient multiplications.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_schurOneMPAlattice_elliptic_lowpass_14_nbits_test_pass}}
\caption{Comparison of the pass-band amplitude responses for a parallel
  all-pass Schur one-multiplier lattice elliptic low-pass filter with 14-bit
  integer coefficients having 4-signed-digits each and performing SDP
  relaxation search.}
\label{fig:sdp-relax-schurOneMPAlattice-elliptic-lowpass-14-nbits-pass}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_schurOneMPAlattice_elliptic_lowpass_14_nbits_test_stop}}
\caption{Comparison of the stop-band amplitude responses for a parallel
  all-pass Schur one-multiplier lattice elliptic low-pass filter with 14-bit
  integer coefficients having 4-signed-digits each and performing SDP
  relaxation search.} 
\label{fig:sdp-relax-schurOneMPAlattice-elliptic-lowpass-14-nbits-stop}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_schurOneMPAlattice_elliptic_lowpass_14_nbits_test_coef_hist}}
\caption{History of the difference of the successive SDP relaxed signed-digit
coefficients from the initial floating-point values.}
\label{fig:sdp-relax-schurOneMPAlattice-elliptic-lowpass-14-nbits-coef-hist}
\end{figure}
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lcccc}  \\ \toprule
& Cost&Stop-band response(dB)&Signed-digits&Shift-and-adds\\ \midrule
\input{sdp_relaxation_schurOneMPAlattice_elliptic_lowpass_14_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the parallel all-pass Schur
  one-multiplier lattice elliptic low-pass filter SDP-relaxation algorithm
  example with 14-bit coefficients]
{Comparison of the cost, stop-band attenuation and number of 14-bit
  shift-and-add operations required to implement the coefficient multiplications
  for a parallel all-pass Schur one-multiplier lattice elliptic-lowpass filter
  with 14-bit integer coefficients with 4-signed-digits each and performing SDP
  relaxation search.} 
\label{tab:sdp-relax-schurOneMPAlattice-elliptic-lowpass-14-nbits-cost}
\end{table}
\clearpage
\section{\label{sec:SDP-relaxation-search-signed-digit-coefficients-IIR-lattice-bandpass-Hilbert}SDP-relaxation search for the signed-digit coefficients of a parallel allpass lattice bandpass Hilbert IIR filter}
The Octave script 
\emph{sdp\_relaxation\_schurOneMPAlattice\_bandpass\_hilbert\_13\_nbits\_test.m}
performs successive SDP relaxations to optimise the response of the band-pass
Hilbert filter designed by the script 
\emph{parallel\_allpass\_socp\_slb\_bandpass\_hilbert\_test.m} described in
Section~\ref{sec:Design-IIR-filter-difference-all-pass-filters-pole-zero-constrained-group-delay}
implemented with $13$ bit coefficients each having an average of
$3$ signed-digits allocated by the heuristic of \emph{Ito et al.} as shown in
Section~\ref{sec:Lim-allocation-signed-digits}. The filter specification is: 
\begin{small}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_spec.m}
\end{small} 
The script compares the filter designed by a single call to the Octave
function \emph{schurOneMPAlattice\_sdp\_mmse} with that designed by successively
fixing the value of the remaining active coefficients to the SDP coefficient
corresponding to that with the largest difference between the upper and lower
signed-digit approximations as in
Section~\ref{sec:SQP-relaxation-search-signed-digit-coefficients-bandpass}.
At each coefficient relaxation step the script finds the upper and lower
signed-digit approximations to the current set of active coefficients and
selects the coefficient with the largest difference in those
approximations. Then the active coefficients are optimised with
\emph{schurOneMPAlattice\_sdp\_mmse}, the set of active coefficients is updated
and the remaining active coefficients are optimised with the Octave function
\emph{schurOneMPAlattice\_socp\_mmse} and the \emph{Selesnick-Lang-Burrus}
constraint algorithm implemented in the Octave function
\emph{schurOneMPAlattice\_slb}. The truncation of the last coefficient is, by
necessity, not PCLS optimised so the final set of coefficients may not meet
the PCLS specifications.

The numbers of signed-digits allocated to each coefficient by the heuristic of
\emph{Ito et al.} are:
\begin{small}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_A1k_allocsd_digits.m}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_A2k_allocsd_digits.m}
\end{small}
The filter coefficients found when the number of signed-digits is allocated by
the heuristic of \emph{Ito et al.} are:
\begin{small}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_A1k0_sd_Ito_coef.m}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_A2k0_sd_Ito_coef.m}
\end{small}

The filter coefficients found by a single ``global'' SDP optimisation are:
\begin{small}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_A1k0_sd_sdp_coef.m}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_A2k0_sd_sdp_coef.m}
\end{small}

The filter coefficients found by the SDP-relaxation search are:
\begin{small}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_A1k0_sd_min_coef.m}
\verbatiminput{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_A2k0_sd_min_coef.m}
\end{small}

Figures~\ref{fig:sdp-relax-schurOneMPAlattice-bandpass-hilbert-13-nbits-pass},
Figure~\ref{fig:sdp-relax-schurOneMPAlattice-bandpass-hilbert-13-nbits-phase}
and
Figure~\ref{fig:sdp-relax-schurOneMPAlattice-bandpass-hilbert-13-nbits-delay}
compare the pass band responses of the filter with floating-point coefficients,
13-bit signed-digit coefficients allocated with the algorithm of
\emph{Ito et al.} and 13-bit signed-digit coefficients allocated with the
algorithm of \emph{Ito et al.} and SDP-relaxation search. The pass band phase
response shown is adjusted for the nominal delay. Likewise,
Figure~\ref{fig:sdp-relax-schurOneMPAlattice-bandpass-hilbert-13-nbits-stop}
shows the filter stop band response.
Table~\ref{tab:sdp-relax-schurOneMPAlattice-bandpass-hilbert-13-nbits-cost}
compares the cost and the number of $13$ bit shift-and-add operations required
to implement the $20$ coefficient multiplications found by the signed-digit
allocation heuristic of \emph{Ito et al.} with the SDP-relaxation search.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_pass}}
\caption{Comparison of the pass-band amplitude responses for a parallel
  all-pass Schur one-multiplier lattice bandpass Hilbert filter with 13-bit
  integer coefficients found by allocating an average of 3-signed-digits to
  each coefficient using the heuristic of \emph{Ito et al.} and performing
  SDP-relaxation search.}
\label{fig:sdp-relax-schurOneMPAlattice-bandpass-hilbert-13-nbits-pass}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_phase}}
\caption{Comparison of the pass-band phase responses for a parallel
  all-pass Schur one-multiplier lattice bandpass Hilbert filter with 13-bit
  integer coefficients found by allocating an average of 3-signed-digits to
  each coefficient using the heuristic of \emph{Ito et al.} and performing
  SDP-relaxation search. The phase responses shown are adjusted for the nominal
  delay.}
\label{fig:sdp-relax-schurOneMPAlattice-bandpass-hilbert-13-nbits-phase}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_delay}}
\caption{Comparison of the pass-band group delay responses for a parallel
  all-pass Schur one-multiplier lattice bandpass Hilbert filter with 13-bit
  integer coefficients found by allocating an average of 3-signed-digits to
  each coefficient using the heuristic of \emph{Ito et al.} and performing
  SDP-relaxation search.}
\label{fig:sdp-relax-schurOneMPAlattice-bandpass-hilbert-13-nbits-delay}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_stop}}
\caption{Comparison of the stop-band amplitude responses for a parallel
  all-pass Schur one-multiplier lattice bandpass Hilbert filter with 13-bit
  integer coefficients found  by allocating an average of 3-signed-digits to
  each coefficient using the heuristic of \emph{Ito et al.} and performing
  SDP-relaxation search.} 
\label{fig:sdp-relax-schurOneMPAlattice-bandpass-hilbert-13-nbits-stop}
\end{figure}

\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lcccc}  \\ \toprule
& Cost&Stop-band response(dB)&Signed-digits&Shift-and-adds\\ \midrule
\input{sdp_relaxation_schurOneMPAlattice_bandpass_hilbert_13_nbits_test_cost.tab}
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for the parallel all-pass Schur
  one-multiplier lattice bandpass Hilbert filter SDP-relaxation algorithm
  example with 13-bit coefficients]
{Comparison of the cost and number of 13-bit shift-and-add operations required 
  to implement the coefficient multiplications for a parallel all-pass Schur
  one-multiplier lattice bandpass Hilbert filter with 13-bit integer
  coefficients found by allocating an average of 3-signed-digits to each
  coefficient using the heuristic of \emph{Ito et al.} and performing
  SDP-relaxation search.}
\label{tab:sdp-relax-schurOneMPAlattice-bandpass-hilbert-13-nbits-cost}
\end{table}

\chapter{\label{sec:Comparison-filter-search-fifth-order-elliptic-filter}Comparison of filter coefficient search methods for a 5th order elliptic filter with 6-bit integer and 2-signed-digit  coefficients}
The signed-digit allocation algorithms shown in 
Chapter~\ref{sec:Signed-digit-representation-filter-coefficients} performed
poorly when the coefficient word-length is less than $10$. This chapter compares
the results of ``brute force'' search for the 6-bit integer coefficients of a 
5th order elliptic filter. The filter responses are compared to an ideal, 
``brick-wall'', amplitude response:
\begin{align*}
A\left(f\right) & = \begin{cases}
1 & f<=0.125\\
0 & f>0.150
\end{cases}
\end{align*}
The response errors are weighted as follows:
\begin{align*}
W_{a}\left(f\right) & = \begin{cases}
1 & f<=0.125\\
0.1 & 0.125<f<0.150\\
10 & f>=0.150
\end{cases}
\end{align*}
The prototype filter is a 5-th order elliptic filter with pass-band edge at
$fpass=0.125$, $1dB$ pass-band ripple and $40dB$ stop-band ripple:
\begin{small}
\begin{verbatim}
% Specify elliptic low pass filter
norder=5;dBpass=1;dBstop=40;fpass=0.125;
[n0,d0]=ellip(norder,dBpass,dBstop,2*fpass);
\end{verbatim}
\end{small}
The prototype filter is implemented as a normalised-scaled lattice filter,
parallel allpass normalised-scaled lattice filters, a one-multiplier lattice
filter, parallel all-pass one-multiplier lattice filters and a cascade of two
2nd order minimum noise state variable sections followed by a first order
section. The stability of each filter is maintained by checking the 
pole locations of the transfer function denominator polynomial in the
corresponding cost function. For each optimisation algorithm and filter, I 
compare the cost function of the floating-point filter response to the response
for each filter with the coefficients truncated as $6$ bit rounded and $6$ bit 
$2$ signed-digits. I anticipate that the average number of signed digits used
by the signed-digit coefficients will be less than $2$. The $6$ bit rounded 
coefficients can be represented exactly by $3$ or fewer signed digits. 
Individual cases may be improved by ``tweaking'' the optimisation 
parameters.

\section{Searching with the bit-flipping algorithm\label{sec:Searching-with-the-bit-flipping-algorithm}}
The Octave script \emph{bitflip\_schurNSlattice\_lowpass\_test.m} implements
the prototype elliptic filter as a normalised-scaled lattice and optimises the
truncated coefficients with the bit-flipping algorithm using $nbits=6$,
$bitstart=4$ and
$msize=3$. Figures~\ref{fig:bitflip_schurNSlattice_lowpass_response} 
and~\ref{fig:bitflip_schurNSlattice_lowpass_passband_response} show the overall
and passband responses of the prototype elliptic filter with floating-point
coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients optimised
with the bit-flipping algorithm, 6 bit 2 signed-digit coefficients and 6 bit 2
signed-digit coefficients optimised with the bit-flipping algorithm. The cost
function used with the signed-digit coefficients does not enforce the
normalised-scaled orthogonal symmetry of $s_{00}=s_{22}$ and $s_{02}=-s_{20}$.

The Octave script \emph{bitflip\_schurOneMlattice\_lowpass\_test.m} implements
the prototype elliptic filter as a one-multiplier lattice and optimises the
truncated coefficients with the bit-flipping algorithm using $nbits=6$,
$bitstart=4$ and
$msize=3$. Figures~\ref{fig:bitflip_schurOneMlattice_lowpass_response}
and~\ref{fig:bitflip_schurOneMlattice_lowpass_passband_response} show the
overall and passband responses of the filter with floating-point coefficients, 6
bit rounded coefficients, 6 bit rounded coefficients optimised with the
bit-flipping algorithm, 6 bit 2 signed-digit coefficients and 6 bit 2
signed-digit coefficients optimised with the bit-flipping algorithm. The
one-multiplier lattice state scaling coefficients are not truncated.

Appendix~\ref{app:Low-passband-sensitivity-IIR-digital-filters} shows how
odd-order ``classical'' digital filter transfer functions can be implemented
as the sum of two parallel all-pass filters. The Octave script
\emph{bitflip\_schurNSPAlattice\_lowpass\_test.m} implements the 5th order
elliptic filter as the sum of two normalised-scaled all-pass lattice filters
and optimises the truncated coefficients with the bit-flipping algorithm using
$nbits=6$, $bitstart=4$ and
$msize=3$. Figures~\ref{fig:bitflip_schurNSPAlattice_lowpass_response}
and~\ref{fig:bitflip_schurNSPAlattice_lowpass_passband_response} show the overall
and passband responses of the parallel all-pass filter with floating-point
coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients optimised
with the bit-flipping algorithm, 6 bit 2 signed-digit coefficients and 2
signed-digit coefficients optimised with the bit-flipping algorithm. The cost
function used with the signed-digit coefficients does not enforce the
normalised-scaled orthogonal symmetry of $s_{00}=s_{22}$ and $s_{02}=-s_{20}$.

The Octave script \emph{bitflip\_schurOneMPAlattice\_lowpass\_test.m}
implements the 5th order elliptic filter as the sum of two one-multiplier
all-pass lattice filters and optimises the truncated coefficients with the
bit-flipping algorithm using $nbits=6$, $bitstart=4$ and $msize=3$.
Figures~\ref{fig:bitflip_schurOneMPAlattice_lowpass_response}
and~\ref{fig:bitflip_schurOneMPAlattice_lowpass_passband_response} show the 
overall and passband responses of the parallel all-pass filter with
floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
coefficients optimised with the bit-flipping algorithm and 6 bit 2 signed-digit
coefficients and 6 bit 2 signed-digit coefficients optimised with the
bit-flipping algorithm. The one-multiplier lattice state scaling coefficients
are not truncated. The structural boundedness of the parallel all-pass
one-multiplier lattice filter is evident.

Finally, the Octave script \emph{bitflip\_svcasc\_lowpass\_test.m} implements
the 5th order elliptic filter as a pair of 2nd order minimum-noise state variable
sections followed by a 1st order state variable section. (See
Section~\ref{sec:Second-order-cascade}). The script optimises the truncated
coefficients with the bit-flipping algorithm using $nbits=6$, $bitstart=4$ and
$msize=3$. Figures~\ref{fig:bitflip_svcasc_lowpass_response}
and~\ref{fig:bitflip_svcasc_lowpass_passband_response} show the overall and
passband responses of the filter with floating-point coefficients, 6 bit rounded
coefficients, 6 bit rounded coefficients optimised with the bit-flipping
algorithm and 6 bit 2 signed-digit coefficients optimised with the bit-flipping
algorithm. Note that the 2nd order state variable cascade filter obtained by
simply converting the floating-point coefficients to 6 bit 2 signed-digit
coefficients is unstable. 

Table~\ref{tab:bitflip-algorithm-cost-summary} compares the cost result for
each test of the bit-flipping algorithm.
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lrrrrr} \toprule
Cost&Normalised-scaled&One-multiplier&Normalised-scaled&One-multiplier&2nd Order\\
&lattice&lattice&PA lattice&PA lattice& cascade\\
\midrule
Exact                          & 1.0008 & 1.0008 & 1.0008 & 1.0008 & 1.0008 \\
Rounded                        & 1.5432 & 1.5299 & 1.2459 & 1.1097 & 1.2362 \\
Rounded with bit-flipping      & 1.1289 & 1.5299 & 0.9861 & 1.1097 & 0.9929 \\
Signed-digit                   & 2.3373 & 2.7157 & 3.6059 & 3.9013 & $\infty$ \\
Signed-digit with bit-flipping & 0.8744 & 2.1571 & 1.3824 & 3.1746 & 1.1334 \\ 
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for each bit-flipping algorithm example]
{Summary of the cost results for the example 5th order
elliptic low-pass filter synthesised as a normalised-scaled or one-multiplier 
lattice filter or as a cascade of 2nd order state variable sections 
with floating-point coefficients, 6 bit rounded coefficients,
6 bit rounded coefficients optimised with the bit-flipping algorithm,
6 bit 2 signed-digit coefficients and 6 bit 2 signed-digit coefficients 
optimised with the bit-flipping algorithm}
\label{tab:bitflip-algorithm-cost-summary}
\end{table}

The normalised-scaled 6 bit 2 signed-digit coefficients optimised with the
bit-flipping algorithm are:
\begin{small}
\begin{verbatim}
s10_bfsd = [  0.968750,  0.875000,  0.468750,  0.187500,  0.031250 ]';
s11_bfsd = [  0.000000,  0.875000,  0.937500,  1.000000,  0.468750 ]';
s20_bfsd = [ -0.750000,  0.937500, -0.875000,  0.750000, -0.468750 ]';
s00_bfsd = [  0.625000,  0.312500,  0.468750,  0.562500,  0.875000 ]';
s02_bfsd = [  0.750000, -0.968750,  0.875000, -0.750000,  0.437500 ]';
s22_bfsd = [  0.625000,  0.218750,  0.468750,  0.500000,  0.875000 ]';
\end{verbatim}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurNSlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass
  filter synthesised as a normalised-scaled lattice filter with floating-point
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients optimised
  with the bit-flipping algorithm, 6 bit 2 signed-digit coefficients, and 6 bit 
  2 signed-digit coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip_schurNSlattice_lowpass_response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurNSlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as a normalised-scaled lattice filter with floating-point
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients optimised
  with the bit-flipping algorithm, 6 bit 2 signed-digit coefficients, and 6 bit 
  2 signed-digit coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip_schurNSlattice_lowpass_passband_response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurOneMlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass
  filter synthesised as a one multiplier lattice filter with floating-point
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients optimised
  with the bit-flipping algorithm, 6 bit 2 signed-digit coefficients, and 6 bit 
  2 signed-digit coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip_schurOneMlattice_lowpass_response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurOneMlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as a one multiplier lattice filter with floating-point
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients optimised
  with the bit-flipping algorithm, 6 bit 2 signed-digit coefficients, and 6 bit 
  2 signed-digit coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip_schurOneMlattice_lowpass_passband_response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurNSPAlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass filter
  synthesised as parallel all-pass normalised-scaled lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the bit-flipping algorithm, 6 bit 2 signed-digit
  coefficients, and 6 bit 2 signed-digit coefficients optimised with the
  bit-flipping algorithm.}
\label{fig:bitflip_schurNSPAlattice_lowpass_response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurNSPAlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as parallel all-pass normalised-scaled lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the bit-flipping algorithm, 6 bit 2 signed-digit
  coefficients, and 6 bit 2 signed-digit coefficients optimised with the
  bit-flipping algorithm.}
\label{fig:bitflip_schurNSPAlattice_lowpass_passband_response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurOneMPAlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass
  filter synthesised as parallel all-pass one multiplier lattice filters with 
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the bit-flipping algorithm, 6 bit 2 signed-digit
  coefficients, and 6 bit 2 signed-digit coefficients optimised with the
  bit-flipping algorithm.}
\label{fig:bitflip_schurOneMPAlattice_lowpass_response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_schurOneMPAlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as parallel all-pass one multiplier lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the bit-flipping algorithm, 6 bit 2 signed-digit
  coefficients, and 6 bit 2 signed-digit coefficients optimised with the
  bit-flipping algorithm.}
\label{fig:bitflip_schurOneMPAlattice_lowpass_passband_response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_svcasc_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass
  filter synthesised as a cascade of 2nd order state variable sections with 
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the bit-flipping algorithm and 6 bit 2 signed-digit
  coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip_svcasc_lowpass_response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{bitflip_svcasc_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as a cascade of 2nd order state variable sections with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the bit-flipping algorithm and 6 bit 2
  signed-digit coefficients optimised with the bit-flipping algorithm.}
\label{fig:bitflip_svcasc_lowpass_passband_response}
\end{figure}
\clearpage
\section{Searching with the \emph{Nelder-Mead} simplex algorithm}
The Octave script \emph{simplex\_schurNSlattice\_lowpass\_test.m} implements
the prototype elliptic filter as a normalised-scaled lattice and optimises the
truncated coefficients with the \emph{nelder\_mead\_min} simplex algorithm
from the Octave-Forge \emph{optim} package~\cite{OctaveForge_OptimPackage}.
Figures~\ref{fig:simplex_schurNSlattice_lowpass_response}
and~\ref{fig:simplex_schurNSlattice_lowpass_passband_response} show the overall 
and passband responses of the prototype elliptic filter with floating-point
coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients optimised
with the simplex algorithm, 6 bit 2 signed-digit coefficients and 6 bit 2
signed-digit coefficients optimised with the simplex algorithm. The cost
function used with the signed-digit coefficients does not enforce the
normalised-scaled orthogonal symmetry of $s_{00}=s_{22}$ and $s_{02}=-s_{20}$.

The Octave script \emph{simplex\_schurOneMlattice\_lowpass\_test.m} implements
the 5th order elliptic filter as a one-multiplier lattice and optimises the
truncated coefficients with the simplex algorithm.
Figures~\ref{fig:simplex_schurOneMlattice_lowpass_response}
and~\ref{fig:simplex_schurOneMlattice_lowpass_passband_response} show the
overall and passband responses of the filter with floating-point coefficients,
6 bit rounded coefficients, 6 bit rounded coefficients optimised with the simplex
algorithm, 6 bit 2 signed-digit coefficients and 6 bit 2 signed-digit
coefficients optimised with the simplex algorithm. The one-multiplier lattice
state scaling coefficients are not truncated.

The Octave script \emph{simplex\_schurNSPAlattice\_lowpass\_test.m} implements
the 5th order elliptic filter as the sum of two normalised scaled all-pass
lattice filters and optimises the truncated coefficients with the simplex
algorithm. Figures~\ref{fig:simplex_schurNSPAlattice_lowpass_response}
and~\ref{fig:simplex_schurNSPAlattice_lowpass_passband_response} show the
overall and passband responses of the parallel all-pass filter with
floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
coefficients optimised with the simplex algorithm, 6 bit 2 signed-digit
coefficients and 6 bit 2 signed-digit coefficients optimised with the simplex
algorithm. The cost function used with the signed-digit coefficients does not
enforce the normalised-scaled orthogonal symmetry of $s_{00}=s_{22}$ and
$s_{02}=-s_{20}$.

The Octave script \emph{simplex\_schurOneMPAlattice\_lowpass\_test.m}
implements the 5th order elliptic filter as the sum of two one-multiplier
all-pass lattice filters and optimises the truncated coefficients with the
simplex algorithm.
Figures~\ref{fig:simplex_schurOneMPAlattice_lowpass_response}
and~\ref{fig:simplex_schurOneMPAlattice_lowpass_passband_response} show the 
overall and passband responses of the parallel all-pass filter with
floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
coefficients optimised with the simplex algorithm, 6 bit 2 signed-digit
coefficients and 6 bit 2 signed-digit coefficients optimised with the simplex
algorithm. The one-multiplier lattice state scaling coefficients are not
truncated.

Finally, the Octave script \emph{simplex\_svcasc\_lowpass\_test.m} implements
the 5th order elliptic filter as a pair of 2nd order minimum-noise state
variable sections followed by a 1st order state variable section. (See
Section~\ref{sec:Second-order-cascade}). The script optimises the truncated
coefficients with the simplex algorithm.
Figures~\ref{fig:simplex_svcasc_lowpass_response}
and~\ref{fig:simplex_svcasc_lowpass_passband_response} show the overall and 
passband responses of the filter with floating-point coefficients, 6 bit rounded
coefficients, 6 bit rounded coefficients optimised with the bit-flipping
algorithm and 6 bit 2 signed-digit coefficients optimised with the simplex
algorithm. Note that the 2nd order state variable cascade filter obtained by
simply converting the floating-point coefficients to 6 bit 2 signed-digit coefficients
is unstable.

Table~\ref{tab:simplex-algorithm-cost-summary} compares the cost result for
each test of the simplex algorithm.
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lrrrrr} \toprule
Cost&Normalised-scaled&One-multiplier&Normalised-scaled&One-multiplier&2nd Order\\
&lattice&lattice&PA lattice&PA lattice& cascade\\
\midrule
Exact                         & 1.0008 & 1.0008 & 1.0008 & 1.0008 & 1.0008 \\
Rounded                       & 1.5432 & 1.5299 & 1.2459 & 1.1097 & 1.2362 \\
Rounded with simplex          & 1.0397 & 1.4617 & 0.9861 & 1.1097 & 0.8395 \\
Signed-digit                  & 2.3373 & 2.7157 & 3.6059 & 3.9013 & $\infty$ \\
Signed-digit with simplex     & 1.6581 & 2.3918 & 3.2559 & 3.1746 & 3.2134 \\
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for each simplex algorithm example]
{Summary of the cost results for the example 5th order
elliptic low-pass filter synthesised as a normalised-scaled or one-multiplier 
lattice filter or as a cascade of 2nd order state variable sections
with floating-point coefficients, 6 bit rounded coefficients,
6 bit rounded coefficients optimised with the simplex algorithm,
6 bit 2 signed-digit coefficients and 6 bit
2 signed-digit coefficients optimised with the simplex algorithm.}
\label{tab:simplex-algorithm-cost-summary}
\end{table}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{simplex_schurNSlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass
filter synthesised as a normalised-scaled lattice filter with floating-point
coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients
optimised with the simplex algorithm, 6 bit 2 signed-digit coefficients and
6 bit 2 signed-digit coefficients optimised with the simplex algorithm.}
\label{fig:simplex_schurNSlattice_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{simplex_schurNSlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as a scaled=normalised lattice filter with floating-point
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients
  optimised with the simplex algorithm, 6 bit 2 signed-digit coefficients and
  6 bit 2 signed-digit coefficients optimised with the simplex algorithm.}
\label{fig:simplex_schurNSlattice_lowpass_passband_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{simplex_schurOneMlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass
  filter synthesised as a one multiplier lattice filter with floating-point 
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients
  optimised with the simplex algorithm, 6 bit 2 signed-digit coefficients and
  6 bit 2 signed-digit coefficients optimised with the simplex algorithm.}
\label{fig:simplex_schurOneMlattice_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{simplex_schurOneMlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as a one multiplier lattice filter with floating-point 
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients
  optimised with the simplex algorithm, 6 bit 2 signed-digit coefficients and
  6 bit 2 signed-digit coefficients optimised with the simplex algorithm.}
\label{fig:simplex_schurOneMlattice_lowpass_passband_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{simplex_schurNSPAlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass filter 
  synthesised as parallel all-pass normalised-scaled lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the simplex algorithm, 6 bit 2 signed-digit
  coefficients and 6 bit 2 signed-digit coefficients optimised with the simplex
  algorithm.}
\label{fig:simplex_schurNSPAlattice_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{simplex_schurNSPAlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass filter
  synthesised as parallel all-pass normalised-scaled lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the simplex algorithm, 6 bit 2 signed-digit
  coefficients and  6 bit 2 signed-digit coefficients optimised with the simplex
  algorithm.}
\label{fig:simplex_schurNSPAlattice_lowpass_passband_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{simplex_schurOneMPAlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass filter 
  synthesised as parallel all-pass one multiplier lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the simplex algorithm, 6 bit 2 signed-digit
  coefficients and 6 bit 2 signed-digit coefficients optimised with the simplex
  algorithm.}
\label{fig:simplex_schurOneMPAlattice_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{simplex_schurOneMPAlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass filter
  synthesised as parallel all-pass one multiplier lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the simplex algorithm, 6 bit 2 signed-digit
  coefficients and 6 bit 2 signed-digit coefficients optimised with the simplex
  algorithm.}
\label{fig:simplex_schurOneMPAlattice_lowpass_passband_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{simplex_svcasc_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass
  filter synthesised as a cascade of 2nd order state variable sections with 
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the simplex algorithm and 6 bit 2 signed-digit
  coefficients optimised with the simplex algorithm.}
\label{fig:simplex_svcasc_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{simplex_svcasc_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as a cascade of 2nd order state variable sections with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients  optimised with the simplex algorithm and 6 bit 2 signed-digit
  coefficients optimised with the simplex algorithm.}
\label{fig:simplex_svcasc_lowpass_passband_response}
\end{figure}
\clearpage
\section{\label{sec:search-with-simulated-annealing}Searching with the \emph{simulated annealing} algorithm}
This section shows the results of searching for the coefficients of a $5$-th
order low-pass filter with the Octave-Forge \emph{optim}
package~\cite{OctaveForge_OptimPackage} implementation of the simulated
annealing algorithm, \emph{nonlin\_min}~\cite[Demonstration
2]{OctaveForge_OptimPackage_nonlin_min}\footnote{The \emph{samin} function has
  been deprecated.}. Unfortunately, the minimum cost found by \emph{nonlin\_min}
may vary by a factor of $2$ or more from run to run. In this section I show the
best results from $20$ runs of each test. You may need to do more runs to find
the best filter.

The Octave script \emph{samin\_schurNSlattice\_lowpass\_test.m} implements the
prototype elliptic filter as a normalised-scaled lattice and optimises the
truncated coefficients with the \emph{nonlin\_min} simulated annealing algorithm
from the Octave-Forge \emph{optim} package~\cite{OctaveForge_OptimPackage}.
Figures~\ref{fig:samin_schurNSlattice_lowpass_response}
and~\ref{fig:samin_schurNSlattice_lowpass_passband_response} show, for the
best results from $10$ runs, the overall and passband responses of the
prototype elliptic filter with floating-point coefficients, 6 bit rounded
coefficients, 6 bit rounded coefficients optimised with the simulated annealing
algorithm, 6 bit 2 signed-digit coefficients and 6 bit 2 signed-digit
coefficients optimised with the simulated annealing algorithm. The cost function
used with the signed-digit coefficients does not enforce the normalised-scaled
orthogonal symmetry of $s_{00}=s_{22}$ and $s_{02}=-s_{20}$.

The Octave script \emph{samin\_schurOneMlattice\_lowpass\_test.m} implements
the prototype elliptic filter as a one-multiplier lattice and optimises the
truncated coefficients with the simulated annealing algorithm.
Figures~\ref{fig:samin_schurOneMlattice_lowpass_response}
and~\ref{fig:samin_schurOneMlattice_lowpass_passband_response} show, for the
best results from $10$ runs, the overall and passband responses of the prototype
elliptic filter with floating-point coefficients, 6 bit rounded coefficients, 6
bit rounded coefficients optimised with the simulated annealing algorithm, 6 bit
2 signed-digit coefficients and 6 bit 2 signed-digit coefficients optimised with
the simulated annealing algorithm. The one multiplier lattice state scaling
coefficients are not truncated.

The Octave script \emph{samin\_schurNSPAlattice\_lowpass\_test.m} implements
the 5th order elliptic filter as the sum of two normalised-scaled all-pass
lattice filters and optimises the truncated coefficients with the simulated
annealing algorithm.
Figures~\ref{fig:samin_schurNSPAlattice_lowpass_response}
and~\ref{fig:samin_schurNSPAlattice_lowpass_passband_response} show, for the
best results from $10$ runs, the overall and passband responses of the prototype
elliptic filter with floating-point coefficients, 6 bit rounded coefficients,
6 bit rounded coefficients optimised with the simulated annealing algorithm,
6 bit 2 signed-digit coefficients and 6 bit 2 signed-digit coefficients
optimised with the simulated annealing algorithm. The cost function used with the
signed-digit coefficients does not enforce the normalised-scaled orthogonal
symmetry of $s_{00}=s_{22}$ and $s_{02}=-s_{20}$.

The Octave script \emph{samin\_schurOneMPAlattice\_lowpass\_test.m} implements
the 5th order elliptic filter as the sum of two one-multiplier all-pass
lattice filters and optimises the truncated coefficients with the simulated
annealing algorithm.
Figures~\ref{fig:samin_schurOneMPAlattice_lowpass_response}
and~\ref{fig:samin_schurOneMPAlattice_lowpass_passband_response} show, for the 
best results from $10$ runs, the overall and passband responses of the
prototype elliptic filter with floating-point coefficients, 6 bit rounded
coefficients, 6 bit rounded coefficients optimised with the simulated annealing
algorithm, 6 bit 2 signed-digit coefficients and 6 bit 2 signed-digit
coefficients optimised with the simulated annealing algorithm. The one
multiplier lattice state scaling coefficients are not truncated.

Finally, the Octave script \emph{samin\_svcasc\_lowpass\_test.m} implements
the 5th order elliptic filter as a pair of 2nd order minimum-noise state
variable sections followed by a 1st order state variable section. (See
Section~\ref{sec:Second-order-cascade}). The script optimises the truncated
coefficients with the simulated annealing algorithm.
Figures~\ref{fig:samin_svcasc_lowpass_response}
and~\ref{fig:samin_svcasc_lowpass_passband_response} show the overall and
passband responses of the filter with floating-point coefficients, 6 bit rounded
coefficients, 6 bit rounded coefficients optimised with the bit-flipping
algorithm and 6 bit 2 signed-digit coefficients optimised with the simulated
annealing algorithm. Note that the 2nd order state variable cascade filter
obtained by simply converting the floating-point coefficients to 6 bit 2
signed-digit coefficients is unstable.

Table~\ref{tab:samin-algorithm-cost-summary} shows the minimum cost result for
$10$ runs of each test. 
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lrrrrr} \toprule
Cost&Normalised-scaled&One-multiplier&Normalised-scaled&One-multiplier&2nd Order\\
&lattice&lattice&PA lattice&PA lattice& cascade\\
\midrule
Exact                   & 1.0008 & 1.0008 & 1.0008 & 1.0008 & 1.0008 \\
Rounded                 & 1.5432 & 1.5299 & 1.2459 & 1.1097 & 1.2362 \\
Rounded with samin      & 0.8420 & 1.4617 & 0.8295 & 0.8803 & 0.6781 \\
Signed-digit            & 2.3373 & 2.7157 & 3.6059 & 3.9013 & $\infty$ \\
Signed-digit with samin & 0.8309 & 1.7673 & 1.0841 & 1.6706 & $\infty$ \\ 
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for each simulated annealing algorithm example]
{Summary of the cost results for the example 5th order elliptic low-pass filter
  synthesised as a normalised-scaled or one-multiplier lattice filter or as 
  a cascade of 2nd order state variable sections with floating-point
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients optimised
  with the simulated annealing algorithm, 6 bit 2 signed-digit coefficients and
  6 bit 2 signed-digit coefficients optimised with the simulated annealing
  algorithm.}
\label{tab:samin-algorithm-cost-summary}
\end{table}

The lowest cost 6 bit 2 signed-digit coefficients of the normalised-scaled 
lattice filter found with the simulated annealing algorithm are:
\begin{small}
\begin{verbatim}
s10_sasd = [  0.968750,  0.750000,  0.375000,  0.156250,  0.031250 ]';
s11_sasd = [  0.156250,  0.750000,  0.875000,  1.000000,  0.500000 ]';
s20_sasd = [ -0.750000,  0.968750, -0.937500,  0.750000, -0.312500 ]';
s00_sasd = [  0.625000,  0.281250,  0.468750,  0.562500,  0.937500 ]';
s02_sasd = [  0.750000, -1.000000,  0.875000, -0.750000,  0.468750 ]';
s22_sasd = [  0.625000,  0.250000,  0.531250,  0.500000,  0.875000 ]';
\end{verbatim}
\end{small}
The lowest cost 6 bit rounded coefficients of the parallel-allpass
one-multiplier lattice filter found with the simulated annealing algorithm 
are\footnote{These coefficient multiplications can be implemented with a total 
of 14 signed-digits and 9 adders}.
\begin{small}
\begin{verbatim}
A1k_sa = [ -0.812500,  0.625000 ];
A2k_sa = [ -0.781250,  0.906250, -0.593750 ];
\end{verbatim}
\end{small}
The lowest cost 6 bit rounded coefficients of the cascade of 2nd
order sections found with the simulated annealing algorithm are:
\begin{small}
\begin{verbatim}
a11_sa = [  0.750000,  0.687500,  0.000000 ];
a12_sa = [ -0.687500, -0.375000,  1.000000 ];
a21_sa = [  0.656250,  0.531250,  0.000000 ];
a22_sa = [  0.625000,  0.687500,  0.687500 ];
b1_sa  = [  0.406250,  0.656250,  0.000000 ];
b2_sa  = [  0.125000,  0.062500,  1.000000 ];
c1_sa  = [  0.375000,  0.062500,  0.000000 ];
c2_sa  = [  0.937500,  0.406250,  0.406250 ];
dd_sa  = [  0.250000,  0.281250,  0.218750 ];
\end{verbatim}
\end{small}
\clearpage
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{samin_schurNSlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass
  filter synthesised as a normalised-scaled lattice filter with floating-point
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients
  optimised with the simulated annealing algorithm, 6 bit 2 signed-digit 
  coefficients and 6 bit 2 signed-digit coefficients optimised with the 
  simulated annealing algorithm.}
\label{fig:samin_schurNSlattice_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{samin_schurNSlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as a scaled=normalised lattice filter with floating-point
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients
  optimised with the simulated annealing algorithm, 6 bit 2 signed-digit 
  coefficients and 6 bit 2 signed-digit coefficients optimised with the
  simulated annealing algorithm.}
\label{fig:samin_schurNSlattice_lowpass_passband_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{samin_schurOneMlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass
  filter synthesised as a one multiplier lattice filter with floating-point 
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients
  optimised with the simulated annealing algorithm, 6 bit 2 signed-digit
  coefficients and 6 bit 2 signed-digit coefficients optimised with the 
  simulated annealing algorithm.}
\label{fig:samin_schurOneMlattice_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{samin_schurOneMlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as a one multiplier lattice filter with floating-point 
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients
  optimised with the simulated annealing algorithm, 6 bit 2 signed-digit 
  coefficients and 6 bit 2 signed-digit coefficients optimised with the 
  simulated annealing algorithm.}
\label{fig:samin_schurOneMlattice_lowpass_passband_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{samin_schurNSPAlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass filter 
  synthesised as parallel all-pass normalised-scaled lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the simulated annealing algorithm, 6 bit 2
  signed-digit coefficients and 6 bit 2 signed-digit coefficients optimised with
  the simulated annealing algorithm.}
\label{fig:samin_schurNSPAlattice_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{samin_schurNSPAlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass filter
  synthesised as parallel all-pass normalised-scaled lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the simulated annealing algorithm, 6 bit 2
  signed-digit coefficients and 6 bit 2 signed-digit coefficients optimised with
  the simulated annealing algorithm.}
\label{fig:samin_schurNSPAlattice_lowpass_passband_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{samin_schurOneMPAlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass filter 
  synthesised as parallel all-pass one multiplier lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the simulated annealing algorithm and 6 bit 2
  signed-digit coefficients optimised with the simulated annealing algorithm.}
\label{fig:samin_schurOneMPAlattice_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{samin_schurOneMPAlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass filter
  synthesised as parallel all-pass one multiplier lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the simulated annealing algorithm and 6 bit 2
  signed-digit coefficients optimised with the simulated annealing algorithm.}
\label{fig:samin_schurOneMPAlattice_lowpass_passband_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{samin_svcasc_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass
  filter synthesised as a cascade of 2nd order state variable sections with 
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the simulated annealing algorithm
  and 6 bit 2 signed-digit coefficients optimised with the simulated annealing
  algorithm}
\label{fig:samin_svcasc_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{samin_svcasc_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as a cascade of 2nd order state variable sections with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the simulated annealing algorithm and 6 bit 2
  signed-digit coefficients optimised with the simulated annealing algorithm.}
\label{fig:samin_svcasc_lowpass_passband_response}
\end{figure}
\clearpage{}
\section{Searching with the \emph{differential evolution} algorithm}
This section shows the results of searching for the coefficients of a $5$-th
order low-pass filter with the Octave-Forge \emph{optim} 
package~\cite{OctaveForge_OptimPackage} implementation of the 
\emph{differential evolution} algorithm of \emph{Storn} and 
\emph{Price}~\cite{StornPrice_DifferentialEvolution}, \emph{de\_min}. 
Unfortunately, the minimum cost found by \emph{de\_min} may vary from run to
run. In this section I show the best results from $20$ runs of each test. You
may need to do more runs to find the best filter. These
tests use the default control settings for \emph{de\_min}. The \emph{de\_min}
function includes $12$ possible optimisation strategies. The default strategy
is \emph{DEGL/SAW/bin}.

The Octave script \emph{de\_min\_schurNSlattice\_lowpass\_test.m} implements
the prototype elliptic filter as a normalised-scaled lattice and optimises the
truncated coefficients with the \emph{de\_min} differential evolution
algorithm from the Octave-Forge \emph{optim}
package~\cite{OctaveForge_OptimPackage}.
Figures~\ref{fig:de_min_schurNSlattice_lowpass_response}
and~\ref{fig:de_min_schurNSlattice_lowpass_passband_response} show, for the
best results from $10$ runs, the overall and passband responses of the
prototype elliptic filter with floating-point coefficients, 6 bit rounded
coefficients, 6 bit rounded coefficients optimised with the differential
evolution algorithm, 6 bit 2 signed-digit coefficients and 6 bit 2 signed-digit
coefficients optimised with the differential evolution algorithm. The cost
function used with the signed-digit coefficients does not enforce the
normalised-scaled orthogonal symmetry of $s_{00}=s_{22}$ and $s_{02}=-s_{20}$.

The Octave script \emph{de\_min\_schurOneMlattice\_lowpass\_test.m} implements
the prototype elliptic filter as a one-multiplier lattice and optimises the
truncated coefficients with the differential evolution algorithm.
Figures~\ref{fig:de_min_schurOneMlattice_lowpass_response}
and~\ref{fig:de_min_schurOneMlattice_lowpass_passband_response} show, for the
best results from $10$ runs, the overall and passband responses of the prototype
elliptic filter with floating-point coefficients, 6 bit rounded coefficients,
6 bit rounded coefficients optimised with the differential evolution algorithm,
6 bit 2 signed-digit coefficients and 6 bit 2 signed-digit coefficients
optimised with the differential evolution algorithm. The one multiplier
lattice state scaling coefficients are not truncated.

The Octave script \emph{de\_min\_schurNSPAlattice\_lowpass\_test.m} implements
the 5th order elliptic filter as the sum of two normalised-scaled all-pass
lattice filters and optimises the truncated coefficients with the differential
evolution algorithm.
Figures~\ref{fig:de_min_schurNSPAlattice_lowpass_response}
and~\ref{fig:de_min_schurNSPAlattice_lowpass_passband_response} show, for the
best results from $10$ runs, the overall and passband responses of the prototype
elliptic filter with floating-point coefficients, 6 bit rounded coefficients,
6 bit rounded coefficients optimised with the differential evolution algorithm,
6 bit 2 signed-digit coefficients and 6 bit 2 signed-digit coefficients
optimised with the differential evolution algorithm. The cost function used
with the signed-digit coefficients does not enforce the normalised-scaled
orthogonal symmetry of $s_{00}=s_{22}$ and $s_{02}=-s_{20}$.

The Octave script \emph{de\_min\_schurOneMPAlattice\_lowpass\_test.m}
implements the 5th order elliptic filter as the sum of two one-multiplier
all-pass lattice filters and optimises the truncated coefficients with the
differential evolution
algorithm. Figures~\ref{fig:de_min_schurOneMPAlattice_lowpass_response}
and~\ref{fig:de_min_schurOneMPAlattice_lowpass_passband_response} show, for the 
best results from $10$ runs, the overall and passband responses of the
prototype elliptic filter with floating-point coefficients, 6 bit rounded
coefficients, 6 bit rounded coefficients optimised with the differential
evolution algorithm, 6 bit 2 signed-digit coefficients and 6 bit 2 signed-digit
coefficients optimised with the differential evolution algorithm. The one
multiplier lattice state scaling coefficients are not truncated.

Finally, the Octave script \emph{de\_min\_svcasc\_lowpass\_test.m} implements
the 5th order elliptic filter as a pair of 2nd order minimum-noise state variable
sections followed by a 1st order state variable section. (See
Section~\ref{sec:Second-order-cascade}). The script optimises the truncated
coefficients with the differential evolution algorithm.
Figures~\ref{fig:de_min_svcasc_lowpass_response}
and~\ref{fig:de_min_svcasc_lowpass_passband_response} show the overall and
passband responses of the filter with floating-point coefficients, 6 bit rounded
coefficients, 6 bit rounded coefficients optimised with the bit-flipping
algorithm and 6 bit 2 signed-digit coefficients optimised with the differential
evolution algorithm. Note that the 2nd order state variable cascade filter
obtained by simply converting the floating-point coefficients to
6 bit 2 signed-digit coefficients is unstable.

Table~\ref{tab:de_min-algorithm-cost-summary} shows the minimum cost result for
$10$ runs of each test. 
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lrrrrr} \toprule
Cost&Normalised-scaled&One-multiplier&Normalised-scaled&One-multiplier&2nd Order\\
&lattice&lattice&PA lattice&PA lattice& cascade\\
\midrule
Exact                     & 1.0008 & 1.0008 & 1.0008 & 1.0008 & 1.0008 \\
Rounded                   & 1.5432 & 1.5299 & 1.2459 & 1.1097 & 1.2362 \\
Rounded with de\_min      & 0.7797 & 1.2765 & 0.7874 & 0.8803 & 0.6572 \\
Signed-digit              & 2.3373 & 2.7157 & 3.6059 & 3.9013 & $\infty$ \\
Signed-digit with de\_min & 0.7768 & 1.9147 & 1.1879 & 1.3505 & 0.6995 \\ 
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Summary of cost results for each differential evolution algorithm example]
{Summary of the cost results for the example 5th order elliptic low-pass filter
  synthesised as a normalised-scaled or one-multiplier lattice filter or as 
  a cascade of 2nd order state variable sections with floating-point
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients optimised
  with the differential evolution algorithm, 6 bit 2 signed-digit coefficients
  and 6 bit 2 signed-digit coefficients optimised with the differential
  evolution algorithm.}
\label{tab:de_min-algorithm-cost-summary}
\end{table}

\clearpage
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{de_min_schurNSlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass
  filter synthesised as a normalised-scaled lattice filter with floating-point
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients
  optimised with the differential evolution algorithm, 6 bit 2 signed-digit 
  coefficients and 6 bit 2 signed-digit coefficients optimised with the 
  differential evolution algorithm.}
\label{fig:de_min_schurNSlattice_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{de_min_schurNSlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as a scaled=normalised lattice filter with floating-point
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients
  optimised with the differential evolution algorithm, 6 bit 2 signed-digit 
  coefficients and 6 bit 2 signed-digit coefficients optimised with the
  differential evolution algorithm.}
\label{fig:de_min_schurNSlattice_lowpass_passband_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{de_min_schurOneMlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass
  filter synthesised as a one multiplier lattice filter with floating-point 
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients
  optimised with the differential evolution algorithm, 6 bit 2 signed-digit
  coefficients and 6 bit 2 signed-digit coefficients optimised with the 
  differential evolution algorithm.}
\label{fig:de_min_schurOneMlattice_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{de_min_schurOneMlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as a one multiplier lattice filter with floating-point 
  coefficients, 6 bit rounded coefficients, 6 bit rounded coefficients
  optimised with the differential evolution algorithm, 6 bit 2 signed-digit 
  coefficients and 6 bit 2 signed-digit coefficients optimised with the 
  differential evolution algorithm.}
\label{fig:de_min_schurOneMlattice_lowpass_passband_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{de_min_schurNSPAlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass filter 
  synthesised as parallel all-pass normalised-scaled lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the differential evolution algorithm, 6 bit
  2 signed-digit coefficients and 6 bit 2 signed-digit coefficients optimised
  with the differential evolution algorithm.}
\label{fig:de_min_schurNSPAlattice_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{de_min_schurNSPAlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass filter
  synthesised as parallel all-pass normalised-scaled lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the differential evolution algorithm, 6 bit
  2 signed-digit coefficients and 6 bit 2 signed-digit coefficients optimised
  with the differential evolution algorithm.}
\label{fig:de_min_schurNSPAlattice_lowpass_passband_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{de_min_schurOneMPAlattice_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass filter 
  synthesised as parallel all-pass one multiplier lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the differential evolution algorithm and 6 bit
  2 signed-digit coefficients optimised with the differential evolution
  algorithm.}
\label{fig:de_min_schurOneMPAlattice_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{de_min_schurOneMPAlattice_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass filter
  synthesised as parallel all-pass one multiplier lattice filters with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the differential evolution algorithm and 6 bit
  2 signed-digit coefficients optimised with the differential evolution
  algorithm.}
\label{fig:de_min_schurOneMPAlattice_lowpass_passband_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{de_min_svcasc_lowpass_test_response}}
\caption{Amplitude response of the 5th order elliptic low-pass
  filter synthesised as a cascade of 2nd order state variable sections with 
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the differential evolution algorithm and 6 bit
  2 signed-digit coefficients optimised with the differential evolution
  algorithm.}
\label{fig:de_min_svcasc_lowpass_response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{de_min_svcasc_lowpass_test_passband_response}}
\caption{Pass-band amplitude response of the 5th order elliptic low-pass
  filter synthesised as a cascade of 2nd order state variable sections with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with the differential evolution algorithm
  and 6 bit 2 signed-digit coefficients optimised with the differential
  evolution algorithm.}
\label{fig:de_min_svcasc_lowpass_passband_response}
\end{figure}
\clearpage{}
\section{Summary of the search algorithm comparison}
Table~\ref{tab:search-algorithm-cost-summary} compares the cost result for
each of the search algorithms. The relative time consumed by the algorithms 
is, in increasing order: simplex, bit-flipping, differential evolution and
simulated annealing. The simulated annealing and differential evolution costs 
shown are the minimum found for $10$ runs of the corresponding test script.
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lrrrrr} \toprule
Cost&Normalised-scaled&One-multiplier&Normalised-scaled&One-multiplier&2nd Order\\
&lattice&lattice&PA lattice&PA lattice& cascade\\
\midrule
Exact                          & 1.0008 & 1.0008 & 1.0008 & 1.0008 & 1.0008 \\
Rounded                        & 1.5432 & 1.5299 & 1.2459 & 1.1097 & 1.2362 \\
Rounded with bit-flipping      & 1.1289 & 1.5299 & 0.9861 & 1.1097 & 0.9929 \\
Rounded with simplex           & 1.0397 & 1.4617 & 0.9861 & 1.1097 & 0.8395 \\
Rounded with samin             & 0.8420 & 1.4617 & 0.8295 & 0.8803 & 0.6781 \\
Rounded with de\_min           & 0.7797 & 1.2765 & 0.7874 & 0.8803 & 0.6572 \\
Signed-digit                   & 2.3373 & 2.7157 & 3.6059 & 3.9013 & $\infty$ \\
Signed-digit with bit-flipping & 0.8744 & 2.1571 & 1.3824 & 3.1746 & 1.1334 \\
Signed-digit with simplex      & 1.6581 & 2.3918 & 3.2559 & 3.1746 & 3.2134 \\
Signed-digit with samin        & 0.8309 & 1.7673 & 1.0841 & 1.6706 & $\infty$ \\ 
Signed-digit with de\_min      & 0.7768 & 1.9147 & 1.1879 & 1.3505 & 0.6995 \\ 
\\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption[Comparison of cost results for each algorithm]
{Comparison of the cost results for the example 5th order
  elliptic low-pass filter synthesised as a normalised-scaled or one-multiplier 
  lattice filter or as a cascade of 2nd order state variable sections with
  floating-point coefficients, 6 bit rounded coefficients, 6 bit rounded
  coefficients optimised with each algorithm, 6 bit 2 signed-digit coefficients
  and 6 bit 2 signed-digit coefficients optimised with each algorithm.}
\label{tab:search-algorithm-cost-summary}
\end{table}

Table~\ref{tab:filter-implementation-number-coef-summary} shows the number of
coefficients for each filter implementation. The figure in parentheses for the
normalised-scaled filters is the number of signed-digit coefficients optimised.
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lrrrrr} \toprule
Cost&Normalised-scaled&One-multiplier&Normalised-scaled&One-multiplier&2nd Order\\
&lattice&lattice&PA lattice&PA lattice& cascade\\
\midrule
Number of filter coefficients    & 20(30) & 11 & 10(20) & 5 & 23 \\ 
\bottomrule
\end{tabular}
\end{threeparttable}
\caption[Comparison of number of coefficients for each filter implementation]
{Comparison of the number of coefficients for the example 5th order
  elliptic low-pass filter synthesised as a normalised-scaled or one-multiplier 
  lattice filter or as a cascade of 2nd order state variable sections. The
  figure in parentheses for the normalised-scaled filters is the number of 
  signed-digit coefficients that are optimised assuming symmetry is not
  required.}
\label{tab:filter-implementation-number-coef-summary}
\end{table}

\cleardoublepage
\appendix
\part{Appendixes}
\cleardoublepage

\chapter{\label{app:Review-of-complex-variables}Review of Complex Variables} 
This chapter summarises 
\emph{Kreyszig}~\cite[Chapter 12(Sections 4 and 5), Chapter
14]{Kreyszig_AdvancedEngineeringMathematics}.
\section{Complex Functions}
Define a function \emph{$f$} on the complex numbers, $\mathbb{C}$,
$w=f\left(z\right)$, where \emph{$z$} varies in \emph{$S$} and is called a
\emph{``complex variable}''. \emph{$S$} is called the \emph{domain} of
\emph{$z$} and the set of complex numbers, \emph{$w$, }that\emph{
  $f\left(z\right)$ }assumes is called the \emph{range }of
$f\left(z\right)$. Write the real and imaginary parts of \emph{$w$} in terms
of the real and imaginary parts of $z=x+\imath y$ as
$w=f\left(z\right)=u(x,y)+\imath v(x,y)$ where \emph{$u$} and \emph{$v$} are
real valued functions of the real variables \emph{$x$} and $y$ and, of course,
$\imath=\sqrt{-1}$.
\section{Limit}
A function \emph{$f\left(z\right)$} is said to have a limit \emph{$\ell$} as
\emph{$z$} approaches \emph{$w=f\left(z\right)=u(x,y)+\imath v(x,y)$} if
$f\left(z\right)$ is defined in a neighbourhood of $z_{0}$ (except perhaps at
$z_{0}$ itself) and if for any positive, non-zero real number $\epsilon$ we
can find a real positive $\delta$ such that, for all \emph{z $\neq$z$_{0}$} in
the disk $\left|z-z_{0}\right|<\delta$ ,
$\left|f\left(z\right)-\ell\right|<\epsilon$. We write:
\begin{align*}
\lim_{z\rightarrow z_{0}}f\left(z\right) & = \ell
\end{align*}
A function \emph{$f\left(z\right)$} is \emph{continuous} at $z=z_{0}$ if $f(z_{0})$
is defined and 
\begin{align*}
\lim_{z\rightarrow z_{0}}f\left(z\right) & = f(z_{0})
\end{align*}
A function \emph{$f\left(z\right)$} is \emph{differentiable} at $z=z_{0}$ if
the limit
\begin{align*}
f^{\prime}\left(z\right) & = \lim_{z\rightarrow z_{0}}\frac{f(z_{0}+\Delta
  z)-f(z_{0})}{\Delta z}
\end{align*}
exists. This limit is called the \emph{derivative} of\emph{ $f\left(z\right)$
}at $z=z_{0}$. $f\left(z\right)$ is said to be \emph{analytic} (or
\emph{holomorphic}) in a domain $D$, if $f\left(z\right)$ is defined and
differentiable at all points of $D$. For example, $f\left(z\right)=x-\imath y$
is not differentiable.  If $\Delta z=\Delta x+\imath\Delta y$ then:
\begin{align*}
\frac{f(z+\Delta z)-f\left(z\right)}{\Delta z} & = \frac{\Delta x-\imath\Delta
  y}{\Delta x+\imath\Delta y}
\end{align*}
If $\Delta z$ approaches $z$ with $\Delta y=0$ then the derivative
is $-1$ but if $\Delta z$ approaches $z$ with $\Delta x=0$ then
the derivative is $1$. Hence the limit approaches different values
along different paths to $z=x+\imath y$.
\section{The Cauchy-Riemann Equations}
Suppose $f\left(z\right)=u(x,y)+\imath v(x,y)$ is defined and continuous
within a neighbourhood of an arbitrary fixed point $z$ and differentiable at
$z$ so that $f^{\prime}\left(z\right)$ exists. Set $\Delta z=\Delta
x+\imath\Delta y$.  On a path for which $\Delta z$ approaches $z$ with $\Delta
y=0$, then:
\begin{align*}
f^{\prime}\left(z\right) & = \lim_{\Delta x\rightarrow0}\frac{u(x+\Delta
  x,y)-u(x,y)}{\Delta x}+\imath\lim_{\Delta x\rightarrow0}\frac{v(x+\Delta
  x,y)-v(x,y)}{\Delta x}\\ & = \frac{\partial u}{\partial
  x}+\imath\frac{\partial v}{\partial x}
\end{align*}
Similarly, for a path on which $\Delta z$ approaches $z$ with $\Delta x=0$
\begin{align*}
f^{\prime}\left(z\right) & = \frac{\partial v}{\partial y}-\imath\frac{\partial u}{\partial y}
\end{align*}
Equating real and imaginary parts, we obtain the Cauchy-Riemann equations
\begin{align*}
\frac{\partial u}{\partial x} & = \frac{\partial v}{\partial y}
\end{align*}
and
\begin{align*}
\frac{\partial u}{\partial y} & = -\frac{\partial v}{\partial x}
\end{align*}
If $f\left(z\right)=u(x,y)+\imath v(x,y)$ is analytic in $D$ then the real
and imaginary parts of $f$ satisfy Laplace's equation in $D$ and
have continuous second partial derivatives in $D$
\begin{align*}
\nabla^{2}u & = \frac{\partial^{2}u}{\partial x^{2}}+\frac{\partial^{2}u}{\partial y^{2}}=0
\end{align*}
and
\begin{align*}
\nabla^{2}v & = 0
\end{align*}
\section{Line integrals in the complex plane}
Let $C$ be a smooth curve in the $z$ plane with $z(t)=x(t)+\imath y(t)$
with $a\leq t\leq b$ where $z(t)$ has a continuous derivative $\dot{z}(t)\neq0$
for all $t$. Let $f\left(z\right)$ be a continuous function defined at each
point of $C$. Divide the interval $a\leq t\leq b$ into sub-intervals
$t_{0}=a\leq t_{1}\leq\cdots\leq t_{n}=b$ corresponding to 
$z_{0}=z(t_{0}),z_{1},\ldots,z_{n}=z(t_{n})$.
For each sub-interval of $C$ choose an arbitrary point, $\zeta_{i}$,
between $z_{i-1}$ and $z_{i}$. Then form the sums
\begin{align*}
S_{n} & = \sum_{i=1}^{n}f(\zeta_{i})\Delta z_{i}
\end{align*}
where $\Delta z_{i}=z_{i}-z_{i-1}$. Define $\zeta_{i}=\varepsilon_{i}+\imath\eta_{i}$
and $\Delta z_{i}=\Delta x_{i}+\imath\Delta y_{i}$ and let 
$f\left(z\right)=u(x,y)+\imath v(x,y)$. Then $S_{n}$ consists of four real sums
\begin{align*}
S_{n} & = \sum_{i=1}^{n}\left(u+\imath v\right)\left(\Delta x_{i}+\imath\Delta y_{i}\right)\\
 & = \sum_{i=1}^{n}u\Delta x_{i}-\sum_{i=1}^{n}v\Delta y_{i}+\imath\left[\sum_{i=1}^{n}u\Delta y_{i}+\sum_{i=1}^{n}v\Delta x_{i}\right]
\end{align*}
and the \emph{line integral} of $f\left(z\right)$ along $C$ is defined as the
limit of the sums $S_{n}$ and
\begin{align*}
\intop_{C}f\left(z\right)dz & = \lim_{n\rightarrow\infty}S_{n}\\
 & = \intop_{C}udx-\intop_{C}vdy+\imath\left[\intop_{C}udy+\intop_{C}vdx\right]\\
 & = \intop_{a}^{b}u\dot{x}dt-\intop_{a}^{b}v\dot{y}dt+\imath\left[\intop_{a}^{b}u\dot{x}dt+\intop_{a}^{b}v\dot{y}dt\right]\\
 & = \intop_{c}f\left[z\left(t\right)\right]\dot{z}dt
\end{align*}
The absolute value of the line integral is bounded by
\begin{align*}
\left|\intop_{C}f\left(z\right)dz\right| & \leq Ml
\end{align*}
where $l$ is the length of the path $C$ and $M$ is a real constant
such that $\left|f\left(z\right)\right|\leq M$ everywhere on the path $C$.

\section{\label{app:Cauchys-Integral-Theorem}Cauchy's Integral Theorem}
A domain $D$ in the complex plane is called \emph{simply connected}
if every simple closed curve in $D$ encloses only points in $D$.
Such a domain $D$ is said to be \emph{bounded} if $D$ lies entirely
within a circle about the origin. If $f\left(z\right)$is analytic in a simply
connected bounded domain $D$ then for each simple closed path $C$
in $D$ 
\begin{align*}
\ointctrclockwise_{C}f\left(z\right) & = 0
\end{align*}
\emph{Proof:}~Cauchy made the additional assumption that $f^{\prime}\left(z\right)$
is continuous and applied Green's theorem. Write
\begin{align*}
\ointctrclockwise_{C}f\left(z\right) & = \intop_{C}udx-vdy+\imath\intop_{C}udy+vdx
\end{align*}
$f\left(z\right)$ is analytic so $f^{\prime}\left(z\right)$ exists.
For the real part, using the Cauchy-Riemann equations, by Green's
theorem
\begin{align*}
\intop_{C}udx-vdy & = \iint_{R}\left[-\frac{\partial v}{\partial x}-\frac{\partial u}{\partial y}\right]dxdy\\
 & = 0
\end{align*}
 where $R$ is the region bounded by $C$. Similarly for the imaginary
part. Goursat provided a proof that does not require $f^{\prime}\left(z\right)$
to be continuous. A corollary of Cauchy's Integral theorem is that
the line integral of $f\left(z\right)$ is independent of the path in $D$.
\section{\label{app:Cauchys-Integral-Formula}Cauchy's Integral 
Formula}
Let $f\left(z\right)$ be analytic in a simply connected domain, $D$. Then for
any point $z_{0}$ in $D$ and any simple closed path $C$ in $D$
which encloses $z_{0}$
\begin{align*}
\ointctrclockwise_{C}\frac{f\left(z\right)}{z-z_{0}}dz & = 2\pi\imath f(z_{0})
\end{align*}
\emph{Proof:}~
Let
\begin{align*}
f\left(z\right) & = f(z_{0})+\left[f\left(z\right)-f(z_{0})\right]
\end{align*}
so
\begin{align*}
\ointctrclockwise_{C}\frac{f\left(z\right)}{z-z_{0}}dz & = f(z_{0})\ointctrclockwise_{C}\frac{dz}{z-z_{0}}+\ointctrclockwise_{C}\frac{f\left(z\right)-f(z_{0})}{z-z_{0}}dz
\end{align*}
For the first term use the identity
\begin{align*}
\intop_{c}(z-z_{0})^{m}dz & = \begin{cases}
2\pi\imath & m=-1\\
0 & m\neq-1,\: integral
\end{cases}
\end{align*}
found by setting $z(t)=z_{0}+\rho e^{\imath t}$ and integrating over
$t$. For the second term, replace $C$ by a small circle $K$, with
centre $z_{0}$. $f\left(z\right)$ is analytic so for any $\epsilon>0$ we can
find a $\delta>0$ so that $\left|f\left(z\right)-f(z_{0})\right|<\epsilon$
for all $z$ in $\left|z-z_{0}\right|<\delta$. Choose the radius
$\rho$ of $K$ smaller than $\delta$ then
\begin{align*}
\left|\frac{f\left(z\right)-f(z_{0})}{z-z_{0}}\right| & < \frac{\epsilon}{\rho}
\end{align*}
at each point of $K$. Since the length of $K$ is $2\pi\rho$
\begin{align*}
\left|\intop_{K}\frac{f\left(z\right)-f(z_{0})}{z-z_{0}}dz\right| & < 2\pi\epsilon
\end{align*}
at each point of $K$ and the second term is shown to be zero.
\section{Derivatives of an analytic function}
If $f\left(z\right)$ is analytic in $D$ then it has derivatives of all orders
in $D$ which are also analytic functions in $D$
\begin{align*}
f^{(n)}\left(z_{0}\right) & = \frac{n!}{2\pi\imath}\ointctrclockwiseop_{c}\frac{f\left(z\right)}{(z-z_{0})^{n+1}}dz,\: n=1,2,\cdots
\end{align*}
\emph{Proof:}~ 
For $f^{\prime}(z_{0})$
\begin{align*}
f^{\prime}(z_{0}) & = \lim_{\Delta z\rightarrow0}\frac{f\left(z_{0}+\Delta z\right)f\left(z_{0}\right)}{\Delta z}
\end{align*}
Applying Cauchy's Integral formula
\begin{align*}
f^{\prime}(z_{0}) & = \lim_{\Delta z\rightarrow0}\frac{1}{2\pi\imath\Delta z}\left[\intop_{C}\frac{f\left(z\right)}{z-(z_{0}+\Delta z)}dz-\intop_{C}\frac{f\left(z\right)}{z-z_{0}}dz\right]\\
 & = \frac{1}{2\pi\imath}\intop_{C}\frac{f\left(z\right)}{(z-z_{0})^{2}}dz+\lim_{\Delta z\rightarrow0}\frac{\Delta z}{2\pi\imath}\intop_{C}\frac{f\left(z\right)}{(z-z_{0}-\Delta z)(z-z_{0})^{2}}dz
\end{align*}
So we need to establish that the second term on the right is zero.
On $C$ the function $f\left(z\right)$ is continuous. Hence $f\left(z\right)$ is bounded
in absolute value on $C$, say $\left|f\left(z\right)\right|<M$. Let $d$ be
the distance of the point or points of $C$ which are closest to $z_{0}$.
Then for all $z$ on $C$, $\left|z-z_{0}\right|\geq d$ hence $\left|z-z_{0}\right|^{-1}\leq\frac{1}{d}$.
Also, if $\left|\Delta z\right|\leq\frac{d}{2}$, then for all $z$
on $C$ we have the inequality $\left|z-z_{0}-\Delta z\right|\geq\frac{d}{2}$
hence $\left|z-z_{0}-\Delta z\right|^{-1}\leq\frac{2}{d}$. Denoting
the length of $C$ by $L$
\begin{align*}
\left|\frac{\Delta z}{2\pi\imath}\intop_{C}\frac{f\left(z\right)}{(z-z_{0}-\Delta z)(z-z_{0})^{2}}dz\right| & < \frac{\left|\Delta z\right|}{2\pi}\frac{M}{\frac{1}{2}dd^{2}}L
\end{align*}
As $\Delta z$ approaches zero the right hand side approaches zero.
The general formula follows by induction.
\section{Laurent's Theorem}
If $f\left(z\right)$ is \emph{analytic} on two concentric circles with centre
$a$ and in the annulus between them, then $f\left(z\right)$ can be represented
by the \emph{Laurent} series
\begin{align*}
f\left(z\right)&=\sum^{\infty}_{n=0}b_{n}\left(z-a\right)^{n}+\
\sum^{\infty}_{n=1}\frac{c_{n}}{\left(z-a\right)^{n}}
\end{align*}
where
\begin{align*}
b_{n}&=\frac{1}{2\pi\imath}\ointctrclockwiseop_{C}\frac{f\left(z^{\ast}\right)}{\left(z^{\ast}-a\right)^{n+1}}dz^{\ast}\\
c_{n}&=\frac{1}{2\pi\imath}\ointctrclockwiseop_{C}\left(z^{\ast}-a\right)^{n-1}f\left(z^{\ast}\right)dz^{\ast}
\end{align*}
each integral being taken in the counter-clockwise direction around any simple
closed path, $C$, which lies in the annulus and encloses the inner circle. This
series converges and represents $f\left(z\right)$ in the open annulus obtained
from the given annulus by continuously increasing the circle $C_{1}$ and
decreasing $C_{2}$ until each if the two circles reaches a point where 
$f\left(z\right)$ is singular. 

For a proof see \emph{Kreyszig}~\cite[Section
16.7]{Kreyszig_AdvancedEngineeringMathematics}. A common case 
occurs when $z=a$ is the only singular point of $f\left(z\right)$ in $C_{2}$.
Then the Laurent expansion converges for all $z$ in $C_{1}$ except at $z=a$.

\section{Residues}
If $f\left(z\right)$ is analytic in the neighbourhood of a point $z=a$,
then by Cauchy's integral theorem
\begin{align*}
\ointctrclockwiseop_{C}f\left(z\right)dz&=0
\end{align*}
for any closed path, $C$, in that neighbourhood. If, however, $f\left(z\right)$
has an isolated singularity at $z=a$ and $a$ lies in the interior of $C$, then
we may represent $f\left(z\right)$ by the Laurent series
\begin{align*}
f\left(z\right)&=\sum^{\infty}_{n=0}b_{n}\left(z-a\right)^{n}+\
\frac{c_{1}}{\left(z-a\right)}+\frac{c_{2}}{\left(z-a\right)^{2}}+\cdots
\end{align*}
which converges on the domain $0<\left|z-a\right|<R$. Consequently
\begin{align*}
\ointctrclockwiseop_{C}f\left(z\right)dz&=2\pi\imath c_{1}
\end{align*}
$c_{1}$ is called the \emph{residue} of $f\left(z\right)$ at $z=a$. The 
integral of $f\left(z\right)$ over $C$ can be extended to paths that contain
finitely many singular points.

\section{\label{app:Cauchy-Argument-Principle}Cauchy's Argument Principle}
A \emph{meromorphic} function on an open subset, \emph{D}, of the complex plane 
is a function that is holomorphic on all \emph{D} except at a set of isolated
points (the \emph{poles} of the function) at which it must have a Laurent 
series. If $f\left(z\right)$ is a meromorphic function inside and on a 
closed contour, $C$, and has no poles or zeros on $C$, then
\begin{align*}
\ointctrclockwiseop_{C}\frac{f^{\prime}\left(z\right)}{f\left(z\right)}dz&=2\pi\imath\left(k-m\right)
\end{align*}
where $k$ and $m$ denote the number of zeros and poles, respectively, of
$f\left(z\right)$ inside $C$. Each zero and pole is counted as many times as
its multiplicity and order, respectively, indicate.

\emph{Proof:}~
Let $z_{N}$ be a zero of $f\left(z\right)$ with multiplicity $k$, then
\begin{align*}
f\left(z\right) &= \left(z-z_{N}\right)^{k}g\left(z\right)
\end{align*}
where $g\left(z_{N}\right) \neq 0$. Differentiating
\begin{align*}
f^{\prime}\left(z\right) &= k\left(z-z_{N}\right)^{k-1}g\left(z\right)+\left(z-z_{N}\right)^{k}g^{\prime}\left(z\right)
\end{align*}
and
\begin{align*}
\frac{f^{\prime}\left(z\right)}{f\left(z\right)} &= \frac{k}{z-z_{N}} + \frac{g^{\prime}\left(z\right)}{g\left(z\right)}
\end{align*}
Since $g\left(z_{N}\right)\ne 0$, 
$\frac{g^{\prime}\left(z\right)}{g\left(z\right)}$ has no singularities and is analytic at $z_{N}$ and the residue of $\frac{f^{\prime}\left(z\right)}{f\left(z\right)}$ at $z_{N}$ is $k$.

Similarly, let $z_{P}$ be a pole of $f\left(z\right)$ with order $k$, then
\begin{align*}
f\left(z\right) &= \left(z-z_{P}\right)^{-m}h\left(z\right)
\end{align*}
where $h\left(z_{P}\right) \neq 0$. Differentiating
\begin{align*}
f^{\prime}\left(z\right) &= -m\left(z-z_{P}\right)^{-m-1}h\left(z\right)+\left(z-z_{N}\right)^{-m}h^{\prime}\left(z\right)
\end{align*}
and
\begin{align*}
\frac{f^{\prime}\left(z\right)}{f\left(z\right)} &= \frac{-m}{z-z_{P}} + \frac{h^{\prime}\left(z\right)}{h\left(z\right)}
\end{align*}
Since $h\left(z_{P}\right)\ne 0$, 
$\frac{h^{\prime}\left(z\right)}{h\left(z\right)}$ has no singularities and is 
analytic at $z_{P}$ and the residue of $\frac{f^{\prime}\left(z\right)}{f\left(z\right)}$ at $z_{P}$ is $-m$.

\section{Rouch\'{e}'s Theorem}
If $f\left(z\right)$ and $g\left(z\right)$ are analytic inside and on a closed
contour $C$, and $\left|g\left(z\right)\right| < \left|f\left(z\right)\right|$
on $C$, then $f\left(z\right)$ and $f\left(z\right)+g\left(z\right)$ have the
same number of zeros inside $C$.

\chapter{\label{app:Review-of-topics-in-linear-algebra}Review of selected results from linear algebra}
This appendix collects some results from linear algebra used in convex
optimisation. See, for example, \emph{Golub and Van
  Loan}~\cite{GolubVanLoan_MatrixComputations}, \emph{Boyd} and
\emph{Vandenberghe}~\cite[Appendixes A, B and
C]{BoydVandenberghe_ConvexOptimization}, \emph{Antoniou} and 
\emph{Lu}~\cite[Appendix A]{AntoniouLu_PracticalOptimization},
\emph{Gallier}~\cite{Gallier_SchurComplement} and many, many other on-line
resources.

\section{\label{app:Linear-algebra-norm-of-matrix}Norm of a matrix}
The vector norms are:
\begin{align*}
\| x\| _{p} &= \left(\left|x_{1}\right|^{p}+\cdots+\left|x_{n}\right|^{p}\right)^{\frac{1}{p}}\quad p\ge1\\
\| x\|_{\infty} &= \max_{1\le i\le n}\left|x_{i}\right|
\end{align*}
$\| x\| $ is assumed to mean $\| x\| _{2}$. 

The matrix norm, $\|{}A\|_{\alpha,\beta}$, is:
\begin{align*}
  \|{}A\|_{\alpha,\beta}
  &=\sup_{x\ne{}0}\frac{\|{}Ax\|_{\beta}}
    {\|{}x\|_{\alpha}}
\end{align*}

\emph{Golub and Van Loan} 
~\cite[Section 2.3.1, Section 2.2.1]{GolubVanLoan_MatrixComputations}
define the \emph{Frobenius norm} (also called the \emph{Euclidean norm}) of a
matrix, $A$, as
\begin{align*}
\| A\| _{F} &= \sqrt{\sum_{i=1}^{m}\sum_{j=1}^{n}\left|a_{ij}\right|^{2}}
\end{align*}

The Octave manual defines the Frobenius norm of a matrix, $A$, as:
\begin{small}
\begin{verbatim}
norm(A,"fro") = sqrt(sum(diag(A'*A))
\end{verbatim}
\end{small}

\section{\label{app:Linear-algebra-trace-of-matrix}Trace of a matrix}
The elements of the product of two matrixes, $\boldsymbol{R}$ and
$\boldsymbol{S}$, of equal size, are:
\begin{align*}
  [RS]_{kl} &= \sum_{m}R_{km}S_{ml}
\end{align*}
The \emph{trace} of a matrix is the sum of the diagonal elements:
\begin{align*}
  \mathtrace\left(\boldsymbol{T}\right) &= \sum_{n}T_{nn}
\end{align*}
For a column vector, $\boldsymbol{y}$, and a matrix, $\boldsymbol{Q}$:
\begin{align*}
  \boldsymbol{y}^{\top}\boldsymbol{Q}\boldsymbol{y}
  &=\sum_{k}\sum_{l}Q_{kl}y_{k}y_{l}\\
  &=\sum_{k}\sum_{l}Q_{kl}Y_{kl} \\
  &=\mathtrace\left(\boldsymbol{QY}\right)
\end{align*}
where $\boldsymbol{Y}=\boldsymbol{y}\boldsymbol{y}^{\top}$ is symmetric. If
$\boldsymbol{Q}$ is also symmetric, then:
\begin{align*}
  \mathtrace\left(\boldsymbol{QY}\right)
  &=2\sum_{k<l}Q_{kl}Y_{kl} + \sum_{k}Q_{kk}Y_{kk}
\end{align*}

\section{\label{app:Linear-algebra-range-and-null-space-of-matrix}Rank, range, span and null-space of a matrix}
\emph{Golub and Van Loan}~\cite[Section
2.1.2]{GolubVanLoan_MatrixComputations} define the \emph{range} and
\emph{null-space} or \emph{kernel} of a matrix, $B$,  as
\begin{align*}
\mathrange\left(B\right) &= \left\{ y\in\mathbb{R}^{n}\mid y=Bx\;,\; x\in\mathbb{R}^{n}\right\}\\
\mathnull\left(B\right) &= \left\{ x\in\mathbb{R}^{n}\mid Bx=0\right\} 
\end{align*}
If $B=\left[b_{1},\ldots,b_{n}\right]$ is a column vector partitioning
then the \emph{span} of $B$ is the set of all linear combinations
of those column vectors
\begin{align*}
\mathspan\left\{ b_{1},\ldots,b_{n}\right\}&=\left\{ \sum_{j=1}^{n}\beta_{j}b_{j}\mid\beta_{j}\in\mathbb{R}\right\} 
\end{align*}
\emph{Golub and Van Loan}~\cite[Theorem
2.5.2]{GolubVanLoan_MatrixComputations} show that if $A$ is a real $m$-by-$n$
matrix then there exist orthogonal matrixes:
\begin{align*}
  U&=\left[ u_{1},\ldots,u_{m}\right]\in\mathbb{R}^{m\times{}m} \\
  V&=\left[ v_{1},\ldots,v_{n}\right]\in\mathbb{R}^{n\times{}n}
\end{align*}
such that:
\begin{align*}
  U^{\top}AV&=\mathdiag\left[\sigma_{1},\hdots,\sigma_{p}\right]\in\mathbb{R}^{m\times{}n}\quad p=\min\left(m,n\right)
\end{align*}
where $\sigma_{1}\ge\sigma_{1}\ge\hdots\ge\sigma_{p}\ge{}0$. The $\sigma_{k}$
are called the \emph{singular values} of $A$. Define $r$ by:
\begin{align*}
\sigma_{1}\ge\sigma_{1}\ge\hdots\ge\sigma_{r}>\sigma_{r+1}=\hdots\sigma_{p}=0
\end{align*}
then, given the singular value decomposition (SVD) of a
matrix, $A$:
\begin{align*}
\mathrank\left(A\right)&=r \\
\mathnull\left(A\right) &= \mathspan\left\{ v_{r+1},\ldots,v_{n}\right\} \\
\mathrange\left(A\right) &= \mathspan\left\{ u_{1},\ldots,u_{r}\right\} \\
A&=\sum_{k=1}^{r}\sigma_{k}u_{k}v_{k}^{\top} =U\Sigma{}V^{\top}
\end{align*}
The columns of $U$, $U^{\mathconj}$, $V$ and $V^{\mathconj}$ each form an
\emph{orthonormal basis}. The column vectors, $u_{k}$, are called \emph{left
singular vectors}. Similarly, the column vectors, $v_{k}$, are called \emph{right
singular vectors}.

\section{\label{app:Linear-algebra-determinants}Matrix determinants}
\subsection{Definitions}
The following definitions of the determinant of a matrix are equivalent:
\begin{enumerate}
\item The determinant is a function of a square matrix
  $A\in\mathbb{R}^{n\times{}n}$, $\det:\left\{A\mapsto\mathbb{R}\right\}$,
  with the following properties: 
  \begin{itemize}
  \item row replacement on row $r_{k}$ (ie: $r_{k}=r_{k}+m\times r_{l}$)
    does not change $\det A$
  \item scaling a row by a scalar $p$ multiplies $\det A$ by $p$
  \item swapping adjacent rows of $A$ multiplies $\det A$ by $-1$
  \item the determinant of the identity matrix $I_{n}$ is $1$
  \end{itemize}

\item Suppose a square matrix, $A$, is reduced to row-echelon form, $B$, by
  Gaussian elimination. Then:
  \begin{align*}
    \det A &= -1^{s}\times\frac{\text{product of the diagonal entries of }B}
             {\text{product of the scaling factors used}}
  \end{align*}
  where $s$ is the number of row swaps performed. This is often the most
  efficient means of calculating $\det{A}$.

\item The parallelpiped determined by $n$ vectors
  $r_{1},\hdots,r_{n}\in\mathbb{R}^{n}$ is the set
  $P=\left\{p_{1}r_{1}+\hdots+p_{n}r_{n}\;\vert\;0\le p_{1},\hdots,
    p_{n}\le 1\right\}$. If $A$ is the matrix formed from the rows, $r_{k}$,
  then the volume of the parallelpiped is $\mathabs{\det A}$. If the unit
  cube is transformed by the affine transformation corresponding to matrix $A$
  and then by that for matrix $B$ it follows that
  $\det{AB}=\det{A}\times\det{B}$ and that
  $\det{A^{-1}}=\left[\det{A}\right]^{-1}$.

\item The \emph{$\left(k,l\right)$-minor} of $A\in\mathbb{R}^{n\times{}n}$,
  $M_{kl}$, is the determinant of the $\left(n-1\right)\times\left(n-1\right)$
  matrix formed by deleting row $k$ and column $l$ of $A$. The \emph{cofactor}
  matrix of $A$ is $C=\left(\left(-1\right)^{k+l}M_{kl}\right)$. The
  \emph{adjugate} matrix of $A$ is $\mathadj{A}=C^{\top}$. The adjugate matrix
  is defined so that $A\mathadj{A}=\mathadj{A}A=\det{A}I_{n}$ and
  $A^{-1}=\left[\det A\right]^{-1}\mathadj{A}$. If the entries of $A$ are
  $a_{kl}$ and the entries of $C$ are $c_{kl}=\left(-1\right)^{k+l}M_{kl}$, then
  the \emph{cofactor expansion alongthe $k$'th row} is
  $\det{A}=\sum_{l=1}^{n}a_{kl}C_{kl}$. The \emph{cofactor expansion along the
    $l$'th column} is similar.
\end{enumerate}

\subsection{Matrix exponential}
The \emph{matrix exponential} is given by the power series:
\begin{align*}
  e^{A}&=\sum_{k=0}^{\infty}\frac{1}{k!}A^{k}
\end{align*}
\emph{Jacobi}'s formula for the derivative of the determinant of a matrix, $A$,
is:
\begin{align*}
  \frac{d}{dt}\det{A\left(t\right)}
  &= \mathtrace\left(\mathadj{A\left(t\right)}\frac{d}{dt}A\left(t\right)\right)
\end{align*}
The following corollory is obtained by substituting $A\left(t\right)=e^{tB}$:
\begin{align*}
  \det{e^{tB}} &= e^{\mathtrace{tB}}
\end{align*}

\section{\label{app:Linear-algebra-positive-definite-matrixes}Positive-definite matrixes}
A matrix, $Q \in \mathbb{R}^{n\times n}$, is positive-definite if 
$x^{\top}Qx>0$ for all nonzero $x \in \mathbb{R}^{n}$.

A complex matrix can be expressed in terms of the real and imaginary parts
as $Z=X+\imath{}Y$. The matrix $Z$ is positive-definite if, for all complex
vectors $z$, $z^{\mathconj}Zz$ is real and greater than $0$ ($\mathconj$
represents the complex conjugate transpose operation). If $z=x+\imath{}y$, then:
\begin{align*}
  z^{\mathconj}Zz
  &= \left(x^{\top}-\imath{} y^{\top}\right)
    \left(X+\imath{}Y\right)
    \left(x+\imath{}y\right) \\
  &= \left(x^{\top}X-\imath{}y^{\top}X+\imath{}x^{\top}Y+y^{\top}Y\right)
    \left(x+\imath{}y\right) \\
  &= x^{\top}Xx-\imath{}y^{\top}Xx+\imath{}x^{\top}Yx+y^{\top}Yx
    +\imath{}x^{\top}y+y^{\top}Xy-x^{\top}Yy+\imath{}y^{\top}Yy \\
  &=\left(x^{\top}Xx+y^{\top}Xy\right)+\imath{}\left(x^{\top}Yx+y^{\top}Yy\right)
\end{align*}
$Z\succ{}0$ if-and-only-if $x^{\top}Yx+y^{\top}Yy=0$ and $\left[\begin{array}{cc}
  \phantom{-} X & Y \\
             -Y & X\end{array}\right] \succ{}0$. Alternatively, $Z\succ{}0$
if-and-only-if $Z$ is \emph{Hermitian}, that is $Z^{\top} = \bar{Z}$, where
$\bar{Z}$ means the element-wise conjugate of $Z$.

\section{\label{app:Linear-algebra-Schur-complement}Schur complement}
This section follows \emph{Gallier}~\cite{Gallier_SchurComplement}. See also
\emph{J\"{o}nsson}~\cite[Section 2.1]{Jonsson_LectureOnSProcedure}. The
\emph{Schur} complement is often used to convert non-linear matrix inequalities
into linear matrix inequalities.
\subsection{Schur complement of a matrix}

The \emph{Schur complement} appears in the decomposition of a matrix
$M=\left[\begin{array}{cc} 
            A & B \\
            C & D \end{array}\right]$ when solving the linear system:
\begin{align*}
  \left[\begin{array}{cc}
           A & B \\
           C & D \end{array}\right]          
  \left[\begin{array}{c}
           x \\
           y \end{array}\right] &=
  \left[\begin{array}{c}
           c \\
           d \end{array}\right]          
\end{align*}
If $D$ is invertible:
\begin{align*}
  y &= D^{-1}\left(d-Cx\right)
\end{align*}
Substituting:
\begin{align*}
  Ax+BD^{-1}\left(d-Cx\right)&=c \\
  \left(A-BD^{-1}C\right)x&=c-BD^{-1}d
\end{align*}
If $A-BD^{-1}C$ is invertible, then:
\begin{align*}
  x &=\left(A-BD^{-1}C\right)^{-1}c-\left(A-BD^{-1}C\right)^{-1}BD^{-1}d \\
  y &=D^{-1}\left(d-C\left(A-BD^{-1}C\right)^{-1}\left(c-BD^{-1}d\right)\right)
\end{align*}
so that:
\begin{align*}
  \left[\begin{array}{cc}
          A & B \\
          C & D \end{array}\right]^{-1}
  &=\left[\begin{array}{cc}
          \left(A-BD^{-1}C\right)^{-1}
          & -\left(A-BD^{-1}C\right)^{-1}BD^{-1} \\
          -D^{-1}C\left(A-BD^{-1}C\right)^{-1}
          & D^{-1}+D^{-1}C\left(A-BD^{-1}C\right)^{-1}BD^{-1}\end{array}\right]\\
  &=\left[\begin{array}{cc}
          \left(A-BD^{-1}C\right)^{-1} & 0 \\
          -D^{-1}C\left(A-BD^{-1}C\right)^{-1} & D^{-1}\end{array}\right]   
    \left[\begin{array}{cc}
            I & -BD^{-1} \\
            0 & I\end{array}\right]\\
  &=\left[\begin{array}{cc}
          I & 0\\
          -D^{-1}C & I \end{array}\right]   
     \left[\begin{array}{cc}
          \left(A-BD^{-1}C\right)^{-1} & 0 \\
          0 & D^{-1}\end{array}\right]   
    \left[\begin{array}{cc}
            I & -BD^{-1} \\
            0 & I\end{array}\right]
\end{align*}
Since:
\begin{align*}
    \left[\begin{array}{cc}
            I & -BD^{-1} \\
            0 & I\end{array}\right]^{-1}
                &=
    \left[\begin{array}{cc}
            I & BD^{-1} \\
            0 & I\end{array}\right]
\end{align*}
then:
\begin{align*}
  \left[\begin{array}{cc}
          A & B \\
          C & D \end{array}\right]
            &=
    \left[\begin{array}{cc}
            I & BD^{-1} \\
            0 & I\end{array}\right]
    \left[\begin{array}{cc}
            A-BD^{-1}C & 0 \\
            0 & D \end{array}\right]   
    \left[\begin{array}{cc}
            I & 0 \\
            D^{-1}C & I \end{array}\right]
\end{align*}
$A-BD^{-1}C$ is called the \emph{Schur complement of $D$ in $M$}\footnote{A
corollary is:
$\det{\left[\begin{array}{cc}
      A & B \\
      C & D \end{array}\right]} =\det\left[A-BD^{-1}C\right]\times\det{D}$.}.

Alternatively, if $A$ and $D-CA^{-1}B$ are invertible, and with
$x=A^{-1}\left(c-By\right)$:  
\begin{align*}
  \left[\begin{array}{cc}
          A & B \\
          C & D \end{array}\right]^{-1}
  &=\left[\begin{array}{cc}
            A^{-1}+A^{-1}B\left(D-CA^{-1}B\right)^{-1}CA^{-1}
            & -A^{-1}B\left(D-CA^{-1}B\right)^{-1} \\
            -\left(D-CA^{-1}B\right)^{-1}CA^{-1}
            & \left(D-CA^{-1}B\right)^{-1} \end{array}\right]\\
  &=\left[\begin{array}{cc}
          A^{-1} & -A^{-1}B\left(D-CA^{-1}B\right)^{-1} \\
          0     & \left(D-CA^{-1}B\right)^{-1} \end{array}\right]
  \left[\begin{array}{cc}
          I & 0\\
          -CA^{-1} & I \end{array}\right] \\
  &=  \left[\begin{array}{cc}
            I & -A^{-1}B \\
              0 & I\end{array}\right]
  \left[\begin{array}{cc}
          A^{-1} & 0 \\
          0 & \left(D-CA^{-1}B\right)^{-1}\end{array}\right]   
  \left[\begin{array}{cc}
          I & 0\\
          -CA^{-1} & I \end{array}\right]\\
  \left[\begin{array}{cc}
          A & B \\
          C & D \end{array}\right]
  &=\left[\begin{array}{cc}
          I & 0\\
          CA^{-1} & I \end{array}\right]   
     \left[\begin{array}{cc}
          A & 0 \\
          0 & D-CA^{-1}B\end{array}\right]   
    \left[\begin{array}{cc}
            I & A^{-1}B \\
            0 & I\end{array}\right]
\end{align*}
$D-CA^{-1}B$ is the \emph{Schur complement of $A$ in $M$}.

Comparing the two decompositions of $M$:
\begin{align*}
  \left(A-BD^{-1}C\right)^{-1}&=A^{-1}+A^{-1}B\left(D-CA^{-1}B\right)^{-1}CA^{-1}
\end{align*}
so that:
\begin{align*}
  \left[\begin{array}{cc}
          A & B \\
          C & D \end{array}\right]^{-1}
  &=\left[\begin{array}{cc}
  \left(A-BD^{-1}C\right)^{-1}&-A^{-1}B\left(D-CA^{-1}B\right)^{-1} \\
 -\left(D-CA^{-1}B\right)^{-1}CA^{-1}&\left(D-CA^{-1}B\right)^{-1}\end{array}\right]
\end{align*}
\subsection{\label{app:Linear-algebra-Schur-complement-positive-definite}Schur complement of a positive definite matrix}
If $M$ is symmetric ($A$ and $D$ are symmetric and $C=B^{\top}$) then if $D$ is
invertible:
\begin{enumerate}
  \item $M\succ{}0\Leftrightarrow D\succeq{}0$ and $A-BD^{-1}B^{\top}\succ{}0$
  \item If $D\succ{}0$, then $M\succeq{}0\Leftrightarrow A-BD^{-1}B^{\top}\succeq{}0$
\end{enumerate}
Similarly, if $A$ is invertible, then:
\begin{enumerate}
  \item $M\succ{}0\Leftrightarrow A\succeq{}0$ and $D-B^{\top}A^{-1}B\succ{}0$
  \item If $A\succ{}0$, then $M\succeq{}0\Leftrightarrow D-B^{\top}A^{-1}B\succeq{}0$
\end{enumerate}
These results follow from:
\begin{enumerate}
  \item a block diagonal matrix, $M$, is positive definite, $M\succ{}0$,
    $\Leftrightarrow$  each diagonal block is positive definite
  \item if matrix $T$ is symmetric and matrix $N$ is invertible then
    $T\succ{}0 \Leftrightarrow NTN^{\top}\succ{}0$
  \item the block decomposition of $M$ with $\left[\begin{array}{cc}
          A & B \\
          B^{\top} & D \end{array}\right]\succ{}0
 \Leftrightarrow
  \left[\begin{array}{cc}
          D & B^{\top} \\
          B & A \end{array}\right]\succ{}0$
\end{enumerate}

Given the quadratic constraint:
\begin{align*}
  \left(Ax+b\right)^{\top}  \left(Ax+b\right)\le c^{\top}x+d
\end{align*}
the equivalent positive semi-definite condition:
\begin{align*}
  \left[\begin{array}{cc}
          I &  \left(Ax+b\right)\\
          \left(Ax+b\right)^{\top} & c^{\top}x+d \end{array}\right]\succeq{}0
\end{align*}
follows from the properties of the \emph{Schur complement}.
\clearpage
\section{\label{app:Linear-algebra-convex-vector-space}Convex vector spaces}

\subsection{Definitions on convex sets}
See, for example, \emph{J\"{o}nsson}~\cite[Section
2]{Jonsson_LectureOnSProcedure}.
A set, $\mathcal{C}$, in a linear vector space is \emph{convex} if
$\alpha{}x_{1}+\left(1-\alpha\right)x_{2}\in\mathcal{C}$ for all
$x_{1},x_{2}\in\mathcal{C}$ and $\alpha\in\left[0,1\right]$.

A set, $\mathcal{C}$, is a \emph{convex cone} if it is convex and
$\alpha{}x\in\mathcal{C}$ for all $x\in\mathcal{C}$ and all $\alpha{}>0$.

A \emph{convex polytope}, $\mathcal{C}$, with vertices at
$x_{1},\hdots,x_{n}\in\mathbb{R}^{m}$ is defined as the convex hull of those
points:
\begin{align*}
  \mathcal{C}
  &= \mathcohull\left\{x_{1} , \hdots , x_{n}\right\}
    =\left\{\sum_{k=0}^{n}\alpha_{k}x_{k} :
     \alpha_{k}\ge{}0, \;\sum_{1}^{n}\alpha_{k}=1\right\}
\end{align*}

An \emph{ellipsoid}, $\mathcal{E}$, with centre $m$, can be defined by:
\begin{align*}
  \mathcal{E}
  &= \left\{x:\left(x-m\right)^{\top}Q^{-1}\left(x-m\right)\le 1\right\} \\
  &= \left\{x:x^{\top}Px+2x^{\top}b+c\le 0\right\}
\end{align*}
where $Q$ is positive definite and symmetric. In the second characterisation
$P=Q^{-1}$, $b=-Q^{-1}m$ and $c=m^{\top}Q^{-1}m-1$. The size, shape and location
of the ellipsoid are determined by $m$ and $Q$. The orientation of $\mathcal{E}$
is determined by the eigenvectors of $Q$ and the lengths of the semi-axes of
$\mathcal{E}$ are defined by the eigenvalues of $Q$. The volume of an ellipsoid
is: 
\begin{align*}
  V\left(\mathcal{E}\right)
  &= k\left(n\right)\det\left(Q\right)^{\frac{1}{2}}
    =k\left(n\right)\det
    \left(\left(b^{\top}P^{-1}b-c\right)P^{-1}\right)^{\frac{1}{2}}
\end{align*}
where $k\left(n\right)$ is a dimension-dependent constraint.
A linear transformation of the ellipsoid, $\mathcal{E}$, changes the centre,
shape and location:
\begin{align*}
  \tilde{\mathcal{E}}
  &=A\mathcal{E}+b \\
  &= \left\{y:y=Ax+b:x\in\mathcal{E}\right\} \\
  &= \left\{y:\left(y-b-Am\right)^{\top}
    \left(AQA^{\top}\right)^{-1}
    \left(y-b-Am\right)\le{} 1\right\} \\
\end{align*}

\subsection{The separating hyperplane theorem\label{sec:Separating-hyperplane-theorem}}
The \emph{separating hyperplane theorem} is an important result in convex
optimisation. I follow the finite dimensional proof of
\emph{J\"{o}nsson}~\cite[Section 3]{Jonsson_LectureOnSProcedure}. Also see
\emph{Rockafellar}~\cite[Section 11]{Rockafellar_ConvexAnalysis}.

\emph{J\"{o}nsson} makes  the following definitions relating to a \emph{linear
  vector space}, $V$, over the real numbers, $\mathbb{R}$: 
\begin{itemize}
\item a \emph{linear functional} on $V$ is a function
  $f:V\mapsto\mathbb{R}$, which is linear,
  i.e.\ $f\left(\alpha_{1}v_{1}+\alpha_{2}v_{2}\right)=
  \alpha_{1}f\left(v_{1}\right)+\alpha_{2}f\left(v_{2}\right)$
  for all $v_{1},v_{2}\in{}V$ and $\alpha_{1},\alpha_{2}\in\mathbb{R}$ 
\item the continuous linear functions on $V$ also make a vector space, called
  the \emph{dual} of $V$, denoted $\hat{V}$ 
\item in applications considering a finite dimensional Hilbert space over
  $\mathbb{R}$, the dual space is $\hat{V}=V$ itself, and the linear functional
  $\hat{v}\left(v\right)\coloneq\langle v,\hat{v}\rangle$ is the inner product
\item the \emph{affine hull} of $S$, denoted by  $\mathaff S$, is the set of all
      linear combinations of the form $\sum\alpha_{k}x_{k}$ where $x_{k}\in S$ and
      $\sum\alpha_{k}=1$ 
\item the \emph{relative interior} of a set $S\subset\mathbb{R}$, denoted by
  $\mathri S$, is the set of points of $S$ which are interior relative to
  $\mathaff S$. This means that for any $x\in S$, there exists an
  $\varepsilon >0$ such that all $y\in \mathaff S$ with
  $\mathabs{x-y}<\varepsilon$ are also members of $S$
\item a \emph{hyperplane} is an affine subset of $V$ with maximal dimension. In
  other words, if $V$ has dimension $n$, then every hyperplane is a translation
  of an $n-1$ dimensional subspace of $V$. A hyperplane can be represented as
  $H=\left\{x\in V:\langle v,z\rangle = c \right\}$ for $z\in \hat{V}$ and
    $c\in\mathbb{R}$.
  The sets $H=\left\{x\in V:\langle v,z\rangle\ge c \right\}$ and
    $H=\left\{x\in V:\langle v,z\rangle\le c \right\}$ are closed half-spaces
    of $V$
\end{itemize}

\emph{J\"{o}nsson} states the following lemma:

\framebox{\begin{minipage}[t]{0.9\columnwidth}
    \emph{The separation lemma: } Let $C\subset{}V$ be a relatively open convex
    set (ie: $\mathri{}C=C$) in a finite dimensional vector space, $V$, and let
    $V_{1}$ be a linear subspace of $V$ such that $C\cap{}V_{1}=\emptyset$. Then
    there exists a hyperplane containing $V_{1}$ such that one of the open
    half-spaces associated with the hyperplane contains $C$, ie:
    $\exists z\in V^{\star}\setminus{}0 \text{ such that }
   \langle x,z \rangle >0 \;     \forall x\in C \text{ and }
   \langle x,z \rangle \le 0 \;  \forall x\in V_{1}$.
  \end{minipage}}

\emph{J\"{o}nsson} applies this lemma to prove the following theorem:

\framebox{\begin{minipage}[t]{0.9\columnwidth}
\emph{Theorem: } Let $C_{1}$ be an open convex cone and $C_{2}$ be a convex
set. If these sets are disjoint, $C_{1}\cap C_{2}=\emptyset$, then there exists
a separating hyperplane, ie: $\exists z\in V^{\star}\setminus 0 \text{ such that }
   \langle x_{1},z \rangle >0 \;     \forall x_{1}\in C_{1} \text{ and }
   \langle x_{2},z \rangle \le 0 \;  \forall x_{2}\in C_{2}$.
 \end{minipage}}

\subsection{\label{app:Jonsson-S-procedure}The S-procedure}
\emph{J\"{o}nsson}~\cite[Section 4]{Jonsson_LectureOnSProcedure}\footnote{See
  also, for example, \emph{P\'{o}lik} and
  \emph{Terlaky}~\cite{PolikTerlaky_SurveySLemma}.} describes the
S-procedure as follows. Let $\sigma_{k}:V\mapsto\mathbb{R}$, $k=0,\hdots,N$,
be real valued functionals on a linear vector space $V$ and consider the
following two conditions:

$S_{1}:\sigma_{0}\left(y\right)\ge 0\; \forall\; y\in V \text{ such that }
\sigma_{k}\left(y\right)\ge 0,\;k=1,\hdots,N$

$S_{2}:\exists\;\tau_{k}\ge 0,\;k=1,\hdots,N\text{ such that }
\sigma_{0}\left(y\right)-\sum_{k=1}^{N}\tau_{k}\sigma_{k}\left(y\right)\ge 0$

Clearly $S_{2}\Rightarrow S_{1}$. The S-procedure is the method of verifying
that $S_{1}\Rightarrow S_{2}$.

Suppose that the functionals are quadratic,
$\sigma_{k}\left(y\right)=y^{\top}Q_{k}y+2s_{k}^{\top}y+r_{k},\; k=0,\hdots,N$,
where $Q_{k}=Q_{k}^{\top}\in\mathbb{R}^{m\times m}$, $s_{k}\in\mathbb{R}^{m}$
and $r_{k}\in\mathbb{R}$. In general, $\sigma_{0}$ is not convex and, likewise,
the set of constraints, $\left\{y\in\mathbb{R}^{m}:\sigma_{k}\left(y\right)\ge
  0,\; k=1,\hdots,N\right\}$ is not convex. On the other hand, $S_{2}$
corresponds to a linear matrix inequality:
\begin{align*}
  S_{2}
  &\Leftrightarrow \exists\;\tau_{k}\ge 0\text{ such that }
\sigma_{0}\left(y\right)-\sum_{k=1}^{N}\tau_{k}\sigma_{k}\left(y\right)\ge
          0,\;\forall\; y\in\mathbb{R}^{m}\\
  &\Leftrightarrow \exists\;\tau_{k}\ge 0\text{ such that }
    \left[\begin{array}{cc}
            Q_{0} & s_{0}\\
            s_{0}^{\top} & r_{0}\end{array}\right]
    -\sum_{k=1}^{N}\tau_{k}
    \left[\begin{array}{cc}
            Q_{k} & s_{k}\\
            s_{k}^{\top} & r_{k}\end{array}\right] \succeq 0
\end{align*}

If the conditions $S_{1}$ and $S_{2}$ are equivalent, then the S-procedure is
said to be \emph{lossless}. The constraints $\sigma_{k}\left(y\right)\ge 0$
for $k=1,\hdots,N$ are said to be \emph{regular} if $\exists\; y^{\star}\in V$
such that $\sigma_{k}\left(y^{\star}\right)\ge 0$.

\emph{J\"{o}nsson}~\cite{Jonsson_LectureOnSProcedure} gives the following
example of the application of the S-procedure to a quadratic programming problem
with one quadratic constraint:
\begin{align*}
\textbf{minimise}   \quad & y^{\top}Q_{0}y+2s_{0}^{\top}y+r_{0}\\
\textbf{subject to} \quad & y^{\top}Q_{1}y+2s_{1}^{\top}y+r_{1}\ge 0
\end{align*}
A lower bound is obtained by the semi-definite relaxation:
\begin{align*}
\textbf{minimise}   \quad & \mathtrace{Q_{0}Y}+2s_{0}^{\top}y+r_{0}\\
\textbf{subject to} \quad & \mathtrace{Q_{1}Y}+2s_{1}^{\top}y+r_{1}\ge 0\\\
   & \left[\begin{array}{cc}
          Y & y \\
          y^{\top} & 1\end{array}\right]\succeq 0
\end{align*}
since $\mathtrace{Q_{k}yy^{\top}}=y^{\top}Q_{k}y$ and the second constraint is
equivalent to $Y\succeq yy^{\top}$.

The dual problem of the semi-definite relaxation is:
\begin{align*}
\textbf{maximise}   \quad & \gamma \\
\textbf{subject to} \quad & \left[\begin{array}{cc}
          Q_{0}-\lambda Q_{1} & s_{0}-\lambda s_{1} \\
          s_{0}^{\top}-\lambda s_{1}^{\top} & r_{0}-\lambda r_{1}-\gamma
                                  \end{array}\right]\succeq 0 \\
  & \lambda \ge 0 \\
  & \gamma \in \mathbb{R}
\end{align*}

\subsection{The \emph{log det A} penalty function}
The $\log\det A$ function is widely used as a penalty function in convex
optimisation. \emph{VanAntwerp} and
\emph{Braatz}~\cite[Appendix]{VanAntwerpBraatz_LinearBilinearMatrixInequalities} 
show that the function $-\log\det A$ is convex if $A=A^{\top}\succ 0$.
Their proof uses the following lemma:

\emph{Lemma: } A function $f\left(x\right)$ is convex in $x\in S$
if-and-only-if $f\left(t\right)=f\left(x_{0}+th\right)$ is convex in $t$
for all $x_{0}$, $h$ and $t$ such that $x_{0}+th\in S$ and $x_{0}\in S$.

The proof begins by defining $S=\left\{A \; : \; A=A^{\top}\succ 0\right\}$.
The lemma implies that $-\log\det A$ is convex in $A$ on $A=A^{\top}\succ 0$
if-and-only-if $-\log\det \left(A_{0}+tH\right)$ is convex in $t$ for all  
$A_{0}=A_{0}^{\top}\succ 0$ and $H$ which satisfy
$A_{0}+tH =\left(A_{0}+tH\right)^{\top} \succ 0$. The latter condition is
equivalent to $I+tA_{0}^{-\frac{1}{2}}HA_{0}^{-\frac{1}{2}} \succ 0$. Also,
if $\lambda_{k}$ are the eigenvalues\footnote{The eigenvalues,
  $\lambda_{k}$, of $A$ are the solutions of
  $\det\left(\lambda I -A\right)$. Also $\det A =\prod_{k}\lambda_{k}$.}
 of $A_{0}^{-\frac{1}{2}}HA_{0}^{-\frac{1}{2}}$,
then $1+t\lambda_{k}$ are the eigenvalues of
$I+tA_{0}^{-\frac{1}{2}}HA_{0}^{-\frac{1}{2}}$. Combining these:
\begin{align*}
-\log\det \left(A_{0}+tH\right)
&= -\log\det A_{0}-\log\det\left(I+tA_{0}^{-\frac{1}{2}}HA_{0}^{-\frac{1}{2}}\right)\\
&= -\log\det A_{0}-\sum_{k}\log\left(1+t\lambda_{k}\right)
\end{align*}

The first and second derivatives of the summand are:
\begin{align*}
  -\frac{d}{dt}\log\left(1+t\lambda_{k}\right)
  &=-\frac{\lambda_{k}}{1+t\lambda_{k}} \\
  -\frac{d^{2}}{dt^{2}}\log\left(1+t\lambda_{k}\right)
  &=\frac{\lambda_{k}^{2}}{\left(1+t\lambda_{k}\right)^{2}} \\
\end{align*}
The second derivative is positive implying that
$-\log\det\left(A_{0}+tH\right)$ is convex in $t$ for all $t$.

\chapter{\label{app:Review-of-Chebyshev-polynomials}Review of Chebyshev's polynomials}
This appendix gathers together results for
\emph{Chebyshev's polynomials of the first and second kind}.

An FIR filter approximation function is generally written as:
\begin{align*}
  H\left(z\right) &= \sum ^{N}_{k=0}h_{k}z^{-k}
\end{align*}
If $N=2M$ and the filter is symmetric, $h_{k}=h_{N-k}$, then the amplitude
response is: 
\begin{align*}
  A\left(\omega\right) &= a_{0}+\sum ^{M}_{k=1}2 a_{k}\cos k\omega
\end{align*}
where $a_{k}=h_{k+M}$. The \emph{Chebyshev polynomials of the first kind} are:
\begin{align}
  T_{k}\left(\cos\omega\right) &= \cos k\omega
\label{eqn:Chebyshev-type-1-trigonmetric}
\end{align}

The Octave function \emph{chebyshevT(k)} returns the coefficients of the $k$'th
Chebyshev polynomial of the first kind.
Figure~\ref{fig:Chebyshev-polynomials-first-kind} plots the first seven Chebyshev
polynomials of the first kind. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{chebyshevT_test_Tk}}
\caption{Chebyshev polynomials of the first kind}
\label{fig:Chebyshev-polynomials-first-kind}
\end{figure}

Similarly, the \emph{Chebyshev polynomials of the second kind} are:
\begin{align*}
  U_{k}\left(\cos\omega\right)\sin\omega &= \sin \left(k+1\right)\omega
\end{align*}

The \emph{Chebyshev polynomials of the second kind} are related to the
\emph{Dirichlet kernel}
\footnote{The convolution of the $k$'th Dirichlet kernel,
  $D_{k}\left(x\right)$, with a function, $f$, of period $2\pi$, is the $k$'th
  degree Fourier series approximation to $f$: 
  \begin{align*}
    \left(D\star f\right)\left(x\right)
    &=\int^{\pi}_{-\pi}f\left(y\right) D_{k}\left(x-y\right)dy
      =\sum^{k}_{l=-k}\hat{f}\left(l\right)e^{\imath lx}
  \end{align*}
  where:
  \begin{align*}
    \hat{f}\left(l\right)
    &=\frac{1}{2\pi}\int^{\pi}_{-\pi}f\left(x\right)e^{-\imath lx}dx
  \end{align*}
}, $D_{k}\left(x\right)$:
\begin{comment}
\begin{align*}
  2\pi D_{k}\left(x\right)
  &=\sum^{k}_{l=-k}e^{\imath lx} \\
  &=e^{-\imath kx}\sum^{2k}_{l=0}e^{\imath lx} \\
  &=e^{-\imath kx}\frac{e^{\imath\left(2k+1\right)\frac{x}{2}}}{e^{\imath\frac{x}{2}}}
    \frac{e^{\imath\left(2k+1\right)\frac{x}{2}}-e^{-\imath\left(2k+1\right)\frac{x}{2}}}
    {e^{\imath\frac{x}{2}}-e^{-\imath\frac{x}{2}}} \\
  
  &= \frac{\sin \left(2k+1\right)\frac{x}{2}}{\sin\frac{x}{2}} \\
  &= U_{2k}\left(\cos\frac{x}{2}\right)
\end{align*}
\end{comment}
\begin{align*}
  2\pi D_{k}\left(x\right)  &= 1+2\sum^{k}_{l=1}\cos lx  \\
  &=\sum^{k}_{l=-k}e^{\imath lx}\\
  &= \frac{\sin \left(2k+1\right)\frac{x}{2}}{\sin\frac{x}{2}} \\
  &= U_{2k}\left(\cos\frac{x}{2}\right)
\end{align*}

The Octave function \emph{chebyshevU(k)} returns the coefficients of the $k$'th
Chebyshev polynomial of the second kind.
Figure~\ref{fig:Chebyshev-polynomials-second-kind} plots the first seven
Chebyshev polynomials of the second kind. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{chebyshevU_test_Uk}}
\caption{Chebyshev polynomials of the second kind}
\label{fig:Chebyshev-polynomials-second-kind}
\end{figure}

\section{Recurrence relations}
The Chebyshev polynomials of the first kind have the recurrence relation:
\begin{align}
\begin{split}
  T_{0}\left(x\right)&= 1 \\
  T_{1}\left(x\right)&= x \\
  T_{k+1}\left(x\right)&= 2xT_{k}\left(x\right)-T_{k-1}\left(x\right)
\end{split}
\label{eqn:Chebyshev-polynomial-first-kind-recurrence}
\end{align}
The recurrence follows from the trigonometric definition:
\begin{align*}
  T_{k+1}\left(\cos\omega\right) &= \cos\omega\; T_{k}\left(\cos\omega\right)
                                   -\sin\omega\sin k\omega \\
  T_{k-1}\left(\cos\omega\right) &= \cos\omega\; T_{k}\left(\cos\omega\right)
                                   +\sin\omega\sin k\omega
\end{align*}

The Chebyshev polynomials of the second kind have the recurrence relation:
\begin{align*}
  U_{0}\left(x\right)&= 1 \\
  U_{1}\left(x\right)&= 2x \\
  U_{k+1}\left(x\right)&= 2xU_{k}\left(x\right)-U_{k-1}\left(x\right)
\end{align*}
The recurrence follows from the trigonometric definition:
\begin{align*}
  U_{k+1}\left(\cos\omega\right)\sin\omega
  &=\cos\omega\sin\left(k+1\right)\omega
    +\sin\omega\cos\left(k+1\right)\omega \\
  U_{k-1}\left(\cos\omega\right)\sin\omega
   &=\cos\omega\sin\left(k+1\right)\omega
     -\sin\omega\cos\left(k+1\right)\omega
\end{align*}

Again, by substitution of the trigonometric definitions, the Chebyshev
polynomials of the first and second kinds are related by the recurrence
relations:
\begin{align*}
  T_{k+1}\left(x\right)&=
       \frac{1}{2}\left(U_{k+1}\left(x\right)-U_{k-1}\left(x\right)\right) \\
  T_{k}\left(x\right)&= U_{k}\left(x\right)-xU_{k-1}\left(x\right)
\end{align*}

\section{Differentiation and integration of the Chebyshev polynomials}
Differentiating  the trigonometric definition of $T_{k}\left(\cos\omega\right)$
with respect to $\omega$ gives: 
\begin{align*}
  \frac{dT_{k}\left(\cos\omega\right)}{d\omega}&=-k\sin k\omega
\end{align*}                                        

Substituting $x=\cos\omega$:
\begin{align*}
  \frac{dT_{k}\left(x\right)}{dx}
  = \frac{dT_{k}\left(\cos\omega\right)}{d\omega}\frac{d\omega}{dx}
  &=k\frac{\sin k\omega}{\sin\omega}\\
  &=kU_{k-1}\left(x\right)
\end{align*}

Consequently:
\begin{align*}
  T_{k+1}\left(x\right)&=\left(k+1\right)\int U_{k}\left(x\right) dx
\end{align*}

Similarly:                         
\begin{align*}
\frac{dU_{k}\left(x\right)}{dx}
  =\frac{dU_{k}\left(\cos\omega\right)}{d\omega}\frac{d\omega}{dx}
    &=\frac{-1}{\sin\omega}\frac{d}{d\omega}
      \frac{\sin\left(k+1\right)\omega}{\sin\omega}\\
    &=\frac{\left(k+1\right)T_{k+1}\left(x\right)-xU_{k}\left(x\right)}{x^{2}-1}
\end{align*}                                        

Finally, integrate $T_{k}\left(x\right)$ with the recurrence relation:
\begin{align*}
\int T_{k}\left(x\right)dx
  &=\frac{1}{2}\left[\int U_{k}\left(x\right)dx-
  \int U_{k-2}\left(x\right)dx\right]\\
  &=\frac{1}{2}\left[\frac{T_{k+1}\left(x\right)}{k+1}
    -\frac{T_{k-1}\left(x\right)}{k-1}\right]
\end{align*}

\section{Chebyshev differential equations}
The Chebyshev polynomials of the first kind satisfy the second order
differential equation: 
\begin{align*}
  \left(1-x^{2}\right)y^{\prime\prime}-xy^{\prime}+k^{2}y&=0
\end{align*}
since, from the previous section:
\begin{align*}
  \frac{dT_{k}\left(x\right)}{dx}-kU_{k-1}\left(x\right)&=0\\
  \frac{d^{2}T_{k}\left(x\right)}{dx^{2}}-k\frac{dU_{k-1}\left(x\right)}{dx}&=0\\
  \left(1-x^{2}\right)\frac{d^{2}T_{k}\left(x\right)}{dx^{2}}
  -kxU_{k-1}\left(x\right)+k^{2}T_{k}\left(x\right)&=0\\
  \left(1-x^{2}\right)\frac{d^{2}T_{k}\left(x\right)}{dx^{2}}
  -x\frac{dT_{k}\left(x\right)}{dx}+k^{2}T_{k}\left(x\right)&=0  
\end{align*}

The Chebyshev polynomials of the second kind satisfy the second order
differential equation: 
\begin{align*}
  \left(1-x^{2}\right)y^{\prime\prime}-3xy^{\prime}+k\left(k+2\right)y&=0
\end{align*}
since, similarly:
\begin{align*}
  \left(1-x^{2}\right)\frac{dU_{k}\left(x\right)}{dx}
  -xU_{k}\left(x\right)+\left(k+1\right)T_{k+1}\left(x\right)&=0\\
  \left(1-x^{2}\right)\frac{d^{2}U_{k}\left(x\right)}{dx^{2}}
  -3x\frac{dU_{k}\left(x\right)}{dx}-U_{k}\left(x\right)
  +\left(k+1\right)^{2}U_{k}\left(x\right)&=0\\
  \left(1-x^{2}\right)\frac{d^{2}U_{k}\left(x\right)}{dx^{2}}
  -3x\frac{dU_{k}\left(x\right)}{dx} +k\left(k+2\right)U_{k}\left(x\right)&=0
\end{align*}
\section{Orthogonality of the Chebyshev polynomials}
The Chebyshev polynomials of the first kind are orthogonal at the
\emph{Chebyshev nodes}, $x_{k}$: 
\begin{align}
  \sum^{n-1}_{k=0}T_{l}\left(x_{k}\right)T_{m}\left(x_{k}\right) &=\begin{cases}
    0 & \text{if } l\ne m \\
    n & \text{if } l = m = 0 \\
    \frac{n}{2} & \text{if } l = m \ne 0
  \end{cases}
  \label{eqn:Chebyshev-type-1-discrete-orthogonality}
\end{align}
where $n\ge\max\left(l,m\right)$ and $x_{k}$ are the $n$ zeros of
$T_{n}\left(x\right)$ in the interval $[-1,1]$:
\begin{align*}
  x_{k}=\cos\pi\frac{2k+1}{2n}\quad \text{for } k=0,1,\hdots,n-1
\end{align*}

\begin{comment}
The Chebyshev polynomials of the first kind, $T_{k}\left(x\right)$, are
solutions of the differential equation:
\begin{align*}
  \left(1-x^{2}\right)y^{\prime\prime}-xy^{\prime}+k^{2}y=0 \\
\end{align*}

\begin{align*}
  \left(1-x^{2}\right)y^{\prime\prime}-3xy^{\prime}+k\left(k+2\right)y=0 
\end{align*}

Consequently, the Chebyshev polynomials are orthogonal:
\begin{align*}
  \int^{1}_{-1}T_{l}\left(x\right)T_{m}\left(x\right)\frac{dx}{\sqrt{1-x^{2}}}
  &=\begin{cases}
    0 & \text{if }l \ne m \\
    \pi & \text{if }l=m=0 \\
    \frac{\pi}{2} & \text{if }l=m\ne 0
  \end{cases}
\end{align*}
and:
\begin{align*}
  \int^{1}_{-1}U_{l}\left(x\right)U_{m}\left(x\right)\sqrt{1-x^{2}}dx
  &=\begin{cases}
    0 & \text{if }l \ne m \\
    \frac{\pi}{2} & \text{if }l=m
  \end{cases}
\end{align*}


The weighted Chebyshev polynomials of the second kind are orthogonal
at the Chebyshev nodes.
\begin{align*}
  \sum^{n-1}_{k=0}U_{l}\left(x_{k}\right)U_{m}\left(x_{k}\right)
  \left(1-x_{k}^{2}\right) &=\begin{cases}
    0 & \text{if } l\ne m \\
    \frac{n}{2} & \text{if } l = m
    \end{cases}\\
\end{align*}

\section{Relations between the Chebyshev functions of the first and second kind}
The integral relations are:
\begin{align*}
  T_{k}\left(x\right) &= -\frac{1}{\pi}
                         \int^{1}_{-1}\frac{U_{k-1}\left(y\right)\sqrt{1-y^{2}}}
                        {\left(y-x\right)}dy \\
  U_{k-1}\left(x\right) &= \phantom{-}\frac{1}{\pi}
                          \int^{1}_{-1}\frac{T_{k}\left(y\right)}
                          {\left(y-x\right)\sqrt{1-y^{2}}}dy
\end{align*}
\end{comment}

\section{Approximation of functions by Clenshaw's recurrence}
The \emph{Clenshaw} algorithm~\cite[Sections 5.4 and
5.8]{Press_NumericalRecipesInC} calculates the weighted sum:
\begin{align*}
  S\left(x\right) &= \sum_{k=0}^{n}a_{k}\phi_{k}\left(x\right)
\end{align*}
where $\phi_{k}$, $k=0,1,\hdots$\;, is a sequence of functions that satisfy the
recurrence relation:
\begin{align*}
  \phi_{k+1}\left(x\right)&=\alpha_{k}\left(x\right)\phi_{k}\left(x\right)+
                            \beta_{k}\left(x\right)\phi_{k-1}\left(x\right)
\end{align*}
If the coefficients, $a_{k}$, are known in advance then the \emph{Clenshaw
  recurrence} calculates auxiliary values, $b_{k}\left(x\right)$, as follows:
\begin{align*}
  b_{n+1}\left(x\right)&=0 \\
  b_{n}\left(x\right)&=0 \\
  b_{k}\left(x\right)&=a_{k}+ b_{k+1}\left(x\right)\alpha_{k}\left(x\right)+
                        b_{k+2}\left(x\right)\beta_{k+1}\left(x\right)
\end{align*}
By induction:
\begin{align*}
  b_{k}\phi_{k}+ b_{k+1}\beta_{k}\phi_{k-1}
  &=a_{k}\phi_{k}+ b_{k+1}\alpha_{k}\phi_{k}+ b_{k+2}\beta_{k+1}\phi_{k}+
    b_{k+1}\beta_{k}\phi_{k-1}\\
  &=a_{k}\phi_{k}+ b_{k+1}\phi_{k+1}+ b_{k+2}\beta_{k+1}\phi_{k}
\end{align*}
so that:
\begin{align*}
  S\left(x\right)
  &=a_{0}\phi_{0}\left(x\right)+
    b_{1}\left(x\right)\phi_{1}\left(x\right)+
    b_{2}\left(x\right)\beta_{1}\left(x\right)\phi_{0}\left(x\right)
\end{align*}

The Chebyshev approximation to an arbitrary function, $f\left(x\right)$, on the
interval $[-1,1]$\footnote{Use the following change of 
  variables for a function defined on the interval $[a,b]$:
\begin{align*}
y \equiv \frac{x - \frac{1}{2}(b+a)}{\frac{1}{2}(b-a)}
\end{align*}} is:   
\begin{align*}
  f(x) \approx  - \frac{a_{0}}{2}+ \sum_{k=0}^{n-1 } a_{k}T_{k}(x)
\end{align*}
With the orthogonality of the Chebyshev polynomials at the Chebyshev nodes:
\begin{align*}
  \sum_{l=0}^{n-1}f\left(x_{k}\right)T_{l}\left(x_{k}\right)
  &=\sum_{l=0}^{n-1}\left[-\frac{a_{0}}{2}+
    \sum_{k=0}^{n-1}a_{k}T_{k}\left(x_{k}\right)\right]T_{l}\left(x_{k}\right) \\
  &=-\sum_{l=0}^{n-1}\frac{a_{0}}{2}T_{l}\left(x_{k}\right)+
    \sum_{l=0}^{n-1}\sum_{k=0}^{n-1}a_{k}T_{k}\left(x_{k}\right)
    T_{l}\left(x_{k}\right) \\
  &=\frac{n}{2}a_{k}
\end{align*}
and:
\begin{align*}
  a_{k} = \frac{2}{n} \sum_{l=0}^{n-1}
  f\left(\cos\pi\frac{2k+1}{2n}\right)\cos\pi l \frac{2k+1}{2n} 
\end{align*}

Now I can use Clenshaw's recurrence to approximate $f\left(x\right)$ with the
Chebyshev polynomials of the first kind, for which, from
Equation~\ref{eqn:Chebyshev-polynomial-first-kind-recurrence},
$\alpha\left(x\right)=2x$ and $\beta\left(x\right)=-1$:
\begin{align*}
b_{n+1} & = 0 \\
b_{n} & = 0 \\
  b_{k} & = a_{k} + 2xb_{k+1} - b_{k+2} \quad  k= n-1,n-2,\hdots,1 \\
  b_{0} &= 2a_{0}+ 2xb_{1} - b_{2} \\
f(x) & \approx \frac{1}{2}\left(b_{0} - b_{2}\right)
\end{align*}


The Octave script \emph{clenshaw\_gaussian\_test.m} calculates the Chebychev
polynomial expansion coefficients of an approximation to the Gaussian 
function, $e^{-2x^2}$. The exact approximation coefficients are:
\begin{small}
\verbatiminput{clenshaw_gaussian_test_ak_coef.m}
\end{small}
Figure~\ref{fig:Chebyshev-Gaussian-approximation-error} shows the Chebyshev
approximation and error with exact coefficients. The approximation is close
to mini-max.
The approximation coefficients rounded to
\input{clenshaw_gaussian_test_bits.tab}-bits are:
\begin{small}
\verbatiminput{clenshaw_gaussian_test_ak_fixed_point_coef.m}
\end{small}
Figure~\ref{fig:Chebyshev-Gaussian-approximation-error-fixed-point} shows the
Chebyshev approximation and error with coefficients rounded
to \input{clenshaw_gaussian_test_bits.tab}-bits and 
the Clenshaw recurrence calculated with a
\input{clenshaw_gaussian_test_bits_acc.tab}-bit accumulator. 

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{clenshaw_gaussian_test_approx}}
\caption{Chebychev polynomial approximation to a Gaussian.}
\label{fig:Chebyshev-Gaussian-approximation-error}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{clenshaw_gaussian_test_approx_fixed_point}}
\caption{Chebychev polynomial approximation to a Gaussian with fixed-point
  coefficients and arithmetic.}
\label{fig:Chebyshev-Gaussian-approximation-error-fixed-point}
\end{figure}

\chapter{\label{app:Review-of-elliptic-integrals-and-functions}Review of Legendre's elliptic integrals and Jacobi's elliptic functions}
This appendix reviews the notation for \emph{Legendre's elliptic
  integrals} and \emph{Jacobi's elliptic functions}. See \emph{Whittaker} and
\emph{Watson}~\cite[Chapters 20, 21 and
22]{WhittakerWatson_CourseModernAnalysis} and the \emph{NIST Digital Library of MathematicalFunctions}~\cite[Chapters 19, 20 and
22]{NIST_DigitalLibraryMathematicalFunctions}\footnote{The ``NIST Digital
  Library of Mathematical Functions'' is the successor to the ``Handbook of
  Mathematical Functions'' by \emph{Abramowitz} and
  \emph{Stegun}~\cite{AbramowitzStegun_HandbookMathematicalFunctions}.
  Unfortunately, pages are missing from scans of \emph{Abramowitz} and
  \emph{Stegun} available on the WWW.}. \emph{Vl\v{c}ek} and
\emph{Unbehauen}~\cite[Appendix]{Vlcek_AnalyticalSolutionsIIRFilter} provide a
brief review of the elliptic function theory required for IIR filter design.

\section{Doubly periodic functions}
\emph{Whittaker} and \emph{Watson}~\cite[Section
20.1]{WhittakerWatson_CourseModernAnalysis} give the following definition of
elliptic functions as doubly-periodic functions:
\begin{quotation}
  Let $\omega_{1}$ and $\omega_{2}$ be any two numbers whose ratio is not
  purely real. A function which satisfies the equations 
  \begin{align*}
    f\left(z+2\omega_{1}\right)&=f\left(z\right) \\
    f\left(z+2\omega_{2}\right)&=f\left(z\right)
  \end{align*}
  for all values of $z$ for which $f\left(z\right)$ exists, is called a
  \emph{doubly periodic} function of $z$, with periods $2\omega_{1}$ and
  $2\omega_{2}$. A doubly-periodic function which is analytic (except at poles),
  and which has no singularities other than poles in the finite part of the
  plane, is called an \emph{elliptic function}.
\end{quotation}

A \emph{cell} of an elliptic function, $f\left(z\right)$ is a parallelogram
$z, z+2\omega_{1}, z+2\omega_{1}+2\omega_{2}, z+2\omega_{2}$ for which none of
the poles of $f\left(z\right)$ lie on the edges of the cell. If $c$ is constant,
then the number of roots of $f\left(z\right)=c$ that lie within a cell is the
\emph{order} of the elliptic function and is equal to the number of poles of
$f\left(z\right)$ within the cell~\cite[Section
20.13]{WhittakerWatson_CourseModernAnalysis}.

\emph{Whittaker} and \emph{Watson} introduce the general properties of elliptic
functions by considering the \emph{Weierstrass} function:
\begin{align*}
  \wp\left(z\right) &= \frac{1}{z^{2}}+\sum_{\omega\in\mathbb{L}\setminus\{0\}}\left(
                      \frac{1}{\left(z-\omega\right)^{2}}-
                      \frac{1}{\omega^{2}}\right)
\end{align*}
where the set of points $\omega=2m\omega_{1}+2n\omega_{2}$ with
$m,n\in\mathbb{Z}$, constitutes a \emph{lattice}, $\mathbb{L}$.
\emph{Whittaker} and \emph{Watson}~\cite[Section
20.51]{WhittakerWatson_CourseModernAnalysis} show that ``any elliptic
  function can be expressed in terms of the Weierstrassian elliptic 
  functions $\wp\left(z\right)$ and $\wp^{\prime}\left(z\right)$ with the same
  periods, the expression being rational in $\wp\left(z\right)$ and linear in 
  $\wp^{\prime}\left(z\right)$''. $\wp^{\prime}\left(z\right)$ represents the
derivative of $\wp\left(z\right)$ with-respect-to $z$.
\section{Legendre's elliptic integrals}
$F\left(\phi,\kappa\right)$ is the \emph{incomplete elliptic integral of the
  first kind}~\cite[Equation 19.2.4]{NIST_DigitalLibraryMathematicalFunctions}
\begin{align*}
  F\left(\phi,\kappa\right)
  &= \int^{\phi}_{0}\frac{d\theta}{\sqrt{1-\kappa^{2}\sin^{2}\theta}}\\
  &= \int^{\sin\phi}_{0}\frac{dt}{\sqrt{1-t^{2}}\sqrt{1-\kappa^{2}t^{2}}}
\end{align*}
where $\kappa$ is the \emph{elliptic
  modulus}. $\kappa^{\prime}=\sqrt{1-\kappa^{2}}$ is the \emph{complementary
  elliptic modulus}. 

$K\left(\kappa\right)=F\left(\frac{\pi}{2},\kappa\right)$ is the \emph{complete
  elliptic integral of the first kind}~\cite[Equation
19.2.8]{NIST_DigitalLibraryMathematicalFunctions}.
$K^{\prime}\left(\kappa\right)=K\left(\kappa^{\prime}\right)$.

$E\left(\phi,\kappa\right)$ is the \emph{incomplete elliptic integral of the
 second kind}~\cite[Equation 19.2.5]{NIST_DigitalLibraryMathematicalFunctions}:
\begin{align*}
  E\left(\phi,\kappa\right)&=\int^{\phi}_{0}\sqrt{1-\kappa^{2}\sin^{2}\theta}d\theta \\
  &= \int^{\sin\phi}_{0}\frac{\sqrt{1-\kappa^{2}t^{2}}}{\sqrt{1-t^{2}}} dt
\end{align*}
$E\left(\kappa\right)=E\left(\frac{\pi}{2},\kappa\right)$ is the \emph{complete
  elliptic integral of the second kind}.

$\Pi\left(\phi,\eta,\kappa\right)$ is the \emph{incomplete elliptic integral of
  the third kind}~\cite[Equation
19.2.7]{NIST_DigitalLibraryMathematicalFunctions}: 
\begin{align*}
  \Pi\left(\phi,\eta,\kappa\right)
  &=\int^{\phi}_{0}\frac{d\theta}{\sqrt{1-\kappa^{2}\sin^{2}\theta}
    \left(1-\eta\sin^{2}\theta\right) } \\
  &= \int^{\sin\phi}_{0}\frac{dt}{\sqrt{1-t^{2}}\sqrt{1-\kappa^{2}t^{2}}
    \left(1-\eta t^{2}\right)}
\end{align*}
$\Pi\left(\eta,\kappa\right)=\Pi\left(\frac{\pi}{2},\eta,\kappa\right)$ is the
\emph{complete elliptic integral of the third kind}. 
\section{Computation of Legendre's elliptic integrals}
\emph{Carlson}~\cite{Carlson_ComputingEllipticIntegrals} and~\cite[Section
19.15]{NIST_DigitalLibraryMathematicalFunctions} describes a method of computing
Legendre's elliptic integrals. He defines the functions:
\begin{align*}
  R_{F}\left(x,y,z\right)
  &=\frac{1}{2}\int_{0}^{\infty}\left[
    \left(t+x\right)\left(t+y\right)\left(t+z\right)\right]^{-\frac{1}{2}}dt\\
   R_{C}\left(x,y\right)&= R_{F}\left(x,y,y\right) \\ 
  R_{J}\left(x,y,z,\rho\right)
  &=\frac{3}{2}\int_{0}^{\infty}\left[
    \left(t+x\right)\left(t+y\right)\left(t+z\right)\right]^{-\frac{1}{2}}
    \left(t+\rho\right)^{-1}dt\\
   R_{D}\left(x,y,z\right)&= R_{J}\left(x,y,z,z\right) 
\end{align*}
and states that~\cite[Section 4]{Carlson_ComputingEllipticIntegrals}:
\begin{align*}
  F\left(\phi,\kappa\right)
&=\left(\sin\phi\right)R_{F}\left(\cos^{2}\phi,1-\kappa^{2}\sin^{2}\phi,1\right)\\
  E\left(\phi,\kappa\right)
&=\left(\sin\phi\right) R_{F}\left(\cos^{2}\phi,1-\kappa^{2}\sin^{2}\phi,1\right)
    -\frac{1}{3}\kappa^{2}\left(\sin\phi\right)^{3}
    R_{D}\left(\cos^{2}\phi,1-\kappa^{2}\sin^{2}\phi,1\right) \\
\Pi\left(\phi,\eta,\kappa\right)
&=\sin\left(\phi\right) R_{F}\left(\cos^{2}\phi,1-\kappa^{2}\sin^{2}\phi,1\right) +
   \frac{\eta}{3}R_{J}
   \left(\cos^{2}\phi,1-\kappa^{2}\sin^{2}\phi,1,1-\eta\sin^{2}\phi\right)
\end{align*}

\textbf{Note that for $\Pi\left(\phi,\eta,\kappa\right)$ the sign of the terms in
  $\eta$ is the reverse of that shown by \emph{Carlson}~\cite[Equation
  4.3]{Carlson_ComputingEllipticIntegrals}.} 

The complete elliptic integrals are:
\begin{align*}
  K\left(\kappa\right)&=R_{F}\left(0,1-\kappa^{2},1\right)\\
  E\left(\kappa\right)&=R_{F}\left(0,1-\kappa^{2},1\right)-
                   \frac{1}{3}\kappa^{2}R_{D}\left(0,1-\kappa^{2},1\right)\\
  \Pi\left(\eta,\kappa\right)&=R_{F}\left(0,1-\kappa^{2},1\right)+
          \frac{\eta}{3}\kappa^{2}R_{J}\left(0,1-\kappa^{2},1,1-\eta\right)
\end{align*}

The computation of $R_{F}$ uses the, so-called, \emph{duplication
  formula}~\cite[Equation 19.26.18]{NIST_DigitalLibraryMathematicalFunctions}:
\begin{align*}
  R_{F}\left(x,y,z\right)
  &=R_{F}\left(\frac{x+\lambda}{4},\frac{y+\lambda}{4},\frac{z+\lambda}{4}\right)
\end{align*}
where $\lambda=\sqrt{xy}+\sqrt{yz}+\sqrt{zx}$.

Algorithm~\ref{alg:Carlson-RF}~\cite[Algorithm
1]{Carlson_ComputingEllipticIntegrals} computes Carlson's $R_{F}$ function,
Algorithm~\ref{alg:Carlson-RC}~\cite[Algorithm
2]{Carlson_ComputingEllipticIntegrals} computes Carlson's $R_{C}$ function,
Algorithm~\ref{alg:Carlson-RJ}~\cite[Algorithm
3]{Carlson_ComputingEllipticIntegrals} computes Carlson's $R_{J}$ function,
and Algorithm~\ref{alg:Carlson-RD}~\cite[Algorithm
4]{Carlson_ComputingEllipticIntegrals} computes Carlson's $R_{D}$ function.

\begin{algorithm}[htbp]
\begin{algorithmic}
\Require $x_{0}\ge{}0$, $y_{0}>0$ and $z_{0}>0$
\For{$n=0,\hdots$}
  \vspace{1.5mm}
\State $\lambda_{n}=\left(x_{n}y_{n}\right)^{\frac{1}{2}}+\left(x_{n}z_{n}\right)^{\frac{1}{2}}+\left(y_{n}z_{n}\right)^{\frac{1}{2}}$
  \vspace{1.5mm}
  \State $\mu_{n}=\left(x_{n}+y_{n}+z_{n}\right)/3$
  \vspace{1.5mm}
  \State $X_{n} = 1-\left(x_{n}/\mu_{n}\right)$,
   $Y_{n} = 1-\left(y_{n}/\mu_{n}\right)$,
   $Z_{n} = 1-\left(z_{n}/\mu_{n}\right)$
  \vspace{1.5mm}
  \State $x_{n+1}= \left(x_{n}+\lambda_{n}\right)/4$,
   $y_{n+1}= \left(y_{n}+\lambda_{n}\right)/4$,
   $z_{n+1}= \left(z_{n}+\lambda_{n}\right)/4$
  \vspace{1.5mm}
  \State
   $s_{n}^{\left(m\right)}=\left(X_{n}^{m}+Y_{n}^{m}+Z_{n}^{m}\right)/2m$, $m=2,3$
  \vspace{1.5mm}
  \State $\varepsilon_{n}=\max\left\{|X_{n}|,|Y_{n}|,|Z_{n}|\right\}\;\left(\varepsilon_{n}\sim\mathcal{O}\left(4^{-n}\right)\right)$
  \vspace{1.5mm}
  \If {$\varepsilon_{n}<1$}
  \vspace{1.5mm}
  \State $R_{F}\left(x_{0},y_{0},z_{0}\right)=\mu_{n}^{-\frac{1}{2}}\left[1+\frac{1}{5}s_{n}^{\left(2\right)}+\frac{1}{7}s_{n}^{\left(3\right)}+\frac{1}{6}\left(s_{n}^{\left(2\right)}\right)^{2}+\frac{3}{11}s_{n}^{\left(2\right)}s_{n}^{\left(3\right)}+r_{n}\right]$
  \vspace{1.5mm}
  \State $|r_{n}|<\frac{\varepsilon_{n}^{6}}{4\left(1-\varepsilon_{n}\right)}$, 
  $r_{n}\sim\frac{5}{26}\left(s_{n}^{\left(2\right)}\right)^{3}+\frac{3}{26}\left(s_{n}^{\left(3\right)}\right)^{2}$
  \vspace{1.5mm}
   \EndIf
  \EndFor
\end{algorithmic}
\caption{Carlson's algorithm for computing the $R_{F}$ function~\cite[Algorithm
1]{Carlson_ComputingEllipticIntegrals}}
\label{alg:Carlson-RF}
\end{algorithm}

\begin{algorithm}[htbp]
\begin{algorithmic}
\Require $x_{0}\ge{}0$ and $y_{0}>0$
\For{$n=0,\hdots$}
  \vspace{1.5mm}
\State $\lambda_{n}=2\left(x_{n}y_{n}\right)^{\frac{1}{2}}+y_{n}$
  \vspace{1.5mm}
  \State $\mu_{n}=\left(x_{n}+2y_{n}\right)/3$
  \vspace{1.5mm}
  \State $s_{n} = \left(y_{n}-x_{n}\right)/3\mu_{n}$,
  \vspace{1.5mm}
  \State $x_{n+1}= \left(x_{n}+\lambda_{n}\right)/4$,
   $y_{n+1}= \left(y_{n}+\lambda_{n}\right)/4$
  \vspace{1.5mm}
  \If {$|s_{n}|<\frac{1}{2}$}
  \vspace{1.5mm}
  \State $R_{c}\left(x_{0},y_{0}\right)=\mu_{n}^{-\frac{1}{2}}
  \left[1+\frac{3}{10}s_{n}^{2}+\frac{1}{7}s_{n}^{3}+\frac{3}{8}s_{n}^{4}+
    \frac{9}{22}s_{n}^{5}+r_{n}\right]$
  \vspace{1.5mm}
  \State $|r_{n}|<\frac{16|s_{n}|^{6}}{1-2|s_{n}|}$,
  $r_{n}\sim\frac{159}{208}s_{n}^{6}$
  \vspace{1.5mm}
   \EndIf
  \EndFor
\end{algorithmic}
\caption{Carlson's algorithm for computing the $R_{C}$ function~\cite[Algorithm
2]{Carlson_ComputingEllipticIntegrals}}
\label{alg:Carlson-RC}
\end{algorithm}

\begin{algorithm}[htbp]
\begin{algorithmic}
\Require $x_{0}\ge{}0$, $y_{0}>0$, $z_{0}>0$ and $\rho_{0}>0$
\For{$n=0,\hdots$}
  \vspace{1.5mm}
\State $\lambda_{n}=\left(x_{n}y_{n}\right)^{\frac{1}{2}}+\left(x_{n}z_{n}\right)^{\frac{1}{2}}+\left(y_{n}z_{n}\right)^{\frac{1}{2}}$
  \vspace{1.5mm}
  \State $\mu_{n}=\left(x_{n}+y_{n}+z_{n}+2\rho_{n}\right)/5$
  \vspace{1.5mm}
  \State $X_{n} = 1-\left(x_{n}/\mu_{n}\right)$,
   $Y_{n} = 1-\left(y_{n}/\mu_{n}\right)$,
   $Z_{n} = 1-\left(z_{n}/\mu_{n}\right)$,
   $P_{n} = 1-\left(\rho_{n}/\mu_{n}\right)$
  \vspace{1.5mm}
  \State $x_{n+1}= \left(x_{n}+\lambda_{n}\right)/4$,
   $y_{n+1}= \left(y_{n}+\lambda_{n}\right)/4$,
   $z_{n+1}= \left(z_{n}+\lambda_{n}\right)/4$,
   $\rho_{n+1}= \left(\rho_{n}+\lambda_{n}\right)/4$
  \vspace{1.5mm}
  \State  $s_{n}^{\left(m\right)}=\left(X_{n}^{m}+Y_{n}^{m}+Z_{n}^{m}+2P_{n}^{m}\right)/2m$, $m=2,3,4,5$
   \vspace{1.5mm}
   \State $\alpha_{n}=\left[\rho_{n}\left(x^{\frac{1}{2}}+y^{\frac{1}{2}}+z^{\frac{1}{2}}\right)+\left(x_{n}y_{n}z_{n}\right)^{\frac{1}{2}}\right]^{2}$,
   $\beta=\rho_{n}\left(\rho_{n}+\lambda_{n}\right)^{2}$
  \vspace{1.5mm}
  \State $\varepsilon_{n}=\max\left\{|X_{n}|,|Y_{n}|,|Z_{n}|,|P_{n}|\right\}\;\left(\varepsilon_{n}\sim\mathcal{O}\left(4^{-n}\right)\right)$
  \vspace{1.5mm}
  \If {$\varepsilon_{n}<1$}
  \vspace{1.5mm}
  \State
  $R_{J}\left(x_{0},y_{0},z_{0},\rho_{0}\right)=3\sum^{n-1}_{m=0}4^{-m}R_{C}\left(\alpha_{m},\beta_{m}\right)+\hdots$ \\
 \State\quad\quad\quad$4^{-n}\mu_{n}^{-\frac{3}{2}}\left[1+\frac{3}{7}s_{n}^{\left(2\right)}+\frac{1}{3}s_{n}^{\left(3\right)}+\frac{3}{22}\left(s_{n}^{\left(2\right)}\right)^{2}+\frac{3}{11}s_{n}^{\left(4\right)}+\frac{3}{13}s_{n}^{\left(2\right)}s_{n}^{\left(3\right)}+\frac{3}{13}s_{n}^{\left(5\right)}+r_{n}\right]$
  \vspace{1.5mm}
  \State $|r_{n}|<\frac{3\varepsilon_{n}^{6}}{\left(1-\varepsilon_{n}\right)^{\frac{3}{2}}}$
  \vspace{1.5mm}
  \State $r_{n}\sim{}-\frac{1}{10}\left(s_{n}^{\left(2\right)}\right)^{3}+\frac{3}{10}\left(s_{n}^{\left(3\right)}\right)^{2}+\frac{3}{5}s_{n}^{\left(2\right)}s_{n}^{\left(4\right)}$
  \vspace{1.5mm}
   \EndIf
  \EndFor
\end{algorithmic}
\caption{Carlson's algorithm for computing the $R_{J}$ function~\cite[Algorithm
3]{Carlson_ComputingEllipticIntegrals}}
\label{alg:Carlson-RJ}
\end{algorithm}

\begin{algorithm}[htbp]
\begin{algorithmic}
\Require $x_{0}\ge{}0$, $y_{0}>0$ and $z_{0}>0$
\For{$n=0,\hdots$}
  \vspace{1.5mm}
\State $\lambda_{n}=\left(x_{n}y_{n}\right)^{\frac{1}{2}}+\left(x_{n}z_{n}\right)^{\frac{1}{2}}+\left(y_{n}z_{n}\right)^{\frac{1}{2}}$
  \vspace{1.5mm}
  \State $\mu_{n}=\left(x_{n}+y_{n}+3z_{n}\right)/5$
  \vspace{1.5mm}
  \State $X_{n} = 1-\left(x_{n}/\mu_{n}\right)$,
   $Y_{n} = 1-\left(y_{n}/\mu_{n}\right)$,
   $Z_{n} = 1-\left(z_{n}/\mu_{n}\right)$ 
  \vspace{1.5mm}
  \State $x_{n+1}= \left(x_{n}+\lambda_{n}\right)/4$,
   $y_{n+1}= \left(y_{n}+\lambda_{n}\right)/4$,
   $z_{n+1}= \left(z_{n}+\lambda_{n}\right)/4$
   \vspace{1.5mm}
   \State
   $s_{n}^{\left(m\right)}=\left(X_{n}^{m}+Y_{n}^{m}+3Z_{n}^{m}\right)/2m$, $m=2,3,4,5$
  \vspace{1.5mm}
  \State $\varepsilon_{n}=\max\left\{|X_{n}|,|Y_{n}|,|Z_{n}|\right\}\;\left(\varepsilon_{n}\sim\mathcal{O}\left(4^{-n}\right)\right)$
  \vspace{1.5mm}
  \If {$\varepsilon_{n}<1$}
  \vspace{1.5mm}
  
  \State
  $R_{D}\left(x_{0},y_{0},z_{0}\right)=3\sum_{m=0}^{n-1}\frac{4^{-m}}{z_{m}^{\frac{1}{2}}\left(z_{m}+\lambda_{m}\right)}$
  
  $\quad\quad\quad\quad+4^{-n}\mu_{n}^{-\frac{3}{2}}\left[1+\frac{3}{7}s_{n}^{\left(2\right)}+\frac{1}{3}s_{n}^{\left(3\right)}+\frac{3}{22}\left(s_{n}^{\left(2\right)}\right)^{2}+\frac{3}{11}s_{n}^{\left(4\right)}+\frac{3}{13}s_{n}^{\left(2\right)}s_{n}^{\left(3\right)}+\frac{3}{13}s_{n}^{\left(5\right)}+r_{n}\right]$
  \vspace{1.5mm}
  \State $|r_{n}|<\frac{3\varepsilon_{n}^{6}}{\left(1-\varepsilon_{n}\right)^{\frac{3}{2}}}$, $r_{n}\sim-\frac{1}{10}\left(s_{n}^{\left(2\right)}\right)^{3}+\frac{3}{10}\left(s_{n}^{\left(3\right)}\right)^{2}+\frac{3}{5}s_{n}^{\left(2\right)}s_{n}^{\left(4\right)}$
  \vspace{1.5mm}
   \EndIf
  \EndFor
  \vspace{1.5mm}
\end{algorithmic}
\caption{Carlson's algorithm for computing the $R_{D}$ function~\cite[Algorithm
4]{Carlson_ComputingEllipticIntegrals}}
\label{alg:Carlson-RD}
\end{algorithm}

\section{Jacobi's theta functions}
Jacobi's elliptic functions can be defined as ratios of Jacobi's \emph{theta}
functions~\cite[Section 20.2]{NIST_DigitalLibraryMathematicalFunctions}. These
are defined by the Fourier series:
\begin{align*}
  \theta_{1}\left(z,q\right)
  &=2\sum^{\infty}_{n=0}\left(-1\right)^{n}q^{\left(n+\frac{1}{2}\right)^{2}}
    \sin\left(\left(2n+1\right)z\right) \\
  \theta_{2}\left(z,q\right)
  &=2\sum^{\infty}_{n=0}q^{\left(n+\frac{1}{2}\right)^{2}}
    \cos\left(\left(2n+1\right)z\right) \\
  \theta_{3}\left(z,q\right)
  &=1+2\sum^{\infty}_{n=1}q^{n^{2}}\cos\left(2nz\right) \\
  \theta_{4}\left(z,q\right)
  &=1+2\sum^{\infty}_{n=1}\left(-1\right)^{n}q^{n^{2}}\cos\left(2nz\right)  
\end{align*}
where $q=e^{\imath\pi\tau}$ is called the \emph{nome}, with
$\Im\tau{}>0$ so that $0<|q|<1$. For most applications, the unit
cell is a rectangle so that $\Re\tau=0$ and $0<q<1$.

Jacobi's \emph{Eta} and \emph{Theta}
functions~\cite[Section 20.1]{NIST_DigitalLibraryMathematicalFunctions} are,
respectively:
\begin{align*}
  H\left(z,q\right)
  &=\theta_{1}\left(\frac{z}{\theta_{3}^{2}\left(0,q\right)},q\right) \\
  \Theta\left(z,q\right)
  &=\theta_{4}\left(\frac{z}{\theta_{3}^{2}\left(0,q\right)},q\right)
\end{align*}
\section{Computation of Jacobi's theta functions}
The Fourier series of Jacobi's theta functions usually converge rapidly because
of the doubly-exponential factors $q^{n^{2}}$. The following
transformations\footnote{See~\cite[Section
  23.15(i)]{NIST_DigitalLibraryMathematicalFunctions}.Suppose $\mathcal{A}$
  denotes a bilinear transformation on $\tau$: 
\begin{align*}
  \mathcal{A}\tau &=\frac{a\tau+b}{c\tau+d}
\end{align*}
where $a$, $b$, $c$ and $d$ are integers and $ad-bc=1$. A \emph{modular
  function} $f\left(\tau\right)$ is a function of $\tau$ that is meromorphic in
the half-plane $\Im\tau>0$, and has the property that for all
$\mathcal{A}$:
\begin{align*}
  f\left(\mathcal{A}\tau\right)
  &= c_{\mathcal{A}}\left(c\tau+d\right)^{l}f\left(\tau\right)
\end{align*}
where $c_{\mathcal{A}}$ is a constant depending on $\mathcal{A}$, and $l$,
called the level, is an integer or half an odd integer. If, as a function of q,
$f\left(\tau\right)$ is analytic at $q=0$, then $f\left(\tau\right)$ is called a
\emph{modular form}.} are used to compute Jacobi's theta functions when $|q|$ is
close to $1$ with $\tau^{\prime}=-\frac{1}{\tau}$~\cite[Section
20.7(viii)]{NIST_DigitalLibraryMathematicalFunctions}:
\begin{align*}
  (-\imath\tau)^{\frac{1}{2}}\theta_{1}\left(z,\tau\right)
  &=-\imath{}\exp\left(\frac{\imath\tau^{\prime}z^{2}}{\pi}\right)
    \theta_{1}\left(z\tau^{\prime},\tau^{\prime}\right)\\
  (-\imath\tau)^{\frac{1}{2}}\theta_{2}\left(z,\tau\right)
  &=\exp\left(\frac{\imath\tau^{\prime}z^{2}}{\pi}\right)
    \theta_{4}\left(z\tau^{\prime},\tau^{\prime}\right)\\
  (-\imath\tau)^{\frac{1}{2}}\theta_{3}\left(z,\tau\right)
  &=\exp\left(\frac{\imath\tau^{\prime}z^{2}}{\pi}\right)
    \theta_{3}\left(z\tau^{\prime},\tau^{\prime}\right)\\
  (-\imath\tau)^{\frac{1}{2}}\theta_{4}\left(z,\tau\right)
  &=\exp\left(\frac{\imath\tau^{\prime}z^{2}}{\pi}\right)
    \theta_{2}\left(z\tau^{\prime},\tau^{\prime}\right)
\end{align*}
\section{Jacobi's elliptic functions}
See~\cite[Section 22.2]{NIST_DigitalLibraryMathematicalFunctions}. The nome,
$q$, is, in terms of the modulus, $\kappa$: 
\begin{align*}
  q&=e^{-\pi\frac{K^{\prime}\left(\kappa\right)}{K\left(\kappa\right)}}
\end{align*}
The elliptic modulus, $\kappa$, is, in terms of the nome, $q$:
\begin{align*}
\kappa&=\frac{\theta_{2}^{2}\left(0,q\right)}{\theta_{3}^{2}\left(0,q\right)}\\
  \kappa^{\prime}
  &=\frac{\theta_{4}^{2}\left(0,q\right)}{\theta_{3}^{2}\left(0,q\right)}\\
K\left(\kappa\right)&=\frac{\pi}{2}\theta_{3}^{2}\left(0,q\right)
\end{align*}
If $\zeta=\frac{\pi{}z}{2K\left(\kappa\right)}$, then:
\begin{align*}
  \jsn\left(z,\kappa\right)
  &=\frac{\theta_{3}\left(0,q\right)}{\theta_{2}\left(0,q\right)}
    \frac{\theta_{1}\left(\zeta,q\right)}{\theta_{4}\left(\zeta,q\right)}
    =\frac{1}{\jns\left(z,\kappa\right)} \\
  \jcn\left(z,\kappa\right)
  &=\frac{\theta_{4}\left(0,q\right)}{\theta_{2}\left(0,q\right)}
    \frac{\theta_{2}\left(\zeta,q\right)}{\theta_{4}\left(\zeta,q\right)}
    =\frac{1}{\jnc\left(z,\kappa\right)} \\
  \jdn\left(z,\kappa\right)
  &=\frac{\theta_{4}\left(0,q\right)}{\theta_{3}\left(0,q\right)}
    \frac{\theta_{3}\left(\zeta,q\right)}{\theta_{4}\left(\zeta,q\right)}
    =\frac{1}{\jnd\left(z,\kappa\right)} \\
  \jsd\left(z,\kappa\right)
  &=\frac{\theta_{3}^{2}\left(0,q\right)}
         {\theta_{2}\left(0,q\right)\theta_{4}\left(0,q\right)}
    \frac{\theta_{1}\left(\zeta,q\right)}{\theta_{3}\left(\zeta,q\right)}
    =\frac{1}{\jds\left(z,\kappa\right)} \\
  \jcd\left(z,\kappa\right)
  &=\frac{\theta_{3}\left(0,q\right)}{\theta_{2}\left(0,q\right)}
    \frac{\theta_{2}\left(\zeta,q\right)}{\theta_{3}\left(\zeta,q\right)}
    =\frac{1}{\jdc\left(z,\kappa\right)} \\
  \jsc\left(z,\kappa\right)
  &=\frac{\theta_{3}\left(0,q\right)}{\theta_{4}\left(0,q\right)}
    \frac{\theta_{1}\left(\zeta,q\right)}{\theta_{2}\left(\zeta,q\right)}
    =\frac{1}{\jcs\left(z,\kappa\right)}  
\end{align*}
From~\cite[Section 22.2]{NIST_DigitalLibraryMathematicalFunctions}:
\begin{quotation}
  As a function of $z$ with fixed $\kappa$, each of the $12$ Jacobian elliptic
  functions is doubly periodic, having two periods whose ratio is not real. Each
  is meromorphic\footnote{See Appendix~\ref{app:Cauchy-Argument-Principle}.} in
  $z$ for fixed $\kappa$, with simple poles and zeros, and each is meromorphic
  in $\kappa$ for fixed $z$. For $k\in\left[0,1\right]$, all functions are real
  for $z\in\mathbb{R}$.
\end{quotation}

The Jacobian elliptic functions have order 2; there are two simple poles in each
cell. Table~\ref{tab:Jacobian-elliptic-function-poles-and-zeros}~\cite[Tables
22.4.1 and 22.4.2]{NIST_DigitalLibraryMathematicalFunctions} summarises the
periods, pole locations and zero locations of the Jacobian elliptic functions.

\begin{table}[htbp]
\centering
\begin{threeparttable}
\bgroup{}
\begin{tabular}{lccccccccc} \toprule
\multirow{3}{*}
{Periods}         &\multicolumn{4}{c}{z-poles}&  &\multicolumn{4}{c}{z-zeros} \\
  \cmidrule{2-5} \cmidrule{7-10}
                  & $\imath{}K^{\prime}$ & $K+\imath{}K^{\prime}$ & K & 0 &
                  & 0 & K & $K+\imath{}K^{\prime}$ & $\imath{}K^{\prime}$ \\
\midrule
  $4K$, $2\imath{}K^{\prime}$
   & $\jsn$ & $\jcd$ & $\jdc$ & $\jns$ & & $\jsn$ & $\jcd$ & $\jdc$ & $\jns$ \\
  $4K$, $2K+2\imath{}K^{\prime}$
   & $\jcn$ & $\jsd$ & $\jnc$ & $\jds$ & & $\jsd$ & $\jcn$ & $\jds$ & $\jnc$ \\
  $2K$, $4\imath{}K^{\prime}$
   & $\jdn$ & $\jnd$ & $\jsc$ & $\jcs$ & & $\jsc$ & $\jcs$ & $\jdn$ & $\jnd$ \\
\bottomrule
\end{tabular}
\egroup{}
\end{threeparttable}
\caption{Periods, pole locations and zero locations of the Jacobian elliptic
  functions.}
\label{tab:Jacobian-elliptic-function-poles-and-zeros}
\end{table}

\emph{Glaisher's} notation for the Jacobian elliptic functions is~\cite[Equation
22.2.10]{NIST_DigitalLibraryMathematicalFunctions}:
\begin{align*}
  pq\left(z,\kappa\right)&=\frac{pr\left(z,\kappa\right)}{qr\left(z,\kappa\right)}
                      =\frac{1}{qp\left(z,\kappa\right)}
\end{align*}
where $p$, $q$ and $r$ are any three of the letters $s$, $c$, $d$ and
$n$. Figure~\ref{fig:elliptic-z-plane-unit-cell}~\cite[Figure
22.4.2]{NIST_DigitalLibraryMathematicalFunctions} shows a mnemonic for the
nomenclature of the Jacobian elliptic functions. If $p$ and $q$ are any two
distinct letters from the set $s$, $c$, $d$ and $n$ which appear in
counter-clockwise orientation at all corners of all lattice unit cells. Then:
\begin{itemize}
  \item in any lattice unit cell $pq\left(z,\kappa\right)$ has a simple zero at $z=p$
    and a simple pole at $z=q$
    \item the difference between $p$ and the nearest $q$ is a half-period of
      $pq\left(z,\kappa\right)$
\end{itemize}
The half-period will be plus or minus a member of the triple $K$,
$\imath{}K^{\prime}$, $K+\imath{}K^{\prime}$; the other two members of this
triple are quarter-periods of $pq\left(z,\kappa\right)$.
\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{elliptic_unit_cell}
\caption{Jacobian elliptic filter z-plane unit cell}
\label{fig:elliptic-z-plane-unit-cell}
\end{figure}

\section{Inverses of Jacobi's elliptic functions}
The inverses of Jacobi's $\jsn$, $\jcn$ and $\jcd$ elliptic functions are,
respectively~\cite[Section 22.15(ii)]{NIST_DigitalLibraryMathematicalFunctions}:
\begin{align*}
  \jarcsn\left(x,\kappa\right)
  &=\int^{x}_{0}\frac{dt}{\sqrt{\left(1-t^{2}\right)\left(1-\kappa^{2}t^{2}\right)}}
    \;\text{,}\quad -1\le{}x\le{}1 \\
  \jarccn\left(x,\kappa\right)
  &=\int^{1}_{x}\frac{dt}
    {\sqrt{\left(1-t^{2}\right)\left(\kappa^{\prime{}2}+\kappa^{2}t^{2}\right)}} 
    \;\text{,}\quad -1\le{}x\le{}1\\
  \jarcdn\left(x,\kappa\right)
  &=\int^{1}_{x}\frac{dt}
    {\sqrt{\left(1-t^{2}\right)\left(\kappa^{\prime{}2}+\kappa^{2}t^{2}\right)}} 
    \;\text{,}\quad -1\le{}x\le{}1\\
  \jarcdn\left(x,\kappa\right)
  &=\int^{1}_{x}\frac{dt}
    {\sqrt{\left(1-t^{2}\right)\left(t^{2}-\kappa^{\prime{}2}\right)}} 
    \;\text{,}\quad\quad \kappa^{\prime}\le{}x\le{}1 \\
  \jarccd\left(x,\kappa\right)
  &=\int^{1}_{x}\frac{dt}
    {\sqrt{\left(1-t^{2}\right)\left(1-\kappa^{2}t^{2}\right)}} 
    \;\text{,}\quad -1\le{}x\le{}1
\end{align*}

\emph{Carlson}~\cite[Section 2.1]{Carlson_PowerSeriesInverseEllipticFunctions}
shows how to calculate the inverse Jacobian elliptic functions with the $R_{F}$
function. For example,
\begin{align*}
  \jarcsn\left(z,\kappa\right)&=zR_{F}\left(1,1-z^{2},1-\kappa^{2}z^{2}\right)
\end{align*}

\section{Elementary identities for the elliptic integrals and elliptic functions}
Note that $\jarcsn\left(x,\kappa\right)=F\left(\arcsin{}x,\kappa\right)$ so that:
\begin{align*}
  x&=\int^{\jsn\left(x,\kappa\right)}_{0}\frac{dt}
     {\sqrt{\left(1-t^{2}\right)\left(1-\kappa^{2}t^{2}\right)}}
     \;\text{,}\quad -1\le{}x\le{}1 \;\text{,}\quad 0\le{}\kappa\le{}1
\end{align*}
The identities:
\begin{align*}
  \jsn\left(x,\kappa\right)&=\sin\phi \\
  \jcn\left(x,\kappa\right)&=\cos\phi \\
  \jdn\left(x,\kappa\right)&=\sqrt{1-\kappa^{2}\jsn^{2}\left(x,\kappa\right)}
\end{align*}
give (omitting the $x$ and $\kappa$ arguments):
\begin{align*}
  \jsn^{2}+\jcn^{2} &=1 \\
  \jdn^{2} &=1-\kappa^{2}\jsn^{2} = \kappa^{\prime{}2}+\kappa^{2}\jcn^{2}
             =\jcn^{2}+\kappa^{\prime{}2}\jsn^{2}
\end{align*}

The identities:
\begin{align*}
  \jsn\left(x,\kappa\right)&=\sin\phi \\
  \jcn\left(x,\kappa\right)&=\cos\phi \\
  \jdn\left(x,\kappa\right)&=\sqrt{1-\kappa^{2}\jsn^{2}\left(x,\kappa\right)}
\end{align*}
give (omitting the $x$ and $\kappa$ arguments):
\begin{align*}
  \jsn^{2}+\jcn^{2} &=1 \\
  \jdn^{2} &=1-\kappa^{2}\jsn^{2} = \kappa^{\prime{}2}+\kappa^{2}\jcn^{2}
             =\jcn^{2}+\kappa^{\prime{}2}\jsn^{2}
\end{align*}

The half-argument identities for the $\jsn$ and $\jcn$ functions
are~\cite[Equations 22.6.19 and
22.6.20]{NIST_DigitalLibraryMathematicalFunctions}:
\begin{align*}
  \jsn^{2}\left(\frac{z}{2},\kappa\right)
  &=\frac{1-\jcn\left(z,\kappa\right)}{1+\jdn\left(z,\kappa\right)} \\
  \jcn^{2}\left(\frac{z}{2},\kappa\right)
  &=\frac{-\kappa^{\prime{}2}+\jdn\left(z,\kappa\right)+
    \kappa^{2}\jcn\left(z,\kappa\right)}
    {\kappa^{2}\left(1+\jcn\left(z,\kappa\right)\right)}
\end{align*}

For many more such identities, see, for example, the DLMF~\cite[Section
22.6]{NIST_DigitalLibraryMathematicalFunctions}.
\section{Related functions}
Jacobi's \emph{amplitude} function~\cite[Equation
22.16.1]{NIST_DigitalLibraryMathematicalFunctions} is:
\begin{align*}
  \jam\left(x,\kappa\right)&=\arcsin\left(\jsn\left(x,\kappa\right)\right)
\end{align*}
If $-K\le x \le K$ then the following four equations are
equivalent~\cite[Equations 22.16.10 to
22.16.13]{NIST_DigitalLibraryMathematicalFunctions}:
\begin{align*}
  x&=F\left(\phi,\kappa\right) \\
  \jam\left(x,\kappa\right)&=\phi \\
\jsn\left(x,\kappa\right)&=\sin\phi=\sin\left(\jam\left(x,\kappa\right)\right)\\
\jcn\left(x,\kappa\right)&=\cos\phi=\cos\left(\jam\left(x,\kappa\right)\right)
\end{align*}

Jacobi's \emph{Epsilon} function~\cite[Equations 22.16.14 and
22.16.31]{NIST_DigitalLibraryMathematicalFunctions} is, for $-K\le x \le K$:
\begin{align*}
  \mathcal{E}\left(x,\kappa\right)
  &=\int_{0}^{\jsn\left(x,\kappa\right)}\sqrt{\frac{1-\kappa^{2}t^{2}}{1-t^{2}}}dt \\
  &=E\left(\jam\left(x,\kappa\right),\kappa\right)
\end{align*}
where $-K<x<K$.

Jacobi's \emph{Zeta}
function~\cite[Equation 22.16.32]{NIST_DigitalLibraryMathematicalFunctions}
is:
\begin{align*}
  Z\left(x,\kappa\right)
  &=E\left(\arcsin\left(\jsn\left(x,\kappa\right)\right),\kappa\right)-
    \frac{E\left(\kappa\right)}{K\left(\kappa\right)}x
\end{align*}
Alternatively~\cite[Equation 22.16.30]{NIST_DigitalLibraryMathematicalFunctions}:
\begin{align*}
  Z\left(z,\kappa\right)
  &=\frac{1}{\Theta\left(z,\kappa\right)}\frac{d\Theta\left(z,\kappa\right)}{dz}
  =\frac{1}{\theta^{2}_{3}\left(0,q\right)\theta_{4}\left(\xi,q\right)}
    \frac{d\theta_{4}\left(\xi,q\right)}{d\xi}
\end{align*}
where $\xi=\frac{z}{\theta^{2}_{3}\left(0,q\right)}$ and $q$ is the \emph{nome}
corresponding to $\kappa$.

The \emph{Zeta} function is periodic in
$2K$~\cite[22.16.34]{NIST_DigitalLibraryMathematicalFunctions}:
\begin{align*}
  Z\left(x+2K,\kappa\right)&=Z\left(x,\kappa\right)
\end{align*}
Also~\cite[22.16.33]{NIST_DigitalLibraryMathematicalFunctions}:
\begin{align*}
  Z\left(x+K,\kappa\right)&=Z\left(x,\kappa\right)-
                       \kappa^{2}\jsn\left(x,\kappa\right)\jcd\left(x,\kappa\right)
\end{align*}

The \emph{Boost} C++ library~\cite{Boost_math_Zeta_website} and 
  \emph{Mathematica}~\cite{Mathematica_Jacobi_Zeta_website} implementations of
  Jacobi's \emph{Zeta} function use: 
\begin{align*}
  Z\left(\phi,\kappa\right)
  &=E\left(\phi,\kappa\right)-
    \frac{E\left(\kappa\right)}{K\left(\kappa\right)}F\left(\phi,\kappa\right)
\end{align*}
This definition obscures the periodicity in $K$. Figure 22.16.3 of the
DLMF~\cite{NIST_DigitalLibraryMathematicalFunctions}, shows the values of
Jacobi's \emph{Zeta} function for several elliptic moduluses,
$\kappa$. Confusingly, this figure expresses the $x$ argument as a multiple of
$\pi$. The Octave script \emph{jacobi\_Zeta\_test.m} reproduces Figure 22.16.3,
as shown in Figure~\ref{fig:DLMF-Figure-22-16-3}.  
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{jacobi_Zeta_test_DLMF_Figure_22_16_3}}
\caption{Jacobi's Zeta function as shown in Figure 22.16.3 of the NIST Digital
  Library of Mathematical
  Functions~\cite{NIST_DigitalLibraryMathematicalFunctions}.}
\label{fig:DLMF-Figure-22-16-3}
\end{figure}

\section{Octave implementations}
Table~\ref{tab:Octave-implementation-of-elliptic-functions} lists the Octave
functions that implement the elliptic functions and integrals referred to in
this Appendix. \emph{ellipj} and \emph{ellipke} are Octave built-in functions.
\begin{table}
\centering
\begin{threeparttable}
\begin{tabular}{llc}  \toprule
Function & Octave implementation\\ 
\midrule
  $\jsn\left(z,\kappa\right)$, $\jcn\left(z,\kappa\right)$, $\jdn\left(z,\kappa\right)$
  & \emph{ellipj} \\ 
 $K\left(\kappa\right)$, $E\left(\kappa\right)$ & \emph{ellipke} \\ 
 $\jarcsn\left(z,\kappa\right)$ & \emph{arcsn} \\
 $\jarcsc\left(z,\kappa\right)$ & \emph{arcsc} \\
 $\jarccs\left(z,\kappa\right)$ & \emph{arccs} \\
 $F\left(\phi,\kappa\right)$ & \emph{elliptic\_F} \\
 $E\left(\phi,\kappa\right)$ & \emph{elliptic\_E} \\ 
 $\Pi\left(\phi,\eta,\kappa\right)$ & \emph{elliptic\_Pi} \\
 $R_{F}\left(x,y,z\right)$ & \emph{carlson\_RF} \\
 $R_{C}\left(x,y\right)$ & \emph{carlson\_RC} \\
 $R_{J}\left(x,y,z,\rho\right)$ & \emph{carlson\_RJ} \\
 $R_{D}\left(x,y,z\right)$ & \emph{carlson\_RD} \\
 $\theta_{1}\left(z,q\right)$ & \emph{jacobi\_theta1} \\
 $\theta_{2}\left(z,q\right)$ & \emph{jacobi\_theta2} \\
 $\theta_{3}\left(z,q\right)$ & \emph{jacobi\_theta3} \\
 $\theta_{4}\left(z,q\right)$ & \emph{jacobi\_theta4} \\
 $H\left(z,\kappa\right)$ & \emph{jacobi\_Eta} \\
 $\Theta\left(z,\kappa\right)$ & \emph{jacobi\_Theta} \\
 $Z\left(x,\kappa\right)$ & \emph{jacobi\_Zeta} \\
\bottomrule
\end{tabular}
\end{threeparttable}
\caption{Octave implementations of elliptic and related functions.}
\label{tab:Octave-implementation-of-elliptic-functions}
\end{table}

\chapter{\label{app:Unsymmetric-Lanczos-tridiagonalisation}Review of \emph{Lanczos} tridiagonalisation of an unsymmetric matrix}
See \emph{Golub and Van Loan}~\cite[Section
9.4.3]{GolubVanLoan_MatrixComputations}. The \emph{Lanczos}  
tridiagonalisation calculates an orthogonal similarity transform, $T$, that
reduces a matrix $A\in\mathbb{R}^{N\times{}N}$ to tridiagonal form, $\mathcal{A}$:
\begin{align*}
T^{-1}AT &= \mathcal{A} = \left[\begin{array}{cccccc}
\alpha_{0} & \beta_{1} & 0 & 0 & \cdots & 0\\
\gamma_{1} & \alpha_{1} & \beta_{2} & 0 & \cdots & 0 \\
0 & \gamma_{2} & \alpha_{2} & \beta_{3} & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & \gamma_{N-2} & \alpha_{N-2} & \beta_{N-1}\\
0 & 0 & \cdots & 0 & \gamma_{N-1} & \alpha_{N-1}\\
\end{array}\right] 
\end{align*}
The \emph{Lanczos} tridiagonalisation calculates the column partitionings:
\begin{align*}
T &= 
\left[\begin{array}{ccc} t_{1} & \cdots & t_{N} \end{array}\right]\\
{T^{-1}}^{\top} = P &= 
\left[\begin{array}{ccc} p_{1} & \cdots & p_{N} \end{array}\right]
\end{align*}
Comparing columns in $AT=T\mathcal{A}$ and $A^{\top}P=P\mathcal{A}^{\top}$, for 
$k\in\left[1,N-1\right]$:
\begin{align*}
At_{k} &= \beta_{k-1} t_{k-1} + \alpha_{k-1}t_{k} + \gamma_{k}t_{k+1}
& \text{with}\;\beta_{0}t_{0} \equiv 0\\
A^{\top}p_{k} &= \gamma_{k-1}p_{k-1} + \alpha_{k-1}p_{k} + \beta_{k}p_{k+1}
& \text{with}\;\gamma_{0}p_{0} \equiv 0
\end{align*}
In addition, since $T$ is orthogonal and $P^{\top}T=I_{N\times{}N}$:
\begin{align*}
\alpha_{k-1} &= p_{k}^{\top}At_{k}\\
\beta_{k}p_{k+1}\equiv r_{k} &=
\left(A-\alpha_{k-1}I\right)^{\top}p_{k}-\gamma_{k-1}p_{k-1}\\
\gamma_{k}t_{k+1}\equiv s_{k} &=
\left(A-\alpha_{k-1}I\right)t_{k}-\beta_{k-1}t_{k-1}\\
\end{align*}
Note that:
\begin{align}
1 = p_{k+1}^{\top}t_{k+1}&=\left(\frac{r_{k}}{\beta_{k}}\right)^{\top}
                      \left(\frac{s_{k}}{\gamma_{k}}\right)
\end{align}
and so if $\gamma_{k}$ is specified in advance:
\begin{align}
\beta_{k}&=\frac{r_{k}^{\top}s_{k}}{\gamma_{k}}
\end{align}
A common choice is $\gamma_{k} = \|s_{k}\|_{2}$\footnote{Recall that 
$\|s_{k}\|_{2}=\left(s_{k}^{\top}s_{k}\right)^{\frac{1}{2}}$.}.
Algorithm~\ref{alg:Unsymmetric-Lanczos-tridiagonalisation} calculates the
\emph{Lanczos tridiagonalisation} of an unsymmetric matrix.
\clearpage
\begin{algorithm}[htbp]
Convert the matrix $A$ to \emph{tri-diagonal} form:
\begin{algorithmic}
\State $r_{0}$ and $s_{0}$ are given unit 2-norm vectors with $r_{0}^{\top}s_{0} \ne 0$
\State $t_{0}=0$
\State $p_{0}=0$. 
\State $k=0$ 

\While {$r_{k}\ne 0 \land s_{k}\ne 0 \land r_{k}^{\top}s_{k}\ne 0$}
\State $\gamma_{k} = \|s_{k}\|_{2}$
\State $\beta_{k} = \frac{r_{k}^{\top}s_{k}}{\gamma_{k}}$
\State $t_{k+1} = \frac{s_{k}}{\gamma_{k}}$
\State $p_{k+1} = \frac{r_{k}}{\beta_{k}}$
\State $k = k+1$
\State $\alpha_{k-1} = p_{k}^{\top}At_{k}$
\State $r_{k} = \left(A-\alpha_{k-1}I\right)^{\top}p_{k}-\gamma_{k-1}p_{k-1}$
\State $s_{k} = \left(A-\alpha_{k-1}I\right)t_{k}-\beta_{k-1}t_{k-1}$
\EndWhile
\end{algorithmic}
\caption{\emph{Lanczos} tridiagonalisation of an unsymmetric matrix.}
\label{alg:Unsymmetric-Lanczos-tridiagonalisation}
\end{algorithm}
If 
\begin{align*}
\mathcal{A}_{k} &= \left[\begin{array}{cccccc}
\alpha_{0} & \beta_{1} & 0 & 0 & \cdots & 0\\
\gamma_{1} & \alpha_{1} & \beta_{2} & 0 & \cdots & 0 \\
0 & \gamma_{2} & \alpha_{2} & \beta_{3} & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & \gamma_{k-2} & \alpha_{k-2} & \beta_{k-1} \\
0 & 0 & \cdots & 0 & \gamma_{k-1} & \alpha_{k-1}
\end{array}\right] 
\end{align*}
then, when the loop of
Algorithm~\ref{alg:Unsymmetric-Lanczos-tridiagonalisation} terminates: 
\begin{align*}
A^{\top}\left[\begin{array}{ccc} p_{1} & \cdots & p_{k}\end{array}\right] &=
\left[\begin{array}{ccc} p_{1}&\cdots&p_{k}\end{array}\right]\mathcal{A}^{\top}_{k}
+r_{k}e_{k}^{\top}\\
A\left[\begin{array}{ccc} t_{1} & \cdots & t_{k}\end{array}\right] &=
\left[\begin{array}{ccc} t_{1} & \cdots & t_{k}\end{array}\right]\mathcal{A}_{k}
+s_{k}e_{k}^{\top}\\
\end{align*}
If $r_{k}=0$ when the iteration terminates then
$\mathspan\left\{\begin{array}{ccc}p_{1} & \cdots & p_{k}\end{array}\right\}$
is a subspace for $A$. If $s_{k}=0$ when the iteration terminates then
$\mathspan\left\{\begin{array}{ccc}t_{1} & \cdots & t_{k}\end{array}\right\}$
is a subspace for $A$. If neither of these conditions is true and 
$r^{\top}_{k}s_{k}=0$, then the tridiagonalisation process has failed. \emph{Golub
and Van Loan}~\cite[Section 9.4.4]{GolubVanLoan_MatrixComputations}
give a brief review of the \emph{Look-Ahead} technique for solving this 
problem. The Octave function \emph{lanczos\_tridiag} implements 
Algorithm~\ref{alg:Unsymmetric-Lanczos-tridiagonalisation}.
% \raggedbottom suppresses the following warning:
% "Underfull \vbox (badness 10000) has occurred while \output is active"
% Pages following \raggedbottom may have unequal page heights.

\chapter{\label{app:Lagrange-Interpolation}Review of Lagrange Interpolation}
This chapter follows the review article of \emph{Berrut} and
\emph{Trefethen}~\cite{BerrutTrefethen_BarycentricLagrangeInterpolation}.
\section{The barycentric Lagrange polynomial}
Let $n+1$ distinct interpolation points or \emph{nodes}, $x_{j}$, be given,
together with corresponding values, $f_{j}$. The interpolation problem is to
find a polynomial such that $p\left(x_{j}\right)=f_{j}$. The \emph{Lagrange}
solution is: 
\begin{align}
\begin{split}
  p\left(x\right)&=\sum^{n}_{j=0}f_{j}l_{j}\left(x\right)\\
  l_{j}&=\frac{\prod^{n}_{k=0,k\ne{}j}\left(x-x_{k}\right)}
         {\prod^{n}_{k=0,k\ne{}j}\left(x_{j}-x_{k}\right)}
\end{split}
\label{eqn:Lagrange-interpolation-polynomial}
\end{align}
The \emph{Lagrange polynomial} $l_{j}$ corresponding to $x_{j}$ has the
property:
\begin{align*}
  l_{j}\left(x_{k}\right)&=\begin{cases}
    1, & j=k \\
    0, & otherwise \\
    \end{cases}
\end{align*}
If $l\left(x\right)=\left(x-x_{0}\right)\hdots\left(x-x_{n}\right)$, and the
\emph{barycentric weights} are defined as:
\begin{align}
  w_{j}&=\frac{1}{\prod_{k\ne{}j}\left(x_{j}-x_{k}\right)}
         =\frac{1}{l^{\prime}\left(x_{j}\right)}
\label{eqn:First-Barycentric-Lagrange-weights}
\end{align}
then $l_{j}$ can be rewritten as:
\begin{align}
  l_{j}&=l\left(x\right)\frac{w_{j}}{\left(x-x_{j}\right)}
\label{eqn:First-Barycentric-Lagrange-weights-for-proof}
\end{align}
so that:
\begin{align}
  p\left(x\right)&=l\left(x\right)\sum^{n}_{j=0}\frac{w_{j}}{x-x_{j}}f_{j}
\label{eqn:First-Barycentric-Lagrange-polynomial}                   
\end{align}

If all $f_{j}=1$,
\begin{align*}
  1&=\sum^{n}_{j=0}l_{j}\left(x\right)
     =l\left(x\right)\sum^{n}_{j=0}\frac{w_{j}}{x-x_{j}}
\end{align*}
giving the \emph{barycentric formula} for $p\left(x\right)$:
\begin{align}
  p\left(x\right)&=\frac{\sum^{n}_{j=0}\frac{w_{j}}{x-x_{j}}f_{j}}
                   {\sum^{n}_{j=0}\frac{w_{j}}{x-x_{j}}}
\label{eqn:True-Barycentric-Lagrange-polynomial}                   
\end{align}

\section{Node distributions}
Explicit formulas for the weights, $w_{j}$, are available for certain sets of
nodes, $x_{j}$. If the nodes are equidistant, with spacing $h=\frac{2}{n}$, in
the interval $\left[-1,1\right]$, then:
\begin{align*}
  w_{j}&=\frac{\left(-1\right)^{n-j}\binom{n}{j}}{h^{n}n!}
\end{align*}
After cancelling factors independent of $j$:
\begin{align*}
  w_{j}&=\left(-1\right)^{j}\binom{n}{j}
\end{align*}
Clearly, for large $n$, the weights vary by exponentially large factors and, 
consequently, interpolation in equally spaced points is
\emph{ill-conditioned}\footnote{This is called the \emph{Runge phenomenon}}.
Unless $n$ is small, it is better to use node distributions that are clustered
at the end-points of the interval. The simplest such distributions are the
\emph{Chebyshev nodes}, formed by projecting equally spaced points on the unit
circle down to the interval $\left[-1,1\right]$. The \emph{Chebyshev nodes of
  the first kind} are:
\begin{align*}
  x_{j}&=\cos\frac{\left(2j+1\right)\pi}{2n+2}
\end{align*}
with weights:
\begin{align*}
  w_{j}&=\left(-1\right)^{j}\sin\frac{\left(2j+1\right)\pi}{2n+2}
\end{align*}
The \emph{Chebyshev nodes of the second kind} are:
\begin{align*}
  x_{j}&=\cos\frac{j\pi}{n}
\end{align*}
with weights:
\begin{align*}
  w_{j}&=\left(-1\right)^{j}\delta_{j}\\
  \quad \delta_{j}&=\begin{cases}
    \frac{1}{2}, & j=0 \text{ or } j=n \\
    1,           & \text{otherwise} \\
    \end{cases}
\end{align*}
\emph{Higham}~\cite{Higham_StabilityBarycentricLagrangianInterpolation} has
shown that Equation~\ref{eqn:First-Barycentric-Lagrange-polynomial} is
unconditionally numerically stable and that
Equation~\ref{eqn:True-Barycentric-Lagrange-polynomial} is stable if the
interpolation points are clustered appropriately.

The Octave script \emph{lagrange\_interp\_test.m} exercises the implementation
of Lagrange interpolation in the Octave function
\emph{lagrange\_interp}\footnote{The interpolation is much more accurate if
the function calculates the weights by the product in
Equation~\ref{eqn:First-Barycentric-Lagrange-weights} rather than
Equation~\ref{eqn:First-Barycentric-Lagrange-weights-for-proof}}. 
Figure~\ref{fig:Lagrange-Interp-n-20-Chebyshev-2} attempts to reproduce
\emph{Berrut} and \emph{Trefethen}'s Figure 5.1 for $21$ Chebyshev nodes of the
second kind. Figure~\ref{fig:Lagrange-Interp-n-20-linear} repeats the
interpolation experiment with linearly spaced nodes.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{lagrange_interp_test_n_20_Chebyshev_2}}
\caption{Lagrange interpolation of the function
  $fun\left(x\right)=|x|+\frac{x}{2}-x^{2}$ with $21$ Chebyshev nodes of the
  second kind and $101$ interpolated values on $\left[-1,1\right]$. The
  marks indicate the values, $f_{k}$, being interpolated.}
\label{fig:Lagrange-Interp-n-20-Chebyshev-2}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{lagrange_interp_test_n_20_linear}}
\caption{Lagrange interpolation of the function
  $fun\left(x\right)=|x|+\frac{x}{2}-x^{2}$ with $21$ linearly spaced nodes
  and $101$ interpolated values on $\left[-1,1\right]$. The marks
  indicate the values, $f_{k}$, being interpolated.}
\label{fig:Lagrange-Interp-n-20-linear}
\end{figure}

\begin{raggedbottom}

\chapter{\label{app:IIR-filter-response}IIR filter amplitude, phase and group-delay frequency responses}
This section describes the derivation of the amplitude (magnitude) and group
delay responses and their first and second partial derivatives (gradient vector
and Hessian matrix) with respect to the pole and zero locations of the 
transfer function. Some possibilities for constructing the first and second 
partial derivatives are:
\begin{itemize}
\item numerical differentiation by evaluation of the function at a perturbed
input coefficient vector
\item symbolic differentiation by a symbolic algebra package. For example, 
\emph{Maxima}~\cite{Maxima_website} or the Octave-Forge \emph{symbolic}
calculation toolbox~\cite{OctaveForge_SymbolicPackage}
\item differentiation by hand
\item so-called \emph{automatic differentiation}: ``a technology
for automatically augmenting computer programs, including arbitrarily complex
simulations, with statements for the computation of derivatives''. See 
~\cite[\emph{tools}]{Autodiff_website}.
\end{itemize}
Below I use a mixture of differentiation by hand and symbolic differentiation
to derive the formulas implemented in Octave code and use numerical 
differentiation to test the formulas. 

\emph{Richards}~\cite{Richards_DeczkyRecursiveDecimator} shows expressions
for the magnitude and group-delay of an IIR filter with an integer
decimation factor, $R$, and transfer function 
\begin{align}
\label{eqn:Transfer-function}
H\left(z\right) = \frac{N\left(z\right)}{D\left(z\right)} =
 K\frac{\sum_{j=0}^{J}n_{j}z^{-j}}{1+\sum_{l=1}^{L}d_{l}z^{-Rl}}
\end{align}
The polar coordinates of the zeros of $H\left(z\right)$ are assumed to be 
$\left\{ z_{0j}\right\} =\left\{ \left(R_{0j}\,,\,0\right)\,,\,\left(r_{0j}\,,\,\pm\theta_{0j}\right)\right\}$. Similarly, the poles of $H\left(z\right)$ are 
assumed to be $\left\{v_{pk}\right\} =\left\{\left(R_{pk}\,,\,0\right)\,,\,\left(r_{pk}\,,\,\pm\theta_{pk}\right)\right\}$ where $v=z^{R}$ (so that each pole 
on the $v$ plane corresponds to $R$ equally spaced poles on the $z$ plane). All 
coefficients are allowed to be negative so that the responses are differentiable
with respect to the coefficients. This means that the amplitude response derived
below can be negative if the gain coefficient is negative and, consequently,
the phase of the gain coefficient is not included in the phase response listed
below. If $R\ge{}2$, the gradients of the amplitude response are undefined for
real and complex poles with radius $0$.

For convenience in the following, rewrite Equation~\ref{eqn:Transfer-function}
as: 
\begin{align*}
\label{eqn:Transfer-function-with-delay}
H\left(z\right) = K\frac{z^{-J}}{z^{-RL}} 
\frac{\sum_{j=0}^{J}n_{j}z^{J-j}}
{\left[z^{RL}+\sum_{l=1}^{L}d_{l}z^{R\left(L-l\right)}\right]}
\end{align*}

Suppose there is a zero at $v=re^{\imath\theta}$, then the magnitude response
due to this zero is 
\begin{align*}
\left|\left(e^{\imath\omega}-re^{\imath\theta}\right)\right| &= \left|\left(\cos\omega-r\cos\theta\right)+\imath\left(\sin\omega-r\sin\theta\right)\right|\\
 &= \left\{ \cos^{2}\omega-2r\cos\omega\cos\theta+r^{2}\cos^{2}\theta+\sin^{2}\omega-2r\sin\omega\sin\theta+r^{2}\sin^{2}\theta\right\} ^{\frac{1}{2}}\\
 &= \left\{ 1-2r\cos\left(\omega-\theta\right)+r^{2}\right\} ^{\frac{1}{2}}
\end{align*}
and the phase due to this zero is
\begin{align*}
\arg\left\{ e^{\imath\omega}-re^{\imath\theta}\right\}  &= \arctan\left\{ \frac{\sin\omega-r\sin\theta}{\cos\omega-r\cos\theta}\right\} 
\end{align*}
so that the group delay due to this zero is 
\begin{align*}
-\frac{d}{d\omega} \arg\left\{ e^{\imath\omega}-re^{\imath\theta}\right\}  &= -\left[1+\left(\frac{\sin\omega-r\sin\theta}{\cos\omega-r\cos\theta}\right)^{2}\right]^{-1}\left[\frac{\left(\cos\omega-r\cos\theta\right)\cos\omega+\left(\sin\omega-r\sin\theta\right)\sin\omega}{\left(\cos\omega-r\cos\theta\right)^{2}}\right]\\
 &= -\frac{1-r\cos\theta\cos\omega-r\sin\theta\sin\omega}{\left(\cos\omega-r\cos\theta\right)^{2}+\left(\sin\omega-r\sin\theta\right)^{2}}\\
 &= -\frac{1-r\cos\left(\omega-\theta\right)}{1-2r\cos\left(\omega-\theta\right)+r^{2}}
\end{align*}

An alternative derivation of the group delay, $T\left(\omega\right)$, requires
that the amplitude response, $A\left(\omega\right)$, be positive: 
\begin{align*}
H\left(e^{ \imath \omega}\right) 
 &= A \left( \omega \right) e^{ \imath \Theta \left( \omega \right)} \\
\ln H\left( e^{ \imath \omega}\right)
 &= \ln A\left( \omega \right) + \imath \Theta \left( \omega \right) \\
T\left( \omega \right) = - \frac{d}{d\omega} \Theta \left( \omega \right) 
 &= -\Im\left\{ \frac{H^{\prime}\left( e^{ \imath \omega}\right)}
   {H \left( e^{ \imath \omega}\right)} \right\}
\end{align*}

In the following, the filter transfer function, $H\left(z\right)$, has
decimation factor $R$, $s=\frac{1}{R}$, $U$ real zeros, $V$ real poles,
$\frac{M}{2}$ conjugate zero pairs and $\frac{Q}{2}$ conjugate pole pairs.

\section{IIR filter responses}
\subsection{IIR filter amplitude response}
The amplitude response of $H\left(z\right)$ is:
\begin{align*}
A\left(\omega\right) &= K \times\frac{\prod_{j=1}^{U}\left\{ 1-2R_{0j}\cos\omega+R_{0j}^{2}\right\} ^{\frac{1}{2}}}{\prod_{j=1}^{V}\prod_{i=0}^{R-1}\left\{ 1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}\right\} ^{\frac{1}{2}}}\times\cdots\\*
 & \cdots\,\frac{\prod_{j=1}^{\frac{M}{2}}\left\{ 1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}\right\} ^{\frac{1}{2}}}{\prod_{j=1}^{\frac{Q}{2}}\prod_{i=0}^{R-1}\left\{ 1-2r_{pj}^{s}\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}\right\} ^{\frac{1}{2}}}\times\cdots\\*
 & \cdots\,\frac{\prod_{j=1}^{\frac{M}{2}}\left\{ 1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}\right\} ^{\frac{1}{2}}}{\prod_{j=1}^{\frac{Q}{2}}\prod_{i=0}^{R-1}\left\{ 1-2r_{pj}^{s}\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}\right\} ^{\frac{1}{2}}}
\end{align*}
The sign of $K$ is included in the amplitude response so that  
$\frac{\partial A\left(\omega\right)}{\partial K}$ is well defined at $K=0$.
\subsection{IIR filter phase response}
The phase response of $H\left(z\right)$ is:
\begin{align*}
P\left(\omega\right) &= \left[(V+Q)R-\left(U+M\right)\right]\omega+\cdots\\*
 & \cdots\,\sum_{j=1}^{U}\arctan\left(\frac{\sin\omega}{\cos\omega-R_{0j}}\right)-\cdots\\*
 & \cdots\,\sum_{j=1}^{V}\left\{\sum_{i=0}^{R-1}\arctan\left(\frac{\sin\omega-R_{pj}^{s}\sin\left(s2\pi i\right)}{\cos\omega-R_{pj}^{s}\cos\left(s2\pi i\right)}\right)\right\}+\cdots\\*
 & \cdots\,\sum_{j=1}^{\frac{M}{2}}\arctan\left(\frac{\sin2\omega-2r_{0j}\cos\theta_{0j}\sin\omega}{\cos2\omega-2r_{0j}\cos\theta_{0j}\cos\omega+r_{0j}^{2}}\right)-\cdots\\*
 & \cdots\,\sum_{j=1}^{\frac{Q}{2}}\left\{ \sum_{i=0}^{R-1}\arctan\left(\frac{\sin2\omega-2r_{pj}^{s}\cos\left[s\left(\theta_{pj}+2\pi i\right)\right]\sin\omega}{\cos2\omega-2r_{pj}^{s}\cos\left[s\left(\theta_{pj}+2\pi i\right)\right]\cos\omega+r_{pj}^{2s}}\right)\right\} 
\end{align*}
As noted above, the phase response does not include the sign of $K$.
\subsection{IIR filter group-delay response}
The group-delay response of $H\left(z\right)$ is:
\begin{align*}
T\left(\omega\right) &= -\left[(V+Q)R-\left(U+M\right)\right]-\cdots\\*
 & \cdots\,\sum_{j=1}^{U}\frac{1-R_{0j}\cos\omega}{1-2R_{0j}\cos\omega+R_{0j}^{2}}+\cdots\\*
 & \cdots\,\sum_{j=1}^{V}\left\{ \sum_{i=0}^{R-1}\frac{1-R_{pj}^{s}\cos\left(\omega-s2\pi i\right)}{1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}}\right\} -\cdots\\*
 & \cdots\,\sum_{j=1}^{\frac{M}{2}}\left\{ \frac{1-r_{0j}\cos\left(\omega-\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}+\frac{1-r_{0j}\cos\left(\omega+\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}\right\} +\cdots\\*
 & \cdots\,\sum_{j=1}^{\frac{Q}{2}}\left\{ \sum_{i=0}^{R-1}\frac{1-r_{pj}^{s}\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)}{1-2r_{pj}^{s}\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}}\right\} +\cdots\\*
 & \cdots\,\sum_{j=1}^{\frac{Q}{2}}\left\{ \sum_{i=0}^{R-1}\frac{1-r_{pj}^{s}\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)}{1-2r_{pj}^{s}\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}}\right\} 
\end{align*}

\section{Partial derivatives of the IIR filter responses}
\subsection{Partial derivatives of the IIR filter amplitude response}
The partial derivatives of the magnitude response with respect to the
coefficients are:
\begin{align*}
\frac{\partial A\left(\omega\right)}{\partial K} &= \frac{A\left(\omega\right)}{K}\\
\frac{\partial A\left(\omega\right)}{\partial R_{0j}} &= A\left(\omega\right)\left\{ \frac{R_{0j}-\cos\omega}{1-2R_{0j}\cos\omega+R_{0j}^{2}}\right\} \\
\frac{\partial A\left(\omega\right)}{\partial R_{pj}} &= -sR_{pj}^{s-1}A\left(\omega\right)\left\{ \sum_{i=0}^{R-1}\frac{R_{pj}^{s}-\cos\left(\omega-s2\pi i\right)}{1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}}\right\} \\
\frac{\partial A\left(\omega\right)}{\partial r_{0j}} &= A\left(\omega\right)\left\{ \frac{r_{0j}-\cos\left(\omega-\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}+\frac{r_{0j}-\cos\left(\omega+\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}\right\} \\
\frac{\partial A\left(\omega\right)}{\partial\theta_{0j}} &= A\left(\omega\right)\left\{ \frac{r_{0j}\sin\left(\omega+\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}-\frac{r_{0j}\sin\left(\omega-\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}\right\} \\
\frac{\partial A\left(\omega\right)}{\partial r_{pj}} &= -sr_{pj}^{s-1}A\left(\omega\right)\sum_{i=0}^{R-1}\left\{ \frac{r_{pj}^{s}-\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)}{1-2r_{pj}^{s}\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}}+\cdots\right.\\*
 & \left.\cdots\,\frac{r_{pj}^{s}-\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)}{1-2r_{pj}^{s}\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}}\right\} \\
\frac{\partial A\left(\omega\right)}{\partial\theta_{pj}} &= -sr_{pj}^{s}A\left(\omega\right)\sum_{i=0}^{R-1}\left\{ \frac{\sin\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)}{1-2r_{pj}^{s}\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}}-\cdots\right.\\*
 & \left.\cdots\,\frac{\sin\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)}{1-2r_{pj}^{s}\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}}\right\} 
\end{align*}

\subsection{Partial derivatives of the IIR filter phase response}
The partial derivatives of the phase response are
\begin{align*}
\frac{\partial P\left(\omega\right)}{\partial K} &= 0\\
\frac{\partial P\left(\omega\right)}{\partial R_{0j}} &= 
\frac{\sin\omega}{1-2R_{0j}\cos\omega+R_{0j}^{2}}\\
\frac{\partial P\left(\omega\right)}{\partial R_{pj}} &= 
-sR_{pj}^{s-1}\sum_{i=0}^{R-1}\frac{\sin\left(\omega-s2\pi i\right)}
{1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}}
\end{align*}
For convenience, write
\begin{align*}
P_{0N}&=\sin2\omega-2r_{0j}\cos\theta_{0j}\sin\omega\\
\frac{\partial P_{0N}}{\partial r_{0j}}&=-2\cos\theta_{0j}\sin\omega\\
\frac{\partial P_{0N}}{\partial \theta_{0j}}&=2r_{0j}\sin\theta_{0j}\sin\omega \\
P_{0D}&=\cos2\omega-2r_{0j}\cos\theta_{0j}\cos\omega+r_{0j}^{2}\\
\frac{\partial P_{0D}}{\partial r_{0j}}&=-2\cos\theta_{0j}\cos\omega+2r_{0j}\\
\frac{\partial P_{0D}}{\partial \theta_{0j}}&=2r_{0j}\sin\theta_{0j}\cos\omega
\end{align*}
then
\begin{align*}
  \frac{\partial P\left(\omega\right)}{\partial r_{0j}}
  &= \frac{P_{0D}\frac{\partial P_{0N}}{\partial r_{0j}}
    -P_{0N}\frac{\partial P_{0D}}{\partial r_{0j}}}{P_{0N}^{2}+P_{0D}^{2}}\\
  \frac{\partial P\left(\omega\right)}{\partial\theta_{0j}}
  &= \frac{P_{0D}\frac{\partial P_{0N}}{\partial\theta_{0j}}
    -P_{0N}\frac{\partial P_{0D}}{\partial\theta_{0j}}}{P_{0N}^{2}+P_{0D}^{2}}
\end{align*}
For convenience, write
\begin{align*}
P_{pN}&= \sin2\omega-
2r_{pj}^{s}\cos\left[s\left(\theta_{pj}+2\pi i\right)\right]\sin\omega\\
\frac{\partial P_{pN}}{\partial r_{pj}}
  &=-2sr_{pj}^{s-1}\cos\left[s\right(\theta_{pj}+2\pi i\left)\right]\sin\omega\\
  \frac{\partial P_{pN}}{\partial \theta_{pj}}
  &=2sr_{pj}^{s}\sin\left[s\right(\theta_{pj}+2\pi i\left)\right]\sin\omega \\
  P_{pD}&=\cos2\omega
          -2r_{pj}^{s}\cos\left[s\left(\theta_{pj}+2\pi i\right)\right]\cos\omega
          +r_{pj}^{2s}\\
  \frac{\partial P_{pD}}{\partial r_{pj}}
  &=-2sr_{pj}^{s-1}\cos\left[s\right(\theta_{pj}+2\pi i\left)\right]\cos\omega
    +2sr_{pj}^{2s-1}\\
  \frac{\partial P_{pD}}{\partial \theta_{pj}}
  &=2sr_{pj}^{s}\sin\left[s\right(\theta_{pj}+2\pi i\left)\right]\cos\omega
\end{align*}
then
\begin{align*}
  \frac{\partial P\left(\omega\right)}{\partial r_{pj}}
&=-\sum_{i=0}^{R-1}\left\{ \frac{P_{pD}\frac{\partial P_{pN}}{\partial r_{pj}}
 -P_{pN}\frac{\partial P_{pD}}{\partial r_{pj}}}{P_{pN}^{2}+P_{pD}^{2}}\right\} \\
  \frac{\partial P\left(\omega\right)}{\partial\theta_{pj}}
&=-\sum_{i=0}^{R-1}\left\{ \frac{P_{pD}\frac{\partial P_{pN}}{\partial\theta_{pj}}
 -P_{pN}\frac{\partial P_{pD}}{\partial\theta_{pj}}}{P_{pN}^{2}+P_{pD}^{2}}\right\}
\end{align*}

\subsection{Partial derivatives of the IIR filter group-delay response}
The partial derivatives of the group delay are
\begin{align*}
\frac{\partial T\left(\omega\right)}{\partial K} &= 0\\
\frac{\partial T\left(\omega\right)}{\partial R_{0j}} &= \frac{2R_{0j}-\left(R_{0j}^{2}+1\right)\cos\omega}{\left[1-2R_{0j}\cos\omega+R_{0j}^{2}\right]^{2}}\\
\frac{\partial T\left(\omega\right)}{\partial R_{pj}} &= sR_{pj}^{s-1}\sum_{i=0}^{R-1}\frac{\left(R_{pj}^{2s}+1\right)\cos\left(\omega-s2\pi i\right)-2R_{pj}^{s}}{\left[1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}\right]^{2}}\\
\frac{\partial T\left(\omega\right)}{\partial r_{0j}} &= \frac{2r_{0j}-\left(r_{0j}^{2}+1\right)\cos\left(\omega-\theta_{0j}\right)}{\left[1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}\right]^{2}}+\frac{2r_{0j}-\left(r_{0j}^{2}+1\right)\cos\left(\omega+\theta_{0j}\right)}{\left[1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}\right]^{2}}\\
\frac{\partial T\left(\omega\right)}{\partial\theta_{0j}} &= \frac{r_{0j}(r_{0j}^{2}-1)\sin\left(\omega-\theta_{0j}\right)}{\left[1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}\right]^{2}}-\frac{r_{0j}(r_{0j}^{2}-1)\sin\left(\omega+\theta_{0j}\right)}{\left[1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}\right]^{2}}\\
\frac{\partial T\left(\omega\right)}{\partial r_{pj}} &= sr_{pj}^{s-1}\sum_{i=0}^{R-1}\left\{ \frac{\left(r_{pj}^{2s}+1\right)\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)-2r_{pj}^{s}}{\left[1-2r_{pj}^{s}\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}\right]^{2}}+\cdots\right.\\*
 & \left.\cdots\,\frac{\left(r_{pj}^{2s}+1\right)\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)-2r_{pj}^{s}}{\left[1-2r_{pj}^{s}\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}\right]^{2}}\right\} \\
\frac{\partial T\left(\omega\right)}{\partial\theta_{pj}} &= sr_{pj}^{s}\left(1-r_{pj}^{2s}\right)\sum_{i=0}^{R-1}\left\{ \frac{\sin\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)}{\left[1-2r_{pj}^{s}\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}\right]^{2}}-\cdots\right.\\*
 & \left.\cdots\,\frac{\sin\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)}{\left[1-2r_{pj}^{s}\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}\right]^{2}}\right\} 
\end{align*}
\section{Second partial derivatives of the IIR filter response}
\subsection{Second partial derivatives of the IIR filter amplitude response}
The second partial derivatives of the magnitude response are (with $j\ne k$, and otherwise assumed to vary across all indexes):
\begin{align*}
\frac{\partial^{2}A\left(\omega\right)}{\partial K^{2}} &= 0\\
\frac{\partial^{2}A\left(\omega\right)}{\partial K\partial R_{0j}} &= \frac{1}{K}\frac{\partial A\left(\omega\right)}{\partial R_{0j}}\\
\frac{\partial^{2}A\left(\omega\right)}{\partial K\partial R_{pj}} &= \frac{1}{K}\frac{\partial A\left(\omega\right)}{\partial R_{pj}}\\
\frac{\partial^{2}A\left(\omega\right)}{\partial K\partial r_{0j}} &= \frac{1}{K}\frac{\partial A\left(\omega\right)}{\partial r_{0j}}\\
\frac{\partial^{2}A\left(\omega\right)}{\partial K\partial\theta_{0j}} &= \frac{1}{K}\frac{\partial A\left(\omega\right)}{\partial\theta_{0j}} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial K\partial r_{pj}} &= \frac{1}{K}\frac{\partial A\left(\omega\right)}{\partial r_{pj}}\\
\frac{\partial^{2}A\left(\omega\right)}{\partial K\partial\theta_{pj}} &= \frac{1}{K}\frac{\partial A\left(\omega\right)}{\partial\theta_{pj}} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial R_{0j}^{2}} &= A\left(\omega\right)\frac{\sin^{2}\omega}{\left[1-2R_{0j}\cos\omega+R_{0j}^{2}\right]^{2}}\\
\frac{\partial^{2}A\left(\omega\right)}{\partial R_{0k}\partial R_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial R_{0k}}\left\{ \frac{R_{0j}-\cos\omega}{1-2R_{0j}\cos\omega+R_{0j}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial R_{pj}\partial R_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial R_{pj}}\left\{ \frac{R_{0j}-\cos\omega}{1-2R_{0j}\cos\omega+R_{0j}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial r_{0j}\partial R_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial r_{0j}}\left\{ \frac{R_{0j}-\cos\omega}{1-2R_{0j}\cos\omega+R_{0j}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{0j}\partial R_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial\theta_{0j}}\left\{ \frac{R_{0j}-\cos\omega}{1-2R_{0j}\cos\omega+R_{0j}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial r_{pj}\partial R_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial r_{pj}}\left\{ \frac{R_{0j}-\cos\omega}{1-2R_{0j}\cos\omega+R_{0j}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{pj}\partial R_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial\theta_{pj}}\left\{ \frac{R_{0j}-\cos\omega}{1-2R_{0j}\cos\omega+R_{0j}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial R_{pj}^{2}} &= -sR_{pj}^{s-1}\frac{\partial A\left(\omega\right)}{\partial R_{pj}}\left\{ \sum_{i=0}^{R-1}\frac{R_{pj}^{s}-\cos\left(\omega-s2\pi i\right)}{1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}}\right\} +\cdots\\*
 & \cdots\, sR_{pj}^{s-2}A\left(\omega\right)\sum_{i=0}^{R-1}\left\{ \frac{R_{pj}^{3s}+\left(s-3\right)R_{pj}^{2s}\cos\left(\omega-s2\pi i\right)}{\left[1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}\right]^{2}}\right.+\cdots\\*
 & \cdots\,\left.\frac{\left(2\cos^{2}\left(\omega-s2\pi i\right)-2s+1\right)R_{pj}^{s}+\left(s-1\right)\cos\left(\omega-s2\pi i\right)}{\left[1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}\right]^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial R_{pk}\partial R_{pj}} &= -sR_{pj}^{s-1}\frac{\partial A\left(\omega\right)}{\partial R_{pk}}\left\{ \sum_{i=0}^{R-1}\frac{R_{pj}^{s}-\cos\left(\omega-s2\pi i\right)}{1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial r_{0j}\partial R_{pj}} &= -sR_{pj}^{s-1}\frac{\partial A\left(\omega\right)}{\partial r_{0j}}\left\{ \sum_{i=0}^{R-1}\frac{R_{pj}^{s}-\cos\left(\omega-s2\pi i\right)}{1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{0j}\partial R_{pj}} &= -sR_{pj}^{s-1}\frac{\partial A\left(\omega\right)}{\partial\theta_{0j}}\left\{ \sum_{i=0}^{R-1}\frac{R_{pj}^{s}-\cos\left(\omega-s2\pi i\right)}{1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial r_{pj}\partial R_{pj}} &= -sR_{pj}^{s-1}\frac{\partial A\left(\omega\right)}{\partial r_{pj}}\left\{ \sum_{i=0}^{R-1}\frac{R_{pj}^{s}-\cos\left(\omega-s2\pi i\right)}{1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{pj}\partial R_{pj}} &= -sR_{pj}^{s-1}\frac{\partial A\left(\omega\right)}{\partial\theta_{pj}}\left\{ \sum_{i=0}^{R-1}\frac{R_{pj}^{s}-\cos\left(\omega-s2\pi i\right)}{1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}}\right\}\\
\frac{\partial^{2}A\left(\omega\right)}{\partial r_{0j}^{2}} &= \frac{\partial A\left(\omega\right)}{\partial r_{0j}}\left\{ \frac{r_{0j}-\cos\left(\omega-\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}+\frac{r_{0j}-\cos\left(\omega+\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}\right\} +\cdots\\*
 & \cdots\, A\left(\omega\right)\left\{ \frac{2\sin^{2}\left(\omega-\theta_{0j}\right)}{\left[1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}\right]^{2}}-\frac{1}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}+\cdots\right.\\*
 & \left.\cdots\,\frac{2\sin^{2}\left(\omega+\theta_{0j}\right)}{\left[1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}\right]^{2}}-\frac{1}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial r_{0k}\partial r_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial r_{0k}}\left\{ \frac{r_{0j}-\cos\left(\omega-\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}+\frac{r_{0j}-\cos\left(\omega+\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{0j}\partial r_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial\theta_{0j}}\left\{ \frac{r_{0j}-\cos\left(\omega-\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}+\frac{r_{0j}-\cos\left(\omega+\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}\right\} +\cdots\\*
 & \cdots\, A\left(\omega\right)\left\{ \frac{\left(1-r_{0j}^{2}\right)\sin\left(\omega+\theta_{0j}\right)}{\left[1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}\right]^{2}}-\frac{\left(1-r_{0j}^{2}\right)\sin\left(\omega-\theta_{0j}\right)}{\left[1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}\right]^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{0k}\partial r_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial\theta_{0k}}\left\{ \frac{r_{0j}-\cos\left(\omega-\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}+\frac{r_{0j}-\cos\left(\omega+\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial r_{pj}\partial r_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial r_{pj}}\left\{ \frac{r_{0j}-\cos\left(\omega-\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}+\frac{r_{0j}-\cos\left(\omega+\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{pj}\partial r_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial\theta_{pj}}\left\{ \frac{r_{0j}-\cos\left(\omega-\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}+\frac{r_{0j}-\cos\left(\omega+\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{0j}^{2}} &= \frac{\partial A\left(\omega\right)}{\partial\theta_{0j}}\left\{ \frac{r_{0j}\sin\left(\omega+\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}-\frac{r_{0j}\sin\left(\omega-\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}\right\} +\cdots\\*
 & \cdots\, A\left(\omega\right)\left\{ \frac{\left(r_{0j}+r_{0j}^{3}\right)\cos\left(\omega+\theta_{0j}\right)-2r_{0j}^{2}}{\left[1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}\right]^{2}}+\frac{\left(r_{0j}+r_{0j}^{3}\right)\cos\left(\omega-\theta_{0j}\right)-2r_{0j}^{2}}{\left[1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}\right]^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{0k}\partial\theta_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial\theta_{0k}}\left\{ \frac{r_{0j}\sin\left(\omega+\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}-\frac{r_{0j}\sin\left(\omega-\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial r_{pj}\partial\theta_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial r_{pj}}\left\{ \frac{r_{0j}\sin\left(\omega+\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}-\frac{r_{0j}\sin\left(\omega-\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{pj}\partial\theta_{0j}} &= \frac{\partial A\left(\omega\right)}{\partial\theta_{pj}}\left\{ \frac{r_{0j}\sin\left(\omega+\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}}-\frac{r_{0j}\sin\left(\omega-\theta_{0j}\right)}{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}}\right\} 
\end{align*}
For convenience set
\begin{align*}
N_{n} &= r_{pj}^{2s-1}-r_{pj}^{s-1}\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)\\
N_{p} &= r_{pj}^{2s-1}-r_{pj}^{s-1}\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)\\
D_{n} &= 1-2r_{pj}^{s}\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}\\
D_{p} &= 1-2r_{pj}^{s}\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)+r_{pj}^{2s}
\end{align*}
so, to continue
\begin{align*}
\frac{\partial^{2}A\left(\omega\right)}{\partial r_{pj}^{2}} &= -s\frac{\partial A\left(\omega\right)}{\partial r_{pj}}\sum_{i=0}^{R-1}\left\{ \frac{N_{n}}{D_{n}}+\frac{N_{p}}{D_{p}}\right\} -\cdots\\*
 & \cdots\, sA\left(\omega\right)\sum_{i=0}^{R-1}\left\{ \frac{\left(2s-1\right)r_{pj}^{2s-2}-\left(s-1\right)r_{pj}^{s-2}\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)}{D_{n}}-\frac{2sN_{n}^{2}}{D_{n}^{2}}+\cdots\right.\\*
 & \left.\cdots\,\frac{\left(2s-1\right)r_{pj}^{2s-2}-\left(s-1\right)r_{pj}^{s-2}\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)}{D_{p}}-\frac{2sN_{p}^{2}}{D_{p}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial r_{pk}\partial r_{pj}} &= -s\frac{\partial A\left(\omega\right)}{\partial r_{pk}}\sum_{i=0}^{R-1}\left\{ \frac{N_{n}}{D_{n}}+\frac{N_{p}}{D_{p}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{pj}\partial r_{pj}} &= -s\frac{\partial A\left(\omega\right)}{\partial\theta_{pj}}\sum_{i=0}^{R-1}\left\{ \frac{N_{n}}{D_{n}}+\frac{N_{p}}{D_{p}}\right\} -\cdots\\*
 & \cdots\, sA\left(\omega\right)\sum_{i=0}^{R-1}\left\{ sr_{pj}^{s-1}\sin\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)\left[\frac{1}{D_{p}}-\frac{2N_{p}r_{pj}}{D_{p}^{2}}\right]-\cdots\right.\\*
 & \left.\cdots\, sr_{pj}^{s-1}\sin\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)\left[\frac{1}{D_{n}}-\frac{2N_{n}r_{pj}}{D_{n}^{2}}\right]\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{pk}\partial r_{pj}} &= -s\frac{\partial A\left(\omega\right)}{\partial\theta_{pk}}\sum_{i=0}^{R-1}\left\{ \frac{N_{n}}{D_{n}}+\frac{N_{p}}{D_{p}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{pj}^{2}} &= -s\frac{\partial A\left(\omega\right)}{\partial\theta_{pj}}\sum_{i=0}^{R-1}\left\{ \frac{r_{pj}^{s}\sin\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)}{D_{p}}-\frac{r_{pj}^{s}\sin\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)}{D_{n}}\right\} -\cdots\\*
 & \cdots sA\left(\omega\right)\sum_{i=0}^{R-1}\left\{ \frac{sr_{pj}^{s}\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)}{D_{p}}-\frac{2sr_{pj}^{2s}\sin^{2}\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)}{D_{p}^{2}}+\cdots\right.\\*
 & \left.\cdots\,\frac{sr_{pj}^{s}\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)}{D_{n}}-\frac{2sr_{pj}^{2s}\sin^{2}\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)}{D_{n}^{2}}\right\} \\
\frac{\partial^{2}A\left(\omega\right)}{\partial\theta_{pk}\partial\theta_{pj}} &= -s\frac{\partial A\left(\omega\right)}{\partial\theta_{pk}}\sum_{i=0}^{R-1}\left\{ \frac{r_{pj}^{s}\sin\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)}{D_{p}}-\frac{r_{pj}^{s}\sin\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)}{D_{n}}\right\} 
\end{align*}

\subsection{Second partial derivatives of the IIR filter phase response}
The non-zero second partial derivatives of the phase response are:
\begin{align*}
  \frac{\partial^{2}P\left(\omega\right)}{\partial R_{0j}^{2}}
  =& \frac{\partial P\left(\omega\right)}{\partial R_{0j}}
     \frac{2\cos\omega-2R_{0j}}{1-2R_{0j}\cos\omega+R_{0j}^{2}}  \\
\frac{\partial^{2}P\left(\omega\right)}{\partial R_{pj}^{2}}
  =& -s\left(s-1\right)R_{pj}^{s-2}\sum_{i=0}^{R-1}
    \frac{\sin\left(\omega-s2\pi i\right)}
    {1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}} \hdots \\
  &  -2s^{2}R_{pj}^{2s-2}\sum_{i=0}^{R-1}\frac{\sin\left(\omega-s2\pi i\right)
    \left[\cos\left(\omega-s2\pi i\right)-R_{pj}^{s}\right]}
    {\left[1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}\right]^{2}}
\end{align*}
For convenience, write:
\begin{align*}
  \frac{\partial^{2} P_{0N}\left(\omega\right)}{\partial r_{0j}^{2}} &=0 \\  
  \frac{\partial^{2} P_{0N}\left(\omega\right)}{\partial r_{0j}\theta_{0j}}
   &=2\sin\theta_{0j}\sin\omega \\  
  \frac{\partial^{2} P_{0N}\left(\omega\right)}{\partial\theta_{0j}^{2}}
   &=2r_{0j}\cos\theta_{0j}\sin\omega \\  
  \frac{\partial^{2} P_{0D}\left(\omega\right)}{\partial r_{0j}^{2}} &=2 \\  
  \frac{\partial^{2} P_{0D}\left(\omega\right)}{\partial r_{0j}\theta_{0j}}
   &=2\sin\theta_{0j}\cos\omega \\  
  \frac{\partial^{2} P_{0D}\left(\omega\right)}{\partial\theta_{0j}^{2}}
   &=2r_{0j}\cos\theta_{0j}\cos\omega
\end{align*}
then:
\begin{align*}
  \frac{\partial^{2} P\left(\omega\right)}{\partial r_{0j}^{2}}
  =&\frac{
    \frac{\partial P_{0D}}{\partial r_{0j}}\frac{\partial P_{0N}}{\partial r_{0j}}
    +P_{0D}\frac{\partial^{2} P_{0N}}{\partial r_{0j}^{2}}
   -\frac{\partial P_{0N}}{\partial r_{0j}}\frac{\partial P_{0D}}{\partial r_{0j}}
   -P_{0N}\frac{\partial^{2} P_{0D}}{\partial r_{0j}^{2}}}
     {P_{0N}^{2}+P_{0D}^{2}} \cdots\\*
 & -\frac{\left[ P_{0D}\frac{\partial P_{0N}}{\partial r_{0j}}
                -P_{0N}\frac{\partial P_{0D}}{\partial r_{0j}}\right]
          \left[2P_{0N}\frac{\partial P_{0N}}{\partial r_{0j}} 
               +2P_{0D}\frac{\partial P_{0D}}{\partial r_{0j}}\right]}
         {\left[P_{0N}^{2}+P_{0D}^{2}\right]^{2}} \\
  \frac{\partial^{2} P\left(\omega\right)}{\partial r_{0j}\partial\theta_{0j}}
  =&\frac{
\frac{\partial P_{0D}}{\partial\theta_{0j}}\frac{\partial P_{0N}}{\partial r_{0j}}
+P_{0D}\frac{\partial^{2} P_{0N}}{\partial r_{0j}\partial\theta_{0j}}
-\frac{\partial P_{0N}}{\partial\theta_{0j}}\frac{\partial P_{0D}}{\partial r_{0j}}
-P_{0N}\frac{\partial^{2} P_{0D}}{\partial r_{0j}\partial\theta_{0j}}}
     {P_{0N}^{2}+P_{0D}^{2}} \cdots\\*
   & -\frac{\left[  P_{0D}\frac{\partial P_{0N}}{\partial r_{0j}}
              -P_{0N}\frac{\partial P_{0D}}{\partial r_{0j}}\right]
            \left[ 2P_{0N}\frac{\partial P_{0N}}{\partial\theta_{0j}} 
                  +2P_{0D}\frac{\partial P_{0D}}{\partial\theta_{0j}}\right]}
           {\left[P_{0N}^{2}+P_{0D}^{2}\right]^{2}}\\
  \frac{\partial^{2} P\left(\omega\right)}{\partial\theta_{0j}^{2}}
  =&\frac{
     \frac{\partial P_{0D}}{\partial\theta_{0j}}
     \frac{\partial P_{0N}}{\partial\theta_{0j}}
     +P_{0D}\frac{\partial^{2} P_{0N}}{\partial\theta_{0j}^{2}}
     -\frac{\partial P_{0N}}{\partial\theta_{0j}}
      \frac{\partial P_{0D}}{\partial\theta_{0j}}
     -P_{0N}\frac{\partial^{2} P_{0D}}{\partial\theta_{0j}^{2}}}
     {P_{0N}^{2}+P_{0D}^{2}} \cdots\\*
  & -\frac{\left[  P_{0D}\frac{\partial P_{0N}}{\partial\theta_{0j}}
                  -P_{0N}\frac{\partial P_{0D}}{\partial\theta_{0j}}\right]
       \left[ 2P_{0N}\frac{\partial P_{0N}}{\partial\theta_{0j}} 
             +2P_{0D}\frac{\partial P_{0D}}{\partial\theta_{0j}}\right]}
    {\left[P_{0N}^{2}+P_{0D}^{2}\right]^{2}}
\end{align*}

For convenience, write:
\begin{align*}
  \frac{\partial^{2} P_{pN}\left(\omega\right)}{\partial r_{pj}^{2}}
  &=-2s\left(s-1\right)r_{pj}^{s-2}
    \cos\left[s\right(\theta_{pj}+2\pi i\left)\right]\sin\omega \\  
  \frac{\partial^{2} P_{pN}\left(\omega\right)}{\partial r_{pj}\theta_{pj}}
  &= 2s^{2}r_{pj}^{s-1}
    \sin\left[s\right(\theta_{pj}+2\pi i\left)\right]\sin\omega \\  
  \frac{\partial^{2} P_{pN}\left(\omega\right)}{\partial\theta_{pj}^{2}}
  &= 2s^{2}r_{pj}^{s}\cos\left[s\right(\theta_{pj}+2\pi i\left)\right]\sin\omega \\
  \frac{\partial^{2} P_{pD}\left(\omega\right)}{\partial r_{pj}^{2}}
  &= -2s\left(s-1\right)r_{pj}^{s-2}
    \cos\left[s\right(\theta_{pj}+2\pi i\left)\right]\cos\omega
    +2s\left(2s-1\right)r_{pj}^{2s-2}\\  
  \frac{\partial^{2} P_{pD}\left(\omega\right)}{\partial r_{pj}\theta_{pj}}
   &=  2s^{2}r_{pj}^{s-1}
    \sin\left[s\right(\theta_{pj}+2\pi i\left)\right]\cos\omega \\  
  \frac{\partial^{2} P_{pD}\left(\omega\right)}{\partial\theta_{pj}^{2}}
   &=2s^{2}r_{pj}^{s}\cos\left[s\right(\theta_{pj}+2\pi i\left)\right]\cos\omega
\end{align*}

then:
\begin{align*}
  \frac{\partial^{2} P\left(\omega\right)}{\partial r_{pj}^{2}}
  = -\sum_{i=0}^{R-1} & \left\{ \frac{
    \frac{\partial P_{pD}}{\partial r_{pj}}\frac{\partial P_{pN}}{\partial r_{pj}}
    +P_{pD}\frac{\partial^{2} P_{pN}}{\partial r_{pj}^{2}}
   -\frac{\partial P_{pN}}{\partial r_{pj}}\frac{\partial P_{pD}}{\partial r_{pj}}
   -P_{pN}\frac{\partial^{2} P_{pD}}{\partial r_{pj}^{2}}}
     {P_{pN}^{2}+P_{pD}^{2}} \cdots \right.\\*
 & \left. -\frac{\left[ P_{pD}\frac{\partial P_{pN}}{\partial r_{pj}}
                -P_{pN}\frac{\partial P_{pD}}{\partial r_{pj}}\right]
          \left[2P_{pN}\frac{\partial P_{pN}}{\partial r_{pj}} 
               +2P_{pD}\frac{\partial P_{pD}}{\partial r_{pj}}\right]}
         {\left[P_{pN}^{2}+P_{pD}^{2}\right]^{2}} \right\}\\
  \frac{\partial^{2} P\left(\omega\right)}{\partial r_{pj}\partial\theta_{pj}}
  = -\sum_{i=0}^{R-1} & \left\{ \frac{
\frac{\partial P_{pD}}{\partial\theta_{pj}}\frac{\partial P_{pN}}{\partial r_{pj}}
+P_{pD}\frac{\partial^{2} P_{pN}}{\partial r_{pj}\partial\theta_{pj}}
-\frac{\partial P_{pN}}{\partial\theta_{pj}}\frac{\partial P_{pD}}{\partial r_{pj}}
-P_{pN}\frac{\partial^{2} P_{pD}}{\partial r_{pj}\partial\theta_{pj}}}
     {P_{pN}^{2}+P_{pD}^{2}} \cdots \right.\\*
   & \left. -\frac{\left[  P_{pD}\frac{\partial P_{pN}}{\partial r_{pj}}
              -P_{pN}\frac{\partial P_{pD}}{\partial r_{pj}}\right]
            \left[ 2P_{pN}\frac{\partial P_{pN}}{\partial\theta_{pj}} 
                  +2P_{pD}\frac{\partial P_{pD}}{\partial\theta_{pj}}\right]}
           {\left[P_{pN}^{2}+P_{pD}^{2}\right]^{2}} \right\} \\
  \frac{\partial^{2} P\left(\omega\right)}{\partial\theta_{pj}^{2}}
  = -\sum_{i=0}^{R-1} & \left\{ \frac{
     \frac{\partial P_{pD}}{\partial\theta_{pj}}
     \frac{\partial P_{pN}}{\partial\theta_{pj}}
     +P_{pD}\frac{\partial^{2} P_{pN}}{\partial\theta_{pj}^{2}}
     -\frac{\partial P_{pN}}{\partial\theta_{pj}}
      \frac{\partial P_{pD}}{\partial\theta_{pj}}
     -P_{pN}\frac{\partial^{2} P_{pD}}{\partial\theta_{pj}^{2}}}
     {P_{pN}^{2}+P_{pD}^{2}} \cdots \right.\\*
  & \left. -\frac{\left[  P_{pD}\frac{\partial P_{pN}}{\partial\theta_{pj}}
                  -P_{pN}\frac{\partial P_{pD}}{\partial\theta_{pj}}\right]
       \left[ 2P_{pN}\frac{\partial P_{pN}}{\partial\theta_{pj}} 
             +2P_{pD}\frac{\partial P_{pD}}{\partial\theta_{pj}}\right]}
    {\left[P_{pN}^{2}+P_{pD}^{2}\right]^{2}} \right\}
\end{align*}

\subsection{Second partial derivatives of the IIR filter group-delay response}
The non-zero second partial derivatives of the group-delay response are:
\begin{align*}
\frac{\partial^{2}T\left(\omega\right)}{\partial R_{0j}^{2}} &= \frac{2\left(R_{0j}^{3}\cos\omega-3R_{0j}^{2}+3R_{0j}\cos\omega-\cos2\omega\right)}{\left[1-2R_{0j}\cos\omega+R_{0j}^{2}\right]^{3}}\\
\frac{\partial^{2}T\left(\omega\right)}{\partial R_{pj}^{2}} &= -sR_{pj}^{s-2}\sum_{i=0}^{R-1}\left\{ \frac{\left(s+1\right)\cos\left(\omega-s2\pi i\right)R_{pj}^{4s}+2\left[\left(s-1\right)\cos^{2}\left(\omega-s2\pi i\right)-\left(2s+1\right)\right]R_{pj}^{3s}}{\left[1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}\right]^{3}}\right.+\cdots\\*
 & \cdots\,\left.\frac{6\cos\left(\omega-s2\pi i\right)R_{pj}^{2s}+2\left[\left(2s-1\right)-\left(s+1\right)\cos^{2}\left(\omega-s2\pi i\right)\right]R_{pj}^{s}-\left(s-1\right)\cos\left(\omega-s2\pi i\right)}{\left[1-2R_{pj}^{s}\cos\left(\omega-s2\pi i\right)+R_{pj}^{2s}\right]^{3}}\right\} \\
\frac{\partial^{2}T\left(\omega\right)}{\partial r_{0j}^{2}} &= \frac{2\left[r_{0j}^{3}\cos\left(\omega-\theta_{0j}\right)-3r_{0j}^{2}+3r_{0j}\cos\left(\omega-\theta_{0j}\right)-\cos2\left(\omega-\theta_{0j}\right)\right]}{\left[1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}\right]^{3}}+\cdots\\*
 & \frac{2\left[r_{0j}^{3}\cos\left(\omega+\theta_{0j}\right)-3r_{0j}^{2}+3r_{0j}\cos\left(\omega+\theta_{0j}\right)-\cos2\left(\omega+\theta_{0j}\right)\right]}{\left[1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}\right]^{3}}\\
\frac{\partial^{2}T\left(\omega\right)}{\partial\theta_{0j}\partial r_{0j}} &= \frac{\sin\left(\omega+\theta_{0j}\right)\left[r_{0j}^{4}+2r_{0j}^{3}\cos\left(\omega+\theta_{0j}\right)-6r_{0j}^{2}+2r_{0j}\cos\left(\omega+\theta_{0j}\right)+1\right]}{\left[1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}\right]^{3}}-\cdots\\*
 & \frac{\sin\left(\omega-\theta_{0j}\right)\left[r_{0j}^{4}+2r_{0j}^{3}\cos\left(\omega-\theta_{0j}\right)-6r_{0j}^{2}+2r_{0j}\cos\left(\omega-\theta_{0j}\right)+1\right]}{\left[1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}\right]^{3}}\\
\frac{\partial^{2}T\left(\omega\right)}{\partial\theta_{0j}^{2}} &= -\frac{r_{0j}\left(r_{0j}^{2}-1\right)\left[r_{0j}^{2}\cos\left(\omega-\theta_{0j}\right)-2r_{0j}\left(1+\sin^{2}\left(\omega-\theta_{0j}\right)\right)+\cos\left(\omega-\theta_{0j}\right)\right]}{\left[1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}\right]^{3}}-\cdots\\*
 & \frac{r_{0j}\left(r_{0j}^{2}-1\right)\left[r_{0j}^{2}\cos\left(\omega+\theta_{0j}\right)-2r_{0j}\left(1+\sin^{2}\left(\omega+\theta_{0j}\right)\right)+\cos\left(\omega+\theta_{0j}\right)\right]}{\left[1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}\right]^{3}}\\
\frac{\partial^{2}T\left(\omega\right)}{\partial r_{pj}^{2}} &= -s\sum_{i=1}^{R-1}r_{pj}^{s-2}\left\{ \frac{2r_{pj}^{s}\left(s\left(r_{pj}^{2s}-1\right)-\left(r_{pj}^{2s}+1\right)\right)\cos^{2}\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)}{D_{p}^{3}}+\cdots\right.\\*
 & \left.\cdots\,\frac{\left(s\left(r_{pj}^{4s}-1\right)+\left(r_{pj}^{4s}+6r_{pj}^{2s}+1\right)\right)\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)-4sr_{pj}^{s}\left(r_{pj}^{2s}-1\right)-2r_{pj}^{s}\left(r_{pj}^{2s}+1\right)}{D_{p}^{3}}+\cdots\right.\\*
 & \left.\cdots\,\frac{2r_{pj}^{s}\left(s\left(r_{pj}^{2s}-1\right)-\left(r_{pj}^{2s}+1\right)\right)\cos^{2}\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)}{D_{n}^{3}}+\cdots\right.\\*
 & \left.\cdots\,\frac{\left(s\left(r_{pj}^{4s}-1\right)+\left(r_{pj}^{4s}+6r_{pj}^{2s}+1\right)\right)\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)-4sr_{pj}^{s}\left(r_{pj}^{2s}-1\right)-2r_{pj}^{s}\left(r_{pj}^{2s}+1\right)}{D_{n}^{3}}\right\} \\
\frac{\partial^{2}T\left(\omega\right)}{\partial\theta_{pj}\partial r_{pj}} &= s^{2}\sum_{i=1}^{R-1}r_{pj}^{s-1}\left\{ \frac{\left[2r_{pj}^{s}\left(r_{pj}^{2s}+1\right)\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)+\left(r_{pj}^{4s}-6r_{pj}^{2s}+1\right)\right]\sin\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)}{D_{n}^{3}}-\cdots\right.\\*
 & \left.\cdots\,\frac{\left[2r_{pj}^{s}\left(r_{pj}^{2s}+1\right)\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)+\left(r_{pj}^{4s}-6r_{pj}^{2s}+1\right)\right]\sin\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)}{D_{p}^{3}}\right\} \\
\frac{\partial^{2}T\left(\omega\right)}{\partial\theta_{pj}^{2}} &= s^{2}\sum_{i=1}^{R-1}r_{pj}^{s}\left(r_{pj}^{2s}-1\right)\left\{ \frac{2r_{pj}^{s}\cos^{2}\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)+\left(r_{pj}^{2s}+1\right)\cos\left(\omega+s\left(\theta_{pj}+2\pi i\right)\right)-4r_{pj}^{s}}{D_{p}^{3}}+\cdots\right.\\*
 & \left.\cdots\;\frac{2r_{pj}^{s}\cos^{2}\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)+\left(r_{pj}^{2s}+1\right)\cos\left(\omega-s\left(\theta_{pj}+2\pi i\right)\right)-4r_{pj}^{s}}{D_{n}^{3}}\right\} 
\end{align*}
The results for group delay were calculated with the assistance of
the \emph{Maxima}~\cite{Maxima_website} script \emph{delay.max}.

\section{Octave implementations}
The Octave function \emph{iirA} calculates the amplitude, and partial
derivatives and Hessian of the amplitude response of an IIR filter with
decimation factor $R$, $U$ real zeros, $V$ real poles, $\frac{M}{2}$ conjugate
zero pairs and $\frac{Q}{2}$ conjugate pole pairs. The Octave script
\emph{iirA\_test.m} exercises \emph{iirA}. Note that $R_{0}$ and $r_{0}$ are
moved off the unit circle when testing the gradients. Likewise, Octave function
\emph{iirT} calculates the group delay, partial derivatives and Hessian of the
group delay response of an IIR filter and is exercised by the test script
\emph{iirT\_test.m}. Again, Octave function \emph{iirP} calculates the phase, 
partial derivatives and Hessian of the phase response of an IIR filter and is
exercised by the test script \emph{iirP\_test.m}.

\textbf{!!! WARNING !!! The \emph{iirA}, \emph{iirP} and \emph{iirT} functions
do not attempt to handle the discontinuity and non-differentiability of
the properties of a zero at $z=1$.}

The Octave function \emph{iirA\_parallel.m} uses the \emph{parcellfun} function
included in the Octave-Forge \emph{parallel}
package~\cite{OctaveForge_ParallelPackage} to test ``parallelising'' the 
calculation of amplitude response and gradients by the \emph{iirA} function 
over $4$ processes. (My Intel i7-7700K CPU has $4$ CPUs). No benefit was seen on 
my PC until the frequency vector length was much longer than those used in the
examples.
\end{raggedbottom}

\chapter{\label{app:Gradient-IIR-filter-amplitude-response-wrt-frequency}Gradient of the IIR filter amplitude response with respect to frequency}
This section describes the derivatives with respect to angular frequency of the
amplitude response, $A\left(\omega\right)$, of an IIR filter expressed in
gain-pole-zero form. This section derives formulas for 
$\frac{\partial A\left(\omega\right)}{\partial\omega}$,
$\frac{\partial^{2} A\left(\omega\right)}{\partial\omega^{2}}$ and
formulas for the gradients with respect to the gain-pole-zero coefficients, 
 $\frac{\partial^{2} A\left(\omega\right)}{\partial\omega\partial K}$,
 $\frac{\partial^{2} A\left(\omega\right)}{\partial\omega\partial R_{0j}}$,
 $\frac{\partial^{2} A\left(\omega\right)}{\partial\omega\partial R_{pj}}$, etc.
In this case the denominator polynomial is \emph{not} decimated by $R$. 
The squared amplitude response is:
\begin{align*}
A^{2}\left(\omega\right) &= K^{2}
\frac{\prod_{j=1}^{U}\left\{ 1-2R_{0j}\cos\omega+R_{0j}^{2}\right\}}
{\prod_{j=1}^{V}\left\{ 1-2R_{pj}\cos\omega + R_{pj}^{2}\right\}}
\frac{\prod_{j=1}^{\frac{M}{2}}
\left\{\left(1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}\right)
\left(1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}\right)\right\}}
{\prod_{j=1}^{\frac{Q}{2}}
\left\{\left(1-2r_{pj}\cos\left(\omega-\theta_{pj}\right)+r_{pj}^{2}\right)
\left(1-2r_{pj}\cos\left(\omega+\theta_{pj}\right)+r_{pj}^{2}\right)\right\}}
\end{align*}
The gradient of the amplitude response with respect to angular frequency is
given by: 
\begin{align*}
\frac{1}{A\left(\omega\right)}
\frac{\partial A\left(\omega\right)}{\partial\omega} = 
&\sum_{j=1}^{U}\frac{R_{0j}\sin\omega}{1-2R_{0j}\cos\omega + R_{0j}^{2}}
-\sum_{j=1}^{V}\frac{R_{pj}\sin\omega}{1-2R_{pj}\cos\omega + R_{pj}^{2}}\cdots\\*
&+\sum_{j=1}^{\frac{M}{2}}\frac{r_{0j}\sin\left(\omega-\theta_{0j}\right)} 
{1-2r_{0j}\cos\left(\omega-\theta_{0j}\right) + r_{0j}^{2}}
-\sum_{j=1}^{\frac{Q}{2}}\frac{r_{pj}\sin\left(\omega-\theta_{pj}\right)} 
{1-2r_{pj}\cos\left(\omega-\theta_{pj}\right) + r_{pj}^{2}}\cdots\\*
&+\sum_{j=1}^{\frac{M}{2}}\frac{r_{0j}\sin\left(\omega+\theta_{0j}\right)} 
{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right) + r_{0j}^{2}}
-\sum_{j=1}^{\frac{Q}{2}}\frac{r_{pj}\sin\left(\omega+\theta_{pj}\right)} 
{1-2r_{pj}\cos\left(\omega+\theta_{pj}\right) + r_{pj}^{2}}
\end{align*}
The gradients with respect to the coefficients are given by
\begin{align*}
-\frac{1}{A^{2}\left(\omega\right)}
\frac{\partial A\left(\omega\right)}{\partial\omega} 
\frac{\partial A\left(\omega\right)}{\partial K}+
\frac{1}{A\left(\omega\right)}
\frac{\partial^{2} A\left(\omega\right)}{\partial\omega\partial K} &= 0 \\
-\frac{1}{A^{2}\left(\omega\right)}
\frac{\partial A\left(\omega\right)}{\partial\omega} 
\frac{\partial A\left(\omega\right)}{\partial R_{0j}}+
\frac{1}{A\left(\omega\right)}
\frac{\partial^{2} A\left(\omega\right)}{\partial\omega\partial R_{0j}} &=
\frac{\left(1-R_{0j}^2\right)\sin\omega}
{\left(1-2R_{0j}\cos\omega+R_{0j}^{2}\right)^2} \\
-\frac{1}{A^{2}\left(\omega\right)}
\frac{\partial A\left(\omega\right)}{\partial\omega} 
\frac{\partial A\left(\omega\right)}{\partial R_{pj}}+
\frac{1}{A\left(\omega\right)}
\frac{\partial^{2} A\left(\omega\right)}{\partial\omega\partial R_{pj}} &=
-\frac{\left(1-R_{pj}^2\right)\sin\omega}
{\left(1-2R_{pj}\cos\omega+R_{pj}^{2}\right)^2} \\
-\frac{1}{A^{2}\left(\omega\right)}
\frac{\partial A\left(\omega\right)}{\partial\omega} 
\frac{\partial A\left(\omega\right)}{\partial r_{0j}}+
\frac{1}{A\left(\omega\right)}
\frac{\partial^{2} A\left(\omega\right)}{\partial\omega\partial r_{0j}} &=
\frac{\left(1-r_{0j}^2\right)\sin\left(\omega-\theta_{0j}\right)}
{\left(1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}\right)^2} 
+\frac{\left(1-r_{0j}^2\right)\sin\left(\omega+\theta_{0j}\right)}
{\left(1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}\right)^2} \\
-\frac{1}{A^{2}\left(\omega\right)}
\frac{\partial A\left(\omega\right)}{\partial\omega} 
\frac{\partial A\left(\omega\right)}{\partial \theta_{0j}}+
\frac{1}{A\left(\omega\right)}
\frac{\partial^{2} A\left(\omega\right)}{\partial\omega\partial \theta_{0j}} &=
-\frac{r_{0j}\left(1+r_{0j}^2\right)\cos\left(\omega-\theta_{0j}\right)-2r_{0j}^{2}}
{\left(1-2r_{0j}\cos\left(\omega-\theta_{0j}\right)+r_{0j}^{2}\right)^2} 
+\frac{r_{0j}\left(1+r_{0j}^2\right)\cos\left(\omega+\theta_{0j}\right)-2r_{0j}^{2}}
{\left(1-2r_{0j}\cos\left(\omega+\theta_{0j}\right)+r_{0j}^{2}\right)^2} \\
-\frac{1}{A^{2}\left(\omega\right)}
\frac{\partial A\left(\omega\right)}{\partial\omega} 
\frac{\partial A\left(\omega\right)}{\partial r_{pj}}+
\frac{1}{A\left(\omega\right)}
\frac{\partial^{2} A\left(\omega\right)}{\partial\omega\partial r_{pj}} &=
-\frac{\left(1-r_{pj}^2\right)\sin\left(\omega-\theta_{pj}\right)}
{\left(1-2r_{pj}\cos\left(\omega-\theta_{pj}\right)+r_{pj}^{2}\right)^2}
-\frac{\left(1-r_{pj}^2\right)\sin\left(\omega+\theta_{pj}\right)}
{\left(1-2r_{pj}\cos\left(\omega+\theta_{pj}\right)+r_{pj}^{2}\right)^2}\\
-\frac{1}{A^{2}\left(\omega\right)}
\frac{\partial A\left(\omega\right)}{\partial\omega} 
\frac{\partial A\left(\omega\right)}{\partial \theta_{pj}}+
\frac{1}{A\left(\omega\right)}
\frac{\partial^{2} A\left(\omega\right)}{\partial\omega\partial \theta_{pj}} &=
\frac{r_{pj}\left(1+r_{pj}^2\right)\cos\left(\omega-\theta_{pj}\right)-2r_{pj}^{2}}
{\left(1-2r_{pj}\cos\left(\omega-\theta_{pj}\right)+r_{pj}^{2}\right)^2} 
-\frac{r_{pj}\left(1+r_{pj}^2\right)\cos\left(\omega+\theta_{pj}\right)-2r_{pj}^{2}}
{\left(1-2r_{pj}\cos\left(\omega+\theta_{pj}\right)+r_{pj}^{2}\right)^2}
\end{align*}
The second derivative of the amplitude response with respect to angular
frequency is given by:
\begin{align*}
-\left[\frac{1}{A\left(\omega\right)}
       \frac{\partial{}A\left(\omega\right)}{\partial\omega}\right]^{2}
+\frac{1}{A\left(\omega\right)}
  \frac{\partial^{2}A\left(\omega\right)}{\partial\omega^{2}} =
  & \phantom{+}\sum_{j=1}^{U}\frac{R_{0j}\cos\omega}
    {1-2R_{0j}\cos\omega + R_{0j}^{2}}
       -\sum_{j=1}^{U}\frac{2R_{0j}^{2}\sin^{2}\omega}
    {\left[1-2R_{0j}\cos\omega + R_{0j}^{2}\right]^{2}} \cdots\\*
  &-\sum_{j=1}^{V}\frac{R_{pj}\cos\omega}{1-2R_{pj}\cos\omega + R_{pj}^{2}}
    +\sum_{j=1}^{V}\frac{2R_{pj}^{2}\sin^{2}\omega}
    {\left[1-2R_{pj}\cos\omega + R_{pj}^{2}\right]^{2}}\cdots\\*
&+\sum_{j=1}^{\frac{M}{2}}\frac{r_{0j}\cos\left(\omega-\theta_{0j}\right)} 
           {1-2r_{0j}\cos\left(\omega-\theta_{0j}\right) + r_{0j}^{2}}
- \sum_{j=1}^{\frac{M}{2}}\frac{2r_{0j}^{2}\sin^{2}\left(\omega-\theta_{0j}\right)} 
{\left[1-2r_{0j}\cos\left(\omega-\theta_{0j}\right) + r_{0j}^{2}\right]^{2}}\cdots\\*
&-\sum_{j=1}^{\frac{Q}{2}}\frac{r_{pj}\cos\left(\omega-\theta_{pj}\right)} 
{1-2r_{pj}\cos\left(\omega-\theta_{pj}\right) + r_{pj}^{2}}
+\sum_{j=1}^{\frac{Q}{2}}\frac{2r_{pj}^{2}\sin^{2}\left(\omega-\theta_{pj}\right)} 
{\left[1-2r_{pj}\cos\left(\omega-\theta_{pj}\right) + r_{pj}^{2}\right]^{2}}\cdots\\*
&+\sum_{j=1}^{\frac{M}{2}}\frac{r_{0j}\cos\left(\omega+\theta_{0j}\right)} 
{1-2r_{0j}\cos\left(\omega+\theta_{0j}\right) + r_{0j}^{2}}
-\sum_{j=1}^{\frac{M}{2}}\frac{2r_{0j}^{2}\sin^{2}\left(\omega+\theta_{0j}\right)} 
{\left[1-2r_{0j}\cos\left(\omega+\theta_{0j}\right) + r_{0j}^{2}\right]^{2}}\cdots\\*
&-\sum_{j=1}^{\frac{Q}{2}}\frac{r_{pj}\cos\left(\omega+\theta_{pj}\right)}
{1-2r_{pj}\cos\left(\omega+\theta_{pj}\right) + r_{pj}^{2}}
+\sum_{j=1}^{\frac{Q}{2}}\frac{2r_{pj}^{2}\sin^{2}\left(\omega+\theta_{pj}\right)} 
{\left[1-2r_{pj}\cos\left(\omega+\theta_{pj}\right) + r_{pj}^{2}\right]^{2}}
\end{align*}

\chapter{\label{app:Allpass-filter-frequency-response}Allpass filter frequency response}

\section{\label{app:Allpass-filter-phase-response}Allpass filter phase response}
This section describes the phase response and the gradient of the phase response
of an all-pass filter in terms of the pole and zero locations of the transfer 
function. If $D\left(z\right)$ has $V$ real zeros and $\frac{Q}{2}$ pairs of 
complex conjugate zeros within the unit circle
\begin{align*}
  D\left(z\right)&=\left\{\prod^{V}_{k=1}z-R_{pk}\right\}
  \left\{\prod^{\frac{Q}{2}}_{k=1}
  \left(z-r_{pk}e^{\imath\theta_{pk}}\right)
  \left(z-r_{pk}e^{-\imath\theta_{pk}}\right)\right\}
\end{align*}
where $R_{pk}$ are the real zeros and $r_{pk}e^{\pm\imath\theta_{pk}}$ are the complex
conjugate zeros of of $D\left(z\right)$.

The all-pass filter transfer function with decimation factor, $R$, is:
\begin{align*}
A\left(z\right)
  &=z^{-R\left(V+Q\right)}\frac{D\left(z^{-R}\right)}{D\left(z^{R}\right)}\\
  &=\left\{\prod^{V}_{k=1}\frac{z^{-R}-R_{pk}}{1-R_{pk}z^{-R}}\right\}
  \left\{\prod^{\frac{Q}{2}}_{k=1}
    \frac{z^{-R}-r_{pk}e^{\imath\theta_{pk}}}{1-r_{pk}e^{-\imath\theta_{pk}}z^{-R}}\right\}
  \left\{\prod^{\frac{Q}{2}}_{k=1}
  \frac{z^{-R}-r_{pk}e^{-\imath\theta_{pk}}}{1-r_{pk}e^{\imath\theta_{pk}}z^{-R}}\right\}
\end{align*}

The squared-magnitude response of $A\left(z\right)$ is
$\left|A\left(e^{\imath \omega}\right)\right|^{2}=1$. The phase response of
$A\left(z\right)$ is
\begin{align*}
  P\left(\omega\right)=
&-\sum_{k=1}^{V}\left\{
         \arctan\frac{R_{pk}\sin R\omega}{1-R_{pk}\cos R\omega}+
         \arctan\frac{\sin R\omega}{\cos R\omega-R_{pk}}\right\}\cdots\\*
&-\sum_{k=1}^{\frac{Q}{2}}\left\{
          \arctan\frac{r_{pk}\sin\left(R\omega+\theta_{pk}\right)}
                       {1-r_{pk}\cos\left(R\omega+\theta_{pk}\right)}-
          \arctan\frac{\sin R\omega+r_{pk}\sin\theta_{pk}}
                       {\cos R\omega-r_{pk}\cos\theta_{pk}}\right\}\cdots\\*
&-\sum_{k=1}^{\frac{Q}{2}}\left\{
          \arctan\frac{r_{pk}\sin\left(R\omega-\theta_{pk}\right)}
                      {1-r_{pk}\cos\left(R\omega-\theta_{pk}\right)}-
          \arctan\frac{\sin R\omega-r_{pk}\sin\theta_{pk}}
                       {\cos R\omega-r_{pk}\cos\theta_{pk}}\right\}
\end{align*}
The partial derivatives of the phase response are:
\begin{align*}
  \frac{\partial P\left(\omega\right)}{\partial R_{pk}} &=
 -\frac{2\sin R\omega}{R_{pk}^{2}-2R_{pk}\cos R\omega+1}\\
  \frac{\partial P\left(\omega\right)}{\partial r_{pk}} &=
 -\frac{2\sin \left(R\omega-\theta_{pk}\right)}
       {r_{pk}^{2}-2r_{pk}\cos\left(R\omega-\theta_{pk}\right)+1}
 -\frac{2\sin \left(R\omega+\theta_{pk}\right)}
       {r_{pk}^{2}-2r_{pk}\cos\left(R\omega+\theta_{pk}\right)+1}\\
  \frac{\partial P\left(\omega\right)}{\partial \theta_{pk}} &=
 -\frac{2r_{pk}^{2}-2r_{pk}\cos\left(R\omega-\theta_{pk}\right)}
       {r_{pk}^{2}-2r_{pk}\cos\left(R\omega-\theta_{pk}\right)+1}
 +\frac{2r_{pk}^{2}-2r_{pk}\cos\left(R\omega+\theta_{pk}\right)}
       {r_{pk}^{2}-2r_{pk}\cos\left(R\omega+\theta_{pk}\right)+1}
\end{align*}
The second partial derivatives of the phase response (on the diagonal of the
Hessian matrix only) are:
\begin{align*}
  \frac{\partial^{2} P\left(\omega\right)}{\partial R_{pk}^{2}} =&
  \frac{4\left[R_{pk}-\cos R\omega\right]\sin R\omega}
         {\left[R_{pk}^{2}-2R_{pk}\cos R\omega+1\right]^{2}}\\
  \frac{\partial^{2} P\left(\omega\right)}{\partial r_{pk}^{2}} =&
  \frac{4\left[r_{pk}-\cos\left(R\omega-\theta_{pk}\right)\right]
        \sin\left(R\omega-\theta_{pk}\right)}
       {\left[r_{pk}^{2}-2r_{pk}\cos\left(R\omega-\theta_{pk}\right) +1\right]^{2}}
 +\frac{4\left[r_{pk}-\cos\left(R\omega+\theta_{pk}\right)\right]
        \sin\left(R\omega+\theta_{pk}\right)}
       {\left[r_{pk}^{2}-2r_{pk}\cos\left(R\omega+\theta_{pk}\right)+1\right]^{2}}\\
  \frac{\partial^{2} P\left(\omega\right)}{\partial \theta_{pk}^{2}}
  =&\phantom{+}\frac{2r_{pk}\sin\left(R\omega-\theta_{pk}\right)}
     {r_{pk}^{2}-2r_{pk}\cos\left(R\omega-\theta_{pk}\right)+1} 
-\frac{4\left[r_{pk}^{2}-r_{pk}\cos\left(R\omega-\theta_{pk}\right)\right]
       r_{pk}\sin\left(R\omega-\theta_{pk}\right)}
 {\left[r_{pk}^{2}-2r_{pk}\cos\left(R\omega-\theta_{pk}\right)+1\right]^{2}}\cdots\\*
&+\frac{2r_{pk}\sin\left(R\omega+\theta_{pk}\right)}
      {r_{pk}^{2}-2r_{pk}\cos\left(R\omega+\theta_{pk}\right)+1} 
-\frac{4\left[r_{pk}^{2}-r_{pk}\cos\left(R\omega+\theta_{pk}\right)\right]
       r_{pk}\sin\left(R\omega+\theta_{pk}\right)}
      {\left[r_{pk}^{2}-2r_{pk}\cos\left(R\omega+\theta_{pk}\right)+1\right]^{2}}
\end{align*}
The Octave function \emph{allpassP}
calculates the phase and partial derivatives of the phase response of an allpass
IIR filter and is exercised by the test script \emph{allpassP\_test.m}.
\section{\label{app:Allpass-filter-delay-response}Allpass filter group delay response}
This section describes the group delay response and the gradient of the group 
delay response of an all-pass filter in terms of the pole and zero locations of 
the transfer function. The phase response, $P\left(\omega\right)$, of the allpass
filter is derived in Section~\ref{app:Allpass-filter-phase-response}. The group
delay of the allpass filter is:
\begin{align*}
T\left(\omega\right) =
&-R\sum_{k=1}^{V}\frac{R_{pk}^{2}-1}{R_{pk}^{2}-2R_{pk}\cos R\omega+1} \hdots \\
&-R\sum_{k=1}^{\frac{Q}{2}}\frac{r_{pk}^{2}-1}
{r_{pk}^{2}-2r_{pk}\cos\left( R\omega+\theta_{pk}\right)+1} \hdots \\
&-R\sum_{k=1}^{\frac{Q}{2}}\frac{r_{pk}^{2}-1}
{r_{pk}^{2}-2r_{pk}\cos\left( R\omega-\theta_{pk}\right)+1}
\end{align*}
The partial derivatives of the group delay with respect to the coefficients are:
\begin{align*}
\frac{\partial T\left(\omega\right)}{\partial R_{pk}} &=
2R\frac{\left(R_{pk}^{2}+1\right)\cos R\omega -2R_{pk}}
{\left[R_{pk}^{2}-2R_{pk}\cos R\omega+1\right]^{2}}\\
\frac{\partial T\left(\omega\right)}{\partial r_{pk}} &=
2R\frac{\left(r_{pk}^{2}+1\right)\cos\left(R\omega+\theta_{pk}\right) -2r_{pk}}
{\left[r_{pk}^{2}-2r_{pk}\cos\left(R\omega+\theta_{pk}\right) +1\right]^{2}}+
2R\frac{\left(r_{pk}^{2}+1\right)\cos\left(R\omega-\theta_{pk}\right) -2r_{pk}}
{\left[r_{pk}^{2}-2r_{pk}\cos\left(R\omega-\theta_{pk}\right) +1\right]^{2}}\\
\frac{\partial T\left(\omega\right)}{\partial \theta_{pk}} &=
2R\frac{r_{pk}\left(r_{pk}^{2}-1\right)\sin\left(R\omega+\theta_{pk}\right)}
{\left[r_{pk}^{2}-2r_{pk}\cos\left(R\omega+\theta_{pk}\right) +1\right]^{2}}-
2R\frac{r_{pk}\left(r_{pk}^{2}-1\right)\sin\left(R\omega-\theta_{pk}\right)}
{\left[r_{pk}^{2}-2r_{pk}\cos\left(R\omega-\theta_{pk}\right) +1\right]^{2}}
\end{align*}
The second partial derivatives of the group delay response (on the diagonal
of the Hessian matrix only) are:
\begin{align*}
\frac{\partial^{2} T\left(\omega\right)}{\partial R_{pk}^{2}} =&
-4R\frac{R_{pk}^{3}\cos R\omega-3R_{pk}^{2}+3R_{pk}\cos R\omega+1-2\cos^{2}R\omega}
{\left[R_{pk}^{2}-2R_{pk}\cos R\omega+1\right]^{3}}\\
\frac{\partial^{2} T\left(\omega\right)}{\partial r_{pk}^{2}} =&
-4R\frac{r_{pk}^{3}\cos\left(R\omega+\theta_{pk}\right)-3r_{pk}^{2}
+3r_{pk}\cos\left(R\omega+\theta_{pk}\right)
+1-2\cos^{2}\left(R\omega+\theta_{pk}\right)}
{\left[r_{pk}^{2}-2r_{pk}\cos\left(R\omega+\theta_{pk}\right)+1\right]^{3}}\cdots\\*
&-4R\frac{r_{pk}^{3}\cos\left(R\omega-\theta_{pk}\right)-3r_{pk}^{2}
+3r_{pk}\cos\left(R\omega-\theta_{pk}\right)
+1-2\cos^{2}\left(R\omega-\theta_{pk}\right)}
{\left[r_{pk}^{2}-2r_{pk}\cos\left(R\omega-\theta_{pk}\right)+1\right]^{3}}\\
\frac{\partial^{2} T\left(\omega\right)}{\partial \theta_{pk}^{2}} =&
\phantom{+}2R\frac{r_{pk}^{5}\cos\left(R\omega+\theta_{pk}\right)
-2r_{pk}^{2}\left(r_{pk}^{2}-1\right)
\left[1+\sin^{2}\left(R\omega+\theta_{pk}\right)\right]
-r_{pk}\cos\left(R\omega+\theta_{pk}\right)}
{\left[r_{pk}^{2}-2r_{pk}\cos\left(R\omega+\theta_{pk}\right)+1\right]^{3}}\cdots\\*
&+2R\frac{r_{pk}^{5}\cos\left(R\omega-\theta_{pk}\right)
-2r_{pk}^{2}\left(r_{pk}^{2}-1\right)
\left[1+\sin^{2}\left(R\omega-\theta_{pk}\right)\right]
-r_{pk}\cos\left(R\omega-\theta_{pk}\right)}
{\left[r_{pk}^{2}-2r_{pk}\cos\left(R\omega-\theta_{pk}\right)+1\right]^{3}}
\end{align*}

The Octave function \emph{allpassT} calculates the phase and partial derivatives
of the group delay response of an allpass IIR filter and is exercised by the 
test script \emph{allpassT\_test.m}.

\chapter{\label{app:Gradients-state-variable-filter-frequency-response}Gradients of the digital state variable filter frequency response}
Section~\ref{sec:Sensitivity-analysis-state-variable-transfer-function} shows
results for the gradients of the complex response, $H\left(z\right)$, with
respect to the matrix components of the corresponding digital state variable
filter. This section shows results for the gradients of the squared-magnitude,
phase and group delay of a state variable filter. In the following, the
components of the state variable filter matrixes $A$, $B$, $C$ and $D$ are
represented by $\alpha$, $\beta$, $\gamma$ and $\delta$ or more generally, $x$.
The matrix components may themselves be functions of other variables (the 
$k$ and $c$ coefficients of a Schur lattice filter, for example). In the
following, the \emph{resolvent} matrix, $R$, is defined on the unit circle as
$R=\left(e^{\imath\omega}I-A\right)^{-1}$. The identities shown in
Equation~\ref{eqn:Sensitivity-analysis-state-variable-transfer-function} apply
with:
\begin{align*}
  \frac{\partial{}R}{\partial{}\omega} =& -\imath{}e^{\imath\omega}RR
\end{align*}

\section{\label{app:State-variable-filter-gradients-complex-frequency-response}Gradients of the state variable  filter complex frequency response}
If the gradients of the state variable matrixes, $A$, $B$, $C$ and $D$, with
respect to a coefficient, $x$, are $\frac{dA}{dx}$, $\frac{dB}{dx}$,
$\frac{dC}{dx}$ and $\frac{dD}{dx}$, then the gradients of the complex frequency
response, $H\left(\omega\right)$, are:

\begin{align*}
\frac{\partial{}H}{\partial\omega}=&
-\imath e^{\imath\omega}CRRB \\
\frac{\partial{}H}{\partial{}x}=&\frac{dC}{dx}RB+
                                  CR\frac{dA}{dx}RB+
                                  CR\frac{dB}{dx}+
                                  \frac{dD}{dx}\\
\frac{\partial{}^{2}H}{\partial{}x\partial{}\omega}=&
-\imath{}e^{\imath\omega}\left[
\frac{dC}{dx}RRB+CRR\frac{dA}{dx}RB+CR\frac{dA}{dx}RRB+CRR\frac{dB}{dx}\right]\\
\begin{split}  
\frac{\partial{}^{2}H}{\partial{}x^{2}}=&
\frac{d^{2}C}{dx^{2}}RB+
2\frac{dC}{dx}R\frac{dA}{dx}RB+
2\frac{dC}{dx}R\frac{dB}{dx}+
2CR\frac{dA}{dx}R\frac{dA}{dx}RB+ \cdots\\
&CR\frac{d^{2}A}{dx^{2}}RB+
2CR\frac{dA}{dx}R\frac{dB}{dx}+
CR\frac{d^{2}B}{dx^{2}}+
\frac{d^{2}D}{dx^{2}}
\end{split}\\
\begin{split}  
\frac{\partial{}^{3}H}{\partial{}\omega\partial{}x^{2}}=&
-\imath{}e^{\imath\omega}\left[
\frac{d^{2}C}{dx^{2}}RRB+
2\frac{dC}{dx}R\frac{dA}{dx}RRB+
2\frac{dC}{dx}RR\frac{dA}{dx}RB+
2\frac{dC}{dx}RR\frac{dB}{dx}+\cdots\right.\\*
&\left.\phantom{-\imath{}e^{\imath\omega}}\;
2CR\frac{dA}{dx}R\frac{dA}{dx}RRB+
CR\frac{d^{2}A}{dx^{2}}RRB+
2CR\frac{dA}{dx}RR\frac{dA}{dx}RB+
2CR\frac{dA}{dx}RR\frac{dB}{dx}+
\cdots\right.\\*
&\left.\phantom{-\imath{}e^{\imath\omega}}\;
2CRR\frac{dA}{dx}R\frac{dA}{dx}RB+
CRR\frac{d^{2}A}{dx^{2}}RB+
2CRR\frac{dA}{dx}R\frac{dB}{dx}+
CRR\frac{d^{2}B}{dx^{2}}\right]\\
\frac{\partial{}^{2}H}{\partial{}y\partial{}x}=&
\frac{d^{2}C}{dydx}RB+
\frac{dC}{dx}R\frac{dA}{dy}RB+
\frac{dC}{dx}R\frac{dB}{dy}+\cdots\\
&\frac{dC}{dy}R\frac{dA}{dx}RB+
CR\frac{dA}{dy}R\frac{dA}{dx}RB+
CR\frac{d^{2}A}{dydx}RB+
CR\frac{dA}{dx}R\frac{dA}{dy}RB+
CR\frac{dA}{dx}R\frac{dB}{dy}+\cdots\\
&\frac{dC}{dy}R\frac{dB}{dx}+
CR\frac{dA}{dy}R\frac{dB}{dx}+
CR\frac{d^{2}B}{dydx}+
\frac{d^{2}D}{dydx}
\end{split}\\
\frac{\partial{}^{3}H}{\partial{}\omega\partial{}y\partial{}x}=&
-\imath{}e^{\imath\omega}\left[
\frac{d^{2}C}{dydx}RRB+
\frac{dC}{dx}RR\frac{dA}{dy}RB+
\frac{dC}{dx}R\frac{dA}{dy}RRB+
\frac{dC}{dx}RR\frac{dB}{dy}+
\frac{dC}{dy}RR\frac{dA}{dx}RB+
\frac{dC}{dy}R\frac{dA}{dx}RRB+\cdots\right.\\*
&\left.\phantom{-\imath{}e^{\imath\omega}}\;
CRR\frac{dA}{dy}R\frac{dA}{dx}RB+
CR\frac{dA}{dy}RR\frac{dA}{dx}RB+
CR\frac{dA}{dy}R\frac{dA}{dx}RRB+\cdots\right.\\*
&\left.\phantom{-\imath{}e^{\imath\omega}}\;
CRR\frac{d^{2}A}{dydx}RB+
CR\frac{d^{2}A}{dydx}RRB+\cdots\right.\\*
&\left.\phantom{-\imath{}e^{\imath\omega}}\;
CRR\frac{dA}{dx}R\frac{dA}{dy}RB+
CR\frac{dA}{dx}RR\frac{dA}{dy}RB+
CR\frac{dA}{dx}R\frac{dA}{dy}RRB+\cdots\right.\\*
&\left.\phantom{-\imath{}e^{\imath\omega}}\;
CRR\frac{dA}{dx}R\frac{dB}{dy}+
CR\frac{dA}{dx}RR\frac{dB}{dy}+
\frac{dC}{dy}RR\frac{dB}{dx}+
CRR\frac{dA}{dy}R\frac{dB}{dx}+
CR\frac{dA}{dy}RR\frac{dB}{dx}+
CRR\frac{d^{2}B}{dydx}\right]
\end{align*}

The Octave function \emph{Abcd2H} calculates these gradients under the assumption
that the components of the state variable matrixes $A$, $B$, $C$ and $D$ are
first-order polynomial functions of coefficients $x$ or $y$ and
$\frac{d^{2}A}{dx^{2}}=\frac{d^{2}B}{dx^{2}}=
\frac{d^{2}C}{dx^{2}}=\frac{d^{2}D}{dx^{2}}=0$. This assumption holds for the
Schur one-multiplier lattice filter.

\section{\label{app:State-variable-filter-squared-magnitude-response}State  variable  filter squared-magnitude response}
The squared-magnitude response of a state variable filter is:
\begin{align*}
\left|H\right|^{2} &=\Im H^{2} + \Re H^{2}
\end{align*}

The gradients of the squared-magnitude response of the filter with respect to 
the state variable coefficients are:
\begin{align*}
\frac{\partial\left|H\right|^{2}}{\partial{}x}
&= 2\left[\Im H\Im\frac{\partial{}H}{\partial{}x}+
          \Re H\Re\frac{\partial{}H}{\partial{}x}\right]
\end{align*}
where $x$ represents the components of the state variable matrixes. The 
diagonal of the Hessian matrix of the squared-magnitude (that is the second
derivatives of the squared-magnitude) is:
\begin{align*}
\frac{\partial^{2}\left|H\right|^{2}}{\partial{}x^{2}}
  &= 2\left[
\left|\frac{\partial{}H}{\partial{}x}\right|^{2}+
    \Im H\Im\frac{\partial^{2}H}{\partial{}x^{2}}+
    \Re H\Re\frac{\partial^{2}H}{\partial{}x^{2}}\right]
\end{align*}
If $A$ is a first-order polynomial function of the state variable matrix
coefficients, $\alpha$, then:
\begin{align*}
\frac{\partial^{2}H}{\partial\alpha^{2}} &= 
2CR\frac{dA}{d\alpha}R\frac{dA}{d\alpha}RB
\end{align*}
Similarly, if $B$ is a first-order polynomial function of the state variable
matrix coefficients, $\beta$, and-so-on, then:
\begin{align*}
\frac{\partial^{2}H}{\partial\beta^{2}} &= 
\frac{\partial^{2}H}{\partial\gamma^{2}} = 
\frac{\partial^{2}H}{\partial\delta^{2}} = 0
\end{align*}

The Hessian matrix of the squared-magnitude (that is the second
derivatives of the squared-magnitude) is:
\begin{align*}
  \frac{\partial^{2}\left|H\right|^{2}}{\partial{}y\partial{}x}
  &=2\left[\Im\frac{\partial{}H}{\partial{}y}
    \Im\frac{\partial{}H}{\partial{}x} +
    \Im H\Im\frac{\partial^{2}H}
    {\partial{}y\partial{}x} + 
    \Re\frac{\partial{}H}{\partial{}y}
    \Re\frac{\partial{}H}{\partial{}x} +
    \Re H\Re\frac{\partial^{2}H}
    {\partial{}y\partial{}x}\right]
\end{align*}
where $x$ and $y$ represent the state variable matrix coefficients $\alpha$,
$\beta$, etc.

The gradient of the squared-magnitude response of the filter with respect to 
the angular frequency is:
\begin{align*}
\frac{\partial\left|H\right|^{2}}{\partial\omega}
&= 2\left[\Im H\Im\frac{\partial{}H}{\partial\omega}+
          \Re H\Re\frac{\partial{}H}{\partial\omega}\right]
\end{align*}
and with respect to the coefficients, $x$:
\begin{align*}
  \frac{\partial^{2}  \left|H\right|^{2}}
  {\partial\omega\partial{}x}
  &= 2\left[ \Im\frac{\partial{}H}{\partial{}x}
             \Im\frac{\partial{}H}{\partial\omega}+
    \Im H\Im\frac{\partial^{2}H}{\partial\omega\partial{}x}+
    \Re\frac{\partial{}H}{\partial{}x}
    \Re\frac{\partial{}H}{\partial\omega}+
    \Re H\Re\frac{\partial^{2}H}{\partial\omega\partial{}x}
  \right]
\end{align*}
The Hessian matrix of the gradient of the squared-magnitude with respect to
angular frequency is:
\begin{align*}
  \begin{split}
  \frac{\partial^{3}\left|H\right|^{2}}
  {\partial\omega\partial{}y\partial{}x}
  =&2\left[\Im\frac{\partial^{2}H}{\partial\omega\partial{}y\partial{}x}
    \Im\frac{\partial{}H}{\partial{}w} +
    \Im\frac{\partial{}H}{\partial{}x}
    \Im\frac{\partial^{2}H}{\partial\omega\partial{}y} +  
    \Im \frac{\partial{}H}{\partial{}y}
    \Im\frac{\partial^{2}H}{\partial\omega\partial{}x} + 
    \Im H\Im\frac{\partial^{3}H}{\partial\omega\partial{}y\partial{}x} +
    \cdots\right.\\*
   &\phantom{2}\left.\;
    \Re\frac{\partial^{2}H}{\partial{}y\partial{}x}
    \Re\frac{\partial{}H}{\partial{}w} +
    \Re\frac{\partial{}H}{\partial{}x}
    \Re\frac{\partial^{2}H}{\partial\omega\partial{}y} +
    \Re\frac{\partial{}H}{\partial{}y}
    \Re\frac{\partial^{2}H}{\partial\omega\partial{}x} +
    \Re H\Re\frac{\partial^{3}H}{\partial\omega\partial{}y\partial{}x}\;\right]
  \end{split}
\end{align*}
\section{\label{app:State-variable-filter-phase-response}State  variable filter phase response}
The phase response, $P$, of the state variable filter is:
\begin{align*}
P&=\arctan\frac{\Im H}{\Re H}
\end{align*}

The gradients of the phase response of the filter with respect to 
the state variable coefficients, $\alpha$, $\beta$, etc., are given by:
\begin{align*}
\left|H\right|^{2}\frac{\partial{}P}{\partial{}x}&=
\Re H\Im\frac{\partial{}H}{\partial{}x}-
\Im H\Re\frac{\partial{}H}{\partial{}x}
\end{align*}
where $x$ represents the components of the state variable matrixes.
The diagonal of the Hessian matrix of the phase (that is the second
derivatives of the phase) is given by:
\begin{align*}
\frac{\partial\left|H\right|^{2}}{\partial{}x}
\frac{\partial{}P}{\partial{}x}+\left|H\right|^{2}
\frac{\partial^{2}P}{\partial{}x^{2}}&=
\Re H\Im\frac{\partial^{2}H}{\partial{}x^{2}}-
\Im H\Re\frac{\partial^{2}H}{\partial{}x^{2}}
\end{align*}

The Hessian matrix of the phase (that is the second
derivatives of the phase) is given by:
\begin{align*}
  \frac{\partial\left|H\right|^{2}}{\partial{}y}
  \frac{\partial{}P}{\partial{}x} +
  \left|H\right|^{2}
  \frac{\partial^{2}P}{\partial{}y\partial{}x}
  &=\Re\frac{\partial{}H}{\partial{}y}
    \Im\frac{\partial{}H}{\partial{}x} +
    \Re H\Im\frac{\partial^{2}H}
    {\partial{}y\partial{}x} -
    \Im\frac{\partial{}H}{\partial{}y}
    \Re\frac{\partial{}H}{\partial{}x} -
    \Im{}H\Re\frac{\partial^{2}H}
    {\partial{}y\partial{}x}
\end{align*}

\section{\label{app:State-variable-filter-group-delay-response}State  variable filter group-delay response}
The group delay response, $T$, of the state variable filter is
\begin{align*}
T &= -\frac{\partial\phantom{\omega}}{\partial\omega}
\arctan\frac{\Im H}
{\Re H}
\end{align*}
so that
\begin{align*}
\left|H\right|^{2}T &= -\left[\Re H\Im\frac{\partial H}{\partial\omega} -
                              \Im H\Re\frac{\partial H}{\partial\omega}\right]
\end{align*}

The gradients of the group delay response with respect to the state
variable coefficients, $\alpha$, $\beta$, etc., are given by:
\begin{align*}
  \frac{\partial\left|H\right|^{2}}{\partial{}x}T+
  \left|H\right|^{2}\frac{\partial{}T}{\partial{}x} = 
&-\left[\Re\frac{\partial{}H}{\partial{}x}
\Im\frac{\partial{}H}{\partial\omega} +
\Re H \Im\frac{\partial^{2}H}{\partial{}x\partial\omega} -
\Im\frac{\partial{}H}{\partial{}x}\Re\frac{\partial{}H}{\partial\omega} -
\Im H\Re \frac{\partial^{2}H}{\partial{}x\partial\omega}\right]
\end{align*}

The diagonal of the Hessian matrix of the group-delay (that is the second
derivatives of the group-delay) is given by:
\begin{align*}
\frac{\partial^{2}\left|H\right|^{2}}{\partial{}x^{2}}T +
2\frac{\partial\left|H\right|^{2}}{\partial{}x}\frac{\partial{}T}{\partial{}x} +
\left|H\right|^{2}\frac{\partial^{2}T}{\partial{}x^{2}}=&
-\Re\frac{\partial^{2}H}{\partial{}x^{2}}
\Im\frac{\partial{}H}{\partial\omega} -
\Re\frac{\partial{}H}{\partial{}x}
\Im\frac{\partial^{2}H}{\partial{}x\partial\omega} -
\Re\frac{\partial{}H}{\partial{}x}
\Im\frac{\partial^{2}H}{\partial{}x\partial\omega} -
\Re H
\Im\frac{\partial^{3}H}{\partial{}x^{2}\partial\omega} \cdots\\*
&+\Im\frac{\partial^{2}H}{\partial{}x^{2}}
\Re\frac{\partial{}H}{\partial\omega} +
\Im\frac{\partial{}H}{\partial{}x}
\Re\frac{\partial^{2}H}{\partial{}x\partial\omega} +
\Im\frac{\partial{}H}{\partial{}x}
\Re\frac{\partial^{2}H}{\partial{}x\partial\omega} +
\Im H
\Re\frac{\partial^{3}H}{\partial\omega\partial{}x^{2}}
\end{align*}

The Hessian matrix of the group delay (that is the second
derivatives of the group delay) is given by:
\begin{align*}
& \frac{\partial^{2}\left|H\right|^{2}}{\partial{}y\partial{}x}T+
\frac{\partial\left|H\right|^{2}}{\partial{}x}\frac{\partial{}T}{\partial{}y}+
\frac{\partial\left|H\right|^{2}}{\partial{}y}\frac{\partial{}T}{\partial{}x}+
\left|H\right|^{2}\frac{\partial^{2}T}{\partial{}y\partial{}x} = \cdots \\
\quad & - \left[ \;
\Re\frac{\partial^{2}H}{\partial{}y\partial{}x}
\Im\frac{\partial{}H}{\partial\omega} +
\Re\frac{\partial{}H}{\partial{}x}
        \Im\frac{\partial^{2}H}{\partial\omega\partial{}y} +
\Re\frac{\partial{}H}{\partial{}y}
\Im\frac{\partial^{2}H}{\partial\omega\partial{}x} +
\Re{}H
\Im\frac{\partial^{3}H}{\partial{}\omega\partial{}y\partial{}x}\cdots\right.\\*
\quad & \phantom{-} \left.\;
-\Im\frac{\partial^{2}H}{\partial{}y\partial{}x}
\Re\frac{\partial{}H}{\partial\omega}-
\Im\frac{\partial{}H}{\partial{}x}
\Re\frac{\partial^{2}H}{\partial\omega\partial{}y}-
\Im\frac{\partial{}H}{\partial{}y}
\Re\frac{\partial^{2}H}{\partial\omega\partial{}x}-
\Im{}H
\Re\frac{\partial^{3}H}{\partial\omega\partial{}y\partial{}x}\;\right]
\end{align*}

\chapter{\label{app:Constrained-Non-linear-Optimisation}Constrained non-linear optimisation}
The following largely follows \emph{Ruszczynski} 
~\cite{Ruszczynski_NonlinearOptimization} with some contributions concerning 
heuristics from \emph{Powell}
~\cite{Powell_FastNonlinearConstrainedOptimization} and 
\emph{Nocedal} and \emph{Wright}~\cite{NocedalWright_NumericalOptimization}.
\section{\label{app:Newtons-method-quadratic-function}Newton's method for a quadratic function}
Consider a quadratic approximation, $f^{k}\left(x\right)$, to a function
$f\left(x\right)$ evaluated at a point $x^{k}$ 
\begin{align*}
f^{k}\left(x\right) &= f\left(x^{k}\right)+
\nabla_{x}f\left(x^{k}\right)\left(x-x^{k}\right)+
\frac{1}{2}\left(x-x^{k}\right)^{\top}\nabla_{x}^{2}f\left(x^{k}\right)\left(x-x^{k}\right)
\end{align*}
where $\nabla_{x}^{2}f\left(x^{k}\right)$ is a positive-definite
matrix\footnote{$Q \in \mathbb{R}^{n\times n}$ is positive-definite if 
$x^{\top}Qx>0$ for all nonzero $x \in \mathbb{R}^{n}$}
(the Hessian matrix). At an optimum point $\nabla_{x}f^{k}\left(x\right)=0$ so,
approximating the gradient with the first two terms of $f^{k}\left(x\right)$:
\begin{align*}
\nabla_{x}f\left(x^{k}\right)+
\nabla_{x}^{2}f\left(x^{k}\right)\left(x-x^{k}\right) &= 0
\end{align*}
Accordingly, given a pair $\left(x^{k},f\left(x^{k}\right)\right)$, 
\emph{Newton's method of tangents} gives the next approximation to the location
of the optimum point as
\begin{align*}
x^{k+1} &= x^{k}-\tau^{k}\left[\nabla_{x}^{2}f\left(x^{k}\right)\right]^{-1}\nabla_{x}f\left(x^{k}\right)
\end{align*}
where $\tau^{k}$ is a stepsize.

\section{Lagrange multipliers}
Consider the problem 
\begin{align*}
\textbf{minimise}   \quad & f\left(x\right)\\
\textbf{subject to} \quad & g\left(x\right) = c
\end{align*}
where $g\left(x\right)$ may represent a set of constraints 
$\left\{ g_{j}\left(x\right) \mid j \in \mathcal{K}\right\}$. When a contour 
of $g\left(x\right)$ is tangent to a contour of $f\left(x\right)$
the gradients $\nabla_{x}f\left(x\right)$ and $\nabla_{x}g\left(x\right)$
are parallel at that point. (See \emph{Nocedal} and
\emph{Wright}~\cite[p. 309]{NocedalWright_NumericalOptimization} for a
justification). The method of \emph{Lagrange multipliers} defines an auxiliary
function (or \emph{Lagrangian}):
\begin{align*}
\mathcal{L}\left(x,\lambda\right) &= f\left(x\right)-\lambda\left(g\left(x\right)-c\right)
\end{align*}
and solves
\begin{align*}
\nabla_{x,\lambda}\mathcal{L}\left(x,\lambda\right) &= 0
\end{align*}
Note that the solution may be a saddle point of 
$\mathcal{L}\left(x,\lambda\right)$. The coefficients of the vector 
$\lambda$ are the \emph{Lagrange multipliers}.

\section{The dual problem}
Define the \emph{dual function} as: 
\begin{align*}
q\left(\lambda\right) &= \min_{x}\mathcal{L}\left(x,\lambda\right)
\end{align*}
The \emph{dual problem} is:
\begin{align*}
\textbf{maximise}   \quad & q\left(\lambda\right)\\
\textbf{subject to} \quad & \lambda\ge0
\end{align*}

\emph{Nocedal} and
\emph{Wright}~\cite[Example 12.12]{NocedalWright_NumericalOptimization} give
an example of the dual problem of a quadratic programming problem:
\begin{align*}
\textbf{minimise}   \quad & a^{\top}x+\frac{1}{2}x^{\top}Hx\\
\textbf{subject to} \quad & Gx-b\ge0
\end{align*}
where $H$ is a symmetric positive-definite matrix. The Lagrangian function of
the dual problem is:
\begin{align*}
  q\left(\lambda\right) &= a^{\top}x+\frac{1}{2}x^{\top}Hx-
                \lambda^{\top}\left(Gx-b\right)
\end{align*}
Since $H$ is positive definite and the Lagrangian is a strictly
\emph{convex}\footnote{A function, $f\left(x\right)$, is convex if
  $f\left(\alpha{}x+\left(1-\alpha\right)y\right)\le{}\alpha{}f\left(x\right)+\left(1-\alpha\right)f\left(y\right),\;\forall\alpha\in\left[0,1\right]$} quadratic
function, the minimum occurs at $\nabla{}q\left(\lambda\right)=0$:
\begin{align*}
  a+Hx-G^{\top}\lambda=0
\end{align*}
Substituting for $x$:
\begin{align*}
  q\left(\lambda\right)&=-\frac{1}{2}\left(G^{\top}\lambda-a\right)^{\top}H^{-1}
                \left(G^{\top}\lambda-a\right)+b^{\top}\lambda
\end{align*}

\emph{Bertsekas}~\cite[Proposition 3.4.2]{Bertsekas_NonlinearProgramming}
gives the following duality theorem:
\begin{enumerate}
\item If the primal problem has an optimal solution then the dual problem also
  has an optimal solution and the corresponding optimal values are equal
\item In order for $\tilde{x}$ to be an optimal primal solution and
  $\tilde{\lambda}$ to be an optimal dual solution, it is necessary and
  sufficient that $\tilde{x}$ is primal feasible, $\tilde{\lambda}\ge0$,
  $\tilde{\lambda_{j}}=0$ over the set of active constraints and
  $\left(\tilde{x},\tilde{\lambda}\right)$ is a solution of the dual problem.
\end{enumerate}

A \emph{primal-dual} or \emph{interior-point} method solves the primal and dual
problems simultaneously. At each iteration both sets of constraints are
satisfied.
\section{\label{sub:Karush-Kuhn-Tucker-Conditions}Karush-Kuhn-Tucker conditions for constrained optimisation}
The \emph{Karush-Kuhn-Tucker} conditions generalise the method of Lagrange 
multipliers to handle inequality constraints. Consider the minimisation problem:
\begin{align*}
\textbf{minimise}   \quad & f\left(x\right) , \quad x \in \mathbb{R}^{n}\\
\textbf{subject to} \quad & g_{i}\left(x\right) \ge 0 , \quad i=1,\ldots,m\\
\textbf{and}        \quad & h_{j}\left(x\right) = 0 , \quad j=1,\ldots,p
\end{align*}
where $f:\mathbb{R}^{n}\mapsto\mathbb{R}$ ,
$g_{i}:\mathbb{R}^{n}\mapsto\mathbb{R}$
and $h_{j}:\mathbb{R}^{n}\mapsto\mathbb{R}$ are continuous differentiable
functions. Define the Lagrangian of the problem as:
\begin{align*}
\mathcal{L}\left(x,\lambda,\mu\right) &= f\left(x\right)-\sum_{i=1}^{m}\lambda_{i}g_{i}\left(x\right)-\sum_{j=1}^{p}\mu_{j}h_{j}\left(x\right)\triangleq f\left(x\right)-\left\langle \lambda,g\right\rangle -\left\langle \mu,h\right\rangle 
\end{align*}
Define a saddle point of the Lagrangian as:
\begin{align*}
\left(\tilde{x},\tilde{\lambda},\tilde{\mu}\right) 
\quad \textbf{such that} \quad
\mathcal{L}\left(\tilde{x},\tilde{\lambda},\tilde{\mu}\right) = 
\max_{\lambda,\mu\ge0}\min_{x}\mathcal{L}\left(x,\lambda,\mu\right)
\end{align*}
so that
\[
\min_{x}\mathcal{L}\left(x,\lambda,\mu\right)\le\max_{\lambda,\mu\ge0}\min_{x}\mathcal{L}\left(x,\lambda,\mu\right)\le\max_{\lambda,\mu\ge{}0}\mathcal{L}\left(x,\lambda,\mu\right)
\]
It can be shown that each such saddle point satisfies the 
\emph{Karush-Kuhn-Tucker} conditions:
\begin{align*}
\nabla_{x}\mathcal{L}\left(\tilde{x},\tilde{\lambda},\tilde{\mu}\right)=\nabla_{x}f\left(\tilde{x}\right)-\left\langle \lambda,\nabla_{x}g\left(\tilde{x}\right)\right\rangle -\left\langle \mu,\nabla_{x}h\left(\tilde{x}\right)\right\rangle  &= 0\\
g_{i}\left(\tilde{x}\right) & \ge 0\\
h_{j}\left(\tilde{x}\right) &= 0\\
\tilde{\lambda_{i}} & \ge 0\\
\tilde{\mu_{j}} & \ge 0\\
\left\langle \lambda,g\left(\tilde{x}\right)\right\rangle  &= 0
\end{align*}
For the \emph{cone}
\footnote{\emph{From \emph{Ruszczynski} 
~\cite[p.26]{Ruszczynski_NonlinearOptimization}, a set
$K\subset\mathbb{R}^{n}$ is called a }cone\emph{ if for every $x\in K$
and all $\alpha>0$ has $\alpha x\in K$. From~\cite[p.28]{Ruszczynski_NonlinearOptimization},
the set $K^{\circ}\triangleq\left\{ y\in\mathbb{R}^{n}:\left\langle y,x\right\rangle \le 0 ~ \forall x\in K\right\} $
is called the }polar cone\emph{ of $K$. From~\cite[p.37]{Ruszczynski_NonlinearOptimization},
for a convex closed set $X\subset\mathbb{R}^{n}$ and a point $x\in X$,
the set $N_{X}\left(x\right)\triangleq\left[cone\left(X-x\right)\right]^{\circ}$
is called the }normal cone\emph{ to $X$ at $x$.}
} $C=\mathbb{R}_{+}^{m}\times\mathbb{R}^{p}$, then these conditions
can be expressed
\begin{align*}
\nabla_{x}\mathcal{L}\left(\tilde{x},\tilde{\lambda},\tilde{\mu}\right) &= 0\\
\left[\begin{array}{c}
g\left(\tilde{x}\right)\\
h\left(\tilde{x}\right)
\end{array}\right] & \in N_{C}\left(\tilde{\lambda},\tilde{\mu}\right)
\end{align*}
Furthermore, these conditions are necessary and sufficient for $\tilde{x}$
to be a minimiser of $f\left(x\right)$. In other words:

\framebox{
\begin{minipage}[t]{0.9\columnwidth}
\centering
 $\tilde{x}$ is a minimiser\\
 $\Uparrow$\\
 $\left(\tilde{x},\tilde{\lambda},\tilde{\mu}\right)$ is a saddle point of 
 $\mathcal{L}\left(x,\lambda,\mu\right)$\\
 $\Downarrow$\\
 $\left(\tilde{x},\tilde{\lambda},\tilde{\mu}\right)$ 
 satisfy Karush-Kuhn-Tucker\\
 $\Uparrow$\\
 $f$ and $g$ are concave and $h$ is affine\\
\end{minipage}
}

For any point $x$, the set of inequality constraints, $\mathcal{K}$,
can be partitioned into a set of \emph{active} constraints
\begin{align*}
\mathcal{A}\left(x\right) &= \left\{ i\mid g_{i}\left(x\right)=0\right\} 
\end{align*}
and the corresponding set of \emph{inactive} constraints, for which
$i\notin\mathcal{A}\left(x\right)$. Following \emph{Bertsekas} 
~\cite[Section 3.3]{Bertsekas_NonlinearProgramming},
note that ``if $\tilde{x}$ is a local minimum of the inequality
constrained problem, then $\tilde{x}$ is also a local minimum of
the identical problem for which the inactive constraints at $\tilde{x}$
have been discarded. On the other hand, at a local minimum, active
inequality constraints can be treated to a large extent as equalities''. 

\section{\label{sub:Constrained-optimisation-Newton}Constrained optimisation using Newton's method}
Consider the non-linear optimisation problem of Section~\ref{sub:Karush-Kuhn-Tucker-Conditions}.
Motivated by Newton's method, at a given point 
$\left(\overline{x},\overline{\lambda},\overline{\mu}\right)$
construct an approximation to the \emph{Karush-Kuhn-Tucker} conditions that
is linearised at $\bar{x}$:
\begin{align*}
\nabla_{x}\mathcal{L}\left(\overline{x},\overline{\lambda},\overline{\mu}\right)
+\nabla_{x}^{2}\mathcal{L}\left(\overline{x},\overline{\lambda},\overline{\mu}\right)\left(x-\overline{x}\right) &= 0\\
\left[\begin{array}{c}
g\left(\overline{x}\right)+\nabla_{x}g\left(\overline{x}\right)
\left(x-\overline{x}\right)\\
h\left(\overline{x}\right)+\nabla_{x}h\left(\overline{x}\right)
\left(x-\overline{x}\right)
\end{array}\right] & \in N_{C}\left(\lambda,\mu\right)
\end{align*}
These are the necessary conditions of optimality for 
\emph{sequential quadratic programming}, shown in 
Algorithm~\ref{alg:Sequential-Programming-Method}.

\begin{algorithm}
At iteration $k$, given the current approximation of the solution
$x^{k}$ and multipliers $\left(\lambda^{k},\mu^{k}\right)$ solve
the tangent quadratic programming problem:
\begin{align*}
\textbf{minimise} \quad & 
\left\langle \nabla_x f\left(x^{k}\right),d^{k}\right\rangle 
+\frac{1}{2}\left\langle {d^{k}}^{\top},\nabla_{x}^{2}
\mathcal{L}\left(x^{k},\lambda^{k},\mu^{k}\right),d^{k}\right\rangle \\
\textbf{subject to} \quad & g\left(x^{k}\right)
+\nabla_{x}g\left(x^{k}\right)d^{k}\le0\\
& h\left(x^{k}\right)+\nabla_{x}h\left(x^{k}\right)d^{k}=0
\end{align*}
Denote the solution to this problem by $d^{k}$ and the Lagrange multipliers
associated with the constraints by $\hat{\lambda}^{k}$ and $\hat{\mu}^{k}$.
Update the approximate solution by:
\begin{align*}
x^{k+1} &= x^{k}+\tau^{k}d^{k}\\
\lambda^{k+1} &= \hat{\lambda}^{k}\\
\mu^{k+1} &= \hat{\mu}^{k}
\end{align*}
and continue. Here $\tau^{k}\in\left(0,1\right]$ is a step-size coefficient.
\caption{The sequential quadratic programming method}
\label{alg:Sequential-Programming-Method}
\end{algorithm}

\section{\label{sub:Local-Convergence}Local convergence}
For simplicity, $\tau^{k}=1$ and assume there are only inequality
constraints ($p=0$). Also assume that the objective function $f\left(x\right)$
has a minimum $\tilde{x}$, at which the gradients of active constraints,
$\nabla_{x}g_{i}\left(\tilde{x}\right)$, $i\in\mathcal{A}\left(\tilde{x}\right)=\left\{ 1\le i\le m\mid g_{i}\left(\tilde{x}\right)=0\right\} $
are linearly independent. In this case the Lagrange multipliers $\hat{\lambda}$
exist and are unique. 

Consider the system of non-linear equations: 
\begin{align*}
\nabla_{x}f\left(x\right)-\sum_{i\in\mathcal{A}\left(x\right)}\lambda_{i}\nabla_{x}g_{i}\left(x\right) &= 0\\
g_{i}\left(x\right) &= 0
\end{align*}
These are the necessary conditions of a modification of the original
minimisation problem in which the active inequality constraints are
treated as equalities. The iterates of the sequential programming
method are the iterates of Newton's method for this system. For the
current iterate $\left(x^{k},\lambda^{k}\right)$, define the matrices:
\begin{align*}
\mathcal{H}_{k} &= \nabla_{x}^{2}\mathcal{L}\left(x^{k},\lambda^{k}\right)\\
\mathcal{B}_{k} &= \left\{ \nabla_{x}g_{i}\left(x^{k}\right)\right\} 
\end{align*}
where $i\in\mathcal{A}\left(x^{k}\right)$ and the columns of $\mathcal{B}_{k}$
correspond to the gradient vectors. When the above equations are linearised,
Newton's method takes the form:
\begin{align*}
\left[\nabla_{x}f\left(x^{k}\right)-\mathcal{B}_{k}\lambda^{k+1}\right]+\mathcal{H}_{k}d^{k} &= 0\\
g_{i}\left(x^{k}\right)+\mathcal{B}_{k}^{\top}d^{k} &= 0
\end{align*}
where $\lambda^{k+1}$ and $g\left(x^{k}\right)$ are the vectors
with coordinates $\lambda_{i}$ and $g_{i}\left(x^{k}\right)$, for
$i\in\mathcal{A}\left(x^{k}\right)$. This system can be simplified
to:
\begin{align*}
\mathcal{H}_{k}d^{k}-\mathcal{B}_{k}\lambda^{k+1} &= -\nabla_{x}f\left(x^{k}\right)\\
-\mathcal{B}_{k}^{\top}d^{k} &= g\left(x^{k}\right)
\end{align*}
which can be solved for the direction $d^{k}$ and the multipliers $\lambda^{k+1}$:
\begin{align}
\lambda^{k+1} &= -\left(\mathcal{B}_{k}^{\top}\mathcal{H}_{k}^{-1}\mathcal{B}_{k}\right)^{-1}\left[g\left(x^{k}\right)-\mathcal{B}_{k}^{\top}\mathcal{H}_{k}^{-1}\nabla_{x}f\left(x^{k}\right)\right]\\
d^{k} &= -\mathcal{H}_{k}^{-1}\left[\nabla_{x}f\left(x^{k}\right)-\mathcal{B}_{k}\lambda^{k+1}\right]
\label{eqn:local-convergence-system-of-equations}
\end{align}
\section{Quasi-Newton methods}
Consider a modified version of the tangent quadratic programming problem
\begin{align*}
\textbf{minimise} \quad &  \nabla_{x}f\left(x^{k}\right)d^{k} +
\frac{1}{2}{d^{k}}^{\top}\mathcal{W}_{k} d^{k} \\
\textbf{subject to} \quad & g\left(x^{k}\right)+\nabla_{x}g\left(x^{k}\right)d^{k}\le0\\
 & h\left(x^{k}\right)+\nabla_{x}h\left(x^{k}\right)d^{k}=0
\end{align*}
where the Hessian of the Lagrangian 
$\nabla_{x}^{2}\mathcal{L}\left(x^{k},\lambda^{k},\mu^{k}\right)$
is replaced by the positive definite matrix $\mathcal{W}_{k}$, guaranteeing
that this is a convex quadratic programming problem. The following
subsections describe methods for constructing the matrix $\mathcal{W}_{k}$.

% The hyperref package doesn't like maths expressions in a link!
\subsection[Updating the Hessian approximation with the 
\emph{Broyden-Fletcher-Goldfarb-Shanno} (BFGS) formula]
{\label{Updating-with-the-BFGS-formula}Updating $\mathcal{W}_{k}$ with the \emph{Broyden-Fletcher-Goldfarb-Shanno} (BFGS) formula}
Typically, $\mathcal{W}_{0}=I$. For convenience, set $\delta_{k}=\tau^{k}d^{k}$.
The update to $\mathcal{W}_{k}$ should depend on $\mathcal{W}_{k}$ and the difference
in gradients of the Lagrangian
\begin{align*}
\gamma_{k} &= \nabla_{x}\mathcal{L}\left(x^{k}+\delta_{k},\lambda^{k},\mu^{k}\right)-\nabla_{x}\mathcal{L}\left(x^{k},\lambda^{k},\mu^{k}\right)
\end{align*}
When there are no constraints it is possible to choose the step-length,
$\tau^{k}$, so that the scalar product $\delta_{k}^{\top}\gamma_{k}$
is positive. On the other hand, when there are constraints, it can
happen that $\delta_{k}^{\top}\gamma_{k}$ is negative for all non-zero
values of $\tau^{k}$. In this case the usual methods for updating
$\mathcal{W}_{k}$ would fail to make the update positive definite. \emph{Powell} 
~\cite[p.148]{Powell_FastNonlinearConstrainedOptimization}
proposes updating $\mathcal{W}_{k}$ as follows. First replace $\gamma_{k}$
with 
\begin{align*}
\eta_{k} &= \theta_{k}\gamma_{k}+\left(1-\theta_{k}\right)\mathcal{W}_{k}\delta_{k}\;,\quad0\le\theta_{k}\le1
\end{align*}
where 
\begin{align}
\theta_{k} &= \begin{cases}
1 & \delta_{k}^{\top}\gamma_{k}\ge0.2\delta_{k}^{\top}\mathcal{W}_{k}\delta_{k}\\
\frac{0.8\delta_{k}^{\top}\mathcal{W}_{k}\delta_{k}}{\delta_{k}^{\top}\mathcal{W}_{k}\delta_{k}-\delta_{k}^{\top}\gamma_{k}} & \delta_{k}^{\top}\gamma_{k}<0.2\delta_{k}^{\top}\mathcal{W}_{k}\delta_{k}
\end{cases}
\label{eqn:damped-BFGS-formula}
\end{align}
The factor of $0.2$ was chosen empirically. Now update $\mathcal{W}_{k}$ with
the \emph{Broyden-Fletcher-Goldfarb-Shanno} (BFGS) formula 
\begin{align*}
W_{k+1} &= \mathcal{W}_{k}-\frac{\mathcal{W}_{k}\delta_{k}\left(\mathcal{W}_{k}\delta_{k}\right)^{\top}}{\delta_{k}^{\top}\mathcal{W}_{k}\delta_{k}}+\frac{\eta_{k}\eta_{k}^{\top}}{\delta_{k}^{\top}\eta_{k}}
\end{align*}
and update $\mathcal{W}_{k}^{-1}$ with the \emph{Sherman-Morrison} formula
\begin{align*}
W_{k+1}^{-1} &= \mathcal{W}_{k}^{-1}+\left[1+\frac{\eta_{k}^{\top}\mathcal{W}_{k}^{-1}\eta_{k}}{\delta_{k}^{\top}\eta_{k}}\right]\left(\frac{\delta_{k}\delta_{k}^{\top}}{\delta_{k}^{\top}\eta_{k}}\right)-\left[\frac{\mathcal{W}_{k}^{-1}\eta_{k}\delta_{k}^{\top}+\delta_{k}\eta_{k}^{\top}\mathcal{W}_{k}^{-1}}{\delta_{k}^{\top}\eta_{k}}\right]
\end{align*}
Note that  $\eta$ and $\delta$ are column vectors and $\delta\eta^{\top}$
is a \emph{dyadic} or \emph{Kronecker }product also written $\delta\otimes\eta$.
\emph{Nocedal} and
\emph{Wright}~\cite[Procedure 18.2]{NocedalWright_NumericalOptimization} refer
to Equation~\ref{eqn:damped-BFGS-formula} as \emph{damped BFGS updating}.

\subsection{\label{app:Bertsekas-modified-Cholesky}A modified Cholesky factorisation of the Hessian}
\emph{Bertsekas}~\cite[Appendix D]{Bertsekas_NonlinearProgramming} describes
implementation of Newton's method by Cholesky factorisation of an
approximation to the Hessian, $\nabla_{x}^{2}\mathcal{L}(x^{k})+\Delta_{k}$,
that is positive definite.

Algorithm~\ref{alg:Cholesky-factorisation}~\cite[Appendix
D.1]{Bertsekas_NonlinearProgramming} shows the Cholesky factorisation
of a positive definite symmetric matrix, $W$, as $LL^{\top}$ where $L$ is lower 
triangular. Firstly, define $W_{i}$ to be the $i$-th leading principal 
submatrix of $W$:
\begin{align*}
W_{i} &= \left[\begin{array}{cccc}
w_{1,1} & w_{1,2} & \cdots & w_{1,i}\\
w_{2,1} & w_{2,2} & \cdots & w_{2,i}\\
\vdots & \vdots & \ddots & \vdots\\
w_{i,1} & w_{i,2} & \cdots & w_{i,i}
\end{array}\right]
\end{align*}
This matrix is positive definite since, for any $y\in\mathbb{R}^{i}$,
$y\neq0$
\[
y^{\top}W_{i}y=\left[\begin{array}{cc}
y^{\top} & 0\end{array}\right]W\left[\begin{array}{c}
y\\
0
\end{array}\right]>0
\]

\begin{algorithm}
\begin{algorithmic}
\State $L_{1}=\sqrt{w_{1,1}}$
\State $W_{1}=L_{1}L_{1}^{\top}$

\For{$i=2,\hdots,n$}
  \State $W_{i} = \left[\begin{array}{cc}
W_{i-1} & \beta_{i}\\
\beta_{i}^{\top} & w_{i,i}
\end{array}\right]$
where 
$\beta_{i} = \left[\begin{array}{c}
w_{1,i}\\
\vdots\\
w_{i-1,i}
\end{array}\right]$
  \State $W_{i} = L_{i}L_{i}^{\top}$ where
$L_{i} = \left[\begin{array}{cc}
L_{i-1} & 0\\
l_{i}^{\top} & \lambda_{ii}
\end{array}\right]$, $l_{i} = L_{i-1}^{-1}\beta_{i}$ and 
$\lambda_{i,i} = \sqrt{w_{i,i}-l_{i}^{\top}l_{i}}$
\EndFor
\State $W=L_{n}L_{n}^{\top}$
\end{algorithmic}
\caption{Cholesky factorisation of an $n\times{}n$ positive-definite symmetric
  matrix, $W$~\cite[Appendix D.1]{Bertsekas_NonlinearProgramming}}
\label{alg:Cholesky-factorisation}
\end{algorithm}

The scalar $\lambda_{ii}$ can be seen to be well-defined by setting
$b=W_{i-1}^{\top}\beta_{i}$ and recalling that $W_{i}$ is positive
definite:
\begin{align*}
0<\left[\begin{array}{cc}
b^{\top} & -1\end{array}\right]W_{i}\left[\begin{array}{c}
b\\
-1
\end{array}\right] &= b^{\top}W_{i-1}b-2b^{\top}\beta_{i}+w_{ii}\\
 &= w_{ii}-b^{\top}\beta_{i}\\
 &= w_{ii}-\beta_{i}^{\top}W_{i-1}^{-1}\beta_{i}\\
 &= w_{ii}-\left(L_{i-1}^{-1}\beta_{i}\right)^{\top}\left(L_{i-1}^{-1}\beta_{i}\right)\\
 &= w_{ii}-l_{i}^{\top}l_{i}
\end{align*}

Note that matrix inversion of an arbitrary matrix is an 
$\mathcal{O}\left(n^{3}\right)$ operation whereas matrix inversion of a 
triangular matrix via backward or forward substitution is an 
$\mathcal{O}\left(n^{2}\right)$ operation\footnote{The $LDL^{\top}$ factorisation
of a symmetric matrix avoids taking the square-root. 
See~\cite[Algorithm 4.1.2]{GolubVanLoan_MatrixComputations}.}.

We wish to add a diagonal correction, $\Delta_{k}$, to the Hessian
matrix such that the resulting matrix is positive definite whilst
simultaneously factoring $\nabla_{x}^{2}\mathcal{L}\left(x^{k}\right)+\Delta_{k}$.
Firstly, fix two positive scalars $\mu_{1}$ and $\mu_{2}$, where
$\mu_{1}<\mu_{2}$. The first column of the factor $L$ is given by
\begin{align*}
l_{11} &= \begin{cases}
\sqrt{w_{11}} & \mu_{1}<w_{11}\\
\sqrt{\mu_{2}} & otherwise
\end{cases}\\
l_{i1} &= \frac{w_{i1}}{l_{11}}\quad i=2,\ldots,n
\end{align*}
Given columns $1,2,\ldots,j-1$ of $L$ the elements of the $j$-th
column are
\begin{align*}
l_{jj} &= \begin{cases}
\sqrt{w_{jj}-\sum_{m=1}^{j-1}l_{jm}^{2}} & \mu_{1}<w_{jj}-\sum_{m=1}^{j-1}l_{jm}^{2}\\
\sqrt{\mu_{2}} & otherwise
\end{cases}\\
l_{ij} &= \frac{w_{ij}-\sum_{m=1}^{j-1}l_{jm}l_{im}}{l_{jj}}\quad i=j+1,\dots,n
\end{align*}
This scheme can be used in a modified Newton's method, where at the
$k$-th iteration, we add a diagonal correction, $\Delta^{k}$, to the
Hessian, $\nabla_{x}^{2}\mathcal{L}\left(x^{k}\right)$, and simultaneously
obtain a Cholesky factorisation of $\nabla_{x}^{2}\mathcal{L}\left(x^{k}\right)+\Delta^{k}$.
The direction vector, $d^{k}$, is found by solving the triangular systems
\begin{align*}
L_{k}y &= -\nabla_{x}f\left(x^{k}\right)\\
L_{k}^{\top}d^{k} &= y
\end{align*}
The next point is found by 
\begin{align*}
x^{k+1} &= x^{k}+\tau^{k}d^{k}
\end{align*}
where $\tau^{k}$ is a step size. The scalars $\mu_{1}$ and $\mu_{2}$
are selected as follows: at each iteration we find the maximum absolute
value of the Hessian diagonal elements
\begin{align*}
w^{k}&=\max\;\mathdiag\;\nabla_{x}^{2}\mathcal{L}\left(x^{k}\right)
\end{align*}
and set $\mu_{1}=r_{1}w^{k}$ and $\mu_{2}=r_{2}w^{k}$. The scalar
$r_{1}$ is set at some ``small'' (or zero) value. The scalar $r_{2}$
is modified at each iteration: if $\tau^{k}<0.2$ then $r_{2}=5r_{2}$;
otherwise if $\tau^{k}>0.9$ then $r_{2}=\frac{r_{2}}{5}$.

\emph{Bertsekas} justifies this correction as
follows~\cite[p. 733]{Bertsekas_NonlinearProgramming}:
\begin{quotation}
  Assuming fixed values of $\mu_{1}$ and $\mu_{2}$, the following may be
  verified for the modified Newton's method just described:
  \begin{itemize}
  \item The algorithm is globally convergent in the sense that every limit
    point of $\left\{x^{k}\right\}$ is a stationary point of
    $\mathcal{L}\left(x^{k}\right)$. This can be shown using ... 
  \item For each local minimum $x^{*}$ with positive definite Hessian, there
    exist scalars $\mu>0$ and $\varepsilon>0$ such that of $\mu_{1}<\mu$ and
    $\mathnorm{x^{0}-x^{*}}\le\varepsilon$, then $x^{k}\rightarrow x^{*}$,
    $\Delta^{k}=0$, and $\tau^{k}=1$ for all $k$. In other words, if $\mu_{1}$
    is not chosen too large, the Hessian will never be modified near $x^{*}$,
    the method will be reduced to the pure form of Newton's method near $x^{*}$,
    and the convergence to $x^{*}$ will be superlinear.
  \end{itemize}
\end{quotation}
\subsection{\label{sub:Degenerate-constraints}Wright's modification for degenerate constraints}
For the filter design problem, the gradients of upper and lower constraints
on the radius and angle of the poles and zeros are not linearly independent
and the resulting Jacobian matrix is degenerate. The \emph{singular
value decomposition} 
~\cite[Sections 2.5.3 and 5.5]{GolubVanLoan_MatrixComputations}
finds the minimum 2-norm solution of a degenerate matrix equation
as follows: if $B$ is a real $m\times n$ matrix, then there exist
orthogonal matrices $U=\left[u_{1},\ldots,u_{m}\right]\in\mathbb{R}^{m\times m}$
and $V=\left[v_{1},\ldots,v_{n}\right]\in\mathbb{R}^{n\times n}$
such that 
\begin{align*}
U^{\top}BV &=\mathdiag\left(\sigma_{1},\ldots,\sigma_{p}\right)\in\mathbb{R}^{m\times n}
\end{align*}
where $\left[u_{1},\ldots,u_{m}\right]$ is a column partitioning of
$U$, $p=\min\left(m,n\right)$ and $\sigma_{1}\ge\sigma_{2}\ge\cdots\ge\sigma_{p}\ge0$.
From \emph{Golub and Van Loan}
~\cite[Section 5.5.4]{GolubVanLoan_MatrixComputations},
the \emph{pseudo-inverse} of $B$ is defined to be $B^{\dagger}=V\Sigma U^{\top}$
where 
\begin{align*}
\Sigma &=\mathdiag\left(\frac{1}{\sigma_{1}},\cdots,\frac{1}{\sigma_{r}},0,\ldots,0\right)\in\mathbb{R}^{n\times m}
\end{align*}
and $\mathrank\left(B\right)=r$. It is the unique minimal Frobenius
norm\footnote{See Appendix~\ref{app:Linear-algebra-norm-of-matrix}.} solution to
the problem:
\begin{align*}
\min_{X\in\mathbb{R}^{n\times m}} & \| BX-I_{m}\| _{F}
\end{align*}
If $\mathrank\left(B\right)=n$, then
$B^{\dagger}=\left(B^{\top}B\right)^{-1}B^{\top}$, 
while if $m=n=\mathrank\left(B\right)$, then $B^{\dagger}=B^{-1}$. Typically,
$B^{\dagger}$ is defined to be the unique matrix $X\in\mathbb{R}^{n\times m}$
that satisfies the four \emph{Moore-Penrose conditions}:
\begin{align}
\label{eq:Moore-Penrose-conditions}
\begin{split}
BXB &= B\\
XBX &= X\\
\left(BX\right)^{\top} &= BX\\
\left(XB\right)^{\top} &= XB
\end{split}
\end{align}
These conditions amount to the requirement that $BB^{\dagger}$ and $B^{\dagger}B$
be orthogonal projections onto $\mathrange\left(B\right)$ and 
$\mathrange\left(B^{\top}\right)$
respectively\footnote{See
  Appendix~\ref{app:Linear-algebra-range-and-null-space-of-matrix}.}.

\emph{Wright}~\cite{Wright_SuperLinearConvergenceSQPDegenerateSolution} points
out that the existence of linearly dependent constraint gradients
can interfere with the super-linear convergence of the sequential quadratic
programming problem (SQP) and provides a stabilised algorithm
for which super-linear convergence is still possible. Given a set of
active constraints $\mathcal{A}\left(x\right)\subset\mathcal{K}$
at a point $x$ and the complement $\mathcal{N}\left(x\right)=\mathcal{K}\setminus\mathcal{A}\left(x\right)$,
\emph{Wright} defines $g_{\mathcal{A}}\left(x\right)=\left\{ g_{i}\left(x\right)\mid i\in\mathcal{A}\left(x\right)\right\} $,
$g_{\mathcal{N}}\left(x\right)=\left\{ g_{i}\left(x\right)\mid i\in\mathcal{N}\left(x\right)\right\} $,
$\lambda_{\mathcal{A}}\left(x\right)=\left\{ \lambda_{i}\left(x\right)\mid i\in\mathcal{A}\left(x\right)\right\} $,
$\lambda_{\mathcal{N}}\left(x\right)=\left\{ \lambda_{i}\left(x\right)\mid i\in\mathcal{N}\left(x\right)\right\} $.
\emph{Wright} considers the usual SQP problem and makes the following assumptions 
\begin{enumerate}
\item a primal-dual solution point $\left(\tilde{x},\tilde{\lambda}\right)$
exists
\item for at least one of the active constraints, $\tilde{\lambda_{i}}>0$
where $i\in\mathcal{A}\left(\tilde{x}\right)$
\item $\tilde{\lambda}_{i} = 0 ~ \forall i\in\mathcal{N}\left(\tilde{x}\right)$ 
\item there exists a $\sigma>0$ such that $w^{\top}\nabla_{x}\mathcal{L}\left(\tilde{x},\tilde{\lambda}\right)w\ge\sigma\| w\| ^{2}$
for all $\tilde{\lambda}$ such that $\left(\tilde{x},\tilde{\lambda}\right)$
satisfies the \emph{Karush-Kuhn-Tucker} conditions and all $w \in \mathnull\left(\nabla g_{\mathcal{A}}\left(\tilde{x}\right)\right)$
\item $\nabla g_{\mathcal{A}}\left(\tilde{x}\right)d<0$ for some $d\in\mathbb{R}^{n}$ 
\end{enumerate}
The latter assumption (known as the \emph{Mangasarian-Fromovitz }constraint
qualification) is weaker than the assumption that the matrix of constraint
gradients has full column rank. \emph{Wright} 
~\cite{Wright_SuperLinearConvergenceSQPDegenerateSolution}
considers the linearised SQP method described in Section 
~\ref{sub:Constrained-optimisation-Newton}.
He points out that the Lagrange multipliers $\lambda_{\mathcal{A}}$
may not be uniquely determined if the Jacobian 
$\nabla_{x}g_{\mathcal{A}}\left(x\right)$
is rank deficient. Consequently, the Hessian 
$\nabla_{x}\mathcal{L}$$\left(x,\lambda_{\mathcal{A}}\right)$
may not be uniquely defined at the next SQP iteration. He proposes
a stabilised version of the SQP algorithm 
\[
\min_{x}\max_{\lambda_{\mathcal{A}}\ge0}\left\langle \nabla f\left(\overline{x}\right),x-\overline{x}\right\rangle -\left\langle \lambda_{\mathcal{A}},g\left(\bar{x}\right)+\nabla_{x}^{\top}g\left(\bar{x}\right)\left(x-\bar{x}\right)\right\rangle +\frac{1}{2}\left\langle x-\overline{x},\left[\nabla_{x}^{2}\mathcal{L}\left(\overline{x},\overline{\lambda}_{\mathcal{A}}\right)\right]\left(x-\overline{x}\right)\right\rangle -\frac{1}{2}\nu\| \lambda_{\mathcal{A}}-\bar{\lambda}_{\mathcal{A}}\| ^{2}
\]
where $\nu$ is defined as 
\begin{align*}
\nu\left(x,\lambda_{\mathcal{A}}\right) &= \| \left(\nabla_{x}\mathcal{L}\left(x,\lambda_{\mathcal{A}}\right),g_{\mathcal{A}}\left(x\right),\left\langle \lambda_{\mathcal{A}},g_{\mathcal{A}}\left(x\right)\right\rangle \right)\| 
\end{align*}
The optimality conditions for a candidate solution $\left(\tilde{x},\tilde{\lambda}_{\mathcal{A}}\right)$
are likewise similar
\begin{align*}
\nabla_{x}f\left(\bar{x}\right)-\nabla g_{\mathcal{A}}\left(\bar{x}\right)\tilde{\lambda}_{\mathcal{A}}+\nabla_{x}\mathcal{L}\left(\bar{x},\bar{\lambda}_{\mathcal{A}}\right)\left(\tilde{x}-\bar{x}\right) &= 0\\
g_{\mathcal{A}}\left(\bar{x}\right)+\nabla_{x}^{\top}g_{\mathcal{A}}\left(\bar{x}\right)\left(\tilde{x}-\bar{x}\right)-\nu\left(\tilde{\lambda}_{\mathcal{A}}-\bar{\lambda}_{\mathcal{A}}\right) & \ge 0\\
\tilde{\lambda}_{\mathcal{A}} & \ge 0\\
\left\langle \tilde{\lambda}_{\mathcal{A}},g_{\mathcal{A}}\left(\bar{x}\right)+\nabla g_{\mathcal{A}}^{\top}\left(\bar{x}\right)\left(\tilde{x}-\bar{x}\right)-\nu\left(\tilde{\lambda}_{\mathcal{A}}-\bar{\lambda}_{\mathcal{A}}\right)\right\rangle  &= 0
\end{align*}
\emph{Wright} shows that for $\left(\bar{x},\bar{\lambda}_{\mathcal{A}}\right)$
sufficiently close to a primal-dual solution $\left(x,\lambda_{\mathcal{A}}\right)$
there is a unique solution $\left(\tilde{x},\tilde{\lambda}_{\mathcal{A}}\right)$
for which $\| \left(\tilde{x}-\bar{x},\tilde{\lambda}_{\mathcal{A}}-\bar{\lambda}_{\mathcal{A}}\right)\| =\mathcal{O}\left(\nu\right)$.
This solution satisfies the following linear system 
\begin{align*}
\left[\begin{array}{cc}
\nabla_{x}\mathcal{L}\left(\bar{x},\bar{\lambda}_{\mathcal{A}}\right) & -\nabla_{x}g_{\mathcal{A}}\left(\bar{x}\right)\\
-\nabla_{x}g_{\mathcal{A}}^{\top}\left(\bar{x}\right) & \nu I
\end{array}\right]\left[\begin{array}{c}
x-\bar{x}\\
\lambda_{\mathcal{A}}-\bar{\lambda}_{\mathcal{A}}
\end{array}\right] &= \left[\begin{array}{c}
-\left(\nabla_{x}f\left(\bar{x}\right)-\nabla_{x}g_{\mathcal{A}}\left(\bar{x}\right)\bar{\lambda}_{\mathcal{A}}\right)\\
g_{\mathcal{A}}\left(\bar{x}\right)
\end{array}\right]\\
\lambda_{\mathcal{N}} &= 0
\end{align*}

\subsection{\label{app:Bertsekas-modification-Hessian}Bertsekas' modification to the Hessian}
\emph{Bertsekas}~\cite[p. 461]{Bertsekas_NonlinearProgramming} describes a 
modification to the Hessian that can ensure
that the Hessian is positive definite and invertible. From the usual
Newton system
\begin{align*}
\mathcal{H}_{k}d^{k}-\mathcal{B}_{k}\lambda^{k+1} &= -\nabla_{x}f\left(x^{k}\right)\\
-\mathcal{B}_{k}^{\top}d^{k} &= g\left(x^{k}\right)
\end{align*}
define a new matrix:
\begin{align*}
\bar{\mathcal{H}_{k}}&=\mathcal{H}_{k}+c^{k}\mathcal{B}_{k}\mathcal{B}_{k}^{\top}
\end{align*}
where the scalar, $c^{k}$, is chosen so that $\bar{\mathcal{H}_{k}}$ is
positive definite. \emph{Bertsekas} points out that
\begin{align*}
{d^{k}}^{\top}\mathcal{B}_{k}\mathcal{B}_{k}^{\top}d^{k}&=\|g\left(x^{k}\right)\|^{2}
\end{align*}
is a constant for \emph{equality} constraints. Consequently, the modified 
optimisation problem
\begin{align*}
\textbf{minimise} \quad &\nabla_{x}f\left(x^{k}\right)d^{k}+
\frac{1}{2}{d^{k}}^{\top}\left(\mathcal{H}_{k}+
c^{k}\mathcal{B}_{k}\mathcal{B}_{k}^{\top}\right)d^{k}\\
\textbf{subject to} \quad & -\mathcal{B}_{k}^{\top}d^{k} = g\left(x^{k}\right)
\end{align*}
has a larger minimum value but the location of that minimum is unchanged.

Given the scalar, $c^{k}$, write:
\begin{align*}
c^{k}\mathcal{B}_{k}\mathcal{B}_{k}^{\top}d^{k} &= -c^{k}\mathcal{B}_{k}g\left(x^{k}\right)
\end{align*}
Adding:
\begin{align*}
\left(\mathcal{H}_{k}+c^{k}\mathcal{B}_{k}\mathcal{B}_{k}^{\top}\right)d^{k}-
\mathcal{B}_{k}\lambda^{k+1} &= 
-\left[\nabla_{x}f\left(x^{k}\right)+c^{k}\mathcal{B}_{k}g\left(x^{k}\right)\right]
\end{align*}
As in Section~\ref{sub:Local-Convergence}:
\begin{align*}
\lambda^{k+1} &= -\left(\mathcal{B}_{k}^{\top}\left(\mathcal{H}_{k}+c^{k}\mathcal{B}_{k}\mathcal{B}_{k}^{\top}\right)^{-1}\mathcal{B}_{k}\right)^{-1}\left[g\left(x^{k}\right)-\mathcal{B}_{k}^{\top}\left(\mathcal{H}_{k}+c^{k}\mathcal{B}_{k}\mathcal{B}_{k}^{\top}\right)^{-1}\left(\nabla_{x}f\left(x^{k}\right)+c^{k}\mathcal{B}_{k}g\left(x^{k}\right)\right)\right]\\
d^{k} &= -\left(\mathcal{H}_{k}+c^{k}\mathcal{B}_{k}\mathcal{B}_{k}^{\top}\right)^{-1}\left[\left(\nabla_{x}f\left(x^{k}\right)+c^{k}\mathcal{B}_{k}g\left(x^{k}\right)\right)-\mathcal{B}_{k}\lambda^{k+1}\right]
\end{align*}
\section{Penalty and barrier methods}
From \emph{Bertsekas}~\cite[Section 4.2]{Bertsekas_NonlinearProgramming},
``The basic idea in penalty methods is to eliminate some or all of
the constraints and add to the cost function a penalty term that prescribes
a high cost to infeasible points.'' Barrier functions are penalty
functions that approach infinity as the constrained variable approaches
the constraint. Clearly a barrier function requires that a feasible
initial point is known.


\subsection{Penalty functions}
In the unconstrained case $\tau^{k}$ is found by a line search that
minimises the objective function $f\left(x\right)$ along the ray
$x^{k}+\tau d^{k}$ over $\tau\ge0$. \emph{Ruszczynski} 
~\cite[p.329]{Ruszczynski_NonlinearOptimization}
suggests that when there are constraints on $x$ we use the \emph{penalty
function} 
\begin{align*}
\Psi_{\varrho}\left(x\right) & \triangleq f\left(x\right)+\varrho\left[\sum_{i=1}^{p}\left|h_{i}\left(x\right)\right|-\sum_{i=1}^{m}\min\left(0,g_{i}\left(x\right)\right)\right]
\end{align*}
and states that a local minimum of the objective function is also
a local minimum of $\Psi_{\varrho}\left(x\right)$, provided that
the penalty coefficient $\varrho$ is larger than the ``max'' norm
of the Lagrange multipliers $\left(\hat{\lambda},\hat{\mu}\right)$
at the solution. Similarly, \emph{Powell}
~\cite[p.151]{Powell_FastNonlinearConstrainedOptimization}
suggests using the penalty function 
\begin{align*}
\Psi\left(x\right) & \triangleq f\left(x\right)-\left[\sum_{i=1}^{m}\Omega_{i}\min\left(0,g_{i}\left(x\right)\right)+\sum_{i=1}^{p}\Upsilon_{i}\left|h_{i}\left(x\right)\right|\right]
\end{align*}
and requiring that $\tau^{k}$ satisfies 
\begin{align*}
\Psi\left(x^{k}+\tau^{k}d^{k},\Omega,\Upsilon\right) & \le \Psi\left(x^{k},\Omega,\Upsilon\right)
\end{align*}
$\Upsilon_{i}$ and $\Omega_{k}$ are defined below. This condition
can be fulfilled if the function 
\begin{align*}
\Phi\left(\tau^{k}\right) &= \Psi\left(x^{k}+\tau^{k}d^{k},\Omega,\Upsilon\right)
\end{align*}
decreases initially when $\tau^{k}$ is made positive. \emph{Powell} 
~\cite{Powell_FastNonlinearConstrainedOptimization}
asserts that this happens if $\mathcal{W}_{k}$ is positive definite and if
\begin{align*}
\Omega_{i} & \ge \left|\lambda_{i}\right|\quad i=1,\ldots,m\\
\Upsilon_{i} & \ge \left|\mu_{i}\right|\quad i=1,\ldots,p
\end{align*}
\emph{Powell}~\cite[p.151]{Powell_FastNonlinearConstrainedOptimization} suggests
$\Omega_{i}=\left|\lambda_{i}\right|$ for the first iteration and
subsequently
\begin{align*}
\Omega_{i} &= \max\left(\left|\lambda_{i}\right|,\frac{1}{2}\left[\overline{\Omega}_{i}+\left|\lambda_{i}\right|\right]\right)
\end{align*}
where $\overline{\Omega}_{i}$ is the value of $\Omega_{i}$ used
on the previous iteration. Similarly for $\Upsilon_{i}$. The line-search
procedure given by \emph{Powell}
~\cite[p.152]{Powell_FastNonlinearConstrainedOptimization}
is obscure but it appears to be a variation of the ``two-slope''
test that is also described by \emph{Ruszczynski}
~\cite[p. 216]{Ruszczynski_NonlinearOptimization}
and \emph{Bersekas}~\cite[p. 28]{Bertsekas_NonlinearProgramming}.
The test assumes that $\Phi^{\prime}\left(0\right)<0$. \emph{Powell}
~\cite[p.152]{Powell_FastNonlinearConstrainedOptimization}
suggests that the line-search terminate when 
\begin{align*}
\Phi\left(\hat{\tau}_{k}\right) & \le \Phi\left(0\right)+0.1\tau^{k}\Phi^{\prime}\left(0\right)
\end{align*}

\emph{Bertsekas}~\cite[p. 405]{Bertsekas_NonlinearProgramming}, describes
use of a quadratic penalty function with inequality constraints. The
inequality constraints are converted to equality constraints by the
addition of slack variables, $z_{i}$, giving the SQP problem
\begin{align*}
\textbf{minimise}   \quad & f\left(x\right)\\
\textbf{subject to} \quad & h_{i}\left(x\right)=0\\
 & g_{i}\left(x\right)-z_{i}^{2}=0
\end{align*}
The Quadratic Penalty Function method (\emph{Bertsekas}
~\cite[Section 4.2.1]{Bertsekas_NonlinearProgramming}
gives a series of unconstrained minimisations of the form
\begin{align*}
\min_{x,z}\bar{\mathcal{L}}_{c^{k}}\left(x,z,\mu^{k},\lambda^{k}\right) &= f\left(x\right)+\left\{ \frac{c^{k}}{2}\| h\left(x\right)\| ^{2}-\left(\mu^{k}\right)^{\top}h\left(x\right)\right\} +\sum_{i=1}^{m}\left\{ \frac{c^{k}}{2}\left|g_{i}\left(x\right)-z_{i}^{2}\right|^{2}-\lambda_{i}^{k}\left(g_{i}\left(x\right)-z_{i}^{2}\right)\right\} 
\end{align*}
where $c^{k}<c^{k+1}$ and $c^{k}\rightarrow\infty$. Minimising the
sum with respect to $z$ is equivalent to
\begin{align*}
\mathcal{L}_{c^{k}}\left(x,v,\mu^{k},\lambda^{k}\right) &= f\left(x\right)+\left\{ \frac{c^{k}}{2}\| h\left(x\right)\| -\left(\mu^{k}\right)^{\top}h\left(x\right)\right\} +\min_{v_{i}\ge0}\sum_{i=1}^{m}\left\{ \frac{c^{k}}{2}\left|g_{i}\left(x\right)-v_{i}\right|^{2}-\lambda_{i}^{k}\left(g_{i}\left(x\right)-v_{i}\right)\right\} 
\end{align*}
If the constrained minimum of the second term is at $\hat{v}_{i}=\max\left\{ 0,\bar{v}_{i}\right\} $
(where $\bar{v}_{i}\ge0$ is the unconstrained minimum at which $\lambda_{i}+c^{k}\left(g_{i}\left(x\right)-\bar{v}_{i}\right)$
is zero) then
\begin{align*}
\hat{v}_{i} &= \max\left\{ 0,g_{i}\left(x\right)+\frac{\lambda_{i}^{k}}{c^{k}}\right\} 
\end{align*}
and
\begin{align*}
g_{i}\left(x\right)-\hat{v}_{i} &= \begin{cases}
-\frac{\lambda_{i}^{k}}{c^{k}} & g_{i}\left(x\right)>-\frac{\lambda_{i}^{k}}{c^{k}}\\
g_{i}\left(x\right) & g_{i}\left(x\right)\le-\frac{\lambda_{i}^{k}}{c^{k}}
\end{cases}\\
 &= \min\left(g_{i}\left(x\right),-\frac{\lambda_{i}^{k}}{c^{k}}\right)
\end{align*}
The Lagrangian summation term becomes
\begin{align*}
\sum_{i=1}^{m}\lambda_{i}^{k}\min\left(g_{i}\left(x\right),-\frac{\lambda_{i}^{k}}{c^{k}}\right)+\frac{c^{k}}{2}\left|\min\left(g_{i}\left(x\right),-\frac{\lambda_{i}^{k}}{c^{k}}\right)\right|^{2} &= \begin{cases}
\frac{1}{2c^{k}}\sum_{i=1}^{m}\left[\left(\lambda_{i}^{k}+c^{k}g_{i}\left(x\right)\right)^{2}-\left(\lambda_{i}^{k}\right)^{2}\right] & g_{i}\left(x\right)\le-\frac{\lambda_{i}^{k}}{c^{k}}\\
-\frac{1}{2c^{k}}\sum_{i=1}^{m}\left(\lambda_{i}^{k}\right)^{2} & g_{i}\left(x\right)>-\frac{\lambda_{i}^{k}}{c^{k}}
\end{cases}
\end{align*}
Substituting into the Lagrangian
\begin{align*}
\mathcal{L}_{c^{k}}\left(x,\mu^{k},\lambda^{k}\right) &= f\left(x\right)+\left\{ \frac{c^{k}}{2}\| h\left(x\right)\| -\left(\mu^{k}\right)^{\top}h\left(x\right)\right\} +\frac{1}{2c^{k}}\sum_{i=1}^{m}\left\{ \min\left[0,\left(\lambda_{i}^{k}+c^{k}g_{i}\left(x\right)\right)\right]^{2}-\lambda_{i}^{2}\right\} 
\end{align*}
The penalty term for the inequality constraints is continuously differentiable
in $x$ if $g_{i}\left(x\right)$ is continuously differentiable.
The optimisation problem is now unconstrained minimisation 
of $\mathcal{L}_{c^{k}}$ with updating of the Lagrange multipliers by
\begin{align*}
\lambda^{k+1} &= \min\left(0,\lambda^{k}+c^{k}g\left(x\right)\right)
\end{align*}
Unfortunately, difficulties arise because the Hessian matrix of
$\mathcal{L}_{c^{k}}$ is discontinuous at the $x$ for which 
$g_{i}\left(x\right)=-\frac{\lambda_{i}^{k}}{c^{k}}$. 

An alternative augmented Lagrangian function that does have a continuous
Hessian adds an exponential penalty function
\begin{align*}
\psi\left(t\right) &= e^{-t}-1
\end{align*}
The constrained optimisation problem becomes unconstrained optimisation
of the following Lagrangian (for inequality constraints only) 
\begin{align*}
\mathcal{L}_{c^{k}}\left(x,\lambda^{k}\right) &= f\left(x\right)+
\sum_{i=1}^{m}\frac{\lambda_{j}^{k}}{c_{j}^{k}}
\psi\left(c_{j}^{k}g_{j}\left(x\right)\right)
\end{align*}
with gradient
\begin{align*}
\nabla \mathcal{L}_{c^{k}}\left(x,\lambda^{k}\right) &= \nabla f\left(x\right)-\sum_{i=1}^{m}\lambda_{j}^{k}g\left(x\right)\exp\left(-c_{j}^{k}g_{j}\left(x\right)\right)
\end{align*}
The $\left\{ c_{j}^{k}\right\} $ are a positive penalty parameter
sequence for each $j$. The $\lambda^{k}$ are updated by
\begin{align*}
\lambda^{k+1} &= \lambda^{k}\exp\left(c^{k}g\left(x\right)\right)
\end{align*}
Two implementation details
\begin{itemize}
\item to avoid overflow $\psi\left(t\right)$ should be defined as the exponential
$e^{-t}-1$ only for the interval in which the exponential is within
the floating point range
\item the penalty parameter for each constraint should depend on the corresponding
multiplier by
\begin{align*}
c_{j}^{k} &= \frac{w^{k}}{\lambda_{j}^{k}}
\end{align*}
where $\left\{ w^{k}\right\} $ is a positive sequence with $w^{k}\le w^{k+1}$
\end{itemize}

\subsection{Barrier functions}
\label{sub:Barrier-functions}
\emph{Bertsekas}~\cite[Section 4.1]{Bertsekas_NonlinearProgramming}, describes
adding a so-called \emph{barrier} function, $B\left(x\right)$, to
the cost function. This function is continuous and goes to $\infty$
as any one of the constraints approaches $0$ from positive values.
Clearly, the barrier function is only defined at iterates, $x^{k}$,
that satisfy the constraints
\begin{align*}
S &= \left\{ x\in X\mid g_{j}\left(x\right)\ge 0,\; j=1,\ldots,m\right\} 
\end{align*}
The two most common barrier functions are 
\begin{align*}
B\left(x\right) &= -\sum_{i=1}^{m}\ln\left\{ g_{i}\left(x\right)\right\} \\
B\left(x\right) &= \sum_{i=0}^{m}\frac{1}{g_{i}\left(x\right)}
\end{align*}
The barrier method consists of finding
\begin{align*}
x^{k} & \in \arg\min_{x\in S}\left\{ f\left(x\right)+\epsilon^{k}B\left(x\right),\; k=0,1,\ldots\right\} 
\end{align*}
where the sequence $\left\{ \epsilon^{k}\right\} $ is defined by
\begin{align*}
  0 < \epsilon^{k+1} < \epsilon^{k}
  \quad k=0,1,\ldots
  \quad \epsilon^{k}\rightarrow 0
\end{align*}

\section{\label{sub:Finding-the-step}Finding the step size}
The coefficient solution space for the IIR filter design problem is highly
non-linear and has many local minima. At each iteration of the SQP method the
maximum step-size to the next estimate must maintain the positive 
semi-definiteness of the Hessian (or its approximation) but at the same time
be large enough that solution approaches a minimum efficiently.

\subsection{Line search with the Golden-Section}
The \emph{Golden Section} (see \emph{Ruszczynski} 
~\cite[p.213]{Ruszczynski_NonlinearOptimization}
and \emph{Bertsekas} 
~\cite[Appendix C.3]{Bertsekas_NonlinearProgramming}) is a simple
means of generating the sequence of intervals required for line-search
on a \emph{convex }function. First, given two endpoint points $\alpha<\delta$,
construct a sequence of four points 
\begin{align*}
\alpha<\beta<\gamma<\delta
\end{align*}
with
\begin{align*}
\beta &= \alpha+\left(1-q\right)\left(\delta-\alpha\right)\\
\gamma &= \delta-\left(1-q\right)\left(\delta-\alpha\right)
\end{align*}
where 
\begin{align*}
q &= \frac{-1+\sqrt{5}}{2}\\
1-q &= q^{2}
\end{align*}
Note that 
\begin{align*}
\frac{\beta-\alpha}{\delta-\alpha} &= 1-q\\
\frac{\gamma-\alpha}{\delta-\alpha} &= q\\
\frac{\gamma-\beta}{\delta-\beta} &= 1-q\\
 & etc.
\end{align*}
At each iteration select a new endpoint based on the function values
at each point. The Octave function \emph{goldensection.m} shows an 
implementation.

A quicker search method makes use of the fact that the gradient 
$\Phi^{\prime}\left(0\right)$ is known and is 
negative~\cite[p.215]{Ruszczynski_NonlinearOptimization}.
First, search for a point $\beta>0$ such that 
$\Phi\left(\beta\right)\ge\Phi\left(0\right)$, then quadratic interpolation gives
\begin{align*}
\tau^{k} &= \frac{-\Phi^{\prime}\left(0\right)\beta^{2}}
{2\left[\Phi\left(\beta\right)-\Phi\left(0\right)-
\Phi^{\prime}\left(0\right)\beta\right]}
\end{align*}
Since $\Phi\left(\beta\right)\ge\Phi\left(0\right)$, we have 
$0<\tau^{k}\le\frac{\beta}{2}$.
If we still have $\Phi\left(\tau\right)>\Phi\left(0\right)$, then
we replace $\beta$ with $\tau^{k}$ and repeat the above interpolation.
If $\Phi\left(\tau\right)<\Phi\left(0\right)$, then we have three
points, with the best one in the middle, and we can apply a Golden
Section search.

Alternatively, interpolate $\Phi\left(x\right)$. Given 
$\alpha_{k}<\tau^{k}<\beta_{k}$
such that 
$\Phi\left(\alpha_{k}\right)>\Phi\left(\tau^{k}\right)<\Phi\left(\beta_{k}\right)$
then a second-order estimate of the minimum is 
\begin{align*}
\gamma_{k} &= \frac{\Phi\left(\alpha_{k}\right)\left[\beta_{k}^{2}-\left(\tau^{k}\right)^{2}\right]+\Phi\left(\tau^{k}\right)\left[\alpha_{k}^{2}-\beta_{k}^{2}\right]+\Phi\left(\beta_{k}\right)\left[\left(\tau^{k}\right)^{2}-\alpha_{k}^{2}\right]}{2\left(\Phi\left(\alpha_{k}\right)\left[\beta_{k}-\tau^{k}\right]+\Phi\left(\tau^{k}\right)\left[\alpha_{k}-\beta_{k}\right]+\Phi\left(\beta_{k}\right)\left[\tau^{k}-\alpha_{k}\right]\right)}
\end{align*}
The initial three points can be found by scanning the values $\Phi\left(0\right),\Phi\left(\tau_{0}\right),\ldots$
or $\Phi\left(0\right),\Phi\left(-\tau_{0}\right),\ldots$ depending
on whether $\Phi\left(\tau_{o}\right)<\Phi\left(0\right)$.

\subsection{\label{Inexact-step-size-selection}Inexact step-size selection}
The previous sub-section describes a brute-force search for the best
step-size. \emph{Bertsekas}~\cite[p. 28]{Bertsekas_NonlinearProgramming}
describes selection rules for finding a step-size that is neither
too large nor too small but ``good enough''. This approach usually
requires far fewer function evaluations than an ``exact'' line search 
for a problem with a convex, differentiable objective function.

The inexact step-size rules are motivated by the solution to the locally
convergent system of equations shown in Equation 
~\ref{eqn:local-convergence-system-of-equations}. Ignoring the constraints:
\begin{align*}
\mathcal{H}_{k}d^{k} &= -\nabla_{x}f\left(x^{k}\right)\\
\end{align*}
Since we approximate $\mathcal{H}_{k}$ by a positive-definite matrix, $\mathcal{W}_{k}$:
\begin{align*}
\left\langle \nabla_{x}f\left(x^{k}\right),d^{k} \right\rangle &=
-\left\langle \nabla_{x}f\left(x^{k}\right),
\mathcal{W}_{k}^{-1}\nabla_{x}f\left(x^{k}\right)\right\rangle  < 0\\
\end{align*}
and $d^{k}$ is a descent direction. 

\emph{Bertsekas}~\cite[p. 29]{Bertsekas_NonlinearProgramming}, recommends
the use of the \emph{Armijo} rule. Given an initial step size $\sigma>0$ and 
$\beta\in\left(0,1\right)$, choose $\tau^{k}$ to be the largest in
$\left\{\sigma,\sigma\beta,\sigma\beta^{2},\hdots\right\}$ so that
\begin{align}
f\left(x^{k}+\tau^{k}d^{k}\right) &\le 
f\left(x^{k}\right)+
c_{1}\tau^{k}\left\langle\nabla_{x}f\left(x^{k}\right),d^{k}\right\rangle
\tag{W1}
\end{align}

The Armijo rule reduces the step size geometrically. An implementation of
line search using the \emph{Armijo} rule is shown in 
Algorithm~\ref{alg:Line-search-Armijo}. 

\begin{algorithm}[htbp]
\begin{algorithmic}
\State $\beta\in\left[0.1,0.5\right]$
\State $\sigma\in\left[10^{-5},10^{-1}\right]$
\While{$f\left(x^{k}\right)-f\left(x^{k}+\beta^{m}d^{k}\right)\ge -
c_{1}\sigma\beta^{m}\left\langle\nabla_{x}f\left(x^{k}\right),d^{k}\right\rangle$}
  \State $m=m+1$
\EndWhile
\State $\tau = \sigma \beta ^{m}$
\end{algorithmic}
\caption{Line search using the Armijo rule.}
\label{alg:Line-search-Armijo}
\end{algorithm}

\emph{Kim et al.} 
~\cite{KimKwonOh_PerformanceModifiedArmijoLineSearchInBFGSOptimisation}
claim improved efficiency with the following modification to the 
\emph{Armijo} rule:
\begin{align}
f\left(x^{k}+\tau^{k}d^{k}\right) &\le 
f\left(x^{k}\right)+c_{1}\tau^{k}\left[
\left\langle\nabla_{x}f\left(x^{k}\right),d^{k}\right\rangle +
\frac{1}{2}\tau^{k} \left\langle d^{k},\mathcal{W}_{k}d^{k}\right\rangle \right]
\end{align}


To rule out unacceptably short steps, the \emph{Wolfe} step-size rules add 
the following to the \emph{Armijo} rule (or $W1$):
\begin{align}
\left\langle \nabla_{x}f\left(x^{k}+\tau^{k}d^{k}\right),d^{k}\right\rangle &\ge
c_{2}\left\langle \nabla_{x}f\left(x^{k}\right),d^{k}\right\rangle
\tag{W2}
\end{align}
where $0<c_{1}<c_{2}<1$. Common choices for the Newton or quasi-Newton
methods are $c_{1}=10^{-4}$ and $c_{2}=0.9$. The second \emph{Wolfe} condition
may be strengthened to
\begin{align}
\left|\left\langle \nabla_{x}f\left(x^{k}+\tau^{k}d^{k}\right),d^{k}\right\rangle
\right| & \le \left|c_{2}\left\langle \nabla_{x}f\left(x^{k}\right)\right\rangle
,d^{k} \right|
\end{align}
This stronger \emph{Wolfe} condition does not allow the gradient to be too 
positive, excluding points that are far from the minimum. \emph{Christianson}
~\cite{Christianson_DeLinkedGoldsteinOrWolf} gives Algorithm 
~\ref{Line-search-using-Wolfe-conditions} for line search using the Wolfe 
conditions.
\begin{algorithm}[htbp]
\begin{algorithmic}
\State $R=1$, $r=0.5$, $\tau=1$, $a=0$, $b=\infty$
\While{$a\neq{}b$}
  \If{$W1\left(\tau\right)$}
    \State $a=\tau$
  \Else
    \State $b=\tau$
  \EndIf
  \If{$W1\left(\tau\right)\land{}W2\left(\tau\right)$}
    \State $b=\tau$
  \Else
    \If{$b=\infty$}
      \State $\tau=\max\left(\tau,Ra\right)$
    \Else
      \State $\tau=\max\left(\left(1-r\right)a+rb\;,\;
                   \min\left(\tau,ra+\left(1-r\right)b\right)\right)$
    \EndIf
  \EndIf
\EndWhile
\end{algorithmic}
\caption{Line search using Wolfe conditions.}
\label{Line-search-using-Wolfe-conditions}
\end{algorithm}

The \emph{Goldstein}  conditions for step-size selection are similar to the 
\emph{Wolfe} conditions:
\begin{align}
f\left(x^{k}+\tau^{k}d^{k}\right) & < f\left(x^{k}\right)+
c_{1}\tau^{k}\left\langle \nabla_{x}f\left(x^{k}\right),d^{k}\right\rangle 
\tag{G1}\\
f\left(x^{k}+\tau^{k}d^{k}\right) & > f\left(x^{k}\right)+
c_{2}\tau^{k}\left\langle \nabla_{x}f\left(x^{k}\right),d^{k}\right\rangle
\tag{G2}
\end{align}
where $0<c_{1}<c_{2}<1$. Usually $c_{1}<0.5$ and $c_{2}=1-c_{1}$.
\emph{Christianson} gives Algorithm~\ref{alg:Line-search-Goldstein} for line
search using the \emph{Goldstein} conditions.
\begin{algorithm}[htbp]
\begin{algorithmic}
\State $\tau=1$, $R=2$
\While{$\neg{}G1\left(\tau\right)$}
  \State $\tau=\frac{\tau}{R}$
\EndWhile
\While{$\neg{}G2\left(\tau\right)$}
  \State $\tau=\tau{}R$
\EndWhile
\end{algorithmic}
\caption{Line search using the Goldstein conditions.}
\label{alg:Line-search-Goldstein}
\end{algorithm}
The first iteration in Algorithm~\ref{alg:Line-search-Goldstein}
must terminate because $f\left(x\right)$ is differentiable at $x^{k}$. The
second iteration must terminate because $f\left(x\right)$ is bounded below.
Note that the two while loops can be placed in either order, and that at most
one of them will ever be performed.

\subsection{\label{sub:Lanczos-update}Lanczos step-size selection}
\emph{Toh}~\cite{Toh_NoteOnStepLengthsSemidefiniteProgramming} describes
estimation of the step-size by the \emph{Lanczos} iteration for
finding the eigenvalues of a matrix. The updated approximation to the Hessian
is expressed as:
\begin{align*}
\mathcal{W}_{k+1}=\mathcal{W}_{k}+\rho_{k}\Delta{}\mathcal{W}_{k}
\end{align*}
Since $\mathcal{W}_{k}$ is symmetric and positive-definite, it has a Cholesky 
factorisation $\mathcal{W}_{k}=L_{k}^{\top}L_{k}$. Let
\begin{align*}
\mathcal{B}_{k} &= -{L_{k}^{-1}}^{\top}\Delta{}\mathcal{W}_{k}L_{k}^{-1}
\end{align*}
then the condition that $\mathcal{W}_{k+1} \succeq 0$ is equivalent to
$I-\rho_{k}\mathcal{B}_{k} \succeq 0$. In other words
\begin{align*}
\max \rho_{k} &= 
\begin{cases}
\frac{1}{\lambda_{1}} & \lambda_{1} > 0\\
\infty & \text{otherwise}
\end{cases}
\end{align*}
where $\lambda_{1}$ is the maximum eigenvalue of $\mathcal{B}_{k}$ and $\rho_{k}$ 
provides an upper bound on the corresponding step-size $\tau^{k}d^{k}$.
\emph{Toh} suggests that the required computation can be reduced by finding
$\lambda_{1}$ with the \emph{Lanczos} iteration method. Given a symmetric 
matrix, $A\in\mathbb{R}^{N\times{}N}$, the \emph{Lanczos} method generates a
sequence of tridiagonal matrices $T_{k}\in\mathbb{R}^{k\times{}k}$ having the
property that the extremal eigenvalues of $T_{k}$ are progressively better
estimates of the extremal eigenvalues of $A$. \emph{Golub and van Loan}
describe efficient methods for finding the eigenvalues of a symmetric
tridiagonal matrix~\cite[Section 8.5]{GolubVanLoan_MatrixComputations} and
have an extensive discussion of \emph{Lanczos} methods 
~\cite[Chapter 9]{GolubVanLoan_MatrixComputations}.

\section{\label{sub:Initial-estimate-with-Goldfarb-Idnani}Initial solution with the Goldfarb-Idnani algorithm}
\emph{Goldfarb} and \emph{Idnani}
~\cite{GoldfarbIdnani_NumericallyStableDualQuadraticPrograms}
observe that the origin in the space of dual variables (ie: Lagrange
multipliers) is always a feasible solution of the dual problem. In Algorithm
~\ref{alg:The-dual-algorithm} I reproduce their dual algorithm for solving 
the tangent quadratic problem with linear constraints.

\begin{algorithm}[htbp]
\begin{enumerate}[start=0]
  \item \emph{Find the unconstrained minimum of $f\left(x\right)$, then:}

    Set $x\leftarrow H^{-1}a$, $f\leftarrow\frac{1}{2}a^{\top}x$,
    $E\leftarrow H^{-1}$, $\mathcal{A}\leftarrow\emptyset$, $q\leftarrow0$

  \item \label{itm:Choose-constraint}\emph{Choose the most violated constraint,
      if any:}

  Compute $g_{j}\left(x\right)$, for all $j\in\mathcal{K}\setminus\mathcal{A}$.

  If $\mathcal{V}=\left\{ j\in\mathcal{K}\setminus
  \mathcal{A}\mid g_{j}\left(x\right)<0\right\} =\emptyset$ then \textbf{stop},
  the current solution $x$ is both feasible and optimal.

  Otherwise, choose $p\in\mathcal{V}$ and set $n^{+}\leftarrow n_{p}$ and 
  $\lambda^{+}\leftarrow\left(\begin{array}{c}\lambda\\
   0
   \end{array}\right)$. 

  If $q=0$ then set $\lambda^{+}\leftarrow0$. 

  Set $\mathcal{A}^{+}=\mathcal{A}\cup\left\{ p\right\}$.

  \item \emph{Check for feasibility and determine a new solution pair:}

  \begin{enumerate}
    \item \label{itm:Determine-step-direction} \emph{Determine the step 
        direction:}

    Compute $d=En^{+}$ (the step direction in the primal space).

    If $q>0$ then  $r=B^{\dagger}n^{+}$ (the negative of the step direction in the
    dual space).

    \item \emph{Compute the step length:}
    \begin{enumerate}
      \item \emph{Partial step length, $\tau_{1}$:} 

        This is the maximum step in dual space without violating dual 
        feasibility. 

        If $r\le0$ or $q=0$ then set $\tau_{1}\leftarrow\infty$. 

        Otherwise, set 
        \begin{align*}
          \tau_{1} & \leftarrow \min_{r_{j}>0,\; j=1,\ldots,q}
                     \left\{ \frac{\lambda_{j}^{+}\left(x\right)}{r_{j}}\right\} =
                     \frac{\lambda_{l}^{+}\left(x\right)}{r_{l}}
        \end{align*}
        In \emph{Step~\ref{itm:new-solution-pair}} below, element 
        $k\in\mathcal{K}$ corresponds to the $l$-th element in $\mathcal{A}$.

      \item \emph{Full step length, $\tau_{2}$:} 

        This is the minimum step in 
        primal space such that the $p$-th constraint becomes feasible. 

        If $\left|d\right|=0$ then set $\tau_{2}\leftarrow\infty$. 

        Otherwise, set 
        $\tau_{2}\leftarrow-\frac{g_{p}\left(x\right)}{d^{\top}n^{+}}$.

      \item \emph{Step length, $\tau$:} 

        Set $\tau\leftarrow\min\left(\tau_{1},\tau_{2}\right)$
    \end{enumerate}
    \item \label{itm:new-solution-pair}\emph{Determine a new solution pair 
        and take the step:}
      \begin{enumerate}
      \item \emph{No step in primal or dual space:} 

        If $\tau=\infty$ then \textbf{stop}. The sub-problem 
        $P\left(\mathcal{A}^{+}\right)$ and hence the quadratic problem are 
        infeasible.

      \item \emph{Step in dual space:} 

        If $\tau_{2}=\infty$, then set 
        $\lambda^{+}\leftarrow\lambda^{+}+
        \tau\left(\begin{array}{c}
                    -r\\
                    1
                  \end{array}\right)$, and drop constraint $k$; 

        \hspace{5mm}i.e.\ set $\mathcal{A}\leftarrow\mathcal{A}\setminus
        \left\{k\right\}$, $q\leftarrow q-1$, update $E$ and $B^{\dagger}$, and go to 
        \emph{Step~\ref{itm:Determine-step-direction}}.

    \item \emph{Step in primal and dual space:} 

      Set $x\leftarrow x+\tau d$, 
      $f\leftarrow f+\tau d^{\top}n^{+}\left(\frac{1}{2}\tau+\lambda_{q+1}^{+}\right)$,
      $\lambda^{+}\leftarrow\lambda^{+}+\tau\left(\begin{array}{c}
                                                    -r\\
                                                    1\end{array}\right)$.

      If $\tau=\tau_{2}$ (a full step) then set $\lambda\leftarrow\lambda^{+}$ 
      and add constraint $p$; 

      \hspace{5mm}i.e.\ set 
      $\mathcal{A}\leftarrow\mathcal{A}\cup\left\{p\right\}$,
      $q\leftarrow q+1$, update $E$ and $B^{\dagger}$ and go to
      \emph{Step~\ref{itm:Choose-constraint}}.

      If $\tau=\tau_{1}$ (partial step) then drop constraint $k$; 

      \hspace{5mm}i.e.\ set
      $\mathcal{A}\leftarrow\mathcal{A}\setminus\left\{ k\right\} $, 
      $q\leftarrow q-1$, update $E$ and $B^{\dagger}$, and go to
      \emph{Step~\ref{itm:Determine-step-direction}}.
    \end{enumerate}
  \end{enumerate}
\end{enumerate}
\caption{The \emph{Goldfarb-Idnani} dual algorithm
~\cite{GoldfarbIdnani_NumericallyStableDualQuadraticPrograms}.}
\label{alg:The-dual-algorithm}
\end{algorithm}

Some explanation of the notation is required. The problem statement is:
\begin{align*}
\textbf{minimise}   \quad & f\left(x\right) = a^{\top}x+\frac{1}{2}x^{\top}Hx\\
\textbf{subject to} \quad & g\left(x\right) \equiv G^{\top}x-b\ge0
\end{align*}

This is equivalent to the linearised optimisation problem defined
in Section~\ref{sub:Constrained-optimisation-Newton}. The 
\emph{Goldfarb-Idnani} dual algorithm commences with the unconstrained 
minimum $x=-H^{-1}a$ and adds constraints to the active constraint set, 
$\mathbb{\mathcal{A}}$, having cardinality $q$, until all constraints are 
satisfied. In the following the set of all constraints is denoted 
$\mathcal{K}$, $\mathcal{A}^{+}$ denotes $\mathcal{A}\cup\left\{ p\right\}$
where $p\in\mathcal{K}\setminus\mathcal{A}$
and $\mathcal{A}^{-}$ represents the subset of $\mathcal{A}$ that
contains one fewer element than $\mathcal{A}$. A \emph{subproblem}
$P\left(\mathcal{A}\right)$ is defined to be the quadratic programming
problem subject only to the subset of the constraints indexed by
$\mathcal{A}\subset\mathcal{K}$.
If the solution $x$ of a subproblem $P\left(\mathcal{J}\right)$
lies on a linearly independent set of constraints indexed by
$\mathcal{A}\subseteq\mathcal{J}$ then $\left(x,\mathcal{A}\right)$ is called
a \emph{solution-pair} or \emph{S-pair}. $B$, $B^{+}$ and $B^{-}$ represent the 
matrices of constraint gradients corresponding to $\mathcal{A}$, 
$\mathcal{A}^{+}$ and $\mathcal{A}^{-}$. $n^{+}$ represents the gradient vector 
added to $B$ to form $B^{+}$. Similarly for $n^{-}$. $I_{k}$ denotes the 
$k\times k$ identity matrix and $e_{j}$ represents the $j$th column of $I_{k}$.

When the constraint gradients (columns of $B$) are linearly independent
one can define the operators
\begin{align*}
B^{\dagger} &= \left(B^{\top}H^{-1}B\right)^{-1}B^{\top}H^{-1}\\
E &= H^{-1}\left(I-BB^{\dagger}\right)
\end{align*}
where $B^{\dagger}$ is the \emph{pseudo-inverse} or \emph{Moore-Penrose}
\emph{generalised inverse} of $B$. $E$ is a reduced inverse Hessian
operator for the quadratic $f\left(x\right)$ subject to the active
set of constraints. In particular, as in 
~\cite{GoldfarbIdnani_NumericallyStableDualQuadraticPrograms},
if $\hat{x}$ is a point in the $\left(n-q\right)$ dimensional manifold
$\mathcal{M}=\left\{ x\in\mathfrak{\mathbb{R}}^{n}\mid n_{i}^{\top}x=b_{i},i\in\mathcal{A}\right\}$
and $\nabla_{x}f\left(\hat{x}\right)=H\hat{x}+a$ is the gradient
of $f\left(x\right)$ at $\hat{x}$ then the minimum of $f\left(x\right)$
over $\mathcal{M}$ is attained at
$\tilde{x}=\hat{x}-E\nabla_{x}f\left(\hat{x}\right)$.
For $\tilde{x}$ to be the optimal solution for the subproblem
$P\left(\mathcal{A}\right)$
\begin{align*}
\nabla_{x}f\left(\tilde{x}\right) &= B\lambda\left(\tilde{x}\right)
\end{align*}
where the vector of Lagrange multipliers $\lambda\left(\tilde{x}\right)\ge0$.
Multiplying both sides by $B^{\dagger}$gives 
\begin{align*}
\lambda\left(\tilde{x}\right) & \equiv
B^{\dagger}\nabla_{x}f\left(\tilde{x}\right)\ge0 
\end{align*}
Also multiplying by $E$ gives 
\begin{align*}
E\nabla f\left(\tilde{x}\right) &= H^{-1}\left(I-BB^{\dagger}\right)B\lambda\\
 &= H^{-1}\left(B-B\right)\lambda\\
 &= 0
\end{align*}
These conditions are necessary and sufficient for $\tilde{x}$ to
be the optimal solution to $P\left(\mathcal{A}\right)$. In addition,
the dual algorithm makes use of a set of, so-called, \emph{infeasibility}
multipliers
\begin{align*}
r &= B^{\dagger}n^{+}
\end{align*}
Some properties of $B^{\dagger}$ and $E$:
\begin{align*}
 & Ew=0\Leftrightarrow w=B\alpha\\
 & E ~ \textit{is positive semidefinite}\\
 & EWE=E\\
 & B^{\dagger}WE=0\\
 & EE^{+}=E^{+}
\end{align*}

\clearpage
When justifying Algorithm~\ref{alg:The-dual-algorithm}, 
\emph{Goldfarb} and \emph{Idnani}
~\cite[p. 7]{GoldfarbIdnani_NumericallyStableDualQuadraticPrograms}
first point out that for a given S-pair $\left(x,\mathcal{A}\right)$
and a violated constraint $p$, if the columns of $B^{+}$ (ie: those
of $B$ and $n^{+}=n_{p}$) are linearly independent, then 
\begin{align*}
g_{p}\left(x\right) & < 0\\
g_{i}\left(x\right) &= 0 ~ \forall i \in \mathcal{A}\\
E^{+}\nabla_{x}f\left(x\right) &= 0\\
\lambda^{+}\left(x\right)\triangleq\left(B^{+}\right)^{\dagger}\nabla_{x}f\left(x\right) & \ge 0
\end{align*}

\framebox{\begin{minipage}[t]{0.9\columnwidth}%
\emph{Definition 1: }A triple $\left(x,\mathcal{A},p\right)$ consisting
of a point x and a set of indices $\mathcal{A}^{+}=\mathcal{A}\cup\left\{ p\right\} $
where $p\in\mathcal{K}\setminus\mathcal{A}$ is said to be a V(violated)-triple
if the columns of $B^{+}$ are linearly independent and the above
conditions apply.%
\end{minipage}}

The point $\hat{x}$ corresponding to the V-triple $(\hat{x},\mathcal{A},p)$
is the optimal solution to the subproblem obtained by replacing the
constraint $g_{p}\left(x\right) \ge 0$ in $P\left(\mathcal{A}^{+}\right)$
by $g_{p}\left(x\right)\ge g_{p}\left(\hat{x}\right)$ i.e.\ by a parallel
constraint which passes through $\hat{x}$. Let $x^{*}$ be the point
on the manifold $\mathcal{M}^{+}=\left\{ x\in\mathbb{R}^{n}\mid
n_{i}^{\top}x=b_{i},i\in\mathcal{A}^{+}\right\} $  
at which $f(x)$ is minimized. The following lemma shows how to move
to such a point from a point $x$ corresponding to a V-triple $(x,\mathcal{A},p)$.

\emph{}
\begin{framed}
\emph{Lemma 1:} Let $\left(x,\mathcal{A},p\right)$ be a V-triple
and consider points of the form $\tilde{x}=x+\tau d$ where $d=En^{+}$.
Then 
\begin{align}
E^{+}\nabla_{x}f\left(\tilde{x}\right) &= 0\\
g_{i}\left(\tilde{x}\right) &= 0 ~ \forall i \in \mathcal{A}\\
\lambda^{+}\left(\tilde{x}\right)\triangleq\left(B^{+}\right)^{\dagger}\nabla_{x}f\left(\tilde{x}\right) &= \lambda^{+}\left(x\right)+\tau\left[\begin{array}{c}
-r\\
1
\end{array}\right]\label{eqn:Lemma1_lambda}
\end{align}
where $r=B^{\dagger}n^{+}$and $g_{p}\left(\tilde{x}\right)=g_{p}\left(x\right)+\tau d^{\top}n^{+}$.

\emph{Proof:}~ The lemma follows from the properties of the V-triple
$(x,\mathcal{A},p)$ and
\begin{align}
\nabla_{x}f\left(\tilde{x}\right) &= \nabla_{x}f\left(x\right)+\tau Hd\label{eqn:Lemma1_gradf}
\end{align}
where 
\begin{align*}
Hd &= HEn^{+}\\
 &= \left(I-BB^{\dagger}\right)n^{+}\\
 &= n^{+}-Br\\
 &= \left[\begin{array}{cc}
B & n^{+}\end{array}\right]\left[\begin{array}{c}
-r\\
1
\end{array}\right]\\
 &= B^{+}\left[\begin{array}{c}
-r\\
1
\end{array}\right]
\end{align*}
Recalling that $EB=H^{-1}\left(B-BB*B\right)=0$, the results follow
from multiplying Equation~\ref{eqn:Lemma1_gradf} on the left by $E^{+}$
and $B^{+}$.\end{framed}

It follows from this lemma that the point $\tilde{x}=x+\tau_{2}d$,
where $\tau_{2}=-\frac{g_{p}\left(x\right)}{d^{\top}n^{+}}$, minimises
the quadratic function $f\left(x\right)$ over $\mathcal{M}^{+}$
(since then $g_{p}\left(\tilde{x}\right)=0$). If $\lambda^{+}\left(\tilde{x}\right)\ge0$
as well, then $\tilde{x}$ is an optimal solution to $P\left(\mathcal{A}^{+}\right)$
and $\left(\tilde{x},\mathcal{A}^{+}\right)$ is an S-pair. If not,
then Equation~\ref{eqn:Lemma1_lambda} implies that there is a smallest
value $\tau_{1}$ of $\tau$, $\tau_{1}<\tau_{2}$, such that some
component of $\lambda^{+}\left(\tilde{x}\left(\tau\right)\right)<0$
for $\tau>\tau_{1}$. If the constraint, say $k\in\mathcal{A}$, corresponding
to this component is dropped from the active set, then $\left(\tilde{x}\left(\tau_{1}\right),\mathcal{A}^{-},p\right)$,
where $\mathcal{A}^{-}=\mathcal{A}\setminus\left\{ k\right\} $, is
again a V-triple. These remarks are formalised by the following two
theorems.
\clearpage
\begin{framed}%
\emph{Theorem 1:} Given a V-triple $\left(x,\mathcal{A},p\right)$
if $\tilde{x}$ is defined as in Lemma 1 with $\tau=\min\left\{ \tau_{1},\tau_{2}\right\} $
where 
\begin{align*}
\tau_{1} &= \min\left\{ \min_{r_{j}>0\;,\;1\le j\le q}\left\{ \frac{\lambda_{j}^{+}\left(x\right)}{r_{j}^{+}\left(x\right)}\right\} ,\infty\right\} \\
\tau_{2} &= -\frac{g_{p}\left(x\right)}{d^{\top}n^{+}}
\end{align*}
then 
\begin{align*}
g_{P}\left(\tilde{x}\right) & \ge g_{p}\left(x\right)\\
f\left(\tilde{x}\right)-f\left(x\right) &= \tau d^{\top}n^{+}\left(\frac{1}{2}\tau+\lambda_{q+1}^{+}\left(x\right)\right) \ge 0
\end{align*}
Moreover, if $\tau=\tau_{1}=\frac{\lambda_{l}^{+}\left(x\right)}{r_{l}}$,
then $\left(\tilde{x},\mathcal{A}\setminus\left\{ k\right\} ,p\right)$
is a V-triple, where element $k\in\mathcal{K}$ corresponds to the
$l$-th element in $\mathcal{A}$. Alternatively, if $\tau=\tau_{2}$,
then $\left(\tilde{x},\mathcal{A}\cup\left\{ p\right\} \right)$ is
an S-pair.

\emph{Proof:}~ Since $\left(x,\mathcal{A},p\right)$ is a V-triple,
\[
d^{\top}n^{+}=n^{+T}En^{+}=n^{+T}EHEn^{+}=d^{\top}Hd>0
\]
and $\tau\ge0$. Hence, from Lemma 1, $g_{P}\left(\tilde{x}\right)\ge g_{p}\left(x\right)$.
Also, from Taylor's theorem 
\begin{align*}
f\left(\tilde{x}\right)-f\left(x\right) &= \tau d^{\top}\nabla_{x}f\left(x\right)+\frac{1}{2}\tau^{2}d^{\top}Hd
\end{align*}
Since $E^{+}\nabla_{x}f\left(x\right)=0$ implies that $\nabla_{x}f\left(x\right)=B^{+}\lambda^{+}\left(x\right)$,
it follows that $E\nabla_{x}f\left(x\right)=En^{+}\lambda_{q+1}^{+}\left(x\right)$
and
\[
d^{\top}\nabla_{x}f\left(x\right)=n^{+T}E\nabla_{x}f\left(x\right)=d^{\top}n^{+}\lambda_{q+1}^{+}\left(x\right)\ge0
\]
The result follows by substitution. Moreover, as long as $\tau>0$,
$f\left(\tilde{x}\right)>f\left(x\right)$. From the definition of
$\tau$ and Lemma 1 it is evident that $E^{+}\nabla_{x}f\left(\tilde{x}\right)=0$,
$g_{i}\left(\tilde{x}\right)=0$, $i\in\mathcal{A}$ and $\lambda^{+}\left(\tilde{x}\right)\ge0$.
If $\tau=\tau_{2}$, then $g_{p}\left(\tilde{x}\right)=0$ and $\left(x,\mathcal{A}\cup\left\{ p\right\} \right)$
is an S-pair. If $\tau=\tau_{1}<\tau_{2}$, then $\lambda_{l}^{+}\left(\tilde{x}\right)=0$
and $g_{p}\left(\tilde{x}\right)<0$. Since $E^{+}\nabla_{x}f\left(\tilde{x}\right)=0$
and $\lambda_{l}^{+}\left(\tilde{x}\right)=0$ we can write 
\begin{align*}
\nabla_{x}f\left(\tilde{x}\right) &= B^{+}\lambda^{+}\left(\tilde{x}\right)\\
 &= \sum_{i\in\mathcal{A}\cup\left\{ p\right\} \setminus\left\{ k\right\} }\lambda_{j\left(i\right)}^{+}n_{i}
\end{align*}
where $i$ is the $j\left(i\right)$-th index in $\mathcal{A}^{+}=\mathcal{A}\cup\left\{ p\right\} $.
As the set of normals $\left\{ n_{i}\mid i\in\mathcal{A}\cup\left\{ p\right\} \setminus\left\{ k\right\} \right\} $
is clearly linearly independent $\left(\tilde{x},\mathcal{A}\setminus\left\{ k\right\} ,p\right)$
is a V-triple. \end{framed}

It follows from the above theorem that starting from a V-triple $\left(x,\mathcal{A},p\right)$
one can obtain an S-pair $\left(\tilde{x,}\mathcal{\tilde{A}}\cup\left\{ p\right\} \right)$
with $\tilde{\mathcal{A}}\subseteq\mathcal{A}$ and $f\left(\tilde{x}\right)>f\left(x\right)$
after at most $q$ partial steps and one full step.

If $n^{+}$ is a linear combination of the columns of $B$ at the
start of Step 2, then $\left(x,\mathcal{A},p\right)$ is not a V-triple.
In this case, either the subproblem $P\left(\mathcal{A}\cup\left\{ p\right\} \right)$
is infeasible or a constraint can be dropped from the active set $\mathcal{A}$
so that $\left(x,\mathcal{A}^{-},p\right)$ is a V-triple. In the
former case, the original quadratic problem must also be feasible, while in the
latter case, one may proceed according to Theorem 1 to obtain a new
S-pair with a higher function value.
\clearpage
\begin{framed}
\emph{Theorem 2:} Let $\left(x,\mathcal{A}\right)$ be an S-pair and
$p$ be an index of a constraint in $\mathcal{K}\setminus\mathcal{A}$
such that $n^{+}\triangleq n_{p}=Br$ and $g_{p}\left(x\right) < 0$.
If $r \le 0$, then $P\left(\mathcal{A}\cup\left\{ p\right\} \right)$
is infeasible; otherwise the $k$-th component can be dropped from
the active set, where $k$ is determined by 
\begin{align*}
\frac{\lambda_{l}\left(x\right)}{r_{l}} &= \min_{r_{j}>0\;,\; j=1,\ldots,q}\left\{ \frac{\lambda_{j}\left(x\right)}{r_{j}}\right\} ,\quad l=j\left(k\right)
\end{align*}
to give $\mathcal{A}^{-}=\mathcal{A}\setminus\left\{ k\right\} $
and the V-triple $\left(x,\mathcal{A}^{-},p\right)$. 

\emph{Proof:}~If there is a feasible solution $\tilde{x}=x+d$ satisfying
the constraints $\mathcal{A}\cup\left\{ p\right\} $, it is necessary
that $n^{+T}d=r^{\top}B^{\top}d>0$ and $B^{\top}d \ge 0$ since $g_{i}\left(x\right)=0$
for all $i\in\mathcal{A}$. But if $r \le 0$, the two requirements
in the theorem cannot be simultaneously satisfied; hence in this case
$P\left(\mathcal{A}\cup\left\{ p\right\} \right)$ is infeasible.
If a component of $r$ is positive, it follows that $r_{l}>0$ and
that
\begin{align*}
n^{+} &= n_{k}r_{l}+\sum_{i\in\mathcal{A}^{-}}r_{j\left(i\right)}n_{i}
\end{align*}
so 
\begin{align*}
n_{k} &= \frac{1}{r_{l}}\left[-\sum_{i\in\mathcal{A}^{-}}r_{j\left(i\right)}n_{i}+n^{+}\right]
\end{align*}
Since $\left(x,\mathcal{A}\right)$ is an S-pair 
\begin{align*}
\nabla_{x}f\left(x\right) &= \sum_{i\in\mathcal{A}^{-}}\lambda_{j\left(i\right)}n_{i}+\lambda_{l}n_{k}\\
 &= \sum_{i\in\mathcal{A}^{-}}\left(\lambda_{j\left(i\right)}-\frac{\lambda_{l}}{r_{l}}r_{j\left(i\right)}\right)n_{i}+\frac{\lambda_{l}}{r_{l}}n^{+}
\end{align*}
If we define $\hat{\mathcal{A}}=\mathcal{A}^{-}\cup\left\{ p\right\} $,
then it is clear that $\hat{B}$ has full column rank, $\hat{E}\nabla_{x}f\left(x\right)=0$
and 
\begin{align*}
\hat{\lambda}\left(x\right) &= \hat{B}^{\dagger}\nabla_{x}f\left(x\right)\\
 &= \begin{cases}
\lambda_{j\left(i\right)}-\frac{\lambda_{l}}{r_{l}}r_{j\left(i\right)}\ge 0 & i\in\mathcal{A}^{-}\\
\frac{\lambda_{l}}{r_{l}}\ge 0
\end{cases}
\end{align*}
and hence that $\left(x,\mathcal{A}^{-},p\right)$ is a V-triple.
\end{framed}

\emph{Goldfarb} and \emph{Idnani}
~\cite[Section 4]{GoldfarbIdnani_NumericallyStableDualQuadraticPrograms}
base their implementation on the \emph{Cholesky} factorisation
\begin{align*}
H &= LL^{\top}
\end{align*}
 of the positive definite symmetric Hessian matrix $H$ and the \emph{QR}
factorisation 
\begin{align*}
C &= Q\left[\begin{array}{c}
R\\
0
\end{array}\right]=\left[Q_{1}\mid Q_{2}\right]\left[\begin{array}{c}
R\\
0
\end{array}\right]
\end{align*}
of the $\left(n\times q\right)$ matrix 
\begin{align*}
C &= L^{-1}B
\end{align*}
where $L$ is an $\left(n\times n\right)$ lower triangular matrix,
$R$ is a $\left(q\times q\right)$ upper triangular matrix and $Q=\left[Q_{1}\mid Q_{2}\right]$
is a $\left(n\times n\right)$ orthogonal matrix partitioned so that
$Q_{1}$ has $q$ columns. By substitution, 
\begin{align*}
B^{\dagger} &= \left(B^{\top}{L^{-1}}^{\top}L^{-1}B\right)^{-1}B^{\top}{L^{-1}}^{\top}L^{-1}\\
 &= \left(C^{\top}C\right)^{-1}C^{\top}L^{-1}\\
 &= R^{-1}{R^{-1}}^{\top}C^{\top}L^{-1}\\
 &= R^{-1}Q_{1}^{\top}L^{-1}\\
 &= R^{-1}J_{1}^{\top}
\end{align*}
and
\begin{align*}
E &= {L^{-1}}^{\top}L^{-1}-{L^{-1}}^{\top}C\left(C^{\top}C\right)^{-1}C^{\top}L^{-1}\\
 &= {L^{-1}}^{\top}L^{-1}-{L^{-1}}^{\top}CR^{-1}{R^{-1}}^{\top}C^{\top}L^{-1}\\
 &= {L^{-1}}^{\top}QQ^{\top}L^{-1}-{L^{-1}}^{\top}Q_{1}Q_{1}^{\top}L^{-1}\\
 &= {L^{-1}}^{\top}Q_{2}Q_{2}^{\top}L^{-1}\\
 &= J_{2}J_{2}^{\top}
\end{align*}
where
\begin{align*}
C^{\top}C &= \left[\begin{array}{cc}
R^{\top} & 0\end{array}\right]Q^{\top}Q\left[\begin{array}{c}
R\\
0
\end{array}\right]\\
 &= R^{\top}R
\end{align*}
and
\begin{align*}
CR^{-1} &= \left[\begin{array}{cc}
Q_{1} & Q_{2}\end{array}\right]\left[\begin{array}{c}
R\\
0
\end{array}\right]R^{-1}\\
 &= Q_{1}
\end{align*}
and
\begin{align*}
J &= \left[\begin{array}{cc}
J_{1} & J_{2}\end{array}\right]\\
 &= \left[\begin{array}{cc}
{L^{-1}}^{\top}Q_{1} & {L^{-1}}^{\top}Q_{2}\end{array}\right]\\
 &= {L^{-1}}^{\top}Q
\end{align*}
In the dual algorithm the vectors $d=En^{+}$ and $r=B^{\dagger}n^{+}$
are required. Compute the intermediate vector 
\begin{align*}
v &= J^{\top}n^{+}\\
 &= \left[\begin{array}{c}
J_{1}^{\top}\\
J_{2}^{\top}
\end{array}\right]n^{+}\\
 &= \left[\begin{array}{c}
v_{1}\\
v_{2}
\end{array}\right]
\end{align*}
from which it follows that
\begin{align*}
d &= J_{2}v_{2}
\end{align*}
and 
\begin{align*}
r &= R^{-1}v_{1}
\end{align*}
\emph{Goldfarb} and \emph{Idnani} describe an efficient method for updating the
factors $J$ and $R$ when a constraint is added or deleted.
\clearpage
\section{Implementation examples}
The archive distributed with this document contains Octave functions for the
line-search and non-linear optimisation techniques described above. 

The Octave script \emph{linesearch\_test.m} implements unconstrained
quasi-Newton optimisation with various line-search methods. The Octave file
\emph{sqp\_common.m} contains the function to be optimised, constraints,
gradients and the Hessian function:
\begin{align*}
  \textbf{minimise}   \quad & f\left(x\right) = x_{1}^{4}+x_{2}^{4}+x_{3}^{4}+
                              x_{1}x_{2}+x_{1}x_{3}+x_{2}x_{3}+x_{1}+x_{2}+x_{3}+5\\
  \textbf{subject to} \quad & g\left(x\right) =
                              \left[x_{2}-1;-x_{1}-\sqrt{2};-x_{3}-0.5\right]\ge0
\end{align*}
The step size is found by line search with the Armijo, Goldstein, golden-section
or quadratic-interpolation methods. Sample output of \emph{linesearch\_test.m}
is:
\begin{small}
\verbatiminput{linesearch_test.diary.warning}
\end{small}

The Octave script \emph{sqp\_bfgs\_test.m} tests constrained quasi-Newton
optimisation with combinations of Hessian initialisation, Hessian
update and linesearch type. Note that the \emph{goldensection} linesearch 
requires many more function calls than the other types. Sample output
filtered for \emph{``SQP''} is:
\begin{small}
\verbatiminput{sqp_bfgs_test.diary.SQP}
\end{small}

\emph{sqp\_gi\_test.m} tests the \emph{Goldfarb-Idnani} algorithm implemented
in \emph{goldfarb\_idnani.m}. Sample output is:
\begin{small}
\verbatiminput{sqp_gi_test.diary}
\end{small}

The Octave script \emph{goldfarb\_idnani\_fir\_minimum\_phase\_test.m} modifies
a bandpass FIR filter designed by the \emph{remez} function by constraining the
zeros of the filter to lie within the unit circle in the $z$-plane and by
constraining the amplitude response at regular intervals in frequency. The
filter specification is:
\begin{small}
\verbatiminput{goldfarb_idnani_fir_minimum_phase_test_spec.m}
\end{small}
Figure~\ref{fig:Goldfarb-Idnani-fir-minimum-phase-initial-response} shows the
amplitude response of the initial band-pass FIR filter and
Figure~\ref{fig:Goldfarb-Idnani-fir-minimum-phase-initial-zeros}
shows the zeros of the initial band-pass FIR filter.
Figure~\ref{fig:Goldfarb-Idnani-fir-minimum-phase-response} shows the
amplitude response of the modified band-pass FIR filter.
The frequencies of the amplitude constraints are marked. Unfortunately, one
amplitude constraint is not satisfied.
Figure~\ref{fig:Goldfarb-Idnani-fir-minimum-phase-zeros}
shows the zeros of the modified band-pass FIR filter.
\clearpage
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{goldfarb_idnani_fir_minimum_phase_test_initial_response}}
\caption{Amplitude response of the initial band-pass FIR filter.}
\label{fig:Goldfarb-Idnani-fir-minimum-phase-initial-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{goldfarb_idnani_fir_minimum_phase_test_initial_zeros}}
\caption{Zeros of the initial band-pass FIR filter.}
\label{fig:Goldfarb-Idnani-fir-minimum-phase-initial-zeros}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{goldfarb_idnani_fir_minimum_phase_test_response}}
\caption{Amplitude response of the band-pass FIR filter after application of the
  Goldfarb-Idnani algorithm. The frequencies of the amplitude constraints are
  marked.}
\label{fig:Goldfarb-Idnani-fir-minimum-phase-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{goldfarb_idnani_fir_minimum_phase_test_zeros}}
\caption{Zeros of the band-pass FIR filter after application of the Goldfarb-Idnani algorithm.}
\label{fig:Goldfarb-Idnani-fir-minimum-phase-zeros}
\end{figure}

\chapter{\label{app:Fourier-transform-of-the-Gaussian-function}Fourier transform of the Gaussian function}  
See \emph{NIST Digital Library of Mathematical Functions}~\cite[Sections 7.2.1
and 1.14.1]{NIST_DigitalLibraryMathematicalFunctions}
\section{Preliminary results}
The Gaussian function is $e^{-t^2}$.
\subsection{Integral of the Gaussian function}
\emph{Poisson} introduced this method of integrating the Gaussian function:
\begin{align*}
  \left[\int_{-\infty}^{\infty}e^{-t^{2}}dt\right]^{2}
  &=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-x^{2}-y^{2}}dxdy\\
  &=\int_{0}^{2\pi}\int_{0}^{\infty}e^{-r^{2}}rdrd\theta\\
  &=2\pi\int_{0}^{\infty}e^{-r^{2}}rdr\\
  &=\pi\int_{0}^{\infty}e^{-s}ds\\
  &=\pi\left[-e^{-s}\right]_{0}^{\infty}\\
  &=\pi
\end{align*}
So:
\begin{align*}
  \int_{0}^{\infty}e^{-t^{2}}dt&=\frac{\sqrt{\pi}}{2}
\end{align*}
\subsection{Fourier transform of the derivative of a function}
If $g\left(t\right)$ is absolutely integrable, bounded and differentiable on
$\left(-\infty{},\infty\right)$ then the Fourier transform, $\mathcal{F}$, of
$g\left(t\right)$ is:
\begin{align*}
G\left(\omega\right) = \mathcal{F}g\left(t\right) 
  &=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}
    g\left(t\right)e^{\imath\omega{}t}dt
\end{align*}
and the inverse Fourier transform is:
\begin{align*}
  g\left(t\right) = \mathcal{F}^{-1}G\left(\omega\right)
  &=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}
    G\left(\omega\right)e^{-\imath\omega{}t}d\omega
\end{align*}
The Fourier transform of $\frac{dg\left(t\right)}{dt}$ is:
\begin{align*} 
  \mathcal{F}\frac{dg\left(t\right)}{dt}
  &=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}
    \frac{dg\left(t\right)}{dt}e^{\imath\omega{}t}dt\\
  &=\frac{1}{\sqrt{2\pi}}
    \left\{\left[g\left(t\right)e^{\imath\omega{}t}\right]_{-\infty}^{\infty}
    -\imath\omega\int_{-\infty}^{\infty}g\left(t\right)e^{\imath\omega{}t}dt\right\}\\
  &=-\imath\omega\mathcal{F}g\left(t\right)
\end{align*}
Similarly:
\begin{align*} 
  \mathcal{F}^{-1}\frac{dG\left(\omega\right)}{d\omega} 
  &=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}
    \frac{dG\left(\omega\right)}{d\omega}e^{-\imath\omega{}t}d\omega\\
  &=\frac{1}{\sqrt{2\pi}}
    \left\{\left[G\left(\omega\right)e^{-\imath\omega{}t}\right]_{-\infty}^{\infty}
    +\imath{}t\int_{-\infty}^{\infty}G\left(\omega\right)
    e^{-\imath\omega{}t}dt\right\}\\
  &=\imath{}t\mathcal{F}^{-1}G\left(\omega\right)
\end{align*}
\section{Derivation of the Fourier transform of the Gaussian function in the frequency domain}
The Gaussian function in the frequency domain is:
\begin{align*}
  G\left(\omega\right)&=e^{-\left(\frac{\omega}{\alpha}\right)^{2}}
\end{align*}
Differentiating both sides:
\begin{align*}
  \frac{dG\left(\omega\right)}{d\omega}
  &= -\frac{2\omega}{\alpha^{2}}G\left(\omega\right)
\end{align*}
Taking the Fourier transform of both sides:
\begin{align*}
  \imath{}tg\left(t\right)
  &= -\frac{2\imath}{\alpha^{2}}\frac{dg\left(t\right)}{dt}
\end{align*}
Rearranging and integrating both sides:
\begin{align*}
  \int_{0}^{t}-\frac{\tau\alpha^{2}}{2}d\tau
  &= \int_{0}^{t}\frac{\frac{dg\left(\tau\right)}{d\tau}}
    {g\left(\tau\right)}d\tau \\
  \ln{}g\left(t\right)-\ln{}g\left(0\right)
  &=-\left(\frac{t\alpha}{2}\right)^{2}\\
  g\left(t\right)&=g\left(0\right)e^{-\left(\frac{t\alpha}{2}\right)^{2}}
\end{align*}
where:
\begin{align*}
  g\left(0\right)&= \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty}
                   e^{-\left(\frac{\omega}{\alpha}\right)^{2}}d\omega \\
                 &= \frac{2\alpha}{\sqrt{2\pi}}
                   \int_{0}^{\infty}e^{-\omega^{2}}d\omega \\ 
                 &= \frac{\alpha}{\sqrt{2}}
\end{align*}

\chapter{Design of IIR digital filter transfer functions}
This chapter reviews methods of constructing IIR digital filter transfer
functions. The first section reviews the analogue-to-digital transformation of
$s$-plane Butterworth filters to the $z$-plane. The subsequent
sections review methods of designing \emph{equi-ripple} amplitude response
IIR filters. 
\section{Design of discrete time filters with the bilinear transform}
Various methods can be used to transform an analog filter prototype
response to the discrete time domain. The ``bi-linear'' transform is:
\begin{align*}
H\left(z\right)&=\hat{H}\left(\frac{1-z^{-1}}{1+z^{-1}}\right)\\
\end{align*}
The bi-linear transform has the following 
properties:
\begin{itemize}
\item the $s$-plane $\imath\omega$ axis maps to the $z$-plane unit circle
  $z=e^{\imath\Omega T}$, where $T$ is the sampling interval, and the $s$-plane
  left-half plane maps to the $z$-plane unit disc, $\left|z\right|\le 1$.
\item if the analog response is stable, the transformed response
is also stable
\item the zero frequency response is the same in both domains
\end{itemize}
The bilinear transform, $H\left(z\right)$ of the analog frequency response, 
$\hat{H}\left(s\right)$ is
\begin{align*}
H\left(e^{\imath\Omega T}\right)&=
\hat{H}\left(\imath\tan\frac{\Omega T}{2}\right)
\end{align*}
The design frequencies of the analog prototype filter on the $s$-plane
$\imath\omega$ axis must be ``pre-warped'' to the $z$-plane unit circle by the
mapping $\tan\frac{\Omega T}{2}\rightarrow\omega$. In other words, the
discrete-time filter behaves at frequency $\Omega$ in the same way that the
continuous-time filter behaves at frequency $\omega=\tan\frac{\Omega T}{2}$.
For example, if the desired cut-off frequency in the z-domain is
$\Omega_{c} T=\frac{\pi}{2}$, then we choose the cutoff frequency of the
$s$-plane prototype filter to be:
\begin{align*}
  \omega_{c}&=\tan\frac{\Omega_{c} T}{2} = \tan\frac{\pi}{4} = 1
\end{align*}
In this work I have assumed that the sampling interval, $T$, is $1$.
Alternatively, one can choose that the \emph{Nyquist} frequency
corresponds to $1$ so that the sampling frequency is $2$. The Octave
\emph{signal} toolbox filter design functions use the latter convention.

Filter design using analog prototypes proceeds as follows:
\begin{itemize}
\item the critical frequencies in the $z$-plane are determined
\item the critical frequencies are mapped to the $s$-plane and used
to design the $s$-plane prototype
\item the bi-linear transform is used to convert that prototype to the $z$-plane
\end{itemize}

\subsection{Design of Butterworth IIR filters}
The Butterworth filter transfer function is described in many textbooks (for
example, \emph{Roberts} and 
\emph{Mullis}~\cite[Chapter 6]{RobertsMullis_DigitalSignalProcessing}). I have
included it here to justify the implementation in
\emph{butter2pq.m}.
\subsubsection{Continuous Time Second Order Butterworth Filter Prototypes}
In the continuous time $s$-plane a low-pass Butterworth filter 
has, by definition, a squared magnitude frequency response of:
\begin{align*}
\left|\hat{H}\left(\omega\right)\right|^{2}&=\frac{1}{1+\omega^{2n}}
\end{align*}
The response with a cutoff angular frequency of $\omega_{c}$ is found by the
$s$-plane transformation $s\rightarrow\frac{s}{\omega_{c}}$. The high-pass
response is found by the $s$-plane transformation $s\rightarrow\frac{1}{s}$.

The $2n$ poles of the Butterworth squared magnitude response are evenly spaced
around the unit circle in the $s$-plane. For stability, the filter realisation 
as a cascade of second order sections uses the poles in the left-hand half
plane, $\lambda_{k}$:
\begin{align*}
\lambda_{k}&=\omega_{c} e^{\imath\theta_{k}} \\
\theta_{k}&=
\frac{\pi}{2}\left(1+\frac{\left( 2 k-1 \right)}{n}\right),\; 1\le k\le n
\end{align*}
For each conjugate pole pair the corresponding low-pass filter second-order
section with unity DC gain has transfer
function\footnote{$\mathconj$ denotes complex conjugate transpose}:
\begin{align*}
\hat{H}_{k}\left(s\right)&=\frac{\lambda_{k}\lambda_{k}^{\mathconj}}
{\left(s-\lambda_{k}\right)\left(s-\lambda_{k}^{\mathconj}\right)}\\
&=\frac{\lambda_{k}\lambda_{k}^{\mathconj}}
{s^{2}-\left(\lambda_{k}+\lambda_{k}^{\mathconj}\right)s+
  \lambda_{k}\lambda_{k}^{\mathconj}}\\
&= \frac{\omega_{c}^{2}}{s^{2}-2\omega_{c}\cos\theta_{k} s +\omega_{c}^{2}}
\end{align*}
If $n$ is odd, there is a single real pole at $s=-\omega_{c}$,
$k=\frac{n+1}{2}$, and the corresponding low-pass first-order section is:
\begin{align*}
\hat{H}_{k}\left(s\right)&=\frac{\omega_{c}}{s+\omega_{c}}
\end{align*}

The Butterworth high-pass filter with cut-off frequency $\omega_{c}$ is found
with the $s$-plane transformation
$\frac{s}{\omega_{c}}\rightarrow\frac{\omega_{c}}{s}$. The second order
high-pass sections are:
\begin{align*}
  \hat{H}_{k}\left(s\right)&=
  \frac{s^{2}}{s^{2}-2\omega_{c}\cos\theta_{k} s +\omega_{c}^{2}}
\end{align*}
and, if $n$ is odd, the first order high-pass section is:
\begin{align*}
\hat{H}_{k}\left(s\right)&=\frac{s}{\omega_{c} + s}
\end{align*}

\subsubsection{Design of  second order Butterworth digital filters with the bilinear transform}
For the Butterworth first order low-pass section:
\begin{align*}
H_{\frac{n+1}{2}}\left(z\right)&=\frac{\omega_{c}\left(1+z^{-1}\right)}
{\left(\omega_{c}+1\right)+\left(\omega_{2}-1\right)z^{-1}}\\
&= d+\frac{qz^{-1}}{1+pz^{-1}}
\end{align*}
where
\begin{align*}
  d &= \frac{\omega_{c}}{\omega_{c}+1} \\
  q &= \frac{2\omega_c}{\left(\omega_{c}+1\right)^{2}} \\
  p &= \frac{\omega_{c}-1}{\omega_{c}+1}
\end{align*}

For the Butterworth second order low-pass section:
\begin{align*}
H_{k}\left(z\right)&=\frac{g\left[1+z^{-1}\right]^{2}}
{a_{0}+a_{1}z^{-1}+a_{2}z^{-2}}\\
&= d_{0}+\frac{q_{1}z^{-1}+q_{2}z^{-2}}{1+p_{1}z^{-1}+p_{2}z^{-2}}
\end{align*}
where:
\begin{align*}
g&=\omega_{c}^{2}\\
a_{0}&=1-2\omega_{c}\cos\theta_{k}+\omega_{c}^{2}\\
a_{1}&=2\left(\omega_{c}^{2}-1\right)\\
a_{2}&=1+2\omega_{c}\cos\theta_{k}+\omega_{c}^{2} \\
d_{0}&=\frac{g}{a_{0}}\\
p_{1}&=\frac{a_{1}}{a_{0}} \\
p_{2}&=\frac{a_{2}}{a_{0}} \\
q_{1}&=d_{0}\left(2-p_{1}\right) \\
q_{2}&=d_{0}\left(1-p_{2}\right) \\
\end{align*}

Similarly, for the first order high-pass section:
\begin{align*}
H_{\frac{n+1}{2}}\left(z\right)&=\frac{\left(1-z^{-1}\right)}
{\left(\omega_{c}+1\right)+\left(\omega_{c}-1\right)z^{-1}} \\
&= \frac{d}{w_{c}}-\frac{qz^{-1}}{1+pz^{-1}}
\end{align*}

and for the Butterworth second order high-pass section:
\begin{align*}
H_{k}\left(z\right)&=\frac{\left[1-z^{-1}\right]^{2}}
{a_{0}+a_{1}z^{-1}+a_{2}z^{-2}} \\
&=t_{0}+\frac{t_{1}z^{-1}+t_{2}z^{-2}}{1+p_{1}z^{-1}+p_{2}z^{-2}}
\end{align*}
where
\begin{align*}
  t_{0}&=\frac{d_{0}}{g}\\
  t_{1}&=-\frac{d_{0}}{g}\left(2+p_{1}\right)\\
  t_{2}&=\frac{q_{2}}{g}
\end{align*}
\clearpage
\section{\label{app:Low-passband-sensitivity-IIR-digital-filters}Low passband sensitivity IIR filters}
\emph{Vaidyanathan et al.}~\cite{VaidyanathanMitraNuevo_LowSensitivityIIRDigitalFilters, VaidyanathanMitra_LowPassbandSensitivityDigitalFilters}
describe the synthesis of IIR digital filters as the parallel connection
of two all-pass filters. The resulting filter has low coefficient
sensitivity if the all-pass filter implementation is \emph{structurally
loss-less} (ie: the all-pass transfer function is preserved when the 
coefficients are truncated).
\subsection{Structural Boundedness}
Consider the $N$-th order IIR filter
\begin{align*}
G\left(z\right)=\frac{P\left(z\right)}{D\left(z\right)}=\frac{p_{0}+p_{1}z^{-1}+\cdots+p_{N}z^{-N}}{1+d_{1}z^{-1}+\cdots+d_{N}z^{-N}}
\end{align*}
where the coefficients $p_{i}$ and $d_{i}$ are real. We wish to
design a structure with multiplier coefficients $m_{0},m_{1},\cdots$
such that the sensitivity of $\left|G\left(e^{\imath\omega}\right)\right|$
with respect to each $m_{i}$ is very small in the pass-band. If $\left|G\left(e^{\imath\omega}\right)\right|\leq1$
for all $\omega$ regardless of the values of the multipliers (so
long as they are within a certain range) then the implementation is
called \emph{structurally bounded} or \emph{structurally passive}
and $G\left(z\right)$ is called \emph{bounded real}. If $\left|G\left(e^{\imath\omega}\right)\right|=1$
for certain frequencies $\omega_{k}$ in the passband, then at those
frequencies, when an $m_{i}$ is perturbed the value of 
$\left| G \left(e^{\imath\omega}\right)\right|$
can only decrease. In other words the first-order sensitivity is zero at 
$\omega_{k}$
\begin{equation*}
\frac{\partial \left|G\left(e^{\imath\omega_{k}}\right)\right|}{\partial m_{i}} 
\Bigg|_{m_{i}=m_{i_{0}}} = 0 \quad \forall i, \, \forall k
\end{equation*}
Now consider a stable all-pass function, $A_{1}\left(z\right)$
\begin{align*}
A_{1}\left(z\right) &=  
\frac{a_{m}+a_{m-1}z^{-1}+\cdots+z^{-m}}{1+a_{1}z^{-1}+\cdots+a_{m}z^{-m}}\\
\left|A_{1}\left(e^{\imath\omega}\right)\right| &= 1
\end{align*}
where $a_{k}$ are real. A number of well-known structures exist for
which the mirror images of the denominator and numerator coefficients
are preserved in spite of multiplier quantisation. Such implementations
are called \emph{structurally lossless}. 

Now consider a parallel connection of two stable all-pass filters
$A_{1}\left(z\right)$ and $A_{2}\left(z\right)$ with
\begin{align*}
A_{2}\left(z\right) &=
\frac{b_{n}+b_{n-1}z^{-1}+\cdots+z^{-n}}{1+b_{1}z^{-1}+\cdots+b_{n}z^{-n}}
\end{align*}
and
\begin{align*}
G\left(z\right) &=
\frac{1}{2}\left[A_{1}\left(z\right)+A_{2}\left(z\right)\right]
\end{align*}
Since $A_{1}\left(z\right)$ and $A_{2}\left(z\right)$ are all-pass functions:
\begin{align*}
A_{1}\left(z\right) 
&= z^{-n_{1}}\frac{\hat{D_{1}}\left(z\right)}{D_{1}\left(z\right)}\\
A_{2}\left(z\right) 
&=  z^{-n_{2}}\frac{\hat{D_{2}}\left(z\right)}{D_{2}\left(z\right)}
\end{align*}
where $n_{1}$ and $n_{2}$ are non-negative, $\hat{D_{1}}\left(z\right)$
denotes the mirror image of $D_{1}\left(z\right)$ and
\begin{align*}
G\left(z\right) 
&= \frac{1}{2} \left[\frac{z^{-n_{1}}D_{2}\left(z\right)\hat{D_{1}}\left(z\right)+z^{-n_{2}}D_{1}\left(z\right)\hat{D_{2}}\left(z\right)}{D_{1}\left(z\right)D_{2}\left(z\right)}\right]
\end{align*}
If $A_{1}\left(z\right)$ and $A_{2}\left(z\right)$ are minimal and
if $D_{1}\left(z\right)$ and $D_{2}\left(z\right)$ have no common
factors then there is no pole-zero cancellation and $G\left(z\right)$
has order $N=n+m$.

On the unit circle
\begin{align*}
G\left(e^{\imath\omega}\right) &=  \frac{1}{2}\left[e^{\imath\theta_{1}\left(\omega\right)}+e^{\imath\theta_{2}\left(\omega\right)}\right]
\end{align*}
where $\theta_{1}\left(\omega\right)$ and $\theta_{2}\left(\omega\right)$
are real-valued functions of $\omega$. Thus,
\begin{align*}
\left|G\left(e^{\imath\omega}\right)\right| 
&= \frac{1}{2}\left|1+e^{\imath\left[\theta_{2}\left(\omega\right)-\theta_{1}\left(\omega\right)\right]}\right|
\end{align*}
and if $A_{1}\left(z\right) \ne A_{2}\left(z\right)$ then $G\left(z\right)$ 
cannot be all-pass. Also, if $A_{1}\left(z\right)$ and $A_{2}\left(z\right)$ are
implemented so that they remain all-pass in spite of parameter quantisation,
then $\left|G\left(e^{\imath\omega}\right)\right| \le 1$ for all $\omega$. 
Accordingly, the structural lossless-ness of $A_{1}\left(z\right)$ and 
$A_{2}\left(z\right)$ induces structural bounded-ness in $G\left(z\right)$.

\subsection{Filter realisation as the sum of all-pass functions}
Consider a typical $N$-th order bounded real transfer function
$G\left(z\right)=P\left(z\right)/D\left(z\right)$ where $P\left(z\right)$ is
symmetric, i.e.: $p_{k}=p_{N-k}$. Now consider another transfer function
$H\left(z\right)$ where 
\begin{align*}
H\left(z\right) &=  \frac{Q\left(z\right)}{D\left(z\right)}\\
 &=  \frac{q_{0}+q_{1}z^{-1}+\cdots+q_{N}z^{-N}}{1+d_{1}z+\cdots+d_{N}z^{-N}}
\end{align*}
and $H\left(z\right)$ is complementary to $G\left(z\right)$
\begin{align*}
\left|H\left(e^{\imath\omega}\right)\right|^{2} 
&=  1-\left|G\left(e^{\imath\omega}\right)\right|^{2}
\end{align*}
In terms of the $z$-variable
\begin{align*}
\tilde{P}\left(z\right)P\left(z\right)+\tilde{Q}\left(z\right)Q\left(z\right) 
&=  \tilde{D}\left(z\right)D\left(z\right)
\end{align*}
where $\tilde{P}\left(z\right)=P\left(z^{-1}\right)$ etc.

Computation of the spectral factor $Q\left(z\right)$ is simplified
by the anti-symmetric nature of its coefficients. 
\begin{align*}
Q^{2}\left(z\right) &= 
P^{2}\left(z\right)-z^{-N}D\left(z^{-1}\right)D\left(z\right)
\end{align*}
$D\left(z\right)$ and $P\left(z\right)$ are known so the right hand
side can be written
\begin{align*}
R\left(z\right) &= \sum_{n=0}^{2N}r_{n}z^{-n}
\end{align*}
Then the coefficients of $Q\left(z\right)$ are related to $r_{n}$ by
\begin{align*}
r_{n} &= \sum_{k=0}^{n}q_{k}q_{n-k}
\end{align*}
and the $q_{k}$ can be computed recursively
\begin{align*}
q_{0} &= \sqrt{r_{0}}\\
q_{1} &= \frac{r_{1}}{2q_{0}}\\
q_{n} &= \frac{r_{n}-\sum_{k=1}^{n-1}q_{k}q_{n-k}}{2q_{0}}\,,\quad2\leq n\leq N
\end{align*}

The specral factor, $Q\left(z\right)$ is calculated by Octave function
\emph{spectralfactor}.

Assume $G\left(z\right)$ is such that $Q\left(z\right)$ is anti-symmetric
i.e.: $q_{i}=-q_{N-i}$. So
\begin{align*}
\tilde{P}\left(z\right) & \triangleq P\left(z^{-1}\right) = z^{N}P\left(z\right)\\
\tilde{Q}\left(z\right) & \triangleq Q\left(z^{-1}\right) = -z^{N}Q\left(z\right)
\end{align*}
and
\begin{align*}
\left[P\left(z\right)+Q\left(z\right)\right]\left[P\left(z\right)-Q\left(z\right)\right] &=  z^{-N}D\left(z\right)D\left(z^{-1}\right)\\
\left[P\left(z\right)+Q\left(z\right)\right]\left[P\left(z^{-1}\right)+Q\left(z^{-1}\right)\right] &=  D\left(z\right)D\left(z^{-1}\right)
\end{align*}
Moreover
\begin{align*}
P\left(z^{-1}\right)+Q\left(z^{-1}\right) &=  z^{N}\left[P\left(z\right)-Q\left(z\right)\right]
\end{align*}

Hence the zeros of $P\left(z\right)+Q\left(z\right)$ are the reciprocals
of the zeros of $P\left(z\right)-Q\left(z\right)$. Since $G\left(z\right)$
is stable, none of its poles are on the unit circle and
\[
P\left(z\right)+Q\left(z\right)\neq0,\quad\left|z\right|=1
\]
Let $z_{1},z_{2},\ldots,z_{r}$ be the zeros of $P\left(z\right)+Q\left(z\right)$
inside the unit circle and let $z_{r+1},z_{r+2},\ldots,z_{N}$ be
those outside. Then
\begin{align*}
D\left(z\right) &=  \prod_{k=1}^{r}\left(1-z^{-1}z_{k}\right)\prod_{k=r+1}^{N}\left(1-z^{-1}z_{k}^{-1}\right)
\end{align*}
and
\begin{align*}
\left[P\left(z\right)+Q\left(z\right)\right]\left[P\left(z\right)-Q\left(z\right)\right]=
\left[\prod_{k=1}^{r}\left(1-z^{-1}z_{k}\right)\prod_{k=r+1}^{N}\left(1-z^{-1}z_{k}^{-1}\right)\right]\left[\prod_{k=1}^{r}\left(z^{-1}-z_{k}\right)\prod_{k=r+1}^{N}\left(z^{-1}-z_{k}^{-1}\right)\right]
\end{align*}
From which
\begin{align*}
P\left(z\right)+Q\left(z\right) &= \alpha\left[\prod_{k=1}^{r}\left(1-z^{-1}z_{k}\right)\prod_{k=r+1}^{N}\left(z^{-1}-z_{k}^{-1}\right)\right]\\
P\left(z\right)-Q\left(z\right) &= \frac{1}{\alpha}\left[\prod_{k=1}^{r}\left(z^{-1}-z_{k}\right)\prod_{k=r+1}^{N}\left(1-z^{-1}z_{k}^{-1}\right)\right]
\end{align*}
where $\alpha$ is a real constant. This leads to the equations
\begin{align*}
G\left(z\right)+H\left(z\right) &= \frac{P\left(z\right)+Q\left(z\right)}{D\left(z\right)}=\alpha\prod_{k=r+1}^{N}\left(\frac{z^{-1}-z_{k}^{-1}}{1-z^{-1}z_{k}^{-1}}\right)\\
G\left(z\right)-H\left(z\right) &= \frac{P\left(z\right)-Q\left(z\right)}{D\left(z\right)}=\frac{1}{\alpha}\prod_{k=1}^{r}\left(\frac{z^{-1}-z_{k}}{1-z^{-1}z_{k}}\right)
\end{align*}
Thus
\begin{align*}
G\left(z\right)+H\left(z\right) &= \alpha A_{1}\left(z\right)\\
G\left(z\right)-H\left(z\right) &= \frac{1}{\alpha}A_{2}\left(z\right)
\end{align*}
where $A_{1}\left(z\right)$ and $A_{2}\left(z\right)$ are stable
all-pass functions of order $N-r$ and $r$ respectively
\begin{align*}
A_{1}\left(z\right) &= \prod_{k=r+1}^{N}\left(\frac{z^{-1}-z_{k}^{-1}}{1-z^{-1}z_{k}^{-1}}\right)\\
A_{2}\left(z\right) &= \prod_{k=1}^{r}\left(\frac{z^{-1}-z_{k}}{1-z^{-1}z_{k}}\right)
\end{align*}
The complementarity condition requires $\alpha^{2}=1$ so, finally
\begin{align*}
G\left(z\right) &= \frac{1}{2}\left[A_{1}\left(z\right)+A_{2}\left(z\right)\right]\\
H\left(z\right) &= \frac{1}{2}\left[A_{1}\left(z\right)-A_{2}\left(z\right)\right]
\end{align*}
and $G\left(z\right)$ is implemented as the parallel combination
of two all-pass functions.

This low-sensitivity realisation is summarised in
Algorithm~\ref{alg:Filter-realisation-sum-of-all-pass-functions}. 
\begin{algorithm}[htbp]
Let $G\left(z\right)=P\left(z\right)/D\left(z\right)$ be a bounded
real function of order $N$ and let $P\left(z\right)$ be symmetric
i.e.: $p_{i}=p_{N-i}$. 

In addition, let $G\left(z\right)$ be such
that an anti-symmetric polynomial $Q\left(z\right)$ (i.e.: $q_{i}=-q_{N-i}$)
exists such that 
\begin{align*}
\tilde{P}\left(z\right)P\left(z\right)+\tilde{Q}\left(z\right)Q\left(z\right) 
&= \tilde{D}\left(z\right)D\left(z\right)
\end{align*}

$G\left(z\right)$ can be implemented as the combination of two
stable all-pass functions $A_{1}\left(z\right)$ and $A_{2}\left(z\right)$
\begin{align*}
G\left(z\right) &= \frac{1}{2}\left[A_{1}\left(z\right)+A_{2}\left(z\right)\right]\\
H\left(z\right) &= \frac{1}{2}\left[A_{1}\left(z\right)-A_{2}\left(z\right)\right]
\end{align*}

Furthermore, $H\left(z\right)$ is also bounded real and is doubly
complementary to $G\left(z\right)$.
\caption{Filter realisation as the sum of all-pass functions.}
\label{alg:Filter-realisation-sum-of-all-pass-functions}
\end{algorithm}

The classical Butterworth, Chebyshev and Cauer low-pass digital filters
of odd order satisfy the following conditions and can be implemented
as the combination of two stable all-pass functions 
\begin{enumerate}
\item N is odd
\item $\left.\frac{\partial^{k}\left|G\left(e^{\imath\omega}\right)\right|}
                       {\partial\omega^{k}} \right|_{\omega=0}=0$
for $k=1,2,\cdots,n_{0}$ where $n_{0}$ is some odd integer \\
(In other words, $\left|G\left(e^{\imath\omega}\right)\right|$ has odd-order
tangency at zero frequency).
\item $\left|G\left(1\right)\right|=1$
\item There are $\left(N-n_{0}\right)/2$ frequencies in the range $0<\omega<\pi$
where $\left|G\left(e^{\imath\omega}\right)\right|=1$
\end{enumerate}
Other filter pass-bands are obtained by frequency transformation.

The Octave script \emph{vaidyanathan\_allpass\_example\_test.m} implements the
example transfer function shown in~\cite[Section
V]{VaidyanathanMitraNuevo_LowSensitivityIIRDigitalFilters}.

\subsection{A note on the numerical calculation of the spectral factor}
The Octave implementation of the calculation of the spectral factor is in the
Octave function file \emph{spectralfactor.m}. 
The file \emph{spectralfactor.cc} shows a C++ version of 
\emph{spectralfactor} using the \emph{MPFR} abitrary precision floating
point library~\cite{Fousse_MPFR,GNU_GMP,Fousse:2007:MMB:1236463.1236468}. The
mantissa precision is set to $256$ bits.
The Octave script \emph{spectralfactor\_test.m}
 illustrates calculation of the spectral
factor for a $13$th order elliptic filter with cut-off frequency $0.05f_{S}$, 
pass-band ripple $0.0005$dB and stop-band ripple $40$dB using 
\emph{spectralfactor.oct}. Figures~\ref{fig:spectralfactor-test-ellip13-0-05}
and~\ref{fig:spectralfactor-test-ellip13-0-05-detail} show the transfer
functions of the elliptic filter, the spectral factor complementary filter
and the summed transfer function. The summed response ripple is satisfactory for
order $13$ but fails catastrophically for order $15$. I suspect that this is
due to roundoff error in the original calculation of the elliptic filter
coefficients that is visible in the transition band detailed view. The
prototype elliptic filter response appears to be not structurally bounded.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{spectralfactor_test_ellip13_0_05}}
\caption{13th order elliptic filter, complementary filter and summed transfer
  functions.}
\label{fig:spectralfactor-test-ellip13-0-05}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{spectralfactor_test_ellip13_0_05_detail}}
\caption{13th order elliptic filter, complementary filter and summed transfer
  functions transition band detail.}
\label{fig:spectralfactor-test-ellip13-0-05-detail}
\end{figure}

\subsection{Examples of parallel all-pass filter synthesis}
\subsubsection{3rd order Butterworth low-pass filter}
The Octave script \emph{butt3NSPA\_test.m}
shows synthesis as a parallel combination of two all-pass filters
of the 3rd order Butterworth filter used in the example of Part I.
Annotated results of the script follow.

The numerator and denominator polynomials, $N\left(z\right)$ and
$D\left(z\right)$ are:
\begin{small}
\begin{verbatim}
n =  0.0028982  0.0086946  0.0086946  0.0028982
d =  1.00000   -2.37409    1.92936   -0.53208
\end{verbatim}
\end{small}
The spectral factor $Q\left(z\right)$ is:
\begin{small}
\begin{verbatim}
q =  0.72944 -2.18832  2.18832 -0.72944
\end{verbatim}
\end{small}
The sum $N\left(z\right)+Q\left(z\right)$ has roots:
\begin{small}
\begin{verbatim}
z =  1.12486 + 0.31652i  
     1.12486 - 0.31652i  
     0.72654 + 0.00000i
\end{verbatim}
\end{small}
The polynomials for the all-pass components are:
\begin{small}
\begin{verbatim}
A1 =  0.73234  -1.64755   1.00000
A2 = -0.72654   1.00000
\end{verbatim}
\end{small}
After quantising to three 10-bit signed-digits the coefficients for the 
normalised-scaled lattice implementation are:
\begin{small}
\begin{verbatim}
A1s10f = [     -488,      376 ]/512;
A1s11f = [      158,      352 ]/512;
A1s20f = [     -488,      376 ]/512;
A1s00f = [      158,      352 ]/512;
A1s02f = [      488,     -376 ]/512;
A1s22f = [      158,      352 ]/512;
\end{verbatim}
\end{small}
and
\begin{small}
\begin{verbatim}
A2s10f = [     -368 ]/512;
A2s11f = [      352 ]/512;
A2s20f = [     -368 ]/512;
A2s00f = [      352 ]/512;
A2s02f = [      368 ]/512;
A2s22f = [      352 ]/512;
\end{verbatim}
\end{small}
The noise gains of each part with three signed-digit coefficients are:
\begin{small}
\begin{verbatim}
A1ngapABCDf =  3.1899
A2ngapABCDf =  0.95500
\end{verbatim}
\end{small}
The estimated and measured round-off noise variances at the combined all-pass
output are:
\begin{small}
\begin{verbatim}
est_varA1yapd =  0.3492
varA1yapd =  0.3451
est_varA2yapd =  0.1629
varA2yapd =  0.1632
est_varyapd =  0.2530
varyapd =  0.2597
\end{verbatim}
\end{small}
The standard deviations of the internal state delay storage elements are:
\begin{small}
\begin{verbatim}
A1stdxf =  133.51   130.68
A2stdxf =  128.10
\end{verbatim}
\end{small}
The amplitude response found from the cross-correlation of the input
and output is shown in
Figure~\ref{fig:Butt3NSPA_combined_allpass_output_response}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{butt3NSPA_test_combined_allpass_output_response}}
\caption{Simulated amplitude response of the 3rd order Butterworth filter 
  synthesised as the parallel combination of two all-pass filters
  implemented as normalised-scaled lattices with 10-bit 3-signed-digit
  coefficients.}
\label{fig:Butt3NSPA_combined_allpass_output_response}
\end{figure}
\subsubsection{6th order Butterworth band-pass}
The Octave script \emph{butt6NSPABP\_test.m} shows synthesis of a 6th order
band-pass Butterworth filter as a parallel combination of two all-pass filters. 
Annotated results of the script follow.

The prototype filter has cutoff frequency:
\begin{small}
\begin{verbatim}
fc = 0.25000
\end{verbatim}
\end{small}
The numerator and denominator polynomials, $N\left(z\right)$ and
$D\left(z\right)$ are:
\begin{small}
\begin{verbatim}
n = 0.16667     0.50000     0.50000     0.16667
d = 1.0000e+00 -3.0531e-16  3.3333e-01 -1.8504e-17
\end{verbatim}
\end{small}
The spectral factor $Q\left(z\right)$ is:
\begin{small}
\begin{verbatim}
q = 0.16667 -0.50000  0.50000 -0.16667
\end{verbatim}
\end{small}
The sum $N\left(z\right)+Q\left(z\right)$ has roots
\begin{small}
\begin{verbatim}
z = 0.00000 + 1.73205i    
    0.00000 - 1.73205i    
    0.00000 + 0.00000i
\end{verbatim}
\end{small}
The polynomials for the all-pass components of the prototype filter
are:
\begin{small}
\begin{verbatim}
Aap1 =  3.3333e-01   0.0000e+00   1.0000e+00
Aap2 =  0.0000e-00   1.0000e+00
\end{verbatim}
\end{small}
The frequency transformation polynomial for a band-pass filter with
band edges $0.2f_{S}$ and $0.25f_{S}$ is
\begin{small}
\begin{verbatim}
p = 1.00000  -0.27346   0.72654
\end{verbatim}
\end{small}
The all-pass polynomials of the parallel components of the band-pass
filter are
\begin{small}
\begin{verbatim}
A1BP = 1.0000e+00 -6.7309e-01  2.3655e+00 -7.8886e-01 1.3655e+00
\end{verbatim}
\end{small}
and
\begin{small}
\begin{verbatim}
A2BP = 1.0000e+00 -3.7638e-01  1.3764e+00
\end{verbatim}
\end{small}
After truncating to 10-bit 3-signed-digits the coefficients for the 
normalised-scaled lattice implementation are:
\begin{small}
\begin{verbatim}
A1s10f = [      -84,      488,      -76,      376 ]/512;
A1s11f = [      505,      158,      506,      352 ]/512;
A1s20f = [      -84,      488,      -76,      376 ]/512;
A1s00f = [      505,      158,      506,      352 ]/512;
A1s02f = [       84,     -488,       76,     -376 ]/512;
A1s22f = [      505,      158,      506,      352 ]/512; 
\end{verbatim}
\end{small}
and
\begin{small}
\begin{verbatim}
A2s10f = [      -81,      368 ]/512;
A2s11f = [      506,      352 ]/512;
A2s20f = [      -81,      368 ]/512;
A2s00f = [      506,      352 ]/512;
A2s02f = [       81,     -368 ]/512;
A2s22f = [      506,      352 ]/512;
\end{verbatim}
\end{small}
The noise gains of each part are:
\begin{small}
\begin{verbatim}
A1ngapABCDf =  7.5062e+00
A2ngapABCDf =  2.8995e+00
\end{verbatim}
\end{small}
The estimated and measured round-off noise variances at the combined all-pass 
output are:
\begin{small}
\begin{verbatim}
est_varA1yapd =  7.088e-01
varA1yapd =  6.891e-01
est_varA2yapd =  3.250e-01
varA2yapd =  3.305e-01
est_varyapd =  3.835e-01
varyapd =  3.889e-01
\end{verbatim}
\end{small}
The standard deviations of the internal state delay storage elements are:
\begin{small}
\begin{verbatim}
A1stdxf =  128.73  128.70  129.30  129.40
A2stdxf =  126.75  126.58
\end{verbatim}
\end{small}
The amplitude response found from the cross-correlation of the input
and output is shown in 
Figure~\ref{fig:Butt6NSPABP_combined_allpass_output_response}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{butt6NSPABP_test_combined_allpass_output_response}}
\caption{Simulated amplitude response of the 6th order Butterworth
  band-pass filter synthesised as the parallel combination of two all-pass
  filters implemented as normalised-scaled lattices with 10-bit 3-signed-digit
  coefficients.}
\label{fig:Butt6NSPABP_combined_allpass_output_response}
\end{figure}
\clearpage
\subsubsection{20th order elliptic multi-band-pass}
The Octave script \emph{ellip20OneMPAMB\_test.m} shows synthesis of a 20th order
multi-band-pass elliptic filter as the difference of two parallel all-pass
filters. Annotated results of the script follow.

The prototype filter is a $5$-th elliptic low-pass filter with cutoff frequency
$f_{c}=0.25$, pass-band ripple $0.5$dB and stop-band attenuation $40$dB.

The low-pass to multi-band-pass transformation defines the two pass-bands
$0.05$ to $0.125$ and $0.175$ to $0.225$:
\begin{small}
\verbatiminput{ellip20OneMPAMB_test_phi_coef.m}
\end{small}

The multi-band-pass numerator and denominator polynomials are:
\begin{small}
\verbatiminput{ellip20OneMPAMB_test_B_coef.m}
\verbatiminput{ellip20OneMPAMB_test_A_coef.m}
\end{small}

The numerator polynomial is ``sanitised'' so that all zeros lie on the
$z$-plane unit circle.

The multi-band-pass polynomials have even order. They are converted to odd order
by adding a zero and a pole at $z=1$. The resulting spectral factor is, after
removing the zero at $z=1$:
\begin{small}
\verbatiminput{ellip20OneMPAMB_test_Qp_coef.m}
\end{small}

The sum $B\left(z\right)+Qp\left(z\right)$ has roots
\begin{small}
\begin{verbatim}
Z =
   0.25704 + 1.05045i
   0.25704 - 1.05045i
   0.78300 + 0.71880i
   0.78300 - 0.71880i
   0.98935 + 0.36462i
   0.98935 - 0.36462i
   0.45133 + 0.91101i
   0.45133 - 0.91101i
   0.45317 + 0.88790i
   0.45317 - 0.88790i
   0.94176 + 0.30369i
   0.94176 - 0.30369i
   0.69726 + 0.70078i
   0.69726 - 0.70078i
   0.14957 + 0.96734i
   0.14957 - 0.96734i
   0.37041 + 0.86443i
   0.37041 - 0.86443i
   0.75232 + 0.44289i
   0.75232 - 0.44289i
\end{verbatim}
\end{small}

The numerator polynomials for the all-pass components of the multi-band-pass
filter are:
\begin{small}
\verbatiminput{ellip20OneMPAMB_test_A1_coef.m}
\verbatiminput{ellip20OneMPAMB_test_A2_coef.m}
\end{small}

The 8-bit 4-signed-digit coefficients of the two one-multiplier lattice
implementations are:
\begin{small}
\verbatiminput{ellip20OneMPAMB_test_k1sd_coef.m}
\verbatiminput{ellip20OneMPAMB_test_epsilon1_coef.m}
\end{small}
and
\begin{small}
\verbatiminput{ellip20OneMPAMB_test_k2sd_coef.m}
\verbatiminput{ellip20OneMPAMB_test_epsilon2_coef.m}
\end{small}

The noise gains of each all-pass filter with signed-digit coefficients are
(with exact state scaling):
\begin{small}
\begin{verbatim}
A1ng =  15.000
A2ng =  23.0000
\end{verbatim}
\end{small}

The estimated and simulated round-off noise variances at the combined all-pass 
output are (again with exact state scaling):
\begin{small}
\begin{verbatim}
est_varysd =  0.9583
varyapsd =  0.9602
\end{verbatim}
\end{small}

Figure~\ref{fig:ellip20OneMPAMB-test-response} shows the response with
floating-point and signed-digit coefficients and the simulated amplitude
response, found from the cross-correlation of the input and output, with
signed-digit coefficients.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{ellip20OneMPAMB_test_response}}
\caption{Simulated amplitude response of the 20th order elliptic
  multi-band-pass filter synthesised as the parallel combination of two all-pass
  filters implemented as one-multiplier lattices with 8-bit 4-signed-digit
  coefficients.}
\label{fig:ellip20OneMPAMB-test-response}
\end{figure}
\clearpage
\section{\label{app:DesignEllipticIIRReducedNumberMultipliers}Design of Elliptic IIR filters with a reduced number of multipliers}
\emph{Lutovac} and \emph{Mili\'{c}}~\cite{Milic_MultiplierlessEllipticIIR,
  Lutovac_EllipticIIRReducedNumberShiftAdd} describe the design of minimum
  Q-factor elliptic filters having a reduced number of multipliers. These
filters are based on the continuous time minimal-Q elliptic filter design of
\emph{Rabrenovi\'{c}} and \emph{Lutovac}~\cite{Rabrenovic_EllipticMinimalQ,
Rabrenovic_AttenuationCauerFiltersWithoutEllipticFunctions}. The minimal-Q
factor elliptic filters have reduced component sensitivity at the expense of
increased filter order or reduced selectivity. 

\subsection{Elliptic filter design with the \emph{Landen transformation}}
In this section I follow the tutorial paper by \emph{Orchard} and
\emph{Willson}~\cite{OrchardWillson_EllipticFunctionsFilterDesign}. Elliptic
filters are an application of the \emph{Jacobian elliptic functions} 
and \emph{elliptic integrals}
(reviewed in Appendix~\ref{app:Review-of-elliptic-integrals-and-functions}).
The original purpose of the elliptic functions
was to invert the integral that finds the arc length of an ellipse. For example,
the elliptic function $w=\jsn{}u$ is defined by the \emph{incomplete elliptic
integral}: 
\begin{align}
  \label{eqn:Elliptic-sn-integral}
u&=\int_{0}^{w}\frac{dt}{\sqrt{\left(1-t^{2}\right)\left(1-\kappa^{2}t^{2}\right)}}
\end{align}
For elliptic filter design, the \emph{modulus}, $\kappa$, is real and
$0\le{}k\le{}1$. The \emph{modular angle}, $\theta$, is defined by
$\kappa=\sin\theta$ and the \emph{complementary modulus} is
$\kappa^{\prime}=\cos\theta$. The elliptic functions are \emph{doubly-periodic}
functions on the complex plane with \emph{quarter-periods} $K$ and $K^{\prime}$,
where:
\begin{align*}
K&=\int_{0}^{1}\frac{dt}{\sqrt{\left(1-t^{2}\right)\left(1-\kappa^{2}t^{2}\right)}}
\end{align*}
and similarly for $K^{\prime}$. The elliptic functions are a generalisation of
the circular and hyperbolic trigonometric functions. For $\kappa=0$ and
$K=\frac{\pi}{2}$, Equation~\ref{eqn:Elliptic-sn-integral} is the $\arcsin$ 
function. For $\kappa=1$ and $K=\infty$, Equation~\ref{eqn:Elliptic-sn-integral}
is the $\arctanh$ function.

The magnitude-squared response of an $n$-th order continuous time elliptic
low-pass filter is:  
\begin{align*}
  \left|H\left(\omega\right)\right|^{2}
  &=\frac{1}{1+\epsilon^{2}R_{n}^{2}\left(\omega,\omega_{a}\right)}
\end{align*}
where $R_{n}\left(\omega,\omega_{a}\right)$ is an $n$-th order
elliptic rational function, $\epsilon$ is the pass-band ripple factor and
$\omega_{a}=\frac{1}{\kappa}$ is the stop-band edge frequency. Both $\omega_{a}$
and the frequency $\omega$ are normalised to $\omega_{p}$, the pass-band edge
frequency. In the pass-band $R_{n}$ varies between $0$ and $1$ so that in the
pass-band $\left|H\left(\omega\right)\right|^{2}$ varies between
$\frac{1}{1+\epsilon^{2}}$ and 1. In the stop-band
$\left|H\left(\omega\right)\right|^{2}$ varies between $0$ and 
$\frac{1}{1+\epsilon^{2}L_{n}^{2}}$ where
$L_{n}=R_{n}\left(\omega_{a}\right)$ is called the discrimination factor.

\emph{Orchard} and \emph{Willson} show how to
derive a continuous time elliptic filter with filter order $n$, pass-band ripple
$\alpha_{p}$ and stop-band ripple $\alpha_{a}$ from the s-plane poles and zeros
of an initial \emph{Chebyshev Type 1} filter. They comment that:
\begin{quotation}
  The fact that the degree $n$ must be an integer means that the smallest value
  of $n$ that meets the specification will normally provide some margin in
  performance that should be distributed amongst the quantities $\alpha_{p}$,
  $\alpha_{a}$ and $\kappa$. How best to do this requires some engineering judgement
  \ldots
\end{quotation}

The \emph{Landen transformation} relates the elliptic functions,
$\jns\left(uG,\gamma\right)$ and $\jns\left(uK,\kappa\right)$, for which the
quarter-periods have $\frac{2G^{\prime}}{G}=\frac{K^{\prime}}{K}$~\cite[Equation 8]
{OrchardWillson_EllipticFunctionsFilterDesign}:
\begin{align*}
  \jns\left(uG,\gamma\right)
  &=\frac{1}{1+\kappa}\left[\jns\left(uK,\kappa\right)+
                       \frac{\kappa}{\jns\left(uK,\kappa\right)}\right]
\end{align*}
\emph{Orchard} and \emph{Willson}~\cite[Section IV]
{OrchardWillson_EllipticFunctionsFilterDesign} derive a recurrence relation for
the modulus, $\kappa$, that appears in successive Landen transformations: 
\begin{align*}
  \kappa_{n+1}&=\left[\frac{\kappa_{n}}{1+\sqrt{1-\kappa_{n}^{2}}}\right]^{2}
\end{align*}
This sequence, $\kappa_{n}$, tends rapidly to zero and the value of the elliptic
function is considered to be equal to that of the the corresponding circular
function value. In this case, $\jns\left(z,\kappa\right)\rightarrow\cosec{}z$ as
$\kappa\rightarrow{}0$. The required elliptic function value at the original
modulus, $\kappa_{0}$, is found by reversing the recurrence:  
\begin{align*}
  \kappa_{n}&=\frac{2\sqrt{\kappa_{n+1}}}{1+\kappa_{n+1}}
\end{align*}
so that:
\begin{align*}
  \jns\left(aK_{n},\kappa_{n}\right)
  &=\frac{1}{1+\kappa_{n+1}}\left[\jns\left(aK_{n+1},\kappa_{n+1}\right)+
    \frac{\kappa_{n+1}}{\jns\left(aK_{n+1},\kappa_{n+1}\right)}\right]
\end{align*}

The normalized $n$-th order Chebyshev Type 1 filter with pass-band peak-to-peak
ripple $\alpha_{p}=10\log_{10}\left(1+\varepsilon^{2}\right)$~dB is defined by the
parametric equations for the squared-magnitude of the filter
attenuation\footnote{\emph{Orchard} prefers the convention that
  $A\left(s\right)$ represents the filter attenuation, i.e.:\ the ratio of
  \emph{input} to \emph{output}.}:
\begin{align*}
  A\left(s\right)A\left(-s\right) &= 1+\varepsilon^{2}\cos^{2}\frac{nu\pi}{2}\\
  \Omega&=\cos\frac{u\pi}{2}  
\end{align*}
\emph{Orchard} and \emph{Willson} generalise the Chebyshev filter by changing
the cosine function into the appropriate elliptic function equivalent. The
resulting parametric equations are:
\begin{align*}
  A\left(s\right)A\left(-s\right)
  &= 1+\varepsilon^{2}\jcd^{2}\left(nuG,\gamma\right)\\
  \Omega&=\jcd\left(uK,\kappa\right)\\
  \frac{nK^{\prime}}{K}&=\frac{G^{\prime}}{G}
\end{align*}
The stop-band loss is
$\alpha_{a}=10\log_{10}\left(1+\frac{\varepsilon^{2}}{\gamma^{2}}\right)$dB.
The following path in the complex $u$-plane maps the $u$ parameter from the
complex plane to the $\Omega$ frequency axis with the desired amplitude response:
\begin{itemize}
\item Pass band: $u=1$ to $u=0$ maps to $\Omega=0$ to $\Omega=1$,
  $\jcd\left(nuG,\gamma\right)$ varies between $1$ and $-1$
  \item Transition band: $u=0$ to $u=\imath\frac{K^{\prime}}{K}$ maps to
    $\Omega=1$ to $\Omega=\frac{1}{\kappa}$
  \item Stop band: $u=\imath\frac{K^{\prime}}{K}$ to
    $u=1+\imath\frac{K^{\prime}}{K}$ maps to
    $\Omega=\frac{1}{\kappa}$ to $\Omega=\infty$,
    $\jcd\left(nuG,\gamma\right)$ has minimums at $\frac{1}{\gamma}$ and
    maximums at $-\frac{1}{\gamma}$
\end{itemize}
The $\jcd$ elliptic function is used because it has a zero at the start of the
path, at $u=1$, and a pole at the end, at $u=1+\imath\frac{K^{\prime}}{K}$.

\emph{Orchard} and \emph{Willson} show a \emph{Matlab} file,
\emph{ellipap1.m}~\cite[Figure 7]
{OrchardWillson_EllipticFunctionsFilterDesign}, that, given the filter order and
pass-band and stop-band ripples, calculates the gain, poles and zeros of a
continuous time elliptic filter by the \emph{Landen transformation} of the poles
and zeros of a \emph{Type 1 Chebyshev} filter with the same pass-band and
stop-band attenuation specifications.

\subsection{Design of elliptic filters with minimal-Q}
\emph{Rabrenovi\'{c}} and \emph{Lutovac}~\cite{Rabrenovic_EllipticMinimalQ,
Rabrenovic_AttenuationCauerFiltersWithoutEllipticFunctions} derive the
properties of a continuous time elliptic filter with poles having minimal-Q.
The poles of the filter lie on a circle with radius $\sqrt{\omega_{a}}$ and
the ripples in the pass-band and stop-band squared-magnitude response are equal:
\begin{align*}
  1-\frac{1}{1+\epsilon_{minQ}^{2}}&=\frac{1}{1+\epsilon_{minQ}^{2}L_{n}^{2}}
\end{align*}
so that the for the minimal-Q elliptic filter:
\begin{align*}
  \epsilon_{minQ}&=\frac{1}{\sqrt{L_{n}}}
\end{align*}

\begin{comment}
  \footnote{\emph{Rabrenovi\'{c}} and
\emph{Lutovac}~\cite{Rabrenovic_AttenuationCauerFiltersWithoutEllipticFunctions}
prove the following relations for $R_{n}\left(\omega_{a}\right)$. In
general:
\begin{align*}
  R_{pq}\left(\omega_{a}\right)&=R_{p}\left(R_{q}\left(\omega_{a}\right)\right)
                               =R_{q}\left(R_{p}\left(\omega_{a}\right)\right)
\end{align*}
For $n=2$:
\begin{align*}
R_{2}\left(\omega_{a}\right)&=2\omega_{a}^{2}-1+2\omega_{a}\sqrt{\omega_{a}^{2}-1}
\end{align*}
For $n=3$:
\begin{align*}
  R_{3}\left(\omega_{a}\right)&=\omega_{a}^{3}\left(\frac{1-\omega_{3}^{2}}
                                {\omega_{a}^{2}-\omega_{3}^{2}}\right)^{2}
\end{align*}
where:
\begin{align*}
  \omega_{3}^{2}&=\frac{2\omega_{a}\sqrt{G}}
{\sqrt{8\omega_{a}^{2}\left(\omega_{a}^{2}+1\right)+12G\omega_{a}^{2}-G^{3}}
              -\sqrt{G^{3}}}
\end{align*}
and:
\begin{align*}
  G&=\sqrt{4\omega_{a}^{2}+
     \left(4\omega_{a}^{2}\left(\omega_{a}^{2}-1\right)\right)^{\frac{2}{3}}}
\end{align*}
These expressions allow calculation of the stop-band attenuation of elliptic
filters with order $n=2^{p}3^{q}$ where $p,q=0,1,2,\ldots$. An approximate
formula for the other filter orders is:
\begin{align*}
  R_{n}^{2}\left(\omega_{a}\right)
  &\approx R_{n+1}\left(\omega_{a}\right)R_{n-1}\left(\omega_{a}\right)
\end{align*}
or more generally:
\begin{align*}
  R_{n}^{r-p}\left(\omega_{a}\right)
  &\approx R_{r}^{n-p}\left(\omega_{a}\right)R_{p}^{r-n}\left(\omega_{a}\right)
\end{align*}
The error in the approximation increases with $\epsilon$. The approximation
error for order $n$ can be reduced by:
\begin{align*}
  R_{n}\left(\omega_{a}\right)
&=\frac{R_{2n}\left(\omega_{a}\right)+1}{2\sqrt{R_{2n}\left(\omega_{a}\right)}}
\end{align*}
For example, $R_{10}^{3}\left(\omega_{a}\right) \approx R_{12}\left(\omega_{a}\right)R_{9}^{2}\left(\omega_{a}\right)$ and
$R_{5}\left(\omega_{a}\right)=\frac{R_{10}\left(\omega_{a}\right)+1}{2\sqrt{R_{10}\left(\omega_{a}\right)}}$.}
\end{comment}

\emph{Lutovac} and
\emph{Mili\'{c}}~\cite{Lutovac_EllipticIIRReducedNumberShiftAdd} describe the
design of an odd order, $n$, discrete-time elliptic filter implemented as the sum
of an odd and an even order all-pass filter in which the all-pass filter
components are expressed as products of second-order all-pass lattice sections:
\begin{align*}
\frac{b_{m}+a_{m}\left(1+b_{m}\right)z^{-1}+z^{-2}}
  {1+a_{m}\left(1+b_{m}\right)z^{-1}+b_{m}z^{-2}}
\end{align*}
with $m>1$, and, for the odd-order filter, a first-order section:
\begin{align*}
\frac{a_{1}+z^{-1}}{1+a_{1}z^{-1}}
\end{align*}

For the second-order sections, with the poles at
$z_{m}=r_{m}e^{\pm\imath\theta_{m}}$: 
\begin{align*}
  a_{m}&=-2\frac{r_{m}\cos\theta_{m}}{1+r_{m}^{2}}\\
  b_{m}&=r_{m}^{2}
\end{align*}
where $m=2,\ldots,\frac{n+1}{2}$. For the first-order section: 
\begin{align*}
  a_{1}&=-r_{1}
\end{align*}

Following the notation of \emph{Lutovac} and
\emph{Mili\'{c}}~\cite{Lutovac_EllipticIIRReducedNumberShiftAdd}, suppose that
the digital filter specification has pass-band and stop-band frequencies $F_{p}$
and $F_{a}$ and corresponding pass-band ripple, $A_{p}$, and stop-band
attenuation, $A_{a}$, given in $dB$. Assume that the digital filter is found by
transformation of a prototype continuous time minimal-Q elliptic filter with
a normalised pass band edge frequency of $\omega=1$. 

The pass-band and stop-band attenuations of the filter are $\alpha_{p}\le A_{p}$
and $\alpha_{a}\ge A_{a}$ with:
\begin{align*}
  \alpha_{p}&=10\log_{10}\left(1+\frac{1}{L_{n}}\right)
\end{align*}
and:
\begin{align*}
  \alpha_{a}&=10\log_{10}\left(1+L_{n}\right)
\end{align*}
The $3$dB frequency is given by:
\begin{align*}
  \tan^{2}\pi{}f_{3dB}&=\tan\pi{}f_{p}\tan\pi{}f_{a}
\end{align*}

The $s$-plane poles of the continuous time prototype are distributed around the
circle $\left|s\right|=\sqrt{\omega_{a}}$. The bilinear transform
\begin{align*}
  s&=\frac{2}{T}\frac{z-1}{z+1}
\end{align*}
where
\begin{align*}
T&=2\frac{\sqrt{\omega_{a}}}{\tan\pi{}f_{3dB}}=2\tan\pi{}f_{p}
\end{align*}
maps that circle onto a circle in the $z$-plane orthogonal to the unit circle
and centred on the real axis of the $z$-plane at $z=x_{0}$ with the $s$-plane
point $\imath\sqrt{\omega_{a}}$ mapped to the $z$-plane point
$z_{3dB}=e^{\imath{}2\pi{}f_{3dB}}$ so that:
\begin{align*}
  x_{0}&=\frac{1}{\cos{}2\pi{}f_{3dB}}
         = \frac{1-\tan^{2}\pi{}f_{3dB}}{1+\tan^{2}\pi{}f_{3dB}}
\end{align*}

For $m=1$, the first order section has:
\begin{align*}
  a_{1}&=-x_{0}\left(1-\sqrt{1-\frac{1}{x_{0}^{2}}}\right)
\end{align*}
For $m>1$, the second-order all-pass filter sections have, as shown
in~\cite[Figure 4]{Lutovac_EllipticIIRReducedNumberShiftAdd}:
\begin{align*}
  r_{m}^{2}+x_{0}^{2}-2r_{m}x_{0}\cos\theta_{m}=x_{0}^2-1
\end{align*}
so that:
\begin{align*}
  2r_{m}\cos\theta_{m}=\frac{1+r_{m}^{2}}{x_{0}}
\end{align*}
and:
\begin{align*}
  a_{m}&=a=-\frac{1}{x_{0}}
\end{align*}
The range of permitted values of $a$ is:
\begin{align*}
 -\frac{1-\tan^{2}\pi{}F_{p}}{1+\tan^{2}\pi{}F_{p}} < a <
   -\frac{1-\tan^{2}\pi{}F_{a}}{1+\tan^{2}\pi{}F_{a}}
\end{align*}
The minimal-Q elliptic filter is implemented with a reduced number of
multipliers by choosing $a$ to be a signed-digit number. \emph{Lutovac}
and \emph{Mili\'{c}}~\cite[Appendix A]{Lutovac_EllipticIIRReducedNumberShiftAdd}
show that the poles can be selected to alternate between the two all-pass
branches with increasing angle or radius. 

The Octave file \emph{ellipMinQ\_test.m} designs a discrete-time minimal-Q
elliptic filter implemented as the sum of parallel all-pass filters. The filter
order is $n=9$, pass-band edge is $F_{p}=0.1$, 
pass-band ripple specification is $0.1dB$, stop-band edge is $F_{a}=0.125$,
and the stop-band ripple specification is $40dB$. The second order lattice
constant, $a$, was set to $-\frac{3}{4}$ with corresponding $f_{3dB}=0.115027$.
Setting $f_{a}=Fa$ gives a corresponding $f_{p}=0.105715$. The continuous-time
$s$-plane stop-band edge angular frequency is $\omega_{a}=1.201010$ with elliptic
filter moduluses $\kappa=0.832632$ and $\gamma=3.1329e-05$. The calculation of
the continuous-time $s$-plane pole and zero locations follows \emph{Orchard} and
\emph{Willson}~\cite[Fig.6] {OrchardWillson_EllipticFunctionsFilterDesign}. The
resulting pass-band ripple is $\alpha_{p}=0.0001361 dB$ and the stop-band ripple
is $\alpha_{a}=45.04 dB$. Figure~\ref{fig:ellip-min-Q-cd} shows the values of
$\Omega$ and $\jcd^{2}\left(nuG,\gamma\right)$ plotted as the complex parameter
$u$ varies. Figure~\ref{fig:ellip-min-Q-s-resp} shows the amplitude response of
the continuous-time $s$-plane filter when calculated with the transfer function
derived from the $s$-plane gain, poles and zeros.
Figure~\ref{fig:ellip-min-Q-z-pz} shows the pole-zero plot of the corresponding
discrete-time $z$-plane filter. Figure~\ref{fig:ellip-min-Q-z-resp} shows the
amplitude response of the  discrete-time $z$-plane filter. The lattice
coefficients are: 
\begin{align*}
  \left\{a_{1},a,b_{2},b_{3},b_{4},b_{5}\right\}
  &=\left[-0.451416,-0.75,0.350740,0.619208,0.822345,0.949033\right]
\end{align*}
  The following $8$-bit, $3$-signed-digit lattice coefficients were found by
  brute-force search: $\left[-58,-96,46,79,104,121\right]$. The maximum stop-band
  response of the signed-digit coefficient filter is $-39.12 dB$ at $0.1304$.
Figure~\ref{fig:ellip-min-Q-z-resp-sd} shows the amplitude response of the
corresponding filter.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{ellipMinQ_test_cd}}
\caption{Values of $\Omega$ and $\jcd^{2}\left(nuG,\gamma\right)$ plotted as the
  complex parameter $u$ varies.} 
\label{fig:ellip-min-Q-cd}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{ellipMinQ_test_s_resp}}
\caption{Amplitude response of the continuous-time $s$-plane filter.}
\label{fig:ellip-min-Q-s-resp}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{ellipMinQ_test_z_pz}}
\caption{Pole-zero plot of the discrete-time $z$-plane filter.}
\label{fig:ellip-min-Q-z-pz}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{ellipMinQ_test_z_resp}}
\caption{Amplitude response of the discrete-time $z$-plane filter.}
\label{fig:ellip-min-Q-z-resp}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{ellipMinQ_test_z_resp_sd}}
\caption{Amplitude response of the discrete-time $z$-plane filter with $8$-bit,
$3$-signed-digit coefficients.}
\label{fig:ellip-min-Q-z-resp-sd}
\end{figure}
\clearpage
\section{\label{app:Saramaki-design-IIR-filters-zeros-unit-circle}\emph{Saram\"{a}ki}'s method for the design of IIR filters with zeros on the unit circle}
Firstly, define the transfer function of an IIR filter:
\begin{align*}
  H\left(z\right)&=Kz^{n-m}\frac{\prod^{m}_{k=1}\left(z-a_{k}\right)}
                   {\prod^{n}_{k=1}\left(z-b_{k}\right)}
\end{align*}
The zeros, $a_{k}$, and poles, $b_{k}$, are real or conjugate pairs. When
$n>m$ ($m>n$), $H\left(z\right)$ has $n-m$ zeros ($m-n$ poles) at the origin. A
stable filter has $\left|b_{k}\right|<1$.
\emph{Saram\"{a}ki}~\cite{Saramaki_OptimumRecursiveFilterZerosUnitCircle}
describes a procedure for designing an IIR filter with either equi-ripple
pass-band and stop-band amplitude response. The algorithm transforms the
frequency response so that the pass-band (stop-band) is equi-ripple and the
amplitude response in the stop-band (pass-band) is optimised. He claims that the
algorithm has improved numerical performance. Also, \emph{Saram\"{a}ki} finds
that for $n\ge{}m$, his procedure produces better narrow-band filters than the
corresponding elliptic filter. Conversely, when $n<m$, his algorithm produces
better wide-band filters. 

Write
\begin{align*}
  H\left(z\right)H\left(\frac{1}{z}\right)&=
E\frac{\prod^{m}_{k=1}\left(z+\frac{1}{z}\right)\left(a_{k}-\frac{1}{a_{k}}\right)}
{\prod^{n}_{k=1}\left(z+\frac{1}{z}\right)\left(b_{k}-\frac{1}{b_{k}}\right)}
\end{align*}

\emph{Saram\"{a}ki}'s procedure maps $z+\frac{1}{z}$ to $v+\frac{1}{v}$ so that
for $n\ge{}m$ ($n<m$) the pass-band (stop-band) on the unit circle in the
$z$-plane is mapped to the entire upper unit circle on the $v$-plane. An
equi-ripple pass-band (stop-band) response is obtained by construction. The
remaining problem is, for $n\ge{}m$ ($n<m$), to find adjustable zeros (poles)
so that the resulting $H\left(z\right)$ has $n-m$ zeros ($m-n$ poles) at the
origin and the squared-magnitude function is equiripple in the stop-band
(pass-band).

The all-pass function
\begin{align*}
F\left(v\right)&=\prod^{r}_{k=1}\left(\frac{1-v_{k}v}{v-v_{k}}\right)
\end{align*}
is, on the unit circle, $v=e^{\imath\Omega}$:
\begin{align*}
F\left(e^{\imath\Omega}\right)&=e^{\imath{}f\left(\Omega\right)}
\end{align*}
where:
\begin{align*}
  f\left(\Omega\right)&=\sum^{r}_{k=}\left\{\Omega-2\arctan\left[
                        \frac{\sin\Omega-\Im v_{k}}
                        {\cos\Omega-\Re v_{k}}\right]\right\}
\end{align*}
Now define:
\begin{align*}
  G\left(v+\frac{1}{v}\right)&=\frac{1}{2}\left[F\left(v\right)+
                               \frac{1}{F\left(v\right)}\right]
\end{align*}
so that, on the unit circle, $v=e^{\imath\Omega}$:
\begin{align*}
  G\left(v+\frac{1}{v}\right)&=\cos{} f\left(\Omega\right)
\end{align*}
This function has $r+1$ alternating extrema, $\pm{}1$, on $v=e^{\imath\Omega}$,
$0\le\Omega\le\pi$. Its value is $+1$ at $v=1$ and $\left(-1\right)^{r}$
at $v=-1$.

\emph{Saram\"{a}ki} now introduces a mapping from $z=e^{\imath\omega}$,
$\omega_{1}\le\omega\le\omega_{2}$, to $v=e^{\imath\Omega}$, $0\le\Omega\le\pi$:
\begin{align*}
  v+\frac{1}{v}&=C\left(z+\frac{1}{z}\right)+D
\end{align*}
where:                
\begin{align*}
  C&=\frac{2}{\cos\omega_{1}-\cos\omega_{2}}\\
  D&=-\frac{2\left(\cos\omega_{1}+\cos\omega_{2}\right)}
     {\cos\omega_{1}-\cos\omega_{2}}
\end{align*}

\subsection{\label{app:Saramaki-optimisation-denominator-order-higher}Optimisation of a low-pass filter with denominator order higher}
When $n\ge{}m$ set $\omega_{1}=0$ and $\omega_{2}=\omega_{p}$. The resulting
transformation maps the pass-band $z=e^{\imath\omega}$,
$0\le\omega\le\omega_{p}$, to the upper-unit circle $v=e^{\imath\Omega}$,
$0\le\Omega\le\pi$, and the stop-band,
$\omega_{s}\le\omega\le\pi$, to the negative real axis part
$\left[\zeta_{1},\zeta_{2}\right]$. Solving the resulting quadratic equations
for $\zeta_{1}$ and $\zeta_{2}$ gives:
\begin{align*}
  \zeta_{1}&=-\frac{1}{2}\left[-2C\cos\omega_{s}-D-
             \sqrt{\left(-2C\cos\omega_{s}-D\right)^{2}-4}\right] \\
  \zeta_{2}&=-\frac{1}{2}\left[2C-D-\sqrt{\left(2C-D\right)^{2}-4}\right]
\end{align*}

The transformed magnitude-squared function is constructed as\footnote{Here
  I follow \emph{Surma-aho} and \emph{Saram\"{a}ki}~\cite[Appendix]
  {SurmaahoSaramaki_ApproximatelyLinearPhaseRecursiveDigitalFilters}
  rather than \emph{Saram\"{a}ki}~\cite[Eqn.16]
  {Saramaki_OptimumRecursiveFilterZerosUnitCircle}}:
\begin{align*}
  \hat{H}\left(v\right)
  \hat{H}\left(\frac{1}{v}\right)
  &=\frac{1}{1+\frac{\Delta_{p}}{1-\Delta_{p}}\left[\frac{1}{2}+
    \left(-1\right)^{n}\frac{1}{4}
    \left[F\left(v\right)+\frac{1}{F\left(v\right)}\right]\right]}
\end{align*}
where
\begin{align*}
  F\left(v\right)&=\prod^{n}_{k=1}\left(\frac{1-\alpha_{k}v}{v-\alpha_{k}}\right)
\end{align*}
and $1-\Delta_{p}=\left(1-\delta_{p}\right)^{2}$,
$\delta_{p}=1-10^{\frac{-dBap}{20}}$. By design,
$\hat{H}\left(v\right)\hat{H}\left( \frac{1}{v}\right)$ has $n+1$ alternating
extrema $1$ and $1-\Delta_{p}$ in $v=e^{\imath\Omega}$, $0\le\Omega\le\pi$. We
want to find $\alpha_{k}$ such that, in the $z$-plane,
$H\left(z\right)H\left(\frac{1}{z}\right)$ has $m+1$ alternating extrema,
$\Delta_{s}$ and 0, on $z=e^{\imath\omega}$, $\omega_{s}\le\omega\le\pi$, and
$H\left(z\right)$ has $n-m$ zeros at the origin. The $z$-to-$v$-plane
transformation maps $z=0$ to $v=0$ so set $\alpha_{k}=0$ for
$k=m+1,\hdots,n$. In addition, since $H\left(z\right)H\left(\frac{1}{z}\right)$
has $\floor{\frac{m}{2}}$ minima, $0$, on $z=e^{\imath\omega}$,
$\omega_{s}<\omega<\pi$, $\hat{H}\left(v\right)\hat{H}\left(\frac{1}{v}\right)$
 has $\floor{\frac{m}{2}}$ double zeros in the transformed stop-band
$\left[\zeta_{1},\zeta_{2}\right]$. For $m$ odd, $H\left(z\right)$ has a zero at 
$z=-1$ which is transformed to $v=\zeta_{2}$. Thus, the $F\left(v\right)$ for
the optimal $H\left(z\right)H\left(\frac{1}{z}\right)$ is:  
\begin{align*}
  F\left(\boldsymbol{\alpha},v\right)&=v^{-\left(n-m\right)}
                     \left(\frac{1-\zeta_{2}v}{v-\zeta_{2}}\right)^{q}
                     \prod^{\floor{\frac{m}{2}}}_{k=1}
                     \left(\frac{1-\alpha_{k}v}{v-\alpha_{k}}\right)^{2}
\end{align*}
where $q=0$ for $m$ even and $q=1$ for $m$ odd, $\zeta_{1}<\alpha_{k}<\zeta_{2}$
and
$\boldsymbol{\alpha}=\left[\alpha_{1},\hdots,\alpha_{\floor{\frac{m}{2}}}\right]$.
The gradient of
$F\left(\boldsymbol{\alpha},v\right)$ with respect to $\alpha_{k}$ is:
\begin{align*}
  \frac{\partial{}F\left(\boldsymbol{\alpha},v\right)}{\partial\alpha_{k}}
  &=2\left[\frac{1-v^{2}}
    {\left(1-\alpha_{k}v\right)\left(v-\alpha_{k}\right)}\right]
    F\left(\boldsymbol{\alpha},v\right)
\end{align*}
By construction, $\left(-1\right)^{n}F\left(\boldsymbol{\alpha},v\right)>0$.
The optimisation problem is to find $\boldsymbol{\alpha}$ and the
scalar, $\Lambda$, such that at the $\floor{\frac{m}{2}}+1$ minima, $v_{l}$: 
\begin{align*}
  \log\left[\left(-1\right)^{n}F\left(\boldsymbol{\alpha},v_{l}\right)\right]
  &=\Lambda
\end{align*}
\emph{Saram\"{a}ki} suggests a Remez-exchange type procedure for solving these
non-linear equations. At each iteration, after linearising:
\begin{align*}
  \log\left[\left(-1\right)^{n}F\left(\boldsymbol{\alpha},v_{l}\right)\right]
  +\frac{\nabla_{\boldsymbol{\alpha}}F\left(\boldsymbol{\alpha},v_{l}\right)}
  {F\left(\boldsymbol{\alpha},v_{l}\right)}\Delta\boldsymbol{\alpha}
  &=\Lambda+\Delta\Lambda 
\end{align*}
The initial $\boldsymbol{\alpha}$ are evenly spaced in
$\left(\zeta_{1},\zeta_{2}\right)$ and $\Lambda=0$. The angles, $\omega_{k}$, of
the $\floor{\frac{m}{2}}$ complex conjugate zero pairs,
$z=e^{\pm\imath\omega_{k}}$, of $H\left(z\right)$ are found from 
\begin{align*}
  \alpha_{k}+\frac{1}{\alpha_{k}}&=2C\cos\omega_{k} + D
\end{align*}
The poles, $b_{k}$, of $H\left(z\right)$ are found by transforming the $n$ poles,
$\beta_{k}$, of $\hat{H}\left(v\right)\hat{H}\left(\frac{1}{v}\right)$ that are
the solutions of:
\begin{align*}
  1+\frac{\Delta_{p}}{1-\Delta_{p}}\left[\frac{1}{2}+
  \left(-1\right)^{n}\frac{1}{4}
  \left[F\left(\boldsymbol{\alpha},v\right)+
  \frac{1}{F\left(\boldsymbol{\alpha},v\right)}\right]\right]&=0
\end{align*}
Re-arranging gives:
\begin{align*}
  F\left(\boldsymbol{\alpha},v\right)
  &=-\left(-1\right)^{n}\left[\frac{2-\Delta_{p}}{\Delta_{p}}
    +\sqrt{\left(\frac{2-\Delta_{p}}{\Delta_{p}}\right)^{2}-1}\right]
\end{align*}
If the stop-band ripple, $\Delta_{s}$, is specified instead of the pass-band
ripple, then the corresponding pass-band ripple, $\Delta_{p}$, is found from the
stop-band equi-ripple maximum, 
$\lambda=\left(-1\right)^{n}F\left(\boldsymbol{\alpha},v_{l}\right)$:
\begin{align*}
\Delta_{p}&=\frac{1}{1+\frac{\Delta_{s}}{1-\Delta_{s}}\left[\frac{1}{2}+
            \frac{1}{4}\left[\lambda+\frac{1}{\lambda}\right]\right]}
\end{align*}
The scaling constant, $K$, is found from the condition
$\left|H\left(e^{\imath\omega_{p}}\right)\right|^{2}=1-\Delta_{p}$. 

The Octave function \emph{saramakiFAvLogNewton} implements
\emph{Saram\"{a}ki}'s procedure for $n\ge{}m$.

The Octave script \emph{saramakiFAvLogNewton\_test.m} designs an IIR filter with
pass-band edge frequency, $fp=0.1$, stop-band edge frequency, $fs=0.125$,
stop-band ripple, $dBas=75$, denominator order, $n=11$, and numerator order,
$m=6$. The resulting pass-band peak-to-peak ripple is $0.001713dB$.
Figure~\ref{fig:saramaki-FAv-LogNewton-resp} shows the amplitude response of the
filter. Figure~\ref{fig:saramaki-FAv-LogNewton-pz} shows the pole-zero plot of
the filter. The numerator and denominator polynomials are, respectively:
\begin{small}
\verbatiminput{saramakiFAvLogNewton_test_n_coef.m}
\verbatiminput{saramakiFAvLogNewton_test_d_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{saramakiFAvLogNewton_test_resp}}
\caption{Amplitude response of an IIR filter with $n=11$ and $m=6$, designed
with the procedure of Saram\"{a}ki.}
\label{fig:saramaki-FAv-LogNewton-resp}
\end{figure}
\clearpage
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{saramakiFAvLogNewton_test_pz}}
\caption{Pole-zero plot of an IIR filter with $n=11$ and $m=6$, designed
with the procedure of Saram\"{a}ki.}
\label{fig:saramaki-FAv-LogNewton-pz}
\end{figure}

\subsection{Optimisation of a low-pass filter with denominator order lower}
When $n<m$ set $\omega_{1}=\omega_{s}$ and $\omega_{2}=\pi$. The resulting
transformation maps the stop-band $z=e^{\imath\omega}$,
$\omega_{s}\le\omega\le\pi$, to the upper-unit circle $v=e^{\imath\Omega}$,
$0\le\Omega\le\pi$, and the pass-band,
$0\le\omega\le\omega_{p}$, to the positive real axis part
$\left[\zeta_{1},\zeta_{2}\right]$. Solving the resulting quadratic equations
for $\zeta_{1}$ and $\zeta_{2}$ gives:
\begin{align*}
  \zeta_{1}&=\frac{1}{2}\left[2C+D-\sqrt{\left(2C+D\right)^{2}-4}\right]\\
  \zeta_{2}&=\frac{1}{2}\left[2C\cos\omega_{p}+D-
             \sqrt{\left(2C\cos\omega_{p}+D\right)^{2}-4}\right]
\end{align*}

The transformed magnitude-squared function,
$\hat{H}\left(v\right)\hat{H}\left(\frac{1}{v}\right)$, having $m+1$ alternating
extrema $\Delta_{s}$ and $0$ on $v=e^{\imath\Omega}$, $0\le\Omega\le\pi$ is
constructed as:
\begin{align*}
  \hat{H}\left(v\right)\hat{H}\left(\frac{1}{v}\right)
  &=\Delta_{s}\left[\frac{1}{2}+\frac{1}{4}
    \left(F\left(v\right)+\frac{1}{F\left(v\right)}\right)\right]
\end{align*}
where:
\begin{align*}
  F\left(v\right)
  &=\prod^{m}_{k=1}\frac{1-\beta_{k}v}{v-\beta_{k}}
\end{align*}
is an all-pass function with $\left|\beta_{k}\right|<1$ for $k=1,\hdots,m$, and
$\beta_{k}=0$ for $k=m+1,\hdots,n$. The poles of $F\left(v\right)$ are poles of
$\hat{H}\left(v\right)$ and the zeros of $F\left(v\right)+1$ are the zeros of
$\hat{H}\left(v\right)$.

Rewrite $F\left(v\right)$ as: 
\begin{align*}
  F\left(\boldsymbol{\beta},v\right)
  &=v^{-\left(m-n\right)}\left(\frac{1-Rv}{v-R}\right)^{q}
    \prod^{\floor{\frac{n}{2}}}_{k=1}\frac{1+s_{k}v+r_{k}v^{2}}{v^{2}+s_{k}v+r_{k}}
\end{align*}
where $q=0$ for $n$ even and $q=1$ for $n$ odd. For $n$ odd, the parameter
vector is 
$\boldsymbol{\beta}=\left[s_{1},r_{1},\hdots,s_{\floor{\frac{n}{2}}},r_{\floor{\frac{n}{2}}},R\right]$
where $R$ is a real pole lying on the real axis in
$\left[-1,\zeta_{1}\right]$. By construction,
$F\left(\boldsymbol{\beta},v\right)>{}0$ in the pass-band. 

The gradients of $F\left(\boldsymbol{\beta},v\right)$ with respect to the
coefficients, $\boldsymbol{\beta}$, are:  
\begin{comment}
The numerators of the gradients in rk and thetak were found with the following
maxima code:
  A(s,r):=1+(s*v)+(r*(v^2));
  B(s,r):=(v^2)+(s*v)+r;
  dds(s,r):=factor((diff(A(s,r),s)*B(s,r)) - (diff(B(s,r),s)*A(s,r)));
  dds(s,r);
  ddr(s,r):=factor((diff(A(s,r),r)*B(s,r)) - (diff(B(s,r),r)*A(s,r)));
  ddr(s,r);
  ddR(R):=factor(diff((1-(R*v))/(v-R),R));
  ddR(R);
\end{comment}
\begin{align*}
  \frac{\partial{}F\left(\boldsymbol{\beta},v\right)}{\partial{}s_{k}}
  &=\frac{\left(1-r_{k}\right)v\left(v^{2}-1\right)}
    {\left(1+s_{k}v+r_{k}v^{2}\right)\left(v^{2}+s_{k}v+r_{k}\right)}
    F\left(\boldsymbol{\beta},v\right)\\
  \frac{\partial{}F\left(\boldsymbol{\beta},v\right)}{\partial{}r_{k}} 
  &=\frac{\left(v^{2}-1\right)\left(v^{2}+s_{k}v+1\right)}
    {\left(1+s_{k}v+r_{k}v^{2}\right)\left(v^{2}+s_{k}v+r_{k}\right)}
  F\left(\boldsymbol{\beta},v\right)\\
  \frac{\partial{}F\left(\boldsymbol{\beta},v\right)}{\partial{}R}
  &= \frac{1-v^2}{\left(v-R\right)\left(1-Rv\right)}
    F\left(\boldsymbol{\beta},v\right)
\end{align*}

If $\Delta_{p}$ is specified, then the optimisation problem is to find the stop
band attenuation, $\Delta_{s}$, and $F\left(\boldsymbol{\beta},v\right)$ such
that $\hat{H}\left(v\right)\hat{H}\left(\frac{1}{v}\right)$ has $n+1$
alternating extrema $1$ and $1-\Delta_{p}$ on
$\left(\zeta_{1},\zeta_{2}\right)$. \emph{Saram\"{a}ki} points out that, if
$\Delta_{s}\ll{}1$, then, in the pass-band:
\begin{align*}
  \hat{H}\left(v\right)\hat{H}\left(\frac{1}{v}\right)&\approx
               \frac{\Delta_{s}}{4}F\left(\boldsymbol{\beta},v\right)
\end{align*}
If $\gamma=\frac{4}{\Delta_{s}}$, then, in the pass-band, the Newton-Raphson
update, $\left[\Delta\boldsymbol{\beta},\Delta\gamma\right]$, is the
solution of: 
\begin{align*}
  F\left(\boldsymbol{\beta},v\right)+
  \nabla_{\boldsymbol{\beta}}F\left(\boldsymbol{\beta},v\right)
  \Delta\boldsymbol{\beta}
  &=\left(\gamma+\Delta\gamma\right)
    \left(1-\frac{\Delta_{p}}{2}\pm\frac{\Delta_{p}}{2}\right)
\end{align*}

\emph{Saram\"{a}ki} suggests that the initial values of $\boldsymbol{\beta}$ and
$\Delta_{s}$ be found by transforming the $n+1$ frequencies of the pass-band
extremal points of an order $n$ Chebyshev Type 1 filter from the $z$-plane to
the $v$-plane and then solving the corresponding $n+1$ non-linear polynomial
equations for $\hat{H}\left(v\right)\hat{H}\left(\frac{1}{v}\right)$ in the
unknowns $e_{0},\hdots,e_{n-1}$ and $\Delta_{s}$, with $e_{n}=1$: 
\begin{align*}
  F\left(v\right)&=v^{-\left(m-n\right)}\frac{\sum^{n}_{k=0}e_{n-k}v^{k}}
                   {\sum^{n}_{k=0}e_{k}v^{k}}
\end{align*}

The Octave function \emph{saramakiFBvNewton} implements
\emph{Saram\"{a}ki}'s procedure for $n<m$. The function initialises
$F\left(\boldsymbol{\beta},v\right)$ and $\Delta_{s}$ with a polynomial fitted to
the $n+1$ frequencies of the pass-band extremal points. This method is simple
but not robust. The Octave script \emph{saramakiFBvNewton\_test.m} designs an
IIR filter with pass-band edge frequency, $fp=0.2$, stop-band edge frequency,
$fs=0.35$, pass-band ripple, $dBap=0.1$, denominator order, $n=6$, and numerator
order, $m=9$. The resulting stop-band suppression is $127.29dB$.
Figure~\ref{fig:saramaki-FBv-Newton-resp} shows the amplitude response of the
filter. Figure~\ref{fig:saramaki-FBv-Newton-pz} shows the pole-zero plot of the
filter. The numerator and denominator polynomials are, respectively:
\begin{small}
\verbatiminput{saramakiFBvNewton_test_n_coef.m}
\verbatiminput{saramakiFBvNewton_test_d_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{saramakiFBvNewton_test_resp}}
\caption{Amplitude response of an IIR filter with $n=6$ and $m=9$, designed
with the procedure of Saram\"{a}ki.}
\label{fig:saramaki-FBv-Newton-resp}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{saramakiFBvNewton_test_pz}}
\caption{Pole-zero plot of an IIR filter with $n=6$ and $m=9$, designed
with the procedure of Saram\"{a}ki.}
\label{fig:saramaki-FBv-Newton-pz}
\end{figure}
\clearpage
\subsection{\label{app:Saram\"{a}ki-unconstrained-minimisation-initial-IIR}Surma-aho and Saram\"{a}ki method of unconstrained optimisation of an initial IIR filter}
The method of \emph{Tarczynski et al.} finds the polynomial transfer function of
an initial filter. \emph{Surma-aho} and
\emph{Saram\"{a}ki}~\cite{SurmaahoSaramaki_ApproximatelyLinearPhaseRecursiveDigitalFilters}
describe an algorithm for finding an initial filter with approximately flat
group delay in terms of the \emph{gain-pole-zero} description\footnote{Although,
  unfortunately, the algorithm requires root-finding of intermediate
  polynomials.} of the cascade-form transfer function, reproduced here as
Algorithm~\ref{alg:Saramaki-initial-filter}. The cascade form filter is
decomposed into a minimum-phase filter and an all-pass equaliser.
\begin{algorithm}[htbp]
\textbf{Step 1:} Determine the minimum order of an elliptic filter to meet the
given amplitude criteria. Denote the minimum order by $n_{min}$ and set
${k=1}$. Then, design an elliptic filter transfer function 
$H^{k}_{min}\left(z\right)$ such that it satisfies:\\
\emph{Condition 1}: $\left|H^{k}_{min}\left(e^{\imath\omega}\right)\right|$
oscillates in the stopband $\left[\omega_{s},\pi\right]$ between $\delta_{s}$
and $0$ achieving these values at $n_{min}+1$ points such that the value at
$\omega=\omega_{s}$ is $\delta_{s}$. Here, $\delta_{s}$ is the specified
stopband ripple.\\
\emph{Condition 2:} $\left|H^{k}_{min}\left(e^{\imath\omega}\right)\right|$ 
oscillates in the interval $\left[0, \Omega^{k}_{p}\right]
\left(\Omega^{k}_{p}\ge\omega_{p}\right)$ between $1$ and $1-\delta^{k}_{p}$
achieving these values at $n_{min}+1$ points such that the value at
$\omega=\Omega^{k}_{p}$ is $1-\delta^{k}_{p}$. For Candidate I,
$\delta^{k}_{p}=\delta_{p}$,
with $\delta_{p}$ being the specified passband ripple, whereas the passband
region $\left[0,\Omega^{k}_{p} \right]$ is the widest possible to still meet the
given stopband requirements. For Candidate II, $\Omega^{k}_{p}=\omega_{p}$ with
$\omega_{p}$ being the specified passband edge, whereas $\delta^{k}_{p}$ is the
smallest passband ripple to still meet the given stopband criteria.


\textbf{Step 2}: Cascade $H^{k}_{min}\left(e^{\imath\omega}\right)$ with a
stable all-pass equalizer with a transfer function
$H^{k}_{all}\left(e^{\imath\omega}\right)$ of order $n_{all}$. Determine the
adjustable  parameters of $H^{k}_{all}\left(z\right)$ and $\psi^{k}$ such that
the maximum deviation of
$\arg\left[H^{k}_{all}\left(z\right)H^{k}_{min}\left(z\right)\right]$ from the
average slope $\phi_{ave}\left(\omega\right)=\psi^{k}\omega$ is
minimized in the specified passband region, $\left[0,\omega_{p}\right]$. Let the
poles of the all-pass filter be located at
$z=z^{k}_{1},z^{k}_{2},\hdots,z^{k}_{n_{all}}$.


\textbf{Step 3:} Set $k=k+1$. Then, design a minimum-phase filter transfer
function $H^{k}_{min}\left(z\right)$ of order $n_{min}+n_{all}$ such that it has
$n_{all}$ fixed zeros at $z=z^{k-1}_{1},z^{k-1}_{2},\hdots,z^{k-1}_{n_{all}}$
and it satisfies Condition 1 of Step 1 with the same number of extremal points,
that is, $n_{min}+1$, and Condition 2 of Step 1 with $n_{min}+n_{all}+1$
extremal points, instead of $n_{min}+1$ points.

\textbf{Step 4:} Like in Step 2, cascade  $H^{k}_{min}\left(z\right)$ with a
stable all-pass filter transfer function $H^{k}_{all}\left(z\right)$ of order
$n_{all}$ and determine its adjustable parameters and $\psi^{k}$ such that the
maximum of
$\left|\arg\left[H^{k}_{all}\left(z\right)H^{k}_{min}\left(z\right)\right]-\psi^{k}\omega\right|$
  is minimized in $\left[0,\omega_{p}\right]$. Let the poles of the all-pass
  filter be  located at $z=z^{k}_{1},z^{k}_{2},\hdots,z^{k}_{n_{all}}$.


\textbf{Step 5:} If $\left|z^{k}_{l}-z^{k-1}_{l}\right|\le\epsilon$ for
  $l=1,2,\hdots,n_{all}$ ($\epsilon$ is a small positive number), then stop. In
  this case, the  zeros of the minimum-phase filter being located inside the
  unit  circle and the poles of the all-pass equalizer coincide, reducing the
  overall order of
  $H\left(z\right)=H^{k}_{all}\left(z\right)H^{k}_{min}\left(z\right)$
  from $n_{min}+2n_{all}$ to $n_{min}+n_{all}$. This filter is the desired
  initial filter with approximately linear-phase characteristics. Otherwise, go
  to Step 3. 
\caption{\emph{Surma-aho} and \emph{Saram\"{a}ki} method for finding an initial
  IIR filter in \emph{gain-pole-zero} form~\cite[pp. 958-959]
  {SurmaahoSaramaki_ApproximatelyLinearPhaseRecursiveDigitalFilters}.} 
\label{alg:Saramaki-initial-filter}
\end{algorithm}

\emph{Saram\"{a}ki}~\cite{Saramaki_DigitalFiltersSumAllPassFilters} and
\emph{Vaidyanathan} and
\emph{Mitra}~\cite{VaidyanathanMitra_LowPassbandSensitivityDigitalFilters}
describe the conditions under which a filter transfer function can be
implemented as the sum of two all-pass filters. \emph{Surma-aho} and
\emph{Saram\"{a}ki} modify their algorithm to design a filter composed of two
parallel allpass filters, 
$H\left(z\right)=\frac{1}{2}\left[A\left(z\right)+B\left(z\right)\right]$,
where the all-pass filter orders differ by $1$ and the numerator polynomial of
$H\left(z\right)$ is a symmetric, even-length FIR filter. Step 3 of
Algorithm~\ref{alg:Saramaki-initial-filter} is modified so that:
\begin{quotation}
the minimum-phase filter is now of order $n_{min}+2n_{all}$ and it possesses
double zeros at $z=z^{k}_{1},z^{k}_{2},\hdots,z^{k}_{n_{all}}$. Consequently,
Condition 2 of Step 1 should be satisfied with $n_{min}+2n_{all}+1$ extremal
points. In the case of Step 5, the algorithm is terminated when the double zeros
of the minimum-phase filter being located inside the unit circle and the poles
of the all-pass phase equaliser coincide. This reduces the overall order of
$H\left(z\right)=H^{k}_{all}\left(z\right)H^{k}_{min}\left(z\right)$ from
$n_{min}+3n_{all}$ to $n_{min}+2n_{all}$. The third modification in the low-pass
case is that $n_{min}$ should be an odd number.
\end{quotation}

\emph{Surma-aho} and \emph{Saram\"{a}ki}~\cite[Appendix]
{SurmaahoSaramaki_ApproximatelyLinearPhaseRecursiveDigitalFilters} describe an
implementation of Steps 1 and 3 of
Algorithm~\ref{alg:Saramaki-initial-filter} that is similar to that described
above in Section~\ref{app:Saramaki-optimisation-denominator-order-higher}, based
on \emph{Saram\"{a}ki}~\cite{Saramaki_OptimumRecursiveFilterZerosUnitCircle}.

Algorithm~\ref{alg:Saramaki-initial-filter} is intialised with a minimum-phase
filter of order $n_{min}$ cascaded with an all-pass phase equaliser of order
$n_{all}$. The squared-magnitude function is constructed with: 
\begin{align*}
  F\left(\boldsymbol{\alpha},v\right)
  &= \left(\frac{1-\xi_{2}v}{v-\xi_{2}}\right)^{q}\times
    \prod^{\floor{\frac{n_{min}}{2}}}_{k=1}\left(\frac{1-R_{k}v}
    {v-R_{k}}\right)^{2}\times
    \prod^{n_{all}}_{k=1}\left(\frac{1-v\Gamma_{k}}{v-\Gamma_{k}}\right)^{p}
\end{align*}
where $n=m=n_{min}+p\times{}n_{all}$, $q=0$ if $n_{min}$ is even, $q=1$ if
$n_{min}$ is odd, $p=2$ if the filter is to be realised as the parallel sum of
two all-pass filters and $p=1$ otherwise. The $v$-plane poles, $\Gamma_{k}$, are
fixed and correspond to the $z$-plane poles of the all-pass filter. As above,
optimising the stop-band peaks results in a new minimum-phase filter with order
$n_{min}+p\times{}n_{all}$. This filter is then equalised with a new all-pass
filter of order $n_{all}$. The procedure is repeated until the poles of the
all-pass filter are cancelled by corresponding zeros of the minimum-phase
filter. The resulting filter has order $n_{min}+p\times{}n_{all }$ and
approximately linear phase in the pass-band. 
\subsubsection{Low-pass filter example of the Surma-aho and Saram\"{a}ki method}
The Octave script \emph{surmaaho\_lowpass\_test.m} designs a low-pass filter
with approximately flat pass-band delay. The filter specification is:
\begin{small}
\verbatiminput{surmaaho_lowpass_test_spec.m}
\end{small}
The gain-zero-pole coefficients are:
\begin{small}
\verbatiminput{surmaaho_lowpass_test_x_coef.m}
\end{small}
Figure~\ref{fig:surmaaho-lowpass-resp} shows the response of the
filter. Figure~\ref{fig:surmaaho-lowpass-pz} shows the pole-zero plot of the
filter. 

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{surmaaho_lowpass_test_resp}}
\caption{Response of a low-pass IIR filter with $nmin=7$ and $nall=4$, designed
  with the procedure of Surma-aho and Saram\"{a}ki.}
\label{fig:surmaaho-lowpass-resp}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{surmaaho_lowpass_test_pz}}
\caption{Pole-zero plot of a low-pass IIR filter with $nmin=7$ and $nall=4$,
  designed with the procedure of Surma-aho and Saram\"{a}ki.}
\label{fig:surmaaho-lowpass-pz}
\end{figure}
\clearpage
\subsubsection{Parallel all-pass low-pass filter example of the Surma-aho and Saram\"{a}ki method}
The Octave script \emph{surmaaho\_parallel\_allpass\_lowpass\_test.m} designs
a low-pass filter with approximately flat pass-band delay, implemented as the
sum of two all-pass filters. The filter specification is:
\begin{small}
\verbatiminput{surmaaho_parallel_allpass_lowpass_test_spec.m}
\end{small}
The combined gain-zero-pole coefficients are:
\begin{small}
\verbatiminput{surmaaho_parallel_allpass_lowpass_test_x_coef.m}
\end{small}
The all-pass filter pole coefficients are:
\begin{small}
\verbatiminput{surmaaho_parallel_allpass_lowpass_test_a1_coef.m}
\verbatiminput{surmaaho_parallel_allpass_lowpass_test_a2_coef.m}
\end{small}
Figure~\ref{fig:surmaaho-parallel-allpass-lowpass-resp} shows the response of
the filter. There are $nmin+2\times{}nall+1=16$ pass-band
extrema. Figure~\ref{fig:surmaaho-parallel-allpass-lowpass-pz} shows the 
pole-zero plot of the filter.
Figures~\ref{fig:surmaaho-parallel-allpass-lowpass-A1-pz}
and~\ref{fig:surmaaho-parallel-allpass-lowpass-A2-pz} show the pole-zero
plots of the all-pass filters.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{surmaaho_parallel_allpass_lowpass_test_A12_resp}}
\caption{Response of a parallel all-pass low-pass IIR filter with $nmin=7$ and
  $nall=4$, designed with the procedure of Surma-aho and Saram\"{a}ki.}
\label{fig:surmaaho-parallel-allpass-lowpass-resp}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{surmaaho_parallel_allpass_lowpass_test_pz}}
\caption{Pole-zero plot of a parallel all-pass low-pass IIR filter with $nmin=7$
  and $nall=4$, designed with the procedure of Surma-aho and Saram\"{a}ki.}
\label{fig:surmaaho-parallel-allpass-lowpass-pz}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{surmaaho_parallel_allpass_lowpass_test_A1_pz}}
\caption{Pole-zero plot of the A1 all-pass low-pass IIR filter designed with the
  procedure of Surma-aho and Saram\"{a}ki.} 
\label{fig:surmaaho-parallel-allpass-lowpass-A1-pz}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{surmaaho_parallel_allpass_lowpass_test_A2_pz}}
\caption{Pole-zero plot of the A2 all-pass low-pass IIR filter designed with the
  procedure of Surma-aho and Saram\"{a}ki.} 
\label{fig:surmaaho-parallel-allpass-lowpass-A2-pz}
\end{figure}

\clearpage
\section{\label{app:Johansson-Saram\"{a}ki-unconstrained-minimisation-initial-IIR}Johansson and Saram\"{a}ki design of all-pass complementary IIR filters}
\emph{Johansson} and \emph{Saram\"{a}ki}~\cite[Figure 1]
{JohanssonSaramaki_ClassComplementaryIIRFilters} describe a class of
all-pass complementary IIR filters ``realised as a
tapped, cascaded interconnection of identical all-pass sub-filters''.
A pair of all-pass complementary filters has:
\begin{align*}
  H\left(z\right)+H_{C}\left(z\right)=H_{ap}\left(z\right)
\end{align*}
where $H_{ap}\left(z\right)$ is all-pass. A pair of magnitude complementary filters
has:
\begin{align*}
|H\left(z\right)|+|H_{C}\left(z\right)|=1
\end{align*}
The transfer function of the filter is:
\begin{align*}
  H\left(z\right)&=\sum^{M}_{k=0}c_{k}\left[A_{0}\left(z\right)\right]^{k}
                   \left[A_{1}\left(z\right)\right]^{M-k}
\end{align*}
where $A_{0}\left(z\right)$ and $A_{1}\left(z\right)$ are stable all-pass
filters, $M$ is even and $c_{k}=c_{M-k}$ for $k=0,\ldots,M$. The all-pass
complementary transfer function is:
\begin{align*}
H_{C}\left(z\right)&=
\left[A_{0}\left(z\right)A_{1}\left(z\right)\right]^{\frac{M}{2}}-H\left(z\right)
\end{align*}


The filter design starts with a pair of all-pass complementary linear-phase FIR
filters: 
\begin{align*}
  F\left(v\right)&=\sum^{M}_{k=0}c_{k}v^{M-k}\\
  F_{C}\left(v\right)&=v^{\frac{M}{2}}-F\left(v\right)
\end{align*}
where:
\begin{align*}
v^{-1}=\frac{A_{0}\left(z\right)}{A_{1}\left(z\right)}
\end{align*}
is an all-pass frequency transformation. On the unit circle, $z=e^{\omega{}T}$
and $v=e^{\Omega{}T}$, where $T$ is the sampling interval. If
$\phi_{0}\left(\omega{}T\right)$ is the phase response of $A_{0}\left(z\right)$
and $\phi_{1}\left(\omega{}T\right)$ is the phase response of
$A_{1}\left(z\right)$, then:
\begin{align*}
\Omega{}T&=\phi_{1}\left(\omega{}T\right)-\phi_{0}\left(\omega{}T\right)
\end{align*}
and the zero-phase response of $F\left(v\right)$ is:
\begin{align*}
  F_{R}\left(\Omega{}T\right)&=c_{\frac{M}{2}}+2\sum^{\frac{M}{2}-1}_{k=0}
      c_{k}\cos \left[\left(\frac{M}{2}-k\right)\Omega{}T\right]
\end{align*}

The gradients of $F_{R}$ with respect to the coefficients are:
\begin{align*}
  \frac{\partial{}F_{R}\left(\Omega{}T\right)}{\partial{}c_{k}}&=\begin{cases}
    2\cos\left[\left(\frac{M}{2}-k\right)\Omega{}T\right] &
    k=0,\ldots,\frac{M}{2}-1\\
    1 & k=\frac{M}{2}
\end{cases}\\
  \frac{\partial{}F_{R} \left(\Omega{}T\right)}{\partial{}\boldsymbol{a}_{0}}&=
\phantom{-}
2\frac{\partial\phi_{0}\left(\omega{}T\right)}{\partial{}\boldsymbol{a}_{0}}
\sum^{\frac{M}{2}-1}_{k=0}c_{k}\left(\frac{M}{2}-k\right)
\sin\left[\left(\frac{M}{2}-k\right)
\left(\phi_{1}\left(\omega{}T\right)-
\phi_{0}\left(\omega{}T\right)\right)\right]\\ 
  \frac{\partial{}F_{R} \left(\Omega{}T\right)}{\partial{}\boldsymbol{a}_{1}}&=
-2\frac{\partial\phi_{1}\left(\omega{}T\right)}{\partial{}\boldsymbol{a}_{1}}
\sum^{\frac{M}{2}-1}_{k=0}c_{k}\left(\frac{M}{2}-k\right)
\sin\left[\left(\frac{M}{2}-k\right)
\left(\phi_{1}\left(\omega{}T\right)-
\phi_{0}\left(\omega{}T\right)\right)\right]
\end{align*}
where $\boldsymbol{a}_{0}$ and $\boldsymbol{a}_{1}$ represent the coefficients
of the all-pass filters $A_{0}$ and $A_{1}$, respectively.

The diagonal of the Hessian of $F_{R}$ with respect to the coefficients is:
\begin{align*}
  \frac{\partial^{2}F_{R}\left(\Omega{}T\right)}{\partial{}c_{k}^{2}}=&
                                                       \phantom{-}0\\
  \frac{\partial^{2}F_{R} \left(\Omega{}T\right)}
  {\partial\boldsymbol{a}_{0}^{2}} =&
\phantom{-}2\frac{\partial^{2}\phi_{0}\left(\omega{}T\right)}
       {\partial\boldsymbol{a}_{0}^{2}}
\sum^{\frac{M}{2}-1}_{k=0}c_{k}\left(\frac{M}{2}-k\right)
\sin\left[\left(\frac{M}{2}-k\right)
\left(\phi_{1}\left(\omega{}T\right)-
\phi_{0}\left(\omega{}T\right)\right)\right] \cdots\\*
&-2\left[\frac{\partial\phi_{0}\left(\omega{}T\right)}
       {\partial\boldsymbol{a}_{0}}\right]^{2}
\sum^{\frac{M}{2}-1}_{k=0}c_{k}\left(\frac{M}{2}-k\right)^{2}
\cos\left[\left(\frac{M}{2}-k\right)
\left(\phi_{1}\left(\omega{}T\right)-
\phi_{0}\left(\omega{}T\right)\right)\right]\\
  \frac{\partial^{2}F_{R} \left(\Omega{}T\right)}
       {\partial\boldsymbol{a}_{1}^{2}}=&
-2\frac{\partial^{2}\phi_{1}\left(\omega{}T\right)}
       {\partial\boldsymbol{a}_{1}^{2}}
\sum^{\frac{M}{2}-1}_{k=0}c_{k}\left(\frac{M}{2}-k\right)
\sin\left[\left(\frac{M}{2}-k\right)
\left(\phi_{1}\left(\omega{}T\right)-
\phi_{0}\left(\omega{}T\right)\right)\right] \cdots\\*
 &-2\left[\frac{\partial\phi_{1}\left(\omega{}T\right)}
               {\partial\boldsymbol{a}_{1}}\right]^{2}
\sum^{\frac{M}{2}-1}_{k=0}c_{k}\left(\frac{M}{2}-k\right)^2
\cos\left[\left(\frac{M}{2}-k\right)
\left(\phi_{1}\left(\omega{}T\right)-
\phi_{0}\left(\omega{}T\right)\right)\right]
\end{align*}

As an example, \emph{Johansson} and \emph{Saram\"{a}ki}~\cite[Figure 2]
{JohanssonSaramaki_ClassComplementaryIIRFilters} design a band-stop filter with
$M=6$, lower pass-band edge, $\omega_{apl}T=0.3\pi$, lower stop-band edge,
$\omega_{asl}T=0.4\pi$, upper stop-band edge $\omega_{asu}T=0.5\pi$ and upper
pass-band edge, $\omega_{apu}T=0.6\pi$. The all-pass transformation phase varies
in the range $\left[0, \Omega_{p}T\right]$ across the lower pass-band, in
the range $\left[\pi-\Omega_{p}T,\pi+\Omega_{p}T\right]$ across the stop band
and in the range $\left[2\pi-\Omega_{p}T,2\pi\right]$ across the upper
pass-band, where $\Omega_{p}T=0.038489$. The specified amplitude peak ripple in
each band of the filter is $\delta_{p}=\delta_{s}=0.00001$. The amplitude
response of the prototype FIR filter is designed to have pass-band and stop-band
widths that correspond to the pass-band peak-to-peak phase and stop-band
peak-to-peak phase, respectively, of the all-pass transformation. In other
words, the amplitude response of the prototype FIR filter is: 
\begin{align*}
  1-\delta_{p}\le\left|F_{R}\left(\Omega{}T\right)\right|&\le 1+\delta_{p},\;
  \Omega{}T\in\left[0,\Omega_{p}T\right]\\
 \left|F_{R}\left(\Omega{}T\right)\right|&\le \delta_{s},\;\phantom{1+}\;\;
  \Omega{}T\in\left[\pi-\Omega_{p}T,\pi\right]
\end{align*}
and the phase response of the all-pass transformation is such that:
\begin{align*}
  -\Omega_{p}T\le\Omega{}T&\le \Omega_{p}T,\;\phantom{2\pi+}\;
              \omega{}T\in\left[0,\omega_{apl}T\right]\\
  \pi-\Omega_{p}T\le\Omega{}T&\le \pi+\Omega_{p}T,\;\phantom{2}
              \omega{}T\in\left[\omega_{asl}T,\omega_{asu}T\right]\\
  2\pi-\Omega_{p}T\le\Omega{}T&\le 2\pi+\Omega_{p}T,\;
              \omega{}T\in\left[\omega_{apu}T,\pi\right]\\
\end{align*}
\emph{Johansson} and \emph{Saram\"{a}ki} recommend designing the all-pass
transformation with the prototype IIR filter:
\begin{align*}
  G\left(z\right)&=\frac{A_{0}\left(z\right)+A_{1}\left(z\right)}{2}
\end{align*}
having magnitude response:
\begin{align*}
  \left|G\left(\omega{}T\right)\right|&=
              \left|\cos\frac{\phi_{1}\left(\omega{}T\right)-
                              \phi_{0}\left(\omega{}T\right)}{2}\right|
\end{align*}
and
\begin{align*}
  1-\Delta_{p}\le\left|G\left(\omega{}T\right)\right|&\le 1+\Delta_{p},\;
  \omega{}T\in\left[0,\omega_{apl}T\right]\cup\left[\omega_{apu}T,\pi\right]\\
  \left|G\left(\omega{}T\right)\right|&\le \Delta_{s},\;\phantom{1+}\;\;
  \omega{}T\in\left[\omega_{asu}T,\omega_{asl}T\right]                        
\end{align*}
where $\Delta_{p}=1-\cos\frac{\Omega_{p}T}{2}$ and
$\Delta_{s}=\cos\frac{\pi-\Omega_{p}T}{2}$.

To design a magnitude complementary pair of filters,
$F_{R}\left(\Omega{}T\right)$ must vary between $1-\delta_{p}$ and $1$ in the
pass-band and between $0$ and $\delta_{s}$ in the stop-band. This is achieved by
first designing an equi-ripple zero-phase FIR filter,
$E_{R}\left(\Omega{}T\right)$, with pass-band ripple, $d_{p}$, and stop-band
ripple, $d_{s}$, given by: 
\begin{align*}
d_{p}&=\frac{\frac{\delta_{p}}{2}}{1-\frac{\delta_{p}}{2}-\frac{\delta_{s}}{2}} \\
d_{s}&=\frac{\frac{\delta_{s}}{2}}{1-\frac{\delta_{p}}{2}-\frac{\delta_{s}}{2}}
\end{align*}
so that:
\begin{align*}
  F_{R}\left(\Omega{}T\right)&=
        \frac{E_{R}\left(\Omega{}T\right)+d_{s}}{1+d_{p}+d_{s}}
\end{align*}

The Octave script \emph{johansson\_cascade\_allpass\_bandstop\_test.m} designs
a pair of band-stop and band-pass filters. The band-pass filter is both all-pass
and magnitude complementary to the band-stop filter. The band-stop filter
specification is:  
\begin{small}
\verbatiminput{johansson_cascade_allpass_bandstop_test_spec.m}
\end{small}
The script designs the prototype FIR filter with the
\emph{directFIRsymmetric\_slb} and \emph{directFIRsymmetric\_socp\_mmse}
functions. Figure~\ref{fig:Johansson-cascade-allpass-bandstop-fir} shows the
response of the prototype FIR filter. The prototype FIR filter coefficients are:
\begin{small}
\verbatiminput{johansson_cascade_allpass_bandstop_test_f1_coef.m}
\end{small}
The script designs the prototype IIR filter as the low-pass to band-stop
transformation of a parallel all-pass elliptic filter found with the
\emph{ellip} function from the Octave-Forge \emph{signal} package.
Figure~\ref{fig:Johansson-cascade-allpass-bandstop-iir} shows the
response of the prototype IIR filter. The prototype IIR filter parallel all-pass
polynomial coefficients are:
\begin{small}
\verbatiminput{johansson_cascade_allpass_bandstop_test_bsA0_coef.m}
\verbatiminput{johansson_cascade_allpass_bandstop_test_bsA1_coef.m}
\end{small}
Figure~\ref{fig:Johansson-cascade-allpass-bandstop-zp-dual} shows the
pass-band and stop-band zero-phase response of the band-stop filter.
Figure~\ref{fig:Johansson-cascade-allpass-bandstop-comp} shows the
responses of the complementary filters.
Figure~\ref{fig:Johansson-cascade-allpass-bandstop-comp-dual} shows the
pass-band and stop-band responses of the complementary filters.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{johansson_cascade_allpass_bandstop_test_fir}}
\caption{Pass-band and stop-band responses of the Johansson and Saram\"{a}ki
  prototype FIR filter.}
\label{fig:Johansson-cascade-allpass-bandstop-fir}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{johansson_cascade_allpass_bandstop_test_iir}}
\caption{Response of the Johansson and Saram\"{a}ki prototype IIR filter.}
\label{fig:Johansson-cascade-allpass-bandstop-iir}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{johansson_cascade_allpass_bandstop_test_zp_dual}}
\caption{Pass-band and stop-band zero-phase response of the Johansson and
  Saram\"{a}ki band-stop IIR filter.}
\label{fig:Johansson-cascade-allpass-bandstop-zp-dual}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{johansson_cascade_allpass_bandstop_test_comp}}
\caption{Responses of the Johansson and Saram\"{a}ki band-stop complementary IIR
  filters.}
\label{fig:Johansson-cascade-allpass-bandstop-comp}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{johansson_cascade_allpass_bandstop_test_comp_dual}}
\caption{Pass-band and stop-band responses of the Johansson and Saram\"{a}ki
  band-stop complementary IIR filters.}
\label{fig:Johansson-cascade-allpass-bandstop-comp-dual}
\end{figure}
\clearpage
The Octave script
\emph{branch\_bound\_johanssonOneMlattice\_bandstop\_16\_bits\_test.m} designs a 
band-stop filter having $3$-signed-digit $16$-bit coefficients with the 
\emph{branch-and-bound} algorithm (see
Chapter~\ref{sec:branch-bound-search-signed-digit-coefficients}). The all-pass  
filters are implemented as Schur one-multiplier lattice filters.

The initial band-stop filter is that designed by the Octave script
\emph{johansson\_cascade\_allpass\_bandstop\_test.m}. The band-stop filter
specification is: 
\begin{small}
\verbatiminput{branch_bound_johanssonOneMlattice_bandstop_16_nbits_test_spec.m}
\end{small}
The resulting band-stop filter $3$-signed-digit, $16$-bit coefficients are: 
\begin{small}
  \verbatiminput
  {branch_bound_johanssonOneMlattice_bandstop_16_nbits_test_f_min_coef.m}
  \verbatiminput
  {branch_bound_johanssonOneMlattice_bandstop_16_nbits_test_k0_min_coef.m}
  \verbatiminput
  {branch_bound_johanssonOneMlattice_bandstop_16_nbits_test_k1_min_coef.m}
\end{small}
Figure~\ref{fig:Johansson-OneM-lattice-bandstop-16-nbits-resp} shows the
pass-band and stop-band responses of the filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{branch_bound_johanssonOneMlattice_bandstop_16_nbits_test_resp}}
\caption{Responses of the Johansson and Saram\"{a}ki band-stop filter with
  $3$-signed-digit, $16$-bit coefficients designed with the
  \emph{branch-and-bound} algorithm.} 
\label{fig:Johansson-OneM-lattice-bandstop-16-nbits-resp}
\end{figure}
\clearpage
The Octave script \emph{johanssonOneMlattice\_socp\_slb\_bandstop\_test.m}
designs a band-stop filter with PCLS constraints. The all-pass filters are
implemented as Schur one-multiplier lattice filters. The initial band-stop
filter is that designed by the Octave script 
\emph{johansson\_cascade\_allpass\_bandstop\_test.m}. The band-stop filter
specification is: 
\begin{small}
\verbatiminput{johanssonOneMlattice_socp_slb_bandstop_test_spec.m}
\end{small}
The resulting band-stop filter coefficients are: 
\begin{small}
  \verbatiminput{johanssonOneMlattice_socp_slb_bandstop_test_f_coef.m}
  \verbatiminput{johanssonOneMlattice_socp_slb_bandstop_test_k0_coef.m}
  \verbatiminput{johanssonOneMlattice_socp_slb_bandstop_test_k1_coef.m}
\end{small}
Figure~\ref{fig:Johansson-OneM-lattice-bandstop-PCLS-resp} shows the
pass-band and stop-band responses of the filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{johanssonOneMlattice_socp_slb_bandstop_test_pcls}}
\caption{Responses of the Johansson and Saram\"{a}ki band-stop filter with
  PCLS constraints.} 
\label{fig:Johansson-OneM-lattice-bandstop-PCLS-resp}
\end{figure}

\chapter{\label{app:Design-of-FIR-digital-filter-transfer-functions}Design of FIR digital filter transfer functions}
This chapter reviews methods of designing FIR digital filter transfer functions.
FIR filters are described by a transfer function polynomial in $z^{-1}$:
\begin{align*}
  H\left(z\right) &= \sum_{n=0}^{N} h_{n}z^{-n}
\end{align*}
This is called the \emph{direct-form} implementation of the FIR filter.
An even-order, $N=2M$, symmetric FIR filter is assumed to have $M+1$
distinct coefficients and odd length, $2M+1$, with $h_{2M-n}=h_{n}$. The
\emph{direct-form} implementation of a symmetric FIR filter requires
approximately half the number of multipliers used by the non-symmetric
direct-form implementation. A symmetric FIR filter has a linear phase
response or, equivalently, a constant group delay response. The
\emph{transposed-direct-form} FIR filter is an alternative FIR filter
implementation that uses \emph{Horner's Rule} to evaluate the filter polynomial:
\begin{align*}
  h\left(z\right) &= \left(\ldots\left(\left(h_{N}z^{-1}+h_{N-1}\right)z^{-1}+
                    h_{N-2}\right)z^{-1}+ \ldots +h_{1}\right)z^{-1}+ h_{0}
\end{align*}
The transposed-direct-form pipelines the arithmetic operations but cannot
make use of a symmetry in the filter polynomial.
\section{\label{app:Low-passband-sensitivity-FIR-digital-filters}Low passband sensitivity FIR lattice filters}
\subsection{\label{app:Lattice-decomposition-of-FIR-digital-filters}Lattice decomposition of an FIR digital filter}
\emph{Vaidyanathan}~\cite{Vaidyanathan_PassiveCascadedLatticeFIR} describes the
design of low passband sensitivity FIR digital filters based on the lattice
decomposition of a bounded-real FIR filter, $H\left(z\right)$, such that
$\left|H\left(e^{\imath\omega}\right)\right|\le 1$, and the bounded-real
complementary filter, $G\left(z\right)$, with
$\left|H\left(e^{\imath\omega}\right)\right|^{2}+\left|G\left(e^{\imath\omega}\right)\right|^{2}=1$. Assume that $H_{m+1}\left(z\right)$ and $G_{m+1}\left(z\right)$ are
complementary FIR filter transfer function polynomials of order $m+1$:
\begin{align}
  H_{m+1}\left(z\right) &= \sum_{n=0}^{m+1}h_{m+1,n}z^{-n} \label{eq:comp_FIR_H}\\
  G_{m+1}\left(z\right) &= \sum_{n=0}^{m+1}g_{m+1,n}z^{-n} \label{eq:comp_FIR_G}
\end{align}
and write $\tilde{H}_{m+1}\left(z\right)=H^{\top}_{m+1}\left(z^{-1}\right)$, where
$^{\top}$ denotes transpose.

$A_{m+1}\left(z\right)=\left[H_{m+1}\left(z\right)~G_{m+1}\left(z\right)\right]^{\top}$
represents the corresponding all-pass filter:
\begin{align*}
  \tilde{A}_{m+1}\left(z\right)A_{m+1}\left(z\right)=1
\end{align*}
or
\begin{align}
  \tilde{H}_{m+1}\left(z\right) H_{m+1}\left(z\right) +
  \tilde{G}_{m+1}\left(z\right) G_{m+1}\left(z\right) &= 1 \label{eq:comp_FIR_HG}
\end{align}

After expanding Equation~\ref{eq:comp_FIR_HG} with Equations~\ref{eq:comp_FIR_H}
and~\ref{eq:comp_FIR_G}, the term in $z^{m+1}$ is, by inspection:
\begin{align}
  h_{m+1,m+1}h_{m+1,0}+g_{m+1,m+1}g_{m+1,0} &= 0 \label{eqn:eq:comp_FIR_alt_reduction}
\end{align}
If $h_{m+1,m+1}=0$ then either $g_{m+1,m+1}=0$, in which case the current
order reduction step is not necessary, or $g_{m+1,0}=0$ in which case:
\begin{align*}
H_{m}\left(z\right) &= H_{m+1}\left(z\right)\\
G_{m}\left(z\right) &= zG_{m+1}\left(z\right)
\end{align*}

For the general case, \emph{Vaidyanathan} derives the following order
reduction of $A_{m+1}\left(z\right)$ to $A_{m}\left(z\right)$:
\begin{align*}
\left[\begin{array}{c}
H_{m}\left(z\right) \\
G_{m}\left(z\right) \\
  \end{array}\right] & = 
\left[\begin{array}{cc}
k_{m+1} & \hat{k}_{m+1} \\
-\hat{k}_{m+1}z & k_{m+1}z \\
  \end{array}\right] 
\left[\begin{array}{c}
H_{m+1}\left(z\right) \\
G_{m+1}\left(z\right) \\
  \end{array}\right]
\end{align*}
where~\cite[Equations 13 and 14]{Vaidyanathan_PassiveCascadedLatticeFIR}:
\begin{align}
k_{m+1} = \frac{-g_{m+1,m+1}}{\sqrt{h_{m+1,m+1}^{2}+g_{m+1,m+1}^{2}}} \; , \;
  \hat{k}_{m+1} = \frac{h_{m+1,m+1}}{\sqrt{h_{m+1,m+1}^{2}+g_{m+1,m+1}^{2}}}
  \label{eqn:complementary-FIR-lattice-order-reduction-eqns-13-14}
\end{align}
or~\cite[Equation 23]{Vaidyanathan_PassiveCascadedLatticeFIR}:
\begin{align}
  k_{m+1} = \frac{h_{m+1,0}}{\sqrt{h_{m+1,0}^{2}+g_{m+1,0}^{2}}} \; , \;
  \hat{k}_{m+1} = \frac{g_{m+1,0}}{\sqrt{h_{m+1,0}^{2}+g_{m+1,0}^{2}}}
  \label{eqn:complementary-FIR-lattice-order-reduction-eqn-23}
\end{align}

The final order reduction step is:
\begin{align*}
  \left[\begin{array}{c}
        1 \\
        0 \\
        \end{array}\right] & = 
\left[\begin{array}{cc}
k_{0} & \hat{k}_{0} \\
-\hat{k}_{0}z & k_{0}z \\
  \end{array}\right] 
\left[\begin{array}{c}
H_{0}\left(z\right) \\
G_{0}\left(z\right) \\
  \end{array}\right]
\end{align*}

The $m+1$'th lattice filter section is related to the $m$'th section by:
\begin{align*}
A_{m+1}\left(z\right) &= \tau_{m+1}\left(z\right)A_{m}\left(z\right)
\end{align*}
where
\begin{align*}
\tau_{m+1}\left(z\right) &=
\left[\begin{array}{cc}
k_{m+1} & -\hat{k}_{m+1}z^{-1} \\
\hat{k}_{m+1} & k_{m+1}z^{-1} \\
\end{array}\right] 
\end{align*}
$A_{m}\left(z\right)$ also represents an allpass filter since
$\tilde{\tau}_{m+1}\left(z\right)\tau_{m+1}\left(z\right)=I$ and:
\begin{align*}
  I &=  \tilde{A}_{m+1}\left(z\right)A_{m+1}\left(z\right)\\
    &=  \tilde{A}_{m}\left(z\right)\tilde{\tau}_{m+1}\left(z\right)
         \tau_{m+1}\left(z\right)A_{m}\left(z\right)\\
    &=  \tilde{A}_{m}\left(z\right)A_{m}\left(z\right)\\
\end{align*}

The Octave function \emph{complementaryFIRdecomp.m} implements FIR lattice
decomposition with filter order reduction by
Equation~\ref{eqn:complementary-FIR-lattice-order-reduction-eqn-23}.
(I found that
Equation~\ref{eqn:complementary-FIR-lattice-order-reduction-eqn-23}
has better numerical performance than
Equation~\ref{eqn:complementary-FIR-lattice-order-reduction-eqns-13-14}).
\subsection{Finite-wordlength properties of the lattice FIR filter}
Section~\ref{sec:State-variable-description-of-complementary-FIR-lattice-filter}
shows that transfer function of the complementary FIR lattice is
the result of $N$ orthogonal transformations:
\begin{align*}
  \left[\begin{array}{cc}
    H_{N}&  G_{N}\end{array}\right]^{\top}&=\tau_{N}\cdots\tau_{1}
  \left[\begin{array}{cc}
          H_{0}& G_{0} \end{array}\right]^{\top}
\end{align*}
      where the $\tau_{m}$ are orthogonal matrixes:
\begin{align*}
  \tau_{m}\left(z\right)
  &=  \left[\begin{array}{cc}
              k_{m} & -\hat{k}_{m}z^{-1} \\
              \hat{k}_{m} & k_{m}z^{-1}
            \end{array}\right]
\end{align*}
      
\emph{Vaidyanathan}~\cite{Vaidyanathan_PassiveCascadedLatticeFIR}[Section VII]
shows that this determines the finite-wordlength properties of the lattice FIR
filter:
\begin{enumerate}
  \item The noise gain from the inputs to the combined complementary outputs
    of the filter is $N$
  \item The multiplier inputs are scaled since if $H_{0}^{2}+G_{0}^{2}= 1$
    then $H_{m}^{2}+G_{m}^{2}= 1$.
    (Section~\ref{sec:Scaling-State-Variable-Filters-To-Avoid-Overflow}
    describes state scaling).
    
  \item The coefficient sensitivities to $k_{m}$ are:
  \begin{align*}
    \frac{\partial}{\partial k_{m}}
    \left[\begin{array}{cc}
    H_{N}&G_{N}\end{array}\right]^{\top}
 &=\tau_{N}\cdots\tau_{m+1}
   \left[\begin{array}{cc}
           1 & 0 \\
           0 & z^{-1}
         \end{array}\right]\tau_{m-1}\cdots\tau_{1}
    \left[\begin{array}{cc}
    H_{0}&G_{0}\end{array}\right]^{\top}
  \end{align*}
  so the coefficient sensitivities of the FIR lattice are bounded:
  \begin{align*} 
    \left|\frac{\partial H_{N}}{\partial k_{m}}\right|^{2}
    +\left|\frac{\partial G_{N}}{\partial k_{m}}\right|^{2} &= 1
  \end{align*}
\end{enumerate}

\subsection{\label{sec:State-variable-description-of-complementary-FIR-lattice-filter}State variable description of the complementary FIR lattice filter}
Figure~\ref{fig:complementary-FIR-filter-structure} (see Figure 3 of
\emph{Vaidyanathan}~\cite{Vaidyanathan_PassiveCascadedLatticeFIR})
shows the complementary FIR lattice structure.
\begin{figure}
\centering
\includegraphics[scale=\DesignOfIIRFiltersIncludeScale]{complementary_FIR_filter}
\caption{Structure of the complementary FIR lattice filter (see
  \emph{Vaidyanathan}~\cite[Figure 3]{Vaidyanathan_PassiveCascadedLatticeFIR}).}
\label{fig:complementary-FIR-filter-structure}
\end{figure}

For convenience, call $x_{n}^{\prime}$ the input to state $x_{n}$ of
the $n$-th section, $\hat{y}_{n}$ the lower output of the $n$-th section
and $y_{n}$ the upper output of the $n$-th section. Construction of the
state variable description of the complementary FIR lattice is summarised in
Algorithm~\ref{alg:Construction-state-variable-complementary-FIR-lattice}.

\begin{algorithm}[htbp]
\begin{algorithmic}
\State $\hat{y}_{0} = \hat{k}_{0}u$
\State $y_{0} = k_{0}u$
\For{$n=1,\hdots,N$}
  \State $x_{n}^{\prime} = \hat{y}_{n-1}$
  \State $\hat{y}_{n} = \hat{k}_{n}y_{n-1} + k_{n}x_{n}$
  \State $y_{n} = k_{n}y_{n-1} - \hat{k}_{n}x_{n}$
\EndFor
\State $y = y_{N}$
\end{algorithmic}
\caption{Construction of a state variable description of the complementary FIR
  lattice filter.}
\label{alg:Construction-state-variable-complementary-FIR-lattice}
\end{algorithm}

As shown in Section~\ref{Sec:Construction-factored-state-variable-description},
the state variable description can be expressed as a series of matrix
multiplications linking the input and state outputs to the output and the next
state inputs.
\begin{align*}
\left[\begin{array}{c}
\hat{y}_{0}\\
y_{0}\\
x_{1}\\
x_{2}\\
\vdots\\
x_{N}
\end{array}\right] & = \left[\begin{array}{cccccc}
0 & \cdots & & \cdots & 0 & \hat{k}_{0} \\
0 & \cdots & & \cdots & 0 & k_{0} \\
1 & \cdots & & \cdots & 0 & 0 \\
\vdots & \ddots & & & & \vdots \\
\vdots &  &  & \ddots &  & \vdots\\
0 & \cdots &  &  & 1 & 0
\end{array}\right]\left[\begin{array}{c}
x_{1}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{N} \\
u
\end{array}\right]
\end{align*}
\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
\hat{y}_{1}\\
y_{1}\\
x_{2}\\
\vdots\\
x_{N}
\end{array}\right] & = \left[\begin{array}{cccccc}
1 & 0 & 0 & 0 & \cdots & 0\\
0 & \hat{k}_{1} & k_{1} & 0 & \cdots & 0\\
0 & k_{1} & -\hat{k}_{1} & 0 & \cdots & 0\\
0 & 0 & 0 & 1 & \cdots & 0\\
\vdots &  &  & & \ddots & \vdots\\
0 & \cdots & & & \cdots & 1
\end{array}\right]\left[\begin{array}{c}
\hat{y}_{0}\\
y_{0}\\
x_{1}\\
x_{2}\\
\vdots\\
x_{N}
\end{array}\right]
\end{align*}
\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
x_{2}^{\prime}\\
\hat{y}_{2}\\
y_{2}\\
x_{3}\\
\vdots\\
x_{N}
\end{array}\right] & = \left[\begin{array}{ccccccc}
1 & 0 & 0 & 0 & 0 & \cdots & 0\\
0 & 1 & 0 & 0 & 0 & \cdots & 0\\
0 & 0 & \hat{k}_{2} & k_{2} & 0 &\cdots & 0\\
0 & 0 & k_{2} & -\hat{k}_{2} & 0 &\cdots & 0\\
0 & 0 & 0 & 0 & 1 & \cdots & 0\\
\vdots &  & & &  & \ddots & \vdots\\
0 & \cdots &  & & & \cdots & 1
\end{array}\right]\left[\begin{array}{c}
x_{1}^{\prime} \\
\hat{y}_{1}\\
y_{1}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{N}
\end{array}\right]
\end{align*}
\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
x_{N-1}^{\prime}\\
\hat{y}_{N-1}\\
y_{N-1}\\
x_{N}
\end{array}\right] & = \left[\begin{array}{ccccccc}
1 & \cdots & & & & \cdots & 0\\
\vdots & \ddots & & & & & \vdots\\
0 & \cdots & & 1 & 0 & 0 & 0\\
0 & \cdots & & 0 & \hat{k}_{N-1} & k_{N-1} & 0\\
0 & \cdots & & 0 & k_{N-1} & -\hat{k}_{N-1} & 0\\
0 & \cdots & & 0 & 0 & 0 & 1
\end{array}\right]\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
x_{N-2}^{\prime}\\
\hat{y}_{N-2}\\
y_{N-2}\\
x_{N-1}\\
x_{N}
\end{array}\right]
\end{align*}
\begin{align*}
\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
x_{N}^{\prime}\\
\hat{y}_{N}\\
y_{N}
\end{array}\right] & = \left[\begin{array}{ccccc}
1 & \cdots &  & \cdots & 0\\
\vdots & \ddots & & & \vdots \\
0 & \cdots & 1 & 0 & 0 \\
0 & \cdots & 0 & \hat{k}_{N} &  k_{N} \\
0 & \cdots &  0 & k_{N} &  -\hat{k}_{N}
\end{array}\right]\left[\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
\hat{y}_{N-1}\\
y_{N-1}\\
x_{N}
\end{array}\right]
\end{align*}
The Octave function \emph{complementaryFIRlattice2Abcd} returns the state
variable description of a complementary FIR lattice filter.
The Octave script \emph{complementaryFIRlattice2Abcd\_symbolic\_test.m} creates a
symbolic state variable description of the complementary FIR lattice filter.

\subsection{\label{app:Design-of-complementary-FIR-digital-filter}Design of the complementary FIR digital filter}
The previous sections of this chapter assume that the complementary FIR filter
is known. This section shows two methods for finding that filter. The first,
\emph{Orchard} and \emph{Willson}'s Newton-Raphson
solution~\cite{OrchardWillson_ComputationMinimumPhaseSpectralFactor}, is
simpler and more accurate than the cepstral method of \emph{Mian} and
\emph{Nainer}~\cite{MianNainer_FastDesignEquiRippleMinimumPhaseFIR}.
\subsubsection{\label{app:Orchard-Willson-Newton-Raphson-solution}\emph{Orchard} and \emph{Willson}'s Newton-Raphson solution}
If an order $N$ FIR filter $H\left(z\right)$ is bounded-real then
$\left|H\left(e^{\imath\omega}\right)\right|\le 1$. The magnitude-squared
complementary filter $1-H^{\mathconj}\left(z\right)H\left(z\right)$, where
$\mathconj$ means \emph{complex conjugate transpose}, is linear-phase and has
double zeros on the 
unit-circle when $\left|H\left(e^{\imath\omega}\right)\right|=1$.
\emph{Orchard} and
\emph{Willson}~\cite{OrchardWillson_ComputationMinimumPhaseSpectralFactor}
find the minimum-phase spectral factor of the magnitude-squared complementary
filter by a Newton-Raphson solution of the non-linear system of equations
linking the coefficients of the two filters. They demonstrate that the
Newton-Raphson recursion converges linearly when the linear phase filter being
factored has zeros on the unit circle. \emph{Orchard} and \emph{Willson} show
a MATLAB (ie: Octave) implementation, \emph{minphase.m}, in Appendix A of the
reference. 

\emph{Orchard} and \emph{Willson} justify their method with the following
example. Firstly, they define a short linear phase FIR filter:
\begin{align*}
  H\left(z\right) &= z^{-3}\left[h_{0}+h_{1}\left(z+z^{-1}\right)+
                    h_{2}\left(z^{2}+z^{-2}\right)+
                    h_{3}\left(z^{3}+z^{-3}\right)\right]
\end{align*}
$H\left(z\right)$ is assumed to be the product of a minimum phase factor:
\begin{align*}
  F_{1}\left(z\right) &= a_{0}+a_{1}z^{-1}+a_{2}z^{-2}+a_{3}z^{-3}
\end{align*}
and the corresponding maximum phase factor:
\begin{align*}
  F_{2}\left(z\right) &= z^{-3}F_{1}\left(z^{-1}\right) \\
                      &= a_{3}+a_{2}z^{-1}+a_{1}z^{-2}+a_{0}z^{-3}
\end{align*}
Equating the coefficients of terms on either side of the equality sign in 
$H\left(z\right)=F_{1}\left(z\right)F_{2}\left(z\right)$ gives the system of
non-linear equations:
\begin{align*}
  h_{0} &= a_{0}^{2}+a_{1}^{2}+a_{2}^{2}+a_{3}^{2} \\
  h_{1} &= a_{0}a_{1} + a_{1}a_{2}  + a_{2}a_{3} \\
  h_{2} &= a_{1}a_{3} + a_{0}a_{2} \\
  h_{3} &= a_{0}a_{3}
\end{align*}
The Newton-Raphson method solves a system of equations
$f\left(\boldsymbol{a}\right)=0$ 
by successive approximations:
\begin{align*}
    f\left(\boldsymbol{a}_{k}\right)+
  J\left(\boldsymbol{a}_{k}\right)
  \left[\boldsymbol{a}_{k+1}-\boldsymbol{a}_{k}\right] &=0
\end{align*}
or:
\begin{align*}
  \boldsymbol{a}_{k+1}
  &= \boldsymbol{a}_{k}
    -J^{-1}\left(\boldsymbol{a}_{k}\right)f\left(\boldsymbol{a}_{k}\right)
\end{align*}
where $J\left(\boldsymbol{a}\right)$ is the Jacobian matrix of
$f\left(\boldsymbol{a}\right)$.

In this case:
\begin{align*}
  f\left(\boldsymbol{a}\right)
  &= \left[ \begin{array}{l}
              h_{0} - a_{0}^{2}  - a_{1}^{2}   - a_{2}^{2}  - a_{3}^{2} \\
              h_{1} - a_{0}a_{1} - a_{1}a_{2}  - a_{2}a_{3} \\
              h_{2} - a_{1}a_{3} - a_{0}a_{2} \\
              h_{3} - a_{0}a_{3}
            \end{array} \right] \\
  J\left(\boldsymbol{a}\right)
  &= -\left[ \begin{array}{cccc}
               2a_{0} & 2a_{1} & 2a_{2} & 2a_{3} \\
               a_{1} & a_{2}+a_{0} & a_{3}+a_{1} & a_{2} \\
               a_{2} & a_{3} & a_{0} & a_{1} \\
               a_{3} & 0 & 0 & a_{0} \\
            \end{array} \right] \\
  &= - \left[ \begin{array}{cccc}
                a_{0} & a_{1} & a_{2} & a_{3} \\
                a_{1} & a_{2} & a_{3} & 0 \\
                a_{2} & a_{3} & 0     & 0 \\
                a_{3} & 0     & 0     & 0
            \end{array} \right]                               
  - \left[ \begin{array}{cccc}
             a_{0} & a_{1} & a_{2} & a_{3} \\
             0     & a_{0} & a_{1} &  a_{2} \\
             0     & 0     & a_{0} & a_{1} \\
             0     & 0     & 0    & a_{0}
            \end{array} \right]                      
\end{align*}
The function \emph{minphase.m} solves for the coefficient update,
$\boldsymbol{d}_{k+1}=\boldsymbol{a}_{k+1}-\boldsymbol{a}_{k}$, by matrix
left division. The C++ file \emph{minphase.cc} implements the \emph{minphase}
algorithm as an \emph{oct-file} using the \emph{Eigen}~\cite{EigenWeb} C++
template library with \emph{long double} matrix elements.

I experimented with the Octave-Forge \emph{optim} package \emph{leasqr}
function, an implementation of Levenberg-Marquardt non-linear optimisation.
I found that \emph{leasqr} needed to be initialised with the \emph{minphase}
solution and did not improve that solution by more than a few machine
\emph{epsilon}.

\subsubsection{\emph{Mian} and \emph{Nainer}'s cepstral method}
\emph{Mian} and
\emph{Nainer}~\cite{MianNainer_FastDesignEquiRippleMinimumPhaseFIR} describe
finding the minimum-phase spectral factor of the magnitude-squared complementary
response by calculating the cepstrum of that response along a $z$-plane
contour slightly off the unit circle. This contour reduces aliasing of the
cepstrum due to the response zeros that lie on the unit circle. See
Appendix~\ref{app:Review-of-complex-variables} for a review of the complex
variables theory used in this section.
\paragraph{Properties of the cepstrum}
Firstly, recall that the $z$-transform of a real sequence, $\boldsymbol{x}$, is
\begin{align*}
  X\left(z\right) &= \sum_{n=-\infty}^{\infty} x\left(n\right)z^{-n}
\end{align*}
and that the inverse $z$-transform is
\begin{align*}
x\left(n\right)&=\frac{1}{2\pi\imath}\ointctrclockwise_{C}X\left(z\right)z^{n-1}dz
\end{align*}
where the contour, $C$, is centred on the origin and lies within the region of
convergence. Cauchy's integral lemma is
\begin{align*}
\ointctrclockwise_{C}z^{n}dz &=\begin{cases}
2\pi\imath  & n=-1 \\
0 & n \ne -1, \text{integral}
\end{cases}
\end{align*}

The \emph{complex cepstrum} is the inverse z-transform of
$\hat{X}\left(z\right)=\log X\left(z\right)=\log\left|X\left(z\right)\right| + \imath \arg X\left(z\right)$ on the unit circle:
\begin{align*}
\hat{x}\left(n\right)&=
\frac{1}{2\pi\imath}\ointctrclockwise_{C}\log X\left(z\right)z^{n-1}dz
\end{align*}
The \emph{real cepstrum} is the inverse z-transform of
$\log\left|X\left(z\right)\right|$ on the unit circle.

For example, suppose $X\left(z\right)=K\left(1-az^{-1}\right)\left(1-bz\right)$,
where $\left|a\right|,\left|b\right|<1$. By Cauchy's integral lemma and the
definition of the z-transform, $K=X\left(0\right)=x\left(0\right)$. The complex
cepstrum is:
\begin{align*}
\hat{x}\left(n\right)&=
\frac{1}{2\pi\imath}\ointctrclockwise_{C}\left[\log K +
\log\left(1-az^{-1}\right)+ \log\left(1-bz\right)\right]z^{n-1}dz
\end{align*}
Applying Cauchy's integral lemma and the series expansion
$\log\left(1+z\right)=\sum_{k=1}^{\infty}\left(-1\right)^{k+1}\frac{z^{k}}{k}$,
where $\left|z\right|<1$:
\begin{align*}
\hat{x}\left(n\right) &= \begin{cases}
  -\frac{a^{n}}{n} , & n>0 \\
  \log K , & n=0 \\
  \frac{b^{n}}{n} , & n<0
\end{cases}
\end{align*}
This example demonstrates the motivation for using the cepstrum to find a
minimum-phase spectral factor: if $\boldsymbol{x}$ is minimum-phase then
the cepstrum, $\boldsymbol{\hat{x}}$, is causal. Similarly, if $\boldsymbol{x}$
is maximum-phase then the cepstrum is anti-causal.

The complex cepstrum is related to the original sequence, $\boldsymbol{x}$, by
a recursion. In the z-domain:
\begin{align*}
  \frac{d}{dz}\hat{X}\left(z\right)&=
  \frac{1}{X\left(z\right)}\frac{d}{dz}X\left(z\right)\\
  \left[-z\frac{d}{dz}\hat{X}\left(z\right)\right] X\left(z\right) &=
  -z\frac{d}{dz}X\left(z\right)
\end{align*}
So, in the time domain:
\begin{align*}
  n\hat{x}\left(n\right) \star x\left(n\right) &= nx\left(n\right)
\end{align*}
In other words:
\begin{align}
x\left(n\right) &= \begin{cases}
e^{ \hat{x}\left(0\right)}  & n=0\\
\sum_{k=-\infty}^{\infty}\frac{k}{n}\hat{x}\left(n\right)x\left(n-k\right) & n\neq 0
\end{cases}\label{eqn:Cepstral-recursion}
\end{align}
\paragraph{Using the cepstrum to find the minimum-phase spectral factor}
Given a bounded-real transfer function $H\left(z\right)$ of order $N$, the
z-transform of the magnitude-squared complementary filter is:
\begin{align*}
  F\left(z\right)&=1-\left|H\left(z\right)\right|^{2}
  =1-H^{\mathconj}\left(z\right)H\left(z\right)
\end{align*}
where $\mathconj$ means \emph{complex conjugate transpose}.
By construction, $F\left(z\right)$ is real, even,
$0\le F\left(e^{\imath\omega}\right) \le 1$ and any zeros of $F\left(z\right)$ 
on the unit circle are double zeros. If $F\left(z\right)$ has zeros on the unit
circle, then $\hat{F}\left(z\right)=\log F\left(z\right)$ is not defined at
those zeros. However we can make use of the z-transform
\begin{align*}
  X\left(\alpha z\right) &=
  \sum_{n=-\infty}^{\infty} \alpha^{-n}x\left(n\right)z^{-n}
\end{align*}
to calculate the cepstrum over a contour that is slightly outside the unit
circle. In this case, $F\left(\alpha z\right)$ is real and even so that,
by construction, the cepstrum, $\hat{f}_{\alpha}\left(n\right)$, is real and
even. Therefore the causal part of the cepstrum is
\begin{align*}
  \hat{h}_{\alpha}\left(n\right) &=\begin{cases}
  \frac{\hat{f}_{\alpha}\left(n\right)}{2} & n = 0\\
  \hat{f}_{\alpha}\left(n\right) & n > 0\\
  0 & n < 0
  \end{cases}
\end{align*}
and the impulse response of the minimum-phase spectral factor is
$h\left(n\right)=\alpha^{n}h_{\alpha}\left(n\right)$ where
$h_{\alpha}\left(n\right)$ is found from the recursion given above in
Equation~\ref{eqn:Cepstral-recursion}. Unfortunately this method fails if
$F\left(\alpha z\right)$ is not positive.

\paragraph{A simple example}
Here is \emph{Octave} code for a simple example recovering the minimum-phase
spectral factor from a magnitude-squared filter with double zeros on the unit
circle\footnote{Note that the Octave convention is that the polynomial
  $\left[a\; b\; c\right]$ corresponds to the z-transform $a+bz^{-1}+cz^{-2}$ so
  the zero-phase squared-magnitude response calculated by \emph{freqz} must be
  scaled by a denominator polynomial $z^{-N}$.}:
\needspace{21\baselineskip}
\begin{small}
\begin{verbatim}
% Construct a minimum phase example with zeros on the unit circle
a1=[1 -1 0.5];a2=[1 -0.5];a3=[1 0 0.81];a4=[1 -1];a5=[1 -sqrt(2) 1];
a=conv(conv(conv(conv(a1,a2),a3),a4),a5);
% Construct the squared-magnitude filter for a contour of |z|=alpha
Na=length(a)-1;
alpha=1.05;
aalpha=a.*(alpha.^[0:-1:-Na]);
asq=conv(fliplr(aalpha),aalpha);
% The zero-phase squared-magnitude frequency response is real, positive and even
Hasq=freqz(asq,[zeros(1,Na) 1],4096,"whole");
Hasq=real(Hasq);
% The cepstrum is real and even
hhatasq=ifft(log(Hasq));
hhatasq=real(hhatasq(:)');
% Use the causal part of the cepstrum
ha=zeros(1,Na+1);
ha(1)=exp(hhatasq(1)/2);
for n=2:(Na+1)
  ha(n)=sum([1:(n-1)].*hhatasq(2:n).*fliplr(ha(1:(n-1))))/(n-1);
endfor
% Recover the original minimum-phase impulse response 
h=ha.*(alpha.^[0:Na]);
\end{verbatim}
\end{small}
\subsubsection{\label{app:Minimum-phase-complementary-filter-semidefinite-duality}\emph{Sturm}'s example of minimum phase spectral factorisation by semi-definite programming}
\emph{Sturm}~\cite[Equation 13, Section 3.2]{Sturm_SeDuMiUserGuide_GitHub} claims
that the solution to the following semi-definite programming problem is a
minimum phase spectral factorisation, $x_{k}$, of an autocovariance sequence,
$r_{k}$:
\begin{align*}
  \textbf{minimise}  \quad& \sum_{l=1}^{m}\left(m-l\right)x_{l,l} \\
  \textbf{subject to}\quad& \sum_{l=1}^{m-k}x_{l,l+k}=r_{k}\quad k=0,\hdots,m-1\\
                     \quad& X \succ 0
\end{align*}
where $X$ is a symmetric matrix with elements $x_{k,l}$.
Unfortunately, \emph{Sturm}'s reference justifying this statement is not
accessible but the associated website states that similar work is described by
\emph{Dumitrescu et
  al.}~\cite{DumitrescuTabusStoica_PositiveRealSequenceMAParameter} and 
\emph{Dumitrescu}~\cite{Dumitrescu_BoundedRealLemma_FIR}.

\emph{Sturm} contributed a spectral factorisation example to the 7'th DIMACS
challenge~\cite{DIMACS_7_FILTER_minphase}. It is reproduced as the Octave script
\emph{sedumi\_minphase\_test.m} which solves the following problem:
\begin{align*}
  \begin{split}
    \textbf{minimise}  \quad& \sum_{l=1}^{n}r_{l}y_{l} \\
    \textbf{subject to}\quad&  
    \mathtpltz{\left[y_{1},\frac{1}{2}y_{2},\hdots,\frac{1}{2}y_{n}\right]}
    - \mathdiag{\left[n-1,\hdots,1,0\right]} \succeq 0
  \end{split}
\end{align*}
I have reversed the sign of the term in $\left[n-1,\hdots,1,0\right]$ so that the
zeros of the complementary filter are inside the unit-circle.

\subsubsection{\label{app:Tuqan-Vaidyanathan-SDP-solution}\emph{Tuqan} and \emph{Vaidyanathan}'s semi-definite programming solution}
\emph{Tuqan} and
\emph{Vaidyanathan}~\cite{TuqanVaidyanathan_StateSpaceFIREnergyCompaction}
propose a state-space approach to solving the optimisation problem:
\begin{align*}
  \begin{split}
    \textbf{maximise}  \quad&
    \int_{-\pi}^{\pi}\mathabs{H\left(e^{\imath\omega}\right)}^{2}
    W\left(e^{\imath\omega}\right) \\
    \textbf{subject to}\quad&  
    \frac{1}{M}\sum_{k=0}^{M-1}
    \mathabs{H\left(e^{\imath\left(\omega-2\pi{}k\right)/M}\right)}^{2}
    = \mathabs{H\left(e^{\imath\omega}\right)}^{2}\rvert_{\downarrow{}M}
  \end{split}
\end{align*}
$H\left(\omega\right)$ is an order $N$ FIR filter, known as the \emph{compaction
  filter}, and $W\left(\omega\right)$ is a weighting function. $M$ is the
decimation factor applied to the output of the filter $H\left(z\right)$.
$H\left(z\right)$ is to be used in an orthonormal filter-bank with
$H_{k}\left(e^{\imath\omega}\right)H_{l}\left(e^{\imath\omega}\right)=\delta_{k-l}$.
Assume that the input to the filter is a zero-mean Gaussian noise sequence,
$x_{n}$, with power spectrum $S_{xx}\left(e^{\imath\omega}\right)$,
autocorrelation sequence, $r_{n}$, that the output sequence is $y_{n}$ and that
$F\left(z\right)=H\left(z\right)H\left(z^{-1}\right)$.
Setting $W\left(\omega\right)=S_{xx}\left(\omega\right)$, the objective
function is the variance of the output sequence:
\begin{align*}
  \sigma_{y}^{2}&= r_{0}+2\sum_{n=1}^{N}f_{n}r_{n}
\end{align*}
and the constraints are:
\begin{align*}
  f_{Mn} &= \delta_{n} \\
  F\left(\omega\right) &= 1+2\sum_{n=1}^{N}f_{n}\cos\omega{}n \; \ge 0 \;
                         \forall \omega
\end{align*}

Suppose $D\left(z\right)$ is implemented as a direct form FIR filter with the
state space representation:
\begin{align*}
  A_{d} &=\left[\begin{array}{cc}
          0 & I \\
          0 & 0 \end{array}\right] \\
  B_{d} &= \left[\begin{array}{cccc}
                   0 & 0 & \cdots & 1 \end{array}\right]^{\top} \\
  C_{d} &= \left[\begin{array}{ccc}
                   f_{N} & \cdots & f_{1} \end{array}\right] \\
  D_{d} &= \frac{1}{2}
\end{align*}

The \emph{discrete time positive real lemma}, a corollary of the
\emph{Kalman-Yakubovitch-Popov lemma}, states that $D\left(z\right)$ is positive
real if-and-only-if there exists a real, symmetric, positive definite matrix,
$P_{d}$, and real matrixes $W_{d}$ and $L_{d}$ such that:
\begin{align*}
  P_{d}-A_{d}^{\top}P_{d}A_{d} &= L_{d}^{\top}L_{d} \\
  C_{d}-A_{d}^{\top}P_{d}B_{d} &= L_{d}^{\top}W_{d} \\
  D_{d}+D_{d}^{\top}-B_{d}^{\top}P_{d}B_{d} &= W_{d}^{\top}W_{d} \\
\end{align*}

By substitution~\cite[Theorem 1]{TuqanVaidyanathan_StateSpaceFIREnergyCompaction}
$H\left(z\right)=W_{d}+L_{d}\left(zI-A_{d}^{-1}\right)B_{d}$ is seen to be a
spectral factor of $F\left(z\right)$. The minimum phase solution,
$H_{min}\left(z\right)$, is that for which $P _{d_{min}}$ is the minimum element
of the convex set of symmetric positive definite matrixes satisfying the
LMI. \emph{Tuqan} and \emph{Vaidyanathan} show~\cite[Theorem 
3]{TuqanVaidyanathan_StateSpaceFIREnergyCompaction} that, if
$D_{d}+D_{d}^{\top}-B_{d}^{\top}P_{d}B_{d}\ne{}0$, then $P_{d_{min}}$ is the
unique solution of the following \emph{algebraic Riccati equation}:
\begin{align*}
  P_{d}&=A_{d}^{\top}P_{d}A_{d}+\left(C_{d}^{\top}-A_{d}^{\top}P_{d}B_{d}\right)
         \left(D_{d}+D_{d}^{\top}-B_{d}^{\top}P_{d}B_{d}\right)^{-1}
         \left(C_{d}^{\top}-A_{d}^{\top}P_{d}B_{d}\right)^{\top}
\end{align*}
or:
\begin{align*}
  P_{d}&=A_{1}^{\top}P_{d}A_{1}+
A_{1}^{\top}P_{d}B_{d}\left(R-B_{d}^{\top}P_{d}B_{d}\right)^{-1}B_{d}^{\top}P_{d}A_{1} +
         C_{d}^{\top}R^{-1}C_{d} \\
  A_{1}&=A_{d}-B_{d}R^{-1}C_{d} \\
  R &= D_{d}+D_{d}^{\top} \succ 0
\end{align*}
In this case, the autocorrelation function, $\left\{D_{d},C_{d}\right\}$, of the
complementary filter is known in advance and the initial semi-definite
programming solution for $P_{d}$ and $C_{d}$ is not required. In addition, the
filter is known to be SISO so that, for the minimum phase
solution, $H_{min}\left(z\right)$: 
\begin{align*}
  W_{d}&=\left(D_{d}+D_{d}^{\top}-B_{d}^{\top}P_{d_{min}}B_{d}\right)^{\frac{1}{2}}  \\
  L_{d}&=W_{d}^{-1}\left(C_{d}-B_{d}^{\top}P_{d_{min}}A_{d}\right)
\end{align*}
\clearpage
\subsection{Example: the minium-phase complementary filter of an FIR bandpass filter}
The Octave script \emph{minphase\_test.m} compares the use of 
\emph{Orchard} and \emph{Willson}'s Newton-Raphson method with the cepstral
method of \emph{Mian} and \emph{Nainer}. The script uses both methods to find
the minimum-phase complementary filter for an FIR bandpass filter designed with
the Octave \emph{remez} function. The filter specification is:
\begin{small}
\verbatiminput{minphase_test_spec.m}
\end{small}
The combined response of the bandpass filter
and the complementary filter found by the Newton-Raphson method is allpass to 
within an order of magnitude of the machine precision ($eps=2.2204e-16$).
The bandpass and complementary filters are:
\begin{small}
  \verbatiminput{minphase_test_brz_coef.m}
  \verbatiminput{minphase_test_brzc_coef.m}
\end{small}
The reflection coefficients of the bandpass and complementary filters are:
\begin{small}
  \verbatiminput{minphase_test_k_coef.m}
  \verbatiminput{minphase_test_khat_coef.m}
\end{small}
Figure~\ref{fig:minphase-simulated-response} shows the simulated FIR lattice 
bandpass and complementary filter amplitude responses.
Figure~\ref{fig:minphase-brzc-zeros} shows the zeros of the complementary filter.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{minphase_test_simulated_response}}
\caption{Simulated amplitude responses of the FIR lattice band-pass filter and
  the minimum-phase complementary filter found with the Newton-Raphson method
  of \emph{Orchard} and
  \emph{Willson}~\cite{OrchardWillson_ComputationMinimumPhaseSpectralFactor}.} 
\label{fig:minphase-simulated-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{minphase_test_brzc_zeros}}
\caption{Zeros of the complementary filter found with the Newton-Raphson method
  of \emph{Orchard} and
  \emph{Willson}~\cite{OrchardWillson_ComputationMinimumPhaseSpectralFactor}.}
\label{fig:minphase-brzc-zeros}
\end{figure}
\clearpage
Unfortunately, in the case of the cepstral method, $F\left(\alpha z\right)$
with $\alpha \approx 1.15$ is real and even but not positive. Fortuitously, when
using $\alpha=1$ with a long FFT the sampling grid did not include the filter
zeros. Response aliasing due to the discontinuities in
$\log F\left(\alpha z\right)$ gave a result that was less accurate than that
obtained with \emph{minphase.m} but was still acceptable. The combined amplitude
response found with the cepstral method is shown in
Figure~\ref{fig:Mian-Nainer-cepstral-combined-response}.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{minphase_test_cepstral_combined_response}}
\caption{Combined amplitude responses of the FIR band-pass filter and the
  minimum-phase complementary filter found with the cepstral method of
  \emph{Mian} and
  \emph{Nainer}~\cite{MianNainer_FastDesignEquiRippleMinimumPhaseFIR}.}
\label{fig:Mian-Nainer-cepstral-combined-response}
\end{figure}

The Octave script \emph{directFIRnonsymmetric\_sdp\_minimum\_phase\_test.m}
finds the complementary filter by following the semi-definite programming
method of \emph{Sturm}~\cite[Section 3.2]{Sturm_SeDuMiUserGuide_GitHub}.
Figure~\ref{fig:Sturm-FIR-sdp-combined-response} shows the resulting combined
response.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRnonsymmetric_sdp_minimum_phase_test_hg_response}}
\caption{Combined amplitude responses of the FIR band-pass filter and the
  complementary filter found with the semi-definite programming method of
  \emph{Sturm}~\cite[Section 3.2]{Sturm_SeDuMiUserGuide_GitHub}.}
\label{fig:Sturm-FIR-sdp-combined-response}
\end{figure}

The Octave script \emph{tuqanFIRnonsymmetric\_dare\_minimum\_phase\_test.m}
attempts to find the complementary filter by following the Riccati equation
method of \emph{Tuqan} and \emph{Vaidyanathan}~\cite[Equation
38]{TuqanVaidyanathan_StateSpaceFIREnergyCompaction}. 
The Riccati equation is solved with the \emph{dare} function from the
Octave-Forge \emph{control} toolbox~\cite{OctaveForge_ControlPackage}.
Figure~\ref{fig:tuqan-FIR-dare-g-response} shows the resulting complementary
filter response.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{tuqanFIRnonsymmetric_dare_minimum_phase_test_g_response}}
\caption{Response of the complementary FIR filter found with the Riccati
  equation method of \emph{Tuqan} and \emph{Vaidyanathan}~\cite[Equation
  38]{TuqanVaidyanathan_StateSpaceFIREnergyCompaction}.}
\label{fig:tuqan-FIR-dare-g-response}
\end{figure}

\clearpage
\subsection{Estimating the MA coefficients of a filtered noise sequence}
This Section follows the description by \emph{Dumitrescu et
  al}~\cite{DumitrescuTabusStoica_PositiveRealSequenceMAParameter} of the
estimation of the MA (or FIR) coefficients of a filtered noise sequence. It is
intended to provide some justification for \emph{Sturm}'s spectral
factorisation example shown in
Section~\ref{app:Minimum-phase-complementary-filter-semidefinite-duality}.

\subsubsection{Autocovariance of a noise sequence}
Suppose we have $N$ samples, $\hat{x}_{l}$ of a real valued
stationary random time series, $x_{l}$:
\begin{align*}
  \hat{x}_{l}&=\begin{cases}
    x_{l} & 1\le l \le N \\
    0 & \text{otherwise} \\
  \end{cases}
\end{align*}
An estimate of the autocovariance\footnote{\emph{covariance} and
  \emph{correlation} are similar concepts. \emph{correlation} is unit-less and
  varies between $-1$ and $1$.} of $\hat{x}_{l}$ is\footnote{Note that for
  $0\le k<N$:
  \begin{align*}
  \hat{r}_{-k} &=\frac{1}{N}\sum_{l=1}^{N}\hat{x}_{l}\hat{x}_{l-k}
               =\frac{1}{N}\sum_{l=1-k}^{N-k}\hat{x}_{l+k}\hat{x}_{l}
               =\frac{1}{N}\sum_{l=1}^{N-k}x_{l+k}x_{l}
  \end{align*}
  }:
\begin{align*}
  \hat{r}_{k}
  &=\frac{1}{N}\sum_{l=1}^{N}\hat{x}_{l}\hat{x}_{l+\mathabs{k}}\\
  &=\begin{cases}
    \frac{1}{N}\sum_{l=1}^{N-\mathabs{k}}
    x_{l}x_{l+\mathabs{k}} & \mathabs{k} < N\\
    0 & \text{otherwise}\\
    \end{cases}
\end{align*}

The expectation, or mean, of this estimate is:
\begin{align*}
  \mathcal{E}\left\{\hat{r}_{k}\right\}
  &=\frac{1}{N}\sum_{l=1}^{N-\mathabs{k}}
    \mathcal{E}\left\{x_{l}x_{l+\mathabs{k}}\right\} \\
  &=\begin{cases}
    \left(N-\mathabs{k}\right)r_{k} & \mathabs{k} < N \\
    0 & \text{otherwise} \\
    \end{cases}
\end{align*}
where $r_{k}$ is the autocovariance function of $x_{l}$.
This definition of the estimator of the autocovariance, $\hat{r}_{k}$, is
biased because $\mathcal{E}\left\{\hat{r}_{k}\right\} \ne r_{k}$.
An unbiased estimator is:
\begin{align*}
  \check{r}_{k}&= \frac{1}{N-\mathabs{k}}\sum_{l=1}^{N-\mathabs{k}}
                 x_{l}x_{l+\mathabs{k}}\quad\mathabs{k} < N
\end{align*}
\subsubsection{Autocovariance of the response of an FIR filter to white noise}
Given an FIR filter transfer function,
$H\left(z\right)=\sum_{k=0}^{n}h_{k}z^{-k}$, with
$y_{k}=\sum_{l=0}^{n}h_{l}e_{k-l}$ where $e_{k}$ is zero mean, unit variance,
white Gaussian noise, then the autocovariance sequence of $y_{k}$
is~\cite[Equation 2 II]{DumitrescuTabusStoica_PositiveRealSequenceMAParameter}:
\begin{align*}
r_{k} &= \mathcal{E}\left\{y_{m}y_{m-k}\right\} \\
&=\mathcal{E}\left\{\sum_{l=0}^{n}h_{l}e_{m-l}\sum_{p=0}^{n}h_{p}e_{m-k-p}\right\}\\
&=\mathcal{E}\left\{\sum_{l=0}^{n}\sum_{p=0}^{n}h_{l}h_{p}e_{m-l}e_{m-k-p}\right\}\\
&=\sum_{l=0}^{n}\sum_{p=-k}^{n-k}h_{l}h_{p+k}\mathcal{E}\left\{e_{m-l}e_{m-p}\right\}\\
&= \sum_{l=0}^{n-k}h_{l}h_{l+k} \\
&= \sum_{l=k}^{n}h_{l}h_{l-k} \\
&= h^{\top}A_{k}h \\
&= \mathtrace{A_{k}hh^{\top}}
\end{align*}
for $k=0,\hdots,n$, $r_{-k}=r_{k}$, $r_{k}=0$ for $\mathabs{k}>n$,
$h=\left[h_{0},h_{1},\hdots,h_{n}\right]$ and $A_{k}$ denotes the matrix with
unit entries on the $k$th diagonal.

\subsubsection{Spectral factorisation of the autocovariance sequence}
The following constraints on the polynomial
$R\left(z\right)=\sum_{k=-n}^{n}r_{k}z^{-k}$ are equivalent~\cite[Section
II]{DumitrescuTabusStoica_PositiveRealSequenceMAParameter}: 
\begin{itemize}
\item $R\left(z\right)$ has a spectral factorisation
  $R\left(z\right)=H\left(z\right)H\left(-z\right)$ 
\item the positiveness of $R\left(e^{\imath\omega}\right)$ is equivalent to
  the real positiveness of
  \begin{align*}
    R_{+}\left(e^{\imath\omega}\right)=\Re\left\{\frac{r_{0}}{2}+
    \sum_{k=1}^{n}r_{k}e^{-\imath{}k\omega}\right\}\ge 0
  \end{align*}
\item the \emph{positive real} condition on a polynomial
\begin{align*}
R_{+}\left(z\right) = \frac{r_{0}}{2}+\sum_{k=1}^{n}r_{k}z^{-k}
\end{align*}
is defined, for the trace parameterisation, as $r_{k}=\mathtrace{A_{k}Q}$ where
$Q$ is an $\left(n+1\right)\times\left(n+1\right)$ positive semi-definite
matrix.
\end{itemize}
\emph{Dumitrescu et al.} remark that, since $Q$ is positive semidefinite, it
may be expressed as $Q=GG^{\top}$ where
$G\in\mathbb{R}^{\left(n+1\right)\times\nu}$, $\nu=\mathrank{Q}$ and 
$G\left(z\right)$ represents an infinite family of SIMO spectral factors of
$R\left(z\right)$. 

\subsubsection{Primal formulation of the covariance estimation problem}
\emph{Dumitrescu et
  al.}~\cite{DumitrescuTabusStoica_PositiveRealSequenceMAParameter} show 
algorithms for estimating the MA (or FIR) parameters of a noisy 
sequence. In this Section I follow \emph{Dumitrescu et al.}'s treatment of the,
so-called, \emph{trace parameterisation}\footnote{The main purpose of their
  paper is to show that the trace parameterisation is equivalent to a
  \emph{Kalman-Yakubovich-Popov} lemma parameterisation. In addition they
  describe the \emph{primal} and \emph{dual} solutions for each
  parameterisation.}. \emph{Dumitrescu et al.} begin by defining a
\emph{positive real} sequence $r_{k}$:
\begin{align*}
  r_{0}+\sum_{k=1}^{n}r_{k}\cos k\omega \ge 0
\end{align*}
for all $\omega\in\left[0,\pi\right]$ and $r_{k}\in\mathbb{R}$.
Given $N$ samples of the filter output $y_{1},\hdots,y_{N}$, the covariance
estimates
\begin{align*}
  \hat{r}_{k} = \frac{1}{N}\sum_{l=k+1}^{N}y_{l}y_{l-k}
\end{align*}
have variance-covariances~\cite[Section II]{Stoica_MAEstimationPolynomialTime}
$\mathcal{E}\left\{\left[\hat{r}_{k}-r_{k}\right]
  \left[\hat{r}_{l}-r_{l}\right]\right\}$,
which can be approximated by~\cite[Equation
B.48]{SoderstromStoica_SystemIdentification}:
\begin{align}
  \label{eqn:Dumitrescu-variance-covariance-estimation}
  \hat{W}_{kl} \approx \frac{1}{N^{2}}\sum_{m=-n}^{n}\left(N-\mathabs{m}\right)
  \left[\hat{r}_{m}\hat{r}_{m+k-l}+\hat{r}_{m-l}\hat{r}_{m+k}\right]
\end{align}
where $k,l=0,1,\hdots$ and $N\gg n$.

\emph{Dumitrescu et al.}~\cite[Section
III]{DumitrescuTabusStoica_PositiveRealSequenceMAParameter} define the
$\left(n+n_{\gamma}+1\right)\times\left(n+n_{\gamma}+1\right)$ matrix $\hat{W}$
with entries $\hat{W}_{kl}$ and the vectors
$\hat{r}=\left[\hat{r}_{0},\hdots,\hat{r}_{n}\right]$ and
$\hat{\gamma}=\left[\hat{r}_{n+1},\hdots,\hat{r}_{n+n_{\gamma}}\right]$. Following
\emph{Stoica et al.}~\cite[Equation 7]{Stoica_MAEstimationPolynomialTime},
they propose the weighted least squares fitting criterion:
\begin{align*}
  f=\frac{1}{2}\left[\begin{array}{c}
                       \hat{r}-r \\
                       \hat{\gamma}\end{array}\right]^{\top}
  \hat{W}^{-1}\left[\begin{array}{c}
                      \hat{r}-r \\
                      \hat{\gamma}\end{array}\right]
\end{align*}
and suggest that $n_{\gamma}=\sqrt{N}$. If $\hat{W}$ is partitioned as
\begin{align*}
  \hat{W}&=\left[\begin{array}{cc}
                      \hat{W}_{11}       & \hat{W}_{12} \\
                      \hat{W}_{12}^{\top} & \hat{W}_{22} \end{array}\right]
\end{align*}
where $\hat{W}_{11}$ is $\left(n+1\right)\times\left(n+1\right)$, then the
fitting criterion becomes:
\begin{align*}
  f&=\frac{1}{2}\left(r-\tilde{r}\right)^{\top}\Gamma^{-1}\left(r-\tilde{r}\right)
     + \text{ const.}
\end{align*}
where
\begin{align*}
  \tilde{r}&=\hat{r}-\hat{W}_{12}\hat{W}_{22}^{-1}\hat{\gamma} \\
  \Gamma &= \hat{W}_{11}-\hat{W}_{12}\hat{W}_{22}^{-1}\hat{W}_{12}^{\top}
\end{align*}
In the trace parameterisation, the problem of estimating the covariances
becomes~\cite[Equation
17]{DumitrescuTabusStoica_PositiveRealSequenceMAParameter}:
\begin{align}
  \label{eqn:Covariance-esimation-trace-param-primal}
  \begin{split}
  \textbf{minimise}  \quad& 
  \frac{1}{2}\left(r-\tilde{r}\right)^{\top}\Gamma^{-1}\left(r-\tilde{r}\right)\\ 
  \textbf{subject to}\quad& r_{k}=\mathtrace{A_{k}Q},\quad k=0,\hdots,n\\
                     \quad& Q \succ 0
  \end{split}
\end{align}

\subsubsection{Dual formulation of the covariance estimation problem}
The Lagrangian of the primal problem is
\begin{align*}
  L\left(r,Q,\mu,X\right)
  &=f\left(r\right)-\mathtrace{XQ}+
    \sum_{k=0}^{n}\mu_{k}\left(\mathtrace{A_{k}Q}-r_{k}\right) \\
  &=f\left(r\right)+
    \mathtrace{\left[-X+
    \left(\sum_{k=0}^{n}\mu_{k}A_{k}\right)Q\right]}-\mu^{\top}r\\
  &=f\left(r\right)+
    \frac{1}{2}\mathtrace{\left[-2X+
    \left(\sum_{k=0}^{n}\mu_{k}\left(A_{k}+A_{k}^{\top}\right)\right)Q\right]}
    -\mu^{\top}r
\end{align*}
where the positive semidefinite symmetric matrix, $X$, is the Lagrange
multiplier for the linear matrix inequality $Q\succeq{}0$. Differentiating
the Lagrangian with respect to $r$:
\begin{align*}
  \frac{\partial{}L\left(r,Q,\mu,X\right)}{\partial{}r}
  &= \Gamma^{-1}\left(r-\tilde{r}\right)-\mu
\end{align*}
so that the solution to the primal problem is $r^{\star}=\tilde{r}+\Gamma\mu$.
The terms of the Lagrangian in $r$ are bounded from below by
\begin{align*}
  f\left(r^{\star}\right)
  &=\frac{1}{2}\mu^{\top}\Gamma\mu - \mu^{\top}\left(\Gamma\mu+\tilde{r}\right)\\
  &=-\frac{1}{2}\mu^{\top}\Gamma\mu - \mu^{\top}\tilde{r}
\end{align*}
The Lagrangian is affine in the elements of $Q$ so that the dual function
is defined to be
\begin{align*}
  g\left(X,\mu\right)
  &=\inf_{r,Q} L\left(r,Q,\mu,X\right) \\
  &=\begin{cases}
    -\frac{1}{2}\mu^{\top}\Gamma\mu - \mu^{\top}\tilde{r} &
    \text{if } X=\frac{1}{2}\sum_{k=0}^{n}\mu_{k}\left(A_{k}+A_{k}^{\top}\right)\\
    -\infty & \text{otherwise}
                 \end{cases}
\end{align*}
If $\Gamma$ has the Cholesky decomposition $\Gamma=G^{\top}G$, then
\begin{align*}
  \frac{1}{2}\mu^{\top}\Gamma\mu+\mu^{\top}\tilde{r}
  &=\frac{1}{2}\left(G\mu+G^{-\top}\tilde{r}\right)^{\top}
    \left(G\mu+G^{-\top}\tilde{r}\right)
    -\frac{1}{2}\tilde{r}^{\top}\Gamma^{-1}\tilde{r}
\end{align*}
The dual problem is~\cite[Equations 24 and
47]{DumitrescuTabusStoica_PositiveRealSequenceMAParameter}: 
\begin{align}
  \label{eqn:Covariance-esimation-trace-param-dual}
  \begin{split}
  \textbf{minimise}  \quad& \eta\\
  \textbf{subject to}\quad& \mathnorm{G\mu+G^{-\top}\tilde{r}}\le\eta \\
  \quad& X\left(\mu\right)=\mathtpltz{
    \left[\mu_{0},\frac{1}{2}\mu_{1},\hdots,\frac{1}{2}\mu_{n}\right]}\succeq 0
  \end{split}
\end{align}
The sign of the objective is reversed to get a minimisation problem.

\emph{Dumitrescu et al.} refer to an approach for fast solutions of SDP problems
with Toeplitz 
LMIs~\cite{GeninNesterovVanDooren_OptimizationOverPositivePolyMatrices}.
\emph{Dumitrescu et al.} suggest spectral factorisation of $r^{\star}$
  by solving a Ricatti equation. This appears to refer to the method proposed by
  \emph{Tuqan} and \emph{Vaidyanathan}~\cite[Theorem
  3]{TuqanVaidyanathan_StateSpaceFIREnergyCompaction}. Also see \emph{Sayed} and
  \emph{Kailath}~\cite[Section 5]{SayedKailath_SurveySpectralFactorization}.

\emph{Dumitrescu et al.}~\cite[Theorem
2 and Section IV]{DumitrescuTabusStoica_PositiveRealSequenceMAParameter} show
that the primal solution pair $\left\{r^{\star},Q^{\star}\right\}$ and the
dual solution $\mu^{\star}$ have the following strong duality properties
\begin{align}
  \label{eqn:Covariance-estimation-primal-dual-properties}
  \begin{split}
  \frac{1}{2}\left(\tilde{r}-r^{\star}\right)^{\top}\Gamma^{-1}
  \left(\tilde{r}-r^{\star}\right)
  &= -\frac{1}{2}\mu^{\star\top}\Gamma\mu^{\star}-\mu^{\star\top}\tilde{r}\\
  r^{\star}&=\Gamma\mu^{\star}+\tilde{r}\\
  X\left(\mu^{\star}\right)Q^{\star}&=0 \\
  \mu^{\star\top}r^{\star}&=0
  \end{split}
\end{align}
\emph{Dumitrescu et al.}\ note that the FIR parameter vector, $h^{\star}$, is an
eigenvector of $X\left(\mu^{\star}\right)$, corresponding to the eigenvalue $0$.

\subsubsection{An example}
The Octave script \emph{dumitrescu\_MA\_estimation\_test.m}
attempts to implement the, so-called, CFD solution of \emph{Dumitrescu et
 al.}~\cite[Equation 47]{DumitrescuTabusStoica_PositiveRealSequenceMAParameter}
described above. The specifications of the original filter and estimation
procedure are:
\begin{small}
\verbatiminput{dumitrescu_MA_estimation_test_spec.m}
\end{small}
Figures~\ref{fig:dumitrescu-MA-estimation-response}
and~\ref{fig:dumitrescu-MA-estimation-zeros} show the
amplitude responses and zeros, respectively, of the original FIR filter and the
estimated filter found by the CFD semi-definite programming method. The
minimum-phase filter was calculated with the method of \emph{Orchard} and
\emph{Willson} shown previously in
Section~\ref{app:Orchard-Willson-Newton-Raphson-solution}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{dumitrescu_MA_estimation_test_response}}
\caption{Amplitude responses of the example FIR filter and the estimated
  filter found with \emph{Dumitrescu et al.}'s CFD semi-definite programming
  method.}
\label{fig:dumitrescu-MA-estimation-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{dumitrescu_MA_estimation_test_zeros}}
\caption{Zeros of the example FIR filter and the estimated filter found with
  \emph{Dumitrescu et al.}'s CFD semi-definite programming method.}
\label{fig:dumitrescu-MA-estimation-zeros}
\end{figure}
I found that:
\begin{itemize}
\item for zero radiuses $Rz=0.9$, $\tilde{r}$ is positive and $r^{\star}=\tilde{r}$
\item for zero radiuses $Rz=0.98$:
  \begin{itemize}
  \item $\tilde{r}$ is not positive
  \item the limits on $l$ in
    Equation~\ref{eqn:Dumitrescu-variance-covariance-estimation} are widened to
    $l=\pm{}\left(n+n_{\gamma}\right)$ so that $\hat{W}_{kl}$ is
    positive-definite and SOCP estimation is possible 
  \end{itemize}
\item for zero radiuses $Rz=0.99$ $r^{\star}$ has zeros very close to the
  unit-circle and \emph{minphase} fails
\end{itemize}
\clearpage
\subsection{\label{sec:FIR-lattice-bandpass-Hilbert-filter}Design of a complementary FIR lattice band-pass Hilbert filter}
The Octave script
\emph{complementaryFIRlattice\_socp\_slb\_bandpass\_hilbert\_test.m}
designs a PCLS optimised FIR lattice Hilbert band-pass filter with order
$16$. The filter specification is:
\begin{small}
\verbatiminput{complementaryFIRlattice_socp_slb_bandpass_hilbert_test_spec.m}
\end{small}
The initial filter is the band-pass filter designed by the Octave script
\emph{iir\_sqp\_slb\_fir\_17\_bandpass\_test.m} in gain-pole-zero form. The
corresponding initial minimum-phase FIR lattice filters  were calculated by the
Octave function \emph{complementaryFIRlattice}.

Figure~\ref{fig:Zeros-initial-band-pass-hilbert-FIR-and-complementary-filter}
shows the zeros of the initial FIR lattice band-pass and complementary filters.

\begin{figure}
\begin{subfigure}[b]{\textwidth}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{complementaryFIRlattice_socp_slb_bandpass_hilbert_test_initial_b0_pz}}
\caption{Zeros of the initial FIR lattice band-pass Hilbert filter.}
\end{subfigure}
\begin{subfigure}[b]{\textwidth}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{complementaryFIRlattice_socp_slb_bandpass_hilbert_test_initial_bc0_pz}}
\caption{Zeros of the initial FIR lattice band-pass Hilbert complementary filter.}
\end{subfigure}
\caption{Zeros of the initial FIR lattice band-pass Hilbert filter and the complementary
 filter.}
\label{fig:Zeros-initial-band-pass-hilbert-FIR-and-complementary-filter}
\end{figure}


The PCLS optimised filter lattice coefficients are:
\begin{small}
\verbatiminput{complementaryFIRlattice_socp_slb_bandpass_hilbert_test_k2_coef.m}
\end{small}
and:
\begin{small}
\verbatiminput{complementaryFIRlattice_socp_slb_bandpass_hilbert_test_khat2_coef.m}
\end{small}
The corresponding direct-form FIR band-pass Hilbert filter coefficients are:
\begin{small}
\verbatiminput{complementaryFIRlattice_socp_slb_bandpass_hilbert_test_Nh2_coef.m}
\end{small}
Figure~\ref{fig:Response-PCLS-optimised-FIR-lattice-band-pass-Hilbert-filter}
shows the amplitude, phase and delay responses of the PCLS optimised FIR lattice
band-pass Hilbert filter. The phase response shown is adjusted for the nominal
delay.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{complementaryFIRlattice_socp_slb_bandpass_hilbert_test_pcls_response}}
\caption{Response of the PCLS optimised FIR lattice band-pass Hilbert
filter. The phase response shown is adjusted for the nominal delay.}
\label{fig:Response-PCLS-optimised-FIR-lattice-band-pass-Hilbert-filter}
\end{figure}
The FIR lattice band-pass Hilbert filter was simulated with a uniformly
distributed random noise input. The standard-deviations of the $16$ states are: 
\begin{small}
\verbatiminput{complementaryFIRlattice_socp_slb_bandpass_hilbert_test_std_xxk2.m}
\end{small}
Figure~\ref{fig:Zeros-PCLS-band-pass-hilbert-FIR-and-complementary-filter}
shows the zeros of the PCLS optimised FIR lattice band-pass Hilbert filter and
the complementary filter. The FIR lattice filters need not be minimum-phase.
\begin{figure}
\begin{subfigure}[b]{\textwidth}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{complementaryFIRlattice_socp_slb_bandpass_hilbert_test_pcls_Nh2_pz}}
\caption{Zeros of the PCLS optimised FIR lattice band-pass Hilbert filter.}
\end{subfigure}
\begin{subfigure}[b]{\textwidth}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{complementaryFIRlattice_socp_slb_bandpass_hilbert_test_pcls_Ng2_pz}}
\caption{Zeros of the PCLS optimised FIR lattice band-pass Hilbert filter
  complementary filter.}
\end{subfigure}
\caption{Zeros of the PCLS optimised FIR lattice band-pass Hilbert filter and
  the complementary filter.}
\label{fig:Zeros-PCLS-band-pass-hilbert-FIR-and-complementary-filter}
\end{figure}

\clearpage
\section{\label{app:Unconstrained-opt-FIR-digital-filters-SOCP}Design of FIR digital filters with unconstrained optimisation  of the piece-wise mean-squared error of the response}
An FIR filter with zero-phase amplitude response
$A\left(\omega\right)$, piece-wise constant desired amplitudes,
$A_{k}$, and weights, $W_{k}$, over frequency regions
$\Omega_{k}\subset\left[0,\pi\right]$, has piece-wise mean-squared-error:
\begin{align*}
  \mathcal{E}_{k}^{2} &= \frac{1}{\pi}\int_{\Omega_{k}}W_{k}
    \left[A\left(\omega\right)-A_{k}\right]^{2}d\omega
\end{align*}
If $\boldsymbol{h}$ is a vector containing the FIR filter impulse response, then
the weighted sum of the piece-wise mean-squared-errors, $\mathcal{E}^{2}$, is a
quadratic form:
\begin{align}
  \label{eqn:mean-squared-error-quadratic-form}
  \mathcal{E}^{2}&=\boldsymbol{h}^{\top}\boldsymbol{Q}\boldsymbol{h}+
                   2\boldsymbol{q}\boldsymbol{h}+c
\end{align}

In this section I give examples of the optimisation of $\mathcal{E}^{2}$ without
constraints on the response of the FIR filter. The examples show optimisation
with the Octave \texttt{qp} function. In each case \texttt{qp} objective
function is the mean-squared-error quadratic form shown in
Equation~\ref{eqn:mean-squared-error-quadratic-form} and there are no \texttt{qp}
constraints. I consider symmetric and non-symmetric FIR filters and
usually assume that the filters are even-order and odd-length. 
\subsection{Zero-phase  transfer functions of symmetric FIR filters}
\subsubsection{Zero-phase transfer functions of even-order symmetric FIR filters}
The transfer function of an even order, $N=2M$, odd length, $2M+1$,
symmetric FIR filter is:  
\begin{align*}
  H\left(z\right) &= \sum_{n=0}^{2M}h_{n}z^{-n} \\
  &= \sum_{n=0}^{M-1}h_{n}z^{-n} + h_{M}z^{-M} + \sum_{n=M+1}^{2M}h_{n}z^{-n} \\
  &= z^{-M}\left\{h_{M}+\sum_{n=0}^{M-1}h_{n}\left[ z^{M-n}+z^{-M+n}\right]\right\}
\end{align*}
where $h_{n}=h_{N-n}$. The zero-phase amplitude response is:
\begin{align*}
  A\left(\omega\right)
  &=h_{M}+\sum^{M-1}_{n=0}2h_{n}\cos\left[\left(M-n\right)\omega\right]
\end{align*}
\subsubsection{Zero-phase transfer functions of odd-order symmetric FIR filters}
The transfer function of an odd-order, even-length, $N=2M-1$, symmetric FIR
filter is: 
\begin{align*}
  H\left(z\right)
  &= \sum_{n=0}^{2M-1}h_{n}z^{-n} \\
  &= \sum_{n=0}^{M-1}h_{n}z^{-n} + \sum_{n=M}^{2M-1}h_{n}z^{-n} \\
  &= \sum_{n=0}^{M-1}h_{n}\left[z^{-n}+z^{n-\left(2M-1\right)}\right]\\
  &= z^{-M+\frac{1}{2}}
    \sum_{n=0}^{M-1}h_{n}\left[z^{-n+M-\frac{1}{2}} + z^{n-M+\frac{1}{2}}\right]
\end{align*}
where $h_{n}=h_{N-1-n}$ and $N=2M-1$. The zero-phase amplitude response is:
\begin{align*}
  A\left(\omega\right)
  &=2\sum^{M-1}_{n=0}h_{n}\cos\left[\left(M-\frac{1}{2}-n\right)\omega\right]
\end{align*}
\subsubsection{Zero-phase transfer functions of anti-symmetric FIR Hilbert filters}
The frequency response of an ideal Hilbert transform filter
is~\cite[pp.790-792]{OppenheimSchafer_DiscreteTimeSignalProcessing}:
\begin{align*}
  H\left(\omega\right) &= \begin{dcases}
    -\imath & \phantom{-}0<\omega<\pi \\
    \phantom{-}\imath & -\pi<\omega<0
    \end{dcases}
\end{align*}

The corresponding impulse response is:
\begin{align*}
  \hat{h}_{k} &= \frac{1}{2\pi}\int^{0}_{-\pi}\imath e^{\imath \omega k}d\omega-
  \frac{1}{2\pi}\int^{\pi}_{0}\imath e^{\imath{}\omega k}d\omega \\
  &=\begin{dcases}
  \frac{2}{\pi k}\sin{}^{2}\frac{\pi k}{2} & k \ne 0 \\
  0 & k = 0
  \end{dcases}
\end{align*}
Clearly $\hat{h}_{k}=-\hat{h}_{-k}$ and $\hat{h}_{2k}=0$.

If the FIR Hilbert filter is truncated to even order $4M-2$ and odd length
$4M-1$, then there are $M$ distinct coefficients, the group-delay of the filter
is $2M-1$ samples and the z-transform of the filter is:  
\begin{align*}
  H\left(z\right)
  &=z^{-2M+1}\sum_{k=-2M+1}^{2M-1}\hat{h}_{k}z^{-k}\\
  &=z^{-2M+1}\sum_{k=1}^{2M-1}\hat{h}_{k}\left[z^{-k}-z^{k}\right]\\
  &=z^{-2M+1}\sum_{k=1}^{M}\hat{h}_{2k-1}\left[z^{-2k+1}-z^{2k-1}\right]\\
  &=z^{-2M+1}\sum_{k=0}^{M-1}\hat{h}_{2k+1}\left[z^{2k+1}-z^{-2k-1}\right] \\
  &=z^{-2M+1}\sum_{k=0}^{M-1}h_{2M-2k-2}\left[z^{2k+1}-z^{-2k-1}\right]
\end{align*}
where $h_{k}=\hat{h}_{-2M+1+k}$, $h_{2M-1+k}=\hat{h}_{k}$ and
$\hat{h}_{2k+1}=-\hat{h}_{-2k-1}=-h_{2M-2k-2}$. 
The zero-phase amplitude response of the even order FIR Hilbert filter is:
\begin{align}
  \begin{split}
  A\left(\omega\right) &= 2\sum_{k=0}^{M-1}h_{2M-2k-2}\sin\left(2k+1\right)\omega\\
  &= 2\sum_{k=0}^{M-1}h_{2k}\sin\left(2M-2k-1\right)\omega                
  \end{split}
  \label{eqn:Even-order-FIR-Hilbert-amplitude-response}
\end{align}

Similarly, the distinct coefficients of an odd order $2M-1$, even length $2M$,
FIR Hilbert filter are $\hat{h}_{k}$ with
$k=\frac{1}{2},\frac{3}{2},\hdots,M-\frac{1}{2}$:
\begin{align*}
  H\left(z\right)
  &=z^{-M+\frac{1}{2}}\sum_{k=-M+\frac{1}{2}}^{M-\frac{1}{2}}\hat{h}_{k}z^{-k}\\
  &=z^{-M+\frac{1}{2}}\sum_{k=\frac{1}{2}}^{M-\frac{1}{2}}\hat{h}_{k}
    \left[z^{-k}-z^{k}\right]\\
  &=z^{-M+\frac{1}{2}}\sum_{k=0}^{M-1}\hat{h}_{k+\frac{1}{2}}
    \left[z^{-k-\frac{1}{2}}-z^{k+\frac{1}{2}}\right]\\
  &=z^{-M+\frac{1}{2}}\sum_{k=0}^{M-1}h_{M-1-k}
    \left[z^{k+\frac{1}{2}}-z^{-k-\frac{1}{2}}\right]
\end{align*}
where $h_{k}=\hat{h}_{-M+\frac{1}{2}+k}$ and
$h_{M-1-k}=-\hat{h}_{k+\frac{1}{2}}$. The zero-phase amplitude response is:
\begin{align}
  \begin{split}
  A\left(\omega\right)
  &= 2\sum_{k=0}^{M-1}h_{M-1-k}\sin\left(2k+1\right)\frac{\omega}{2} \\
  &= 2\sum_{k=0}^{M-1}h_{k}\sin\left(2M-2k-1\right)\frac{\omega}{2}
\end{split}
  \label{eqn:Odd-order-FIR-Hilbert-amplitude-response}
\end{align}
Note that, in practice, the odd order $h_{k}$ is interpolated with zeros and
Equation~\ref{eqn:Odd-order-FIR-Hilbert-amplitude-response} and 
Equation~\ref{eqn:Even-order-FIR-Hilbert-amplitude-response} are effectively
identical.

\subsection{Piece-wise mean-squared-error of the response of an FIR filter}
\subsubsection{Piece-wise mean-squared-error of the response of a symmetric FIR filter}
If impulse response of a symmetric FIR
filter is $\boldsymbol{h}=\left[h_{0}, \ldots ,h_{M}\right]^{\top}$ then:
\begin{align*}
  \int A\left(\omega\right)d\omega
  &=h_{M}\omega+2\sum_{n=0}^{M-1}h_{n}\frac{\sin\left(M-n\right)\omega}{M-n}  
\end{align*}
and:
\begin{align*}
  \int A\left(\omega\right)^{2}d\omega =
  & h_{M}^{2}\omega
   -4h_{M}\sum_{n=0}^{M-1}h_{n}\frac{\sin\left(M-n\right)\omega}{M-n}\quad\ldots\\
  & +2\sum_{n=0}^{M-1}\sum_{m=0}^{M-1}h_{n}h_{m}
    \frac{\sin\left(2M-m-n\right)\omega}{2M-m-n}
    +2\sum_{n=0}^{M-1}h_{n}^{2}\omega
    +2\sum_{n=0}^{M-1}\sum_{m=0,m\ne n}^{M-1}h_{n}h_{m}
    \frac{\sin\left(n-m\right)\omega}{n-m}
\end{align*}
Similarly, the gradient of the mean-squared error with respect to the
coefficients is:
\begin{align*}
  \frac{\partial\mathcal{E}}{\partial h_{n}} 
  &= \frac{2}{\pi}\int_{\Omega_{k}}W_{k}
    \left[A\left(\omega\right)-A_{k}\right]
    \frac{\partial A\left(\omega\right)}{\partial h_{n}}d\omega
\end{align*}
which can be expressed in the form
$2\boldsymbol{q}+2\boldsymbol{Q}\boldsymbol{h}$. The components of
$\boldsymbol{q}$ and $\boldsymbol{Q}$ are found with:
\begin{align*}
  \int \frac{\partial A\left(\omega\right)}{\partial h_{n}}d\omega
  &= \begin{dcases}
    2\frac{\sin\left(M-n\right)\omega}{M-n}  & n=0, \ldots ,M-1 \\
    \omega & n=M
    \end{dcases}
\end{align*}
and:
\begin{align*}
  \int A\left(\omega\right)
  \frac{\partial A\left(\omega\right)}{\partial h_{n}}d\omega
&= \begin{dcases}
 2\sum_{m=0}^{M}h_{m}\frac{\sin\left(2M-m-n\right)\omega}{2M-m-n}
 +2h_{n}\omega+2\sum_{m=0,m\ne n}^{M-1}h_{m}\frac{\sin\left(n-m\right)\omega}{n-m} &
 n=0,\ldots,M-1 \\
 h_{M}\omega +2\sum_{m=0}^{M-1}h_{m}\frac{\sin\left(M-m\right)\omega}{M-m} & n=M
\end{dcases}
\end{align*}
since, for $n=0,\ldots ,M-1$:
\begin{align*}
 \int A\left(\omega\right)\cos\left(M-n\right)\omega\;d\omega &=
 \sum_{m=0}^{M}h_{m}\int\cos\left(2M-m-n\right)\omega\;d\omega 
 + \sum_{m=0}^{M-1}h_{m}\int\cos\left(n-m\right)\omega\;d\omega
\end{align*}

The Octave function \emph{directFIRsymmetricEsqPW} implements the piece-wise
calculation of $\mathcal{E}^{2}$, and its gradients with respect to the
coefficients, $h_{n}$, of a symmetric FIR filter.
\subsubsection{Piece-wise mean-squared-error of the response of a non-symmetric FIR
  filter}
If the impulse response of a non-symmetric filter is 
$\boldsymbol{h}=\left[h_{0}, \ldots ,h_{N}\right]^{\top}$ and the nominal
FIR filter delay, $0<d_{k}<N$, is an integral number of samples,
then the mean-squared-error over each frequency region $\Omega_{k}$ is:
\begin{align*}
  \mathcal{E}_{k}^{2}
  &=\frac{1}{\pi}\int_{\Omega_{k}} W_{k}\left| H\left(\omega\right)-
    A_{k}e^{-\imath{}d_{k}\omega} \right|^{2}d\omega\\
  &=\frac{1}{\pi}\int_{\Omega_{k}}W_{k}\left[\sum_{n=0}^{N}h_{n}e^{-\imath{}n\omega}-
    A_{k}e^{-\imath{}d_{k}\omega}\right]
    \left[\sum_{n=0}^{N}h_{n}e^{\imath{}n\omega}-
    A_{k}e^{\imath{}d_{k}\omega}\right]
    d\omega\\
  &=\frac{1}{\pi}\int_{\Omega_{k}}W_{k}\left[
    \sum_{n=0}^{N}\sum_{m=0}^{N}h_{n}h_{m}\cos \left(n-m\right)\omega
    -2A_{k}\sum_{n=0}^{N}h_{n}\cos\left(n-d_{k}\right)\omega +
    A_{k}^{2}\right]d\omega\\
  &=\frac{1}{\pi}W_{k}\left[\omega\sum_{n=0}^{N}h_{n}^{2}
 + \sum_{m=0}^{N}\sum_{m=0,m\ne{}n}^{N}h_{n}h_{m}
    \frac{\sin\left(n-m\right)\omega}{n-m}
 -2 A_{k}h_{d_{k}}\omega
 -2A_{k}\sum_{n=0,n\ne{}d_{k}}^{N}h_{n}\frac{\sin\left(n-d_{k}\right)\omega}{n-d_{k}}
 +A_{k}^{2}\omega\right]_{\Omega_{k}}
\end{align*}
In stop bands the nominal delay, $d_{k}$, is assumed to be zero. 
The Octave function \emph{directFIRnonsymmetricEsqPW.m} calculates the
piece-wise calculation of $\mathcal{E}^{2}$, and its gradients
with respect to the coefficients, $h_{n}$, of a non-symmetric FIR filter.
\subsubsection{Piece-wise mean-squared-error of the response of an anti-symmetric FIR
  Hilbert filter}
The piece-wise mean-squared-error of the response of an anti-symmetric FIR
Hilbert filter is calculated in a similar fashion to that of a symmetric FIR
filter. The Octave function \emph{directFIRhilbertEsqPW} implements the
piece-wise calculation of $\mathcal{E}^{2}$, and its gradients with respect to
the coefficients, $h_{n}$, of an anti-symmetric FIR Hilbert filter.
\subsection{Examples of the design of  FIR filters with unconstrained optimisation}

\subsubsection{Design of  FIR low-pass filters with unconstrained optimisation}
The Octave script \emph{qp\_lowpass\_filter.m} uses
\texttt{qp} to design a low-pass filter with unconstrained optimisation.
The filter specification is similar to a \emph{Parks-McClellan} low-pass filter
example~\cite[Table
I]{ParksMcClellan_ChebyshevApproxNonRecursiveDigitalFilters}. The filter is
designed as both a symmetric FIR filter and a non-symmetric filter with nominal
delay $M/2$ samples. The filter specification is:
\begin{small}
\verbatiminput{qp_lowpass_test_spec.m}
\end{small}

Figure~\ref{fig:qp_symmetric_FIR_lowpass_response} shows the amplitude
response of the symmetric FIR filter. The symmetric FIR filter coefficients are:
\begin{small}
\verbatiminput{qp_lowpass_test_h_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{qp_lowpass_test_h_response}}
\caption{Amplitude response of a symmetric FIR low-pass filter designed
  with unconstrained optimisation.}
\label{fig:qp_symmetric_FIR_lowpass_response}
\end{figure}

For comparison, Figure~\ref{fig:mcclellan_FIR_lowpass_response} shows the
response of a symmetric FIR filter designed with the \emph{Parks-McClellan}
algorithm shown in Appendix~\ref{sec:Parks-McClellan-mini-max-FIR} implemented
by the Octave function \emph{mcclellanFIRsymmetric}. The filter distinct filter
coefficients are:
\begin{small}
\verbatiminput{qp_lowpass_test_hPM_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{qp_lowpass_test_hPM_response}}
\caption{Amplitude response of a symmetric FIR low-pass filter designed
  with the Parks-McClellan algorithm.}
\label{fig:mcclellan_FIR_lowpass_response}
\end{figure}

Figure~\ref{fig:qp_nonsymmetric_FIR_lowpass_response} shows the
amplitude and group delay responses of the non-symmetric low-pass FIR filter
with nominal delay $M/2$ samples. The non-symmetric FIR filter coefficients are:
\begin{small}
\verbatiminput{qp_lowpass_test_hd_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{qp_lowpass_test_hd_response}}
\caption{Amplitude and group delay responses of a non-symmetric FIR low-pass
  filter designed with unconstrained optimisation.}
\label{fig:qp_nonsymmetric_FIR_lowpass_response}
\end{figure}

\subsubsection{Design of  FIR band-pass filters with unconstrained optimisation}
The Octave script \emph{qp\_bandpass\_test.m} uses
\texttt{qp} to design a band-pass filter with unconstrained optimisation.
The filter is designed as both a symmetric FIR filter and a non-symmetric filter
with nominal delay $M/2$ samples. The filter specification is:
\begin{small}
\verbatiminput{qp_bandpass_test_spec.m}
\end{small}

Figure~\ref{fig:qp_symmetric_FIR_bandpass_response} shows the amplitude
response of the symmetric FIR filter. The symmetric FIR filter coefficients are:
\begin{small}
\verbatiminput{qp_bandpass_test_h_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{qp_bandpass_test_h_response}}
\caption{Amplitude response of a symmetric FIR band-pass filter designed
  with unconstrained optimisation.}
\label{fig:qp_symmetric_FIR_bandpass_response}
\end{figure}

For comparison, Figure~\ref{fig:mcclellan_FIR_bandpass_response} shows the
response of a symmetric FIR filter designed with the \emph{Parks-McClellan}
algorithm shown in Appendix~\ref{sec:Parks-McClellan-mini-max-FIR} implemented
by the Octave function \emph{mcclellanFIRsymmetric}. The filter distinct filter
coefficients are:
\begin{small}
\verbatiminput{qp_bandpass_test_hPM_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{qp_bandpass_test_hPM_response}}
\caption{Amplitude response of a symmetric FIR band-pass filter designed
  with the Parks-McClellan algorithm.}
\label{fig:mcclellan_FIR_bandpass_response}
\end{figure}

Figure~\ref{fig:qp_nonsymmetric_FIR_bandpass_response} shows the
amplitude and group delay responses of the non-symmetric band-pass FIR filter
with nominal delay $M/2$ samples. The non-symmetric FIR filter coefficients are:
\begin{small}
\verbatiminput{qp_bandpass_test_hd_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{qp_bandpass_test_hd_response}}
\caption{Amplitude and group delay responses of a non-symmetric FIR band-pass
  filter designed with unconstrained optimisation.}
\label{fig:qp_nonsymmetric_FIR_bandpass_response}
\end{figure}
\clearpage
\subsubsection{Design of  an anti-symmetric FIR Hilbert filter with unconstrained
  optimisation}
The Octave script \emph{qp\_hilbert\_filter.m} uses
\texttt{qp} to design an anti-symmetric FIR Hilbert filter with unconstrained
optimisation. The filter specification is:
\begin{small}
\verbatiminput{qp_hilbert_test_spec.m}
\end{small}

Figure~\ref{fig:qp_antisymmetric_FIR_Hilbert_response} shows the amplitude
response of the anti-symmetric FIR Hilbert filter. The distinct filter
coefficients are:
\begin{small}
\verbatiminput{qp_hilbert_test_hM_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{qp_hilbert_test_response}}
\caption{Amplitude response of an anti-symmetric FIR Hilbert filter designed
  with unconstrained optimisation.}
\label{fig:qp_antisymmetric_FIR_Hilbert_response}
\end{figure}
\clearpage
\section{\label{app:PCLS-design-symmetric-FIR-digital-filters-Lagrange-multipliers}PCLS design of symmetric FIR digital filters with Lagrange multipliers}
This section describes peak-constrained-least-squares (PCLS) design of
non-symmetric FIR filters with optimisation by Lagrange multipliers and the
exchange algorithm of \emph{Selesnick}, \emph{Lang} and
\emph{Burrus}~\cite{SelesnickLangBurrus_ConstrainedLeastSquareFIRFilters}.
In the following, I will almost always consider odd-length, even-order,
symmetric FIR filters.

Given a desired amplitude response, $A_{d}\left(\omega\right)$, and a weight
function, $W\left(\omega\right)$, the mean-squared-error of the amplitude
response of the FIR filter is:
\begin{align*}
  \mathcal{E}
  &= \frac{1}{\pi}\int_{0}^{\pi}W\left(\omega\right)
    \left[A\left(\omega\right)-A_{d}\left(\omega\right)\right]^{2}d\omega
\end{align*}

The design problem is to minimise the mean-squared-error subject to
constraints on the amplitude response:
\begin{align*}
  A\left(\omega_{p}\right) &\ge L\left(\omega_{p}\right) \\
  A\left(\omega_{q}\right) &\le U\left(\omega_{q}\right)
\end{align*}

The method of \emph{Lagrange multipliers} defines a \emph{Lagrangian} function:
\begin{align*}
  \mathcal{L}\left(\omega\right) &=  \mathcal{E}
-\sum_{p}\lambda_{p}\left[A\left(\omega_{p}\right)-L\left(\omega_{p}\right)\right]
-\sum_{q}\lambda_{q}\left[U\left(\omega_{q}\right)-A\left(\omega_{q}\right)\right]
\end{align*}
where $\lambda_{p}$ and $\lambda_{q}$ are the \emph{Lagrange multipliers} for
the amplitude constraints at the corresponding frequencies $\omega_{p}$ and
$\omega_{q}$.  The method of Lagrange multipliers minimises
$\mathcal{E}$ subject to the constraints by solving the
following system of equations for $h_{n}$, $\lambda_{p}$ and $\lambda_{q}$:
\begin{align*}
  \frac{\partial\mathcal{E}}{\partial h_{n}} 
-\sum_{p}\lambda_{p}\frac{\partial A\left(\omega_{p}\right)}{\partial h_{n}}
+\sum_{q}\lambda_{q}\frac{\partial A\left(\omega_{q}\right)}{\partial h_{n}}&=0\\
  A\left(\omega_{p}\right) &= L\left(\omega_{p}\right) \\
  A\left(\omega_{q}\right) &= U\left(\omega_{q}\right)
\end{align*}
where:
\begin{align*}
  \frac{\partial\mathcal{E}}{\partial h_{n}} 
  &= \frac{2}{\pi}\int_{0}^{\pi}W\left(\omega\right)
    \left[A\left(\omega\right)-A_{d}\left(\omega\right)\right]
    \frac{\partial A\left(\omega\right)}{\partial h_{n}}d\omega
\end{align*}
and, for an even-order, symmetric, FIR filter:
\begin{align*}
  \frac{\partial A\left(\omega\right)}{\partial h_{n}} &= \begin{cases}
    2\cos\left(M-n\right)\omega & n=0, \ldots ,M-1 \\
    1 & n=M 
    \end{cases}
\end{align*}

The minimisation problem can be written in matrix form as:
\begin{align}
\left[\begin{array}{cc}
\boldsymbol{R} & \boldsymbol{G}^{\top}\\
\boldsymbol{G} & \boldsymbol{0}
\end{array}\right] 
\left[\begin{array}{c}
        \boldsymbol{h} \\
        \boldsymbol{\lambda}
\end{array}\right] &=
\left[\begin{array}{c}
        \boldsymbol{C} \\
        \boldsymbol{D}
      \end{array}\right]
\label{eqn:Design-constrained-FIR-digital-filters-Lagrange-Multipliers}
\end{align}
where $\boldsymbol{R}$ is a symmetric matrix. The solution is:
\begin{align*}
  \boldsymbol{\lambda}
  &= \left(\boldsymbol{G}\boldsymbol{R^{-1}}\boldsymbol{G}^{\top}\right)^{-1}
    \left(\boldsymbol{G}\boldsymbol{R^{-1}}\boldsymbol{C}-\boldsymbol{D}\right)\\
  \boldsymbol{h}
  &= \boldsymbol{R^{-1}} 
     \left(\boldsymbol{C}-\boldsymbol{G^{\top}}\boldsymbol{\lambda}\right)
\end{align*}

When the Lagrange multipliers are non-negative,
$\lambda_{p},\lambda_{q}\ge 0$, then the \emph{Karush-Kuhn-Tucker} conditions
guarantee that the equality-constrained problem also solves the
inequality-constrained problem. The exchange algorithm of \emph{Selesnick et
  al.} solves successive minimisation problems with constraints on the peaks
of the response. If any Lagrange multipliers are negative at some iteration
then the corresponding constraint frequencies are sequentially dropped so that
an inequality-constrained problem is solved.

\subsection{\label{app:Examples-design-symmetric-FIR-band-pass-filter}Examples of the design of constrained least-squared error symmetric FIR filters with
optimisation by the method of Lagrange multipliers}
This section shows examples of the design of an even-order, symmetric, FIR
filter by the exchange algorithm described by \emph{Selesnick et 
al.}~\cite[p.498]{SelesnickLangBurrus_ConstrainedLeastSquareMultiBandFIRFilters}
and summarised in Section~\ref{sub:Choice-of-Active-Constraints}.
\subsubsection{\label{app:Design-symmetric-FIR-low-pass-filter}Design of a
  constrained least-squared error symmetric FIR low-pass filter}
The Octave script \emph{directFIRsymmetric\_slb\_lowpass\_test.m}
implements the design of an even-order symmetric FIR low-pass filter with
constraints on the amplitude response by the method of Lagrange multipliers. The
matrix equation shown above in
Equation~\ref{eqn:Design-constrained-FIR-digital-filters-Lagrange-Multipliers}
is solved by left division in the Octave function
\emph{directFIRsymmetric\_mmsePW} and the exchange algorithm of
\emph{Selesnick et al.} is implemented by the Octave function
\emph{directFIRsymmetric\_slb}. The low-pass filter specification is:
\begin{small}
\verbatiminput{directFIRsymmetric_slb_lowpass_test_spec.m}
\end{small}
The bandwidth of the constrained low-pass filter is slightly narrower than that
of the initial unconstrained filter. The amplitude responses of the initial
and optimised low-pass filters are shown in
Figure~\ref{fig:Symmetric_FIR_lowpass_response}. The distinct optimised filter
coefficients are:
\begin{small}
\verbatiminput{directFIRsymmetric_slb_lowpass_test_hM1_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_slb_lowpass_test_response}}
\caption{Amplitude response of the initial FIR low-pass filter
  and the optimised low-pass FIR filter designed
  with Lagrange multipliers and the exchange algorithm of
  \emph{Selesnick et al.}\;.}
\label{fig:Symmetric_FIR_lowpass_response}
\end{figure}

Figure~\ref{fig:Symmetric_FIR_lowpass_truncated} shows the initial response
and the response obtained when one coefficient of the floating-point solution is
rounded and the remaining coefficients are optimised with the pass-band ripple
constraint relaxed.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_slb_lowpass_test_truncated}}
\caption{Amplitude response of the initial FIR low-pass filter
  and the optimised band pass FIR filter designed
  with one coefficient rounded and the remaining coefficients optimised by
  the Lagrange multipliers and the exchange algorithm of
  \emph{Selesnick et al.}\;.}
\label{fig:Symmetric_FIR_lowpass_truncated}
\end{figure}
\clearpage
\subsubsection{\label{app:Design-symmetric-FIR-band-pass-filter}Design of a
  constrained least-squared error symmetric FIR band-pass filter}
Similarly to the previous example, the Octave script
\emph{directFIRsymmetric\_slb\_bandpass\_test.m} implements the design of an
even-order symmetric FIR band-pass filter with constraints on the amplitude
response by the method of Lagrange multipliers. The band-pass filter
specification is:
\begin{small}
\verbatiminput{directFIRsymmetric_slb_bandpass_test_spec.m}
\end{small}
Figure~\ref{fig:Symmetric_FIR_bandpass_response} shows the amplitude responses
of the initial and optimised band-pass filters. The distinct optimised filter
coefficients are:
\begin{small}
\verbatiminput{directFIRsymmetric_slb_bandpass_test_hM1_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_slb_bandpass_test_response}}
\caption{Amplitude response of the initial FIR band-pass filter
  and the optimised band-pass FIR filter designed
  with Lagrange multipliers and the exchange algorithm of
  \emph{Selesnick et al.}\;.}
\label{fig:Symmetric_FIR_bandpass_response}
\end{figure}
Figure~\ref{fig:Symmetric_FIR_bandpass_truncated} shows the initial response
and the response obtained when three coefficients of the floating-point solution
are rounded and the remaining coefficients are optimised with the stop-band
ripple constraint relaxed.
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_slb_bandpass_test_truncated}}
\caption{Amplitude response of the initial FIR band-pass filter
  and the optimised band-pass FIR filter designed
  with three coefficients rounded and the remaining coefficients optimised by
  Lagrange multipliers and the exchange algorithm of
  \emph{Selesnick et al.}\;.}
\label{fig:Symmetric_FIR_bandpass_truncated}
\end{figure}
\subsubsection{\label{app:Design-even-order-FIR-Hilbert-filter}Design of a
  least-mean-squared error even-order FIR Hilbert filter} 
The design problem is to minimise the mean-squared-error subject to
constraints on the zero-phase amplitude response of the Hilbert filter:
\begin{align*}
  \mathcal{E}  &= \frac{1}{\pi}\int_{0}^{\pi}W\left(\omega\right)
  \left[A\left(\omega\right)+1\right]^{2}d\omega \\
  A\left(\omega_{p}\right) &\ge L\left(\omega_{p}\right) \\
  A\left(\omega_{q}\right) &\le U\left(\omega_{q}\right)
\end{align*}
where $Ad\left(\omega\right)=-1$.

In a similar fashion to that shown in
Appendix~\ref{app:PCLS-design-non-symmetric-FIR-filters-SOCP},
the method of \emph{Lagrange multipliers} optimises the mean-squared-error
by solving the following system of equations for $\lambda_{p}$, $\lambda_{q}$
and the coefficients of an even order $4M-2$ Hilbert filter,
$h_{2k}$, with $k=0,1,\hdots,M-1$:
\begin{align*}  
  \frac{\partial\mathcal{E}}{\partial h_{2k}} 
-\sum_{p}\lambda_{p}\frac{\partial A\left(\omega_{p}\right)}{\partial h_{2k}}
+\sum_{q}\lambda_{q}\frac{\partial A\left(\omega_{q}\right)}{\partial h_{2k}}
&=0 \\
  A\left(\omega_{p}\right) &= L\left(\omega_{p}\right) \\
  A\left(\omega_{q}\right) &= U\left(\omega_{q}\right)
\end{align*}
where:
\begin{align*}
  \frac{\partial\mathcal{E}}{\partial h_{2k}} 
  &= \frac{2}{\pi}\int_{0}^{\pi}W\left(\omega\right)
  \left[A\left(\omega\right)+1\right]
    \frac{\partial A\left(\omega\right)}{\partial h_{2k}}d\omega
\end{align*}
and:
\begin{align*}
  \frac{\partial A\left(\omega\right)}{\partial h_{2k}} &=
    2\sin\left(2M-2k-1\right)\omega
\end{align*}

This system of equations can be expressed in matrix form with components given
by:~\footnote{$2\sin{}x\sin{}y=\cos\left(x-y\right)-\cos\left(x+y\right)$}
\begin{align*}
  \int \frac{\partial A\left(\omega\right)}{\partial h_{2k}}d\omega
  &= -2\frac{\cos\left(2M-2k-1\right)\omega}
       {\left(2M-2k-1\right)}\\
  \int A\left(\omega\right)
  \frac{\partial A\left(\omega\right)}{\partial h_{2k}}d\omega
  &= 2h_{2k}\omega
    +2\sum_{l=0,l\ne k}^{M-1}h_{2l}\frac{\sin\left(2k-2l\right)\omega}{2k-2l}
  -2\sum_{l=0}^{M-1}h_{2l}\frac{\sin\left(4M-2k-2l-2\right)\omega}{4M-2k-2l-2}
\end{align*}

The Octave script \emph{directFIRhilbert\_slb\_test.m} implements
the design of an FIR Hilbert filter with constraints on the
amplitude response by the method of Lagrange multipliers. The matrix equation
shown above in
Equation~\ref{eqn:Design-constrained-FIR-digital-filters-Lagrange-Multipliers}
is solved by left division in the Octave function
\emph{directFIRhilbert\_mmsePW} and the PCLS exchange algorithm of
\emph{Selesnick et al.} is implemented by the Octave function
\emph{directFIRhilbert\_slb}. The FIR Hilbert filter specification is:
\begin{small}
\verbatiminput{directFIRhilbert_slb_test_spec.m}
\end{small}
The group delay of the filter is $2M-1$ samples. The bandwidth of the constrained
Hilbert filter is slightly wider than that of the initial unconstrained
filter. The absolute value of the PCLS pass-band response is constrained to be
less than $1$. Figure~\ref{fig:Symmetric_FIR_Hilbert_response} shows the
amplitude responses of the initial and optimised Hilbert filters. The FIR
Hilbert filter pass-band response is symmetrical about the frequency $0.25$,
where the sampling rate is normalised to $1$. The distinct optimised filter
coefficients are:
\begin{small}
\verbatiminput{directFIRhilbert_slb_test_hM2_coef.m}
\end{small}
The corresponding FIR filter is:
\begin{small}
\begin{verbatim}
h=kron([hM2(:);-flipud(hM2(:))],[1;0])(1:(end-1));
\end{verbatim}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRhilbert_slb_test_response}}
\caption{Amplitude response of the initial FIR Hilbert filter and the
  optimised FIR Hilbert filter designed with Lagrange
  multipliers and the exchange algorithm of \emph{Selesnick et al.}\;.}
\label{fig:Symmetric_FIR_Hilbert_response}
\end{figure}
\clearpage
\subsubsection{\label{app:Design-even-order-FIR-Hilbert-bandpass-filter}Design of a least-mean-squared error even-order FIR Hilbert band-pass filter}
The Octave script \emph{directFIRhilbert\_bandpass\_slb\_test.m} designs an FIR
Hilbert filter with a band-pass response. The corresponding filter specification
is:
\begin{small}
\verbatiminput{directFIRhilbert_bandpass_slb_test_spec.m}
\end{small}
Figure~\ref{fig:Symmetric_FIR_Hilbert_bandpass_response} shows the amplitude
responses of the initial and optimised band-pass Hilbert filters
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRhilbert_bandpass_slb_test_response}}
\caption{Amplitude response of the initial band-pass FIR Hilbert filter and the
  optimised FIR Hilbert bandpass filter designed with Lagrange
  multipliers and the exchange algorithm of \emph{Selesnick et al.}\;.}
\label{fig:Symmetric_FIR_Hilbert_bandpass_response}
\end{figure}
Figure~\ref{fig:Symmetric_FIR_Hilbert_bandpass_passband_response} shows
the pass-band responses. The distinct optimised filter coefficients are: 
\begin{small}
\verbatiminput{directFIRhilbert_bandpass_slb_test_hM2_coef.m}
\end{small}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRhilbert_bandpass_slb_test_passband_response}}
\caption{Pass-band amplitude response of the initial band-pass FIR Hilbert filter
  and the optimised FIR Hilbert bandpass filter designed with 
  Lagrange multipliers and the exchange algorithm of \emph{Selesnick et al.}\;.}
\label{fig:Symmetric_FIR_Hilbert_bandpass_passband_response}
\end{figure}
\clearpage
\section{\label{app:PCLS-design-non-symmetric-FIR-filters-SOCP}PCLS design of non-symmetric FIR filters with SOCP}
This section describes peak-constrained-least-squares (PCLS) design of
non-symmetric FIR filters with SOCP optimisation and the exchange algorithm
of \emph{Selesnick}, \emph{Lang} and
\emph{Burrus}~\cite{SelesnickLangBurrus_ConstrainedLeastSquareFIRFilters}.
The results of this section are, of course, also applicable to the design of
symmetric FIR filters.
\subsection{\label{app:Frequency-response-gradients-nonsymmetric-FIR}Frequency
response and gradients of a non-symmetric FIR filter}
The complex frequency response of an order $N$ non-symmetric FIR filter with
coefficients $h_{k}$ is:
\begin{align*}
H\left(\omega\right)&=\sum_{k=0}^{N}h_{k}e^{-\imath{}k\omega}
\end{align*}
\subsubsection{Squared magnitude response of a non-symmetric FIR filter}
The squared magnitude response is differentiable. The squared magnitude response
of a non-symmetric FIR filter is:
\begin{align*}
\mathabs{H\left(\omega\right)}^{2}
&=H\left(\omega\right)^{\mathconj}H\left(\omega\right)\\
&= \left(\sum_{l=0}^{N}h_{l}e^{\imath{}l\omega}\right) 
   \left(\sum_{k=0}^{N}h_{k}e^{-\imath{}k\omega}\right) \\
&= \sum_{l=0}^{N}\sum_{k=0}^{N}h_{l}h_{k}\left(\cos{}l\omega\cos{}k\omega+
                                           \sin{}l\omega\sin{}k\omega\right) \\
&= \sum_{l=0}^{N}\sum_{k=0}^{N}h_{l}h_{k}\cos\left(l-k\right)\omega
\end{align*}
The gradient with respect to $h_{k}$ of the squared magnitude of a non-symmetric
FIR filter is:
\begin{align*}
\frac{\partial\mathabs{H\left(\omega\right)}^{2}}{\partial h_{k}}
  &= e^{\imath{}k\omega}\sum_{l=0}^{N}h_{l}e^{-\imath{}l\omega}
  + e^{-\imath{}k\omega}\sum_{l=0}^{N}h_{l}e^{\imath{}l\omega} \\
  &=2\sum_{l=0}^{N}h_{l}\cos\left(l-k\right)\omega
\end{align*}
The calculation of the squared magnitude response of a non-symmetric FIR filter
is implemented in the Octave function \emph{directFIRnonsymmetricAsq.m}
exercised by the Octave script \emph{directFIRnonsymmetricAsq\_test.m}.

\subsubsection{Phase response of a non-symmetric FIR filter}
The phase response of a non-symmetric FIR filter is:
\begin{align*}
\arg{}H\left(\omega\right)
&=\arctan\frac{\Im H\left(\omega\right)}{\Re H\left(\omega\right)} \\
&=-\arctan\frac{\sum_{k=0}^{N}h_{k}\sin{}k\omega}{\sum_{k=0}^{N}h_{k}\cos{}k\omega}
\end{align*}
The gradient with respect to $h_{k}$ of the phase response of a non-symmetric
FIR filter is:
\begin{align*}
\mathabs{H\left(\omega\right)}^{2}
\frac{\partial\arg{}H\left(\omega\right)}{\partial h_{k}}
&=\Re H\left(w\right)\frac{\partial\Im H\left(w\right)}{\partial h_{k}}
 -\Im H\left(w\right)\frac{\partial\Re H\left(w\right)}{\partial h_{k}} \\
&=-\sin{}k\omega\sum_{l=0}^{N}h_{l}\cos{}l\omega
  +\cos{}k\omega\sum_{l=0}^{N}h_{l}\sin{}l\omega \\ 
&=\sum_{l=0}^{N}h_{l}\sin{}\left(l-k\right)\omega
\end{align*}
The calculation of the phase response of a non-symmetric FIR filter
is implemented in the Octave function \emph{directFIRnonsymmetricP.m}
exercised by the Octave script \emph{directFIRnonsymmetricP\_test.m}.
\subsubsection{Group delay response of a non-symmetric FIR filter}
The group delay response, $T\left(\omega\right)$, of a non-symmetric FIR filter
is:
\begin{align*}
T\left(\omega\right)
&=-\frac{\partial\arg{}H\left(\omega\right)}{\partial\omega}\\
\mathabs{H\left(\omega\right)}^{2}T\left(\omega\right)
&=\sum_{l=0}^{N}h_{l}\cos{}l\omega\sum_{k=0}^{N}kh_{k}\cos{}k\omega
+\sum_{l=0}^{N}h_{l}\sin{}l\omega\sum_{k=0}^{N}kh_{k}\sin{}k\omega\\
&=\sum_{k=0}^{N}\sum_{l=0}^{N}kh_{k}h_{l}\cos\left(l-k\right)\omega
\end{align*}
The gradient with respect to $h_{k}$ of the group delay response of a
non-symmetric FIR filter is:
\begin{align*}
\frac{\partial\mathabs{H\left(\omega\right)}^{2}}{\partial h_{k}}
T\left(\omega\right)
+\mathabs{H\left(\omega\right)}^{2}
\frac{\partial T\left(\omega\right)}{\partial h_{k}}
&=\sum_{k=0}^{N}\sum_{l=0}^{N}h_{l}\cos\left[\left(l-k\right)\omega\right]
    \frac{\partial}{\partial{}h_{k}} kh_{k}+
      \sum_{k=0}^{N}\sum_{l=0}^{N}lh_{l}\frac{\partial}{\partial{}h_{k}}
      h_{k}\cos\left(k-l\right)\omega\\
&=\sum_{l=0}^{N}\left(l+k\right)h_{l}\cos\left(l-k\right)\omega
\end{align*}
The calculation of the group delay response of a non-symmetric FIR filter
is implemented in the Octave function \emph{directFIRnonsymmetricT.m}
exercised by the Octave script \emph{directFIRnonsymmetricT\_test.m}.
\subsection{\label{app:Examples-PCLS-design-nonsymmetric-FIR}Examples of the
  PCLS design of non-symmetric FIR filters with SOCP optimisation}
\subsubsection{\label{app:Design-socp-slb-non-symmetric-FIR-low-pass-filter}Design of a non-symmetric FIR low pass filter}
The Octave script \emph{directFIRnonsymmetric\_socp\_slb\_lowpass\_test.m}
designs a low pass non-symmetric FIR filter with a nominal pass band delay using
SOCP optimisation and the PCLS exchange algorithm of \emph{Selesnick},
\emph{Lang} and \emph{Burrus}. The FIR filter specification is:
\begin{small}
\verbatiminput{directFIRnonsymmetric_socp_slb_lowpass_test_spec.m}
\end{small}
The resulting FIR impulse response is:
\begin{small}
\verbatiminput{directFIRnonsymmetric_socp_slb_lowpass_test_h_coef.m}
\end{small}

Figure~\ref{fig:Direct-FIR-nonsymmetric-socp-slb-lowpass-response} shows the
amplitude response.
Figure~\ref{fig:Direct-FIR-nonsymmetric-socp-slb-lowpass-passband} 
shows the pass band amplitude, phase error and delay responses. The pass band
phase error is adjusted for the nominal delay.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRnonsymmetric_socp_slb_lowpass_test_response}}
\caption{Amplitude response of a non-symmetric low pass FIR filter designed
with SOCP and PCLS.}
\label{fig:Direct-FIR-nonsymmetric-socp-slb-lowpass-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRnonsymmetric_socp_slb_lowpass_test_passband}}
\caption{Pass band amplitude, phase error and delay responses of a non-symmetric
low pass FIR filter designed with SOCP and PCLS. The pass band phase error is
adjusted for the nominal delay.} 
\label{fig:Direct-FIR-nonsymmetric-socp-slb-lowpass-passband}
\end{figure}

\subsubsection{Design of a non-symmetric FIR band pass Hilbert filter}
The Octave script
\emph{directFIRnonsymmetric\_socp\_slb\_bandpass\_hilbert\_test.m}
designs a band pass non-symmetric FIR Hilbert filter with a nominal pass band
delay using SOCP optimisation and the PCLS exchange algorithm
of \emph{Selesnick}, \emph{Lang} and \emph{Burrus}.
The FIR filter specification is: 
\begin{small}
\verbatiminput{directFIRnonsymmetric_socp_slb_bandpass_hilbert_test_spec.m}
\end{small}
The resulting FIR impulse response is:
\begin{small}
\verbatiminput{directFIRnonsymmetric_socp_slb_bandpass_hilbert_test_h_coef.m}
\end{small}

Figure~\ref{fig:Direct-FIR-nonsymmetric-socp-slb-bandpass-hilbert-response}
shows the amplitude response.
Figure~\ref{fig:Direct-FIR-nonsymmetric-socp-slb-bandpass-hilbert-passband} 
shows the pass band amplitude, phase and delay responses. The pass band
phase response shown is adjusted for the nominal delay. (In fact the response
requires an 
additional $\pi$ radians phase shift or multiplication of the amplitude by $-1$).

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRnonsymmetric_socp_slb_bandpass_hilbert_test_response}}
\caption{Amplitude response of a non-symmetric band pass FIR Hilbert filter
designed with SOCP and PCLS.}
\label{fig:Direct-FIR-nonsymmetric-socp-slb-bandpass-hilbert-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRnonsymmetric_socp_slb_bandpass_hilbert_test_passband}}
\caption{Pass band amplitude, phase and delay responses of a non-symmetric
band pass FIR Hilbert filter designed with SOCP and PCLS. The pass band phase
response shown is adjusted for the nominal delay.} 
\label{fig:Direct-FIR-nonsymmetric-socp-slb-bandpass-hilbert-passband}
\end{figure}
\clearpage
\section{\label{app:Minimax-error-design-FIR-filters}Constrained
  mini-max error optimisation of FIR digital filters}
\subsection{The alternation theorem}
A symmetric or linear phase FIR filter with even order $2M$ and a symmetric
impulse response with $2M+1$ coefficients has zero-phase frequency response:
\begin{align*}
  A\left(\omega\right)&=h_{M}+2\sum^{M-1}_{k=0}h_{k}\cos\left(M-k\right)\omega\\
                      &= \sum^{M}_{k=0}a_{k}\cos{}k\omega\\
                      &= \sum^{M}_{k=0}a_{k}T_{k}\left(\cos{}\omega\right)
\end{align*}
where $T_{k}\left(x\right)$ is the $k$-th order \emph{Chebyshev polynomial of
  the first kind}. This section considers methods of minimising the maximum
error:
\begin{align*}
  \max_{\omega}E\left(\omega\right)
&=W\left(\omega\right)\lvert A\left(\omega\right)-A_{d}\left(\omega\right)\rvert
\end{align*}
where $W\left(\omega\right)$ is a weighting function and
$A_{d}\left(\omega\right)$ is the desired response. This is also called the
\emph{Chebyshev distance}. For a given filter order (assumed to be even) the
number of frequency constraints is limited by the \emph{approximation} theorem,
shown by \emph{Roberts} and
\emph{Mullis}~\cite[p. 192]{RobertsMullis_DigitalSignalProcessing} as:
\begin{framed}
  \emph{Theorem (Chebyshev)}: Let $d\left(x\right)$ be a real-valued function
  which is continuous on $-1\le x\le 1$.
  \begin{enumerate}
    \item There is a unique polynomial $p\left(x\right)$ of degree at most $M$
      which minimizes $\left\|d\left(x\right)-p\left(x\right)\right\|_{\infty}$.
    \item $p\left(x\right)$ is that polynomial if-and-only-if there exist points
      $-1\le x_{0} \le x_{1} \le \hdots \le x_{n+1}\le 1$ for which
      \begin{align*}
        d\left(x_{i}\right)-p\left(x_{i}\right)
        &=\left(-1\right)^{i}\varepsilon \; , \quad i=0,1,\hdots,n+1
      \end{align*}
      where $\left|\varepsilon\right|=
      \left\|d\left(x\right)-p\left(x\right)\right\|_{\infty}$.
   \end{enumerate}
\end{framed}
\emph{Oppenheim} and \emph{Schafer} show a similar theorem~\cite[Page
489]{OppenheimSchafer_DiscreteTimeSignalProcessing}: 
\begin{framed}
  \emph{Alternation Theorem}: Let $F_{P}$ denote the closed subset consisting of
  the disjoint union of closed subsets of the real axis $x$. Then
  \begin{align*}
    P\left(x\right)&=\sum^{r}_{k=0}a_{k}x^{r}
  \end{align*}
is an $r$-th order polynomial. Also, $D_{P}\left(x\right)$ denotes a given
desired function of $x$ that is continuous on $F_{P}$; $W_{P}\left(x\right)$ is
a positive function, continuous on $F_{P}$, and
  \begin{align*}
    E_{P}\left(x\right)&=W_{P}\left(x\right)
                         \left[D_{P}\left(x\right)-P\left(x\right)\right]
  \end{align*}
  is the weighted error. The maximum error is defined as
  \begin{align*}
    \left\|E\right\|&=\max_{x\in{}F_{P}}\left|E_{P}\left(x\right)\right|
  \end{align*}
  A necessary and sufficient condition that $P\left(x\right)$ be the unique
  $r$th order polynomial that minimises $\left\|E\right\|$ is that
  $E_{P}\left(x\right)$ exhibit \emph{at least} $\left(r+2\right)$ alternations;
  i.e., there must exist at least $\left(r+2\right)$ values $x_{i}$ in $F_{P}$
  such that $x_{1}<x_{2}<\hdots<x_{r+2}$ and such that
  $E_{P}\left(x_{i}\right)=-E_{P}\left(x_{i+1}\right)=\left\|E\right\|$ for $i=1,2,\hdots,\left(r+1\right)$.
\end{framed}
\emph{Oppenheim} and \emph{Schafer} illustrate the conditions under which an
extremum of a polynomial function is also considered to be an
\emph{alternation}~\cite[Figure
7.34]{OppenheimSchafer_DiscreteTimeSignalProcessing}. They point out that, for a
polynomial of order $M$, the Alternation Theorem requires that the optimal
approximation have at least $M+2$ alternations (the \emph{equi-ripple}
approximation) and that a low-pass filter may have at most $M+3$ alternations
(the \emph{extra-ripple} case). They include alternations at the pass-band edge
(for which the polynomial amplitude is $1-\delta_{p}$) and at the stop-band edge
(for which the amplitude is $+\delta_{s}$). Further, the polynomial amplitude
will be equi-ripple except possibly at $\omega=0$ or $\omega=\pi$.

\subsection{\emph{Hofstetter}'s algorithm for mini-max FIR filter approximation}
\emph{Hofstetter}~\cite{Hofstetter_DesignNonRecursiveDigitalFilters} describes
an iterative technique for the design of FIR transfer functions that have the
specified pass-band and stop-band ripple. The technique:
\begin{quotation}
  begins by making an
initial estimate of the frequencies at which these extrema will occur and the
uses Lagrange interpolation to obtain a polynomial that goes through the
maximum allowable ripple values at these frequencies. ... The next stage of the
algorithm is to locate the frequencies at which the extrema of the first
Lagrange interpolation polynomial occur. These frequencies are taken to be a
second, hopefully improved, guess as to the frequencies at which the extrema of
the filter response will achieve the desired ripple values. ... The algorithm
now ``closes the loop'' by using these new frequencies to construct a Lagrange
interpolation polynomial that achieves the desired ripple values at these
frequencies. The extrema of this new polynomial are then located and used to
start the next cycle of the algorithm. The algorithm is reminiscent of, but
different from, the Remes exchange algorithm used in the theory of Tchebycheff
approximation. 
\end{quotation}

The pass-band constraint frequencies are $\omega_{1},\hdots,\omega_{N_{p}}$ and
the stop-band constraint frequencies are
$\omega_{N_{p}+1},\hdots,\omega_{N_{p}+N_{s}}$, where $M+1=N_{p}+N_{s}$,
$\omega_{1}=0$ and $\omega_{N_{p}+N_{s}}=\pi$. At each iteration, the
algorithm solves the system of equations:  
\begin{align*}
  A\left(\omega_{l}\right)&=\begin{cases}
    1+\left(-1\right)^{l+c}\delta_{p} & \text{for } 1\le l\le N_{p} \\
    \left(-1\right)^{l+c}\delta_{s} & \text{for } N_{p}+1\le l\le N_{p}+N_{s} \\
    \end{cases}
\end{align*}
where $c$ is chosen to be $0$ or $1$. These equations can be solved efficiently
by \emph{barycentric Lagrange interpolation}\footnote{The
  Octave \emph{polyfit} built-in function inverts the corresponding
  \emph{Vandermonde} matrix}~\cite[Page
5]{Hofstetter_DesignNonRecursiveDigitalFilters}~\cite[Page 
192]{ParksMcClellan_ChebyshevApproxNonRecursiveDigitalFilters}~\cite{BerrutTrefethen_BarycentricLagrangeInterpolation}.

The Octave script \emph{hofstetterFIRsymmetric\_lowpass\_test.m} uses an
implementation of \emph{Hofstetter}'s algorithm in the Octave function
\emph{hofstetterFIRsymmetric.m} to design a low-pass filter. The filter
specification is:
\begin{small}
\verbatiminput{hofstetterFIRsymmetric_lowpass_test_spec.m}
\end{small}

Figure~\ref{fig:hofstetterFIRsymmetric-lowpass-test-dual} shows the pass-band
and stop-band amplitude responses of the
filter. Figure~\ref{fig:hofstetterFIRsymmetric-lowpass-test-zeros} shows the
zeros of the filter. The distinct filter coefficients are:
\begin{small}
\verbatiminput{hofstetterFIRsymmetric_lowpass_test_hM_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{hofstetterFIRsymmetric_lowpass_test_dual}}
\caption{Response of a mini-max FIR low-pass filter designed with
  \emph{Hofstetter}'s algorithm.}
\label{fig:hofstetterFIRsymmetric-lowpass-test-dual}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{hofstetterFIRsymmetric_lowpass_test_zeros}}
\caption{Zeros of a mini-max FIR low-pass filter designed with
  \emph{Hofstetter}'s algorithm.}
\label{fig:hofstetterFIRsymmetric-lowpass-test-zeros}
\end{figure}

The Octave script \emph{hofstetterFIRsymmetric\_bandpass\_test.m} calls the
Octave function \emph{hofstetterFIRsymmetric.m} to design a band-pass
filter. The filter specification is:
\begin{small}
\verbatiminput{hofstetterFIRsymmetric_bandpass_test_spec.m}
\end{small}

Figure~\ref{fig:hofstetterFIRsymmetric-bandpass-test-dual} shows the pass-band
and stop-band amplitude responses of the
filter. Figure~\ref{fig:hofstetterFIRsymmetric-bandpass-test-zeros} shows the
zeros of the filter. The distinct filter coefficients are:
\begin{small}
\verbatiminput{hofstetterFIRsymmetric_bandpass_test_hM_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{hofstetterFIRsymmetric_bandpass_test_dual}}
\caption{Response of a mini-max FIR band-pass filter designed with
  \emph{Hofstetter}'s algorithm.}
\label{fig:hofstetterFIRsymmetric-bandpass-test-dual}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{hofstetterFIRsymmetric_bandpass_test_zeros}}
\caption{Zeros of a mini-max FIR band-pass filter designed with
  \emph{Hofstetter}'s algorithm.}
\label{fig:hofstetterFIRsymmetric-bandpass-test-zeros}
\end{figure}

The Octave script \emph{hofstetterFIRsymmetric\_multiband\_test.m} calls the
Octave function \emph{hofstetterFIRsymmetric.m} to design a multi-band
filter. The filter specification is: 
\begin{small}
\verbatiminput{hofstetterFIRsymmetric_multiband_test_spec.m}
\end{small}

Some experimentation was required to find the number of extrema in each band
that approximately satisfied the
specification. Figure~\ref{fig:hofstetterFIRsymmetric-multiband-test-dual}
shows the pass-band and stop-band amplitude responses of the
filter. Figure~\ref{fig:hofstetterFIRsymmetric-multiband-test-zeros} shows the
zeros of the filter. The distinct filter coefficients are:
\begin{small}
\verbatiminput{hofstetterFIRsymmetric_multiband_test_hM_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{hofstetterFIRsymmetric_multiband_test_dual}}
\caption{Response of a mini-max FIR multi-band filter designed with
  \emph{Hofstetter}'s algorithm.}
\label{fig:hofstetterFIRsymmetric-multiband-test-dual}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{hofstetterFIRsymmetric_multiband_test_zeros}}
\caption{Zeros of a mini-max FIR multi-band filter designed with
  \emph{Hofstetter}'s algorithm.}
\label{fig:hofstetterFIRsymmetric-multiband-test-zeros}
\end{figure}
\clearpage
\subsubsection{\emph{Selesnick-Burrus} modification to  \emph{Hofstetter}'s
  algorithm for low-pass filters\label{sec:Selesnick-Burrus-modification-Hofstetter-low-pass}}
\emph{Selesnick} and 
\emph{Burrus}~\cite{SelesnickBurrus_ExchangeAlgorithmsParksMcClellanAlgorithm}
point out that whilst \emph{Hofstetter}'s algorithm ``produces equi-ripple
filters with the specified $\delta_{p}$ and $\delta_{s}$, it is not widely used
because if allows limited control over the location of the band edges and only
produces extra-ripple filters''. They add a non-extremal frequency constraint in
the transition band at $\omega_{t}$.

Suppose $\omega_{1},\hdots,\omega_{M+1}$ is the ordered reference set of
frequencies in $\left[0,\pi\right]$ including $\omega_{t}$. Let
$\omega_{1},\hdots,\omega_{q-1}$ be the frequencies in the pass-band, less than
$\omega_{t}$, and $\omega_{q+1},\hdots,\omega_{M+1}$ be the frequencies in the
stop-band, greater than $\omega_{t}$. The system of equations to be solved at
each iteration is:
\begin{align*}
  A\left(\omega_{k}\right)&=1+\left(-1\right)^{k+c}\delta_{p}
                            \quad\text{for }1\le{}k\le{}q-1 \\
  A\left(\omega_{t}\right)&=A_{t} \\
  A\left(\omega_{k}\right)&=\left(-1\right)^{k+c+1}\delta_{s}
                            \quad\text{for }q+1\le{}k\le{}M+1                  
\end{align*}
where $c$ is chosen to equal $0$ or $1$, whichever yields
$A\left(\omega_{q-1}\right)=1+\delta_{p}$.

The exchange algorithm is described as follows:
\begin{quotation}
  Let \emph{S} be the set obtained by appending $\omega_{t}$ to the set of
  extrema of $A\left(\omega\right)$ in $[0,\pi]$:\emph{S} will have either
  $M+1$  or $M+2$ frequencies and will include both $0$ and $\pi$. If \emph{S}
  has $M+1$ frequencies, then take the new reference set to be \emph{S}. If
  \emph{S} has $M+2$ frequencies, then remove either $0$ or $\pi$ from \emph{S}
  according to the following rules:
  \begin{enumerate}
    \item If $A\left(\omega\right)$ has no extrema in the open interval
      $\left(0,\omega_{t}\right)$, then remove $0$ from \emph{S}.
    \item If $A\left(\omega\right)$ has no extrema in the open interval
      $\left(\omega_{t},\pi\right)$ then remove $\pi$ from \emph{S}.
    \item Otherwise, let $\omega_{a}$ be the extrema of $A\left(\omega\right)$
      in $\left(0,\omega_{t}\right)$ closest to $0$, and let $\omega_{b}$ be the
      extrema of $A\left(\omega\right)$
      in $\left(\omega_{t},\pi\right)$ closest to $\pi$. If
$\left|A\left(0\right)-A\left(\omega_{a}\right)\right|\delta_{s}< 
\left|A\left(\pi\right)-A\left(\omega_{b}\right)\right|\delta_{p}$ then remove
$0$ from \emph{S}, otherwise remove $\pi$ from \emph{S}.
  \end{enumerate}
\end{quotation}

The Octave script \emph{selesnickFIRsymmetric\_lowpass\_test.m} designs a
low-pass filter with the implementation of \emph{Hofstetter}'s algorithm with
the modifications of \emph{Selesnick} and \emph{Burrus} in the Octave function
\emph{selesnickFIRsymmetric\_lowpass.m}. The extremal frequencies are found by
quadratic interpolation on a coarse grid. The filter specification is:
\begin{small}
\verbatiminput{selesnickFIRsymmetric_lowpass_test_hMb_spec.m}
\end{small}

Figure~\ref{fig:selesnickFIRsymmetric-lowpass-test-dual} shows the pass-band
and stop-band amplitude responses of the
filter. Figure~\ref{fig:selesnickFIRsymmetric-lowpass-test-zeros} shows the
zeros of the filter. The distinct filter coefficients are:
\begin{small}
\verbatiminput{selesnickFIRsymmetric_lowpass_test_hMb_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{selesnickFIRsymmetric_lowpass_test_hMb_dual}}
\caption{Response of a mini-max FIR low-pass filter designed with
  \emph{Hofstetter}'s algorithm and the modifications of \emph{Selesnick} and
  \emph{Burrus}.}
\label{fig:selesnickFIRsymmetric-lowpass-test-dual}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{selesnickFIRsymmetric_lowpass_test_hMb_zeros}}
\caption{Zeros of a mini-max FIR low-pass filter designed with
  \emph{Hofstetter}'s algorithm and the modifications of \emph{Selesnick} and
  \emph{Burrus}.}
\label{fig:selesnickFIRsymmetric-lowpass-test-zeros}
\end{figure}

The Octave script \emph{selesnickFIRsymmetric\_halfband\_test.m} calls the
Octave function \emph{selesnickFIRsymmetric\_lowpass} to design a half-band
filter with the specification:
\begin{small}
\verbatiminput{selesnickFIRsymmetric_halfband_test_spec.m}
\end{small}
For the half-band filter, $\delta_{p}=\delta_{s}$, $f_{t}=0.25$ and $A_{t}=0.5$. 
Figure~\ref{fig:selesnickFIRsymmetric-halfband-test-dual} shows the
amplitude response of the half-band filter. The distinct filter coefficients are:
\begin{small}
\verbatiminput{selesnickFIRsymmetric_halfband_test_hM_coef.m}
\end{small}

Assuming $M$ is odd, the following Octave code converts an even-order half-band
filter with $M+1$ distinct coefficients, $h_{M}$, into a Hilbert filter (see
Section~\ref{app:PCLS-design-non-symmetric-FIR-filters-SOCP}) and plots the
amplitude response:  
\begin{small}
\begin{verbatim}
altm1=zeros((2*M)+1,1);
altm1(1:2:end)=((-1).^(0:M))';
hhilbert=2*[hM(1:M);0;hM(M:-1:1)].*altm1;
[Hhilbert,w]=freqz(hhilbert,1,4096);
subplot(211)
plot(w*0.5/pi,imag(Hhilbert.*exp(j*w*M)));
subplot(212)
plot(w*0.5/pi,mod((unwrap(angle(Hhilbert))+(w*(M)))/pi,2));
\end{verbatim}
\end{small}
Figure~\ref{fig:selesnickFIRsymmetric-halfband-test-hilbert-response} shows the
amplitude and phase responses of the Hilbert filter derived from the half-band
filter shown in Figure~\ref{fig:selesnickFIRsymmetric-halfband-test-dual}. The
phase response shown is adjusted for the nominal delay.
Figure~\ref{fig:selesnickFIRsymmetric-halfband-test-hilbert-zeros} shows the
zeros of the Hilbert filter.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{selesnickFIRsymmetric_halfband_test_dual}}
\caption{Pass-band and stop-band response of a mini-max FIR half-band filter
  designed with \emph{Hofstetter}'s algorithm and the modifications of
  \emph{Selesnick} and \emph{Burrus}.}
\label{fig:selesnickFIRsymmetric-halfband-test-dual}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{selesnickFIRsymmetric_halfband_test_hilbert_response}}
\caption{Amplitude response of a mini-max FIR Hilbert filter derived from the
  half-band filter designed with \emph{Hofstetter}'s algorithm and the
  modifications of \emph{Selesnick} and \emph{Burrus}. The phase response shown
  is adjusted for the nominal delay.}
\label{fig:selesnickFIRsymmetric-halfband-test-hilbert-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{selesnickFIRsymmetric_halfband_test_hilbert_zeros}}
\caption{Zeros of a mini-max FIR Hilbert filter derived from the half-band
  filter designed with \emph{Hofstetter}'s algorithm and the modifications of
  \emph{Selesnick} and \emph{Burrus}.} 
\label{fig:selesnickFIRsymmetric-halfband-test-hilbert-zeros}
\end{figure}
\clearpage
\subsubsection{\emph{Selesnick-Burrus} modification to \emph{Hofstetter}'s
  algorithm for band-pass filters}
\emph{Selesnick} and 
\emph{Burrus}~\cite[Section
II.C]{SelesnickBurrus_ExchangeAlgorithmsParksMcClellanAlgorithm} also describe an
exchange algorithm for band-pass filters with lower stop-band, pass-band and
upper stop-band errors $\delta_{sl}$, $\delta_{p}$ and $\delta_{su}$ and
lower and upper transition-band frequencies $\omega_{tl}$ and $\omega_{tu}$. An
additional constraint makes the slope of $A\left(\omega\right)$ is equal in
magnitude and opposite in sign at the transition frequencies. \emph{Selesnick}
and \emph{Burrus} state that: ``because the reference set must contain $M-2$
extremal frequencies, it will therefore be necessary to exclude $0$, $1$, $2$ or
$3$ local minima and maxima when updating the reference set.'' Suppose
$\omega_{1},\ldots,\omega_{L}$ are the local extrema of $A\left(\omega\right)$
listed in order. The procedure for excluding maxima and minima is: 
\begin{enumerate}
\item To exclude $1$ local extremum $\left(L=M-1\right)$, use the same update
  rule used for the low-pass case.
\item To exclude $2$ local extrema $\left(L=M\right)$, find the index $k$ that
  minimises
  \begin{align*}
    \left[E\left(\omega_{k}\right)-E\left(\omega_{k+1}\right)\right]
    \left(-1\right)^{k+c}
  \end{align*}
  where $c=1$ if $\omega_{1}$ is a local maximum and $c=0$ if $\omega_{1}$ is a
  local minimum. $E\left(\omega\right)$ denotes the error function. ... If
  $1<k<M-2$, then exclude $\omega_{k}$ and $\omega_{k+1}$ from the reference
  set. If $k=1$ or $K=L$, then exclude $\omega_{k}$ and use the procedure above
  for excluding $1$ local extremum.
\item To exclude $3$ local extrema $\left(L=M+1\right)$, use the procedure for
  excluding $1$ extremum, followed by the procedure for excluding $2$ extrema.
\end{enumerate}

The Octave script \emph{selesnickFIRsymmetric\_bandpass\_test.m} designs a
band-pass filter with the implementation of \emph{Hofstetter}'s algorithm with
the modifications of \emph{Selesnick} and \emph{Burrus} in the Octave function
\emph{selesnickFIRsymmetric\_bandpass.m}. Unlike the MATLAB implementation made
available by \emph{Selesnick}, \emph{firebp.m}~\cite{Selesnick_faffine}, this
function uses Lagrange interpolation to find the response in the $x=\cos\omega$
domain rather than using left division to find the coefficients directly and
does not attempt to implement the constraint on the slope of the response at the
transition frequencies. Consequently, the exchange algorithm uses a reference
set of $M-1$, rather than $M-2$, extremal frequencies plus the two transition
band frequencies and only $1$ or, at most, $2$ extremal frequencies need be
removed. The case of removing $3$ frequencies, listed above, should not
occur. The extremal frequencies are found by quadratic interpolation. The filter
specification is:  
\begin{small}
\verbatiminput{selesnickFIRsymmetric_bandpass_test_hMc_spec.m}
\end{small}
Figure~\ref{fig:selesnickFIRsymmetric-bandpass-test-hMc-dual} shows the pass-band
and stop-band amplitude responses of the filter.
Figure~\ref{fig:selesnickFIRsymmetric-bandpass-test-hMc-zeros} shows the zeros
of the filter. The distinct filter coefficients are:
\begin{small}
\verbatiminput{selesnickFIRsymmetric_bandpass_test_hMc_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{selesnickFIRsymmetric_bandpass_test_hMc_dual}}
\caption{Response of a mini-max FIR band-pass filter designed with
  \emph{Hofstetter}'s algorithm and the modifications of \emph{Selesnick} and
  \emph{Burrus}.}
\label{fig:selesnickFIRsymmetric-bandpass-test-hMc-dual}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{selesnickFIRsymmetric_bandpass_test_hMc_zeros}}
\caption{Zeros of a mini-max FIR band-pass filter designed with
  \emph{Hofstetter}'s algorithm and the modifications of \emph{Selesnick} and
  \emph{Burrus}.}
\label{fig:selesnickFIRsymmetric-bandpass-test-hMc-zeros}
\end{figure}

\clearpage
\subsection{\label{sec:Parks-McClellan-mini-max-FIR}\emph{Parks-McClellan} algorithm for mini-max FIR filter approximation}
\emph{Parks} and
\emph{McClellan}~\cite{ParksMcClellan_ChebyshevApproxNonRecursiveDigitalFilters,
  McClellanParks_ComputerProgramFIRLinearPhaseFilters}\cite[Section
7.4.3]{OppenheimSchafer_DiscreteTimeSignalProcessing} modify \emph{Hofstetter}'s
algorithm by substituting non-extremal amplitude constraints at the filter band
edges. This allows the designer to specify $\omega_{p}$, $\omega_{s}$ and the
ratio $\delta_{p}/\delta_{s}$ but does not allow direct specification of
$\delta_{p}$ and $\delta_{s}$. \emph{Parks} and 
\emph{McClellan}~\cite{ParksMcClellan_ChebyshevApproxNonRecursiveDigitalFilters}
and \emph{Oppenheim} and \emph{Schafer}~\cite[Section
  7.4.3]{OppenheimSchafer_DiscreteTimeSignalProcessing} describe the algorithm
  shown in Algorithm~\ref{alg:Parks-McClellan-FIR-filter-design}\footnote{None
    of the references justify the calculation of $\rho$ (eg:~\cite[Equation
    7.101]{OppenheimSchafer_DiscreteTimeSignalProcessing}). The following is my
    unsatisfactory attempt. Suppose that the alternations of
    $A\left(x_{k}\right)$ mean that 
    $\sum^{M+2}_{k=1}\left|A\left(x_{k}\right)-A_{d}\left(x_{k}\right)\right|$ 
    may be  approximated by
    $\sum^{M+2}_{k=1}\left(-1\right)^{k+1}A\left(x_{k}\right)/2$
  and that, since $\left|x-x_{k}\right|\le{}2$, $\left(x-x_{k}\right)$ is
  replaced with $2$. For the minimum possible approximation error: 
\begin{align*}
  \sum^{M+2}_{k=1}b_{k}\left[A_{d}\left(x_{k}\right)-
  \frac{\left(-1\right)^{k+1}\rho}{W\left(x_{k}\right)}\right]=0
\end{align*}
The result follows. In his MATLAB scripts~\cite{Selesnick_faffine},
\emph{Selesnick} avoids this difficulty by directly calculating $\rho$ and the
coefficients of $A\left(x\right)$ by left-division.}.

\begin{algorithm}
\begin{enumerate}
  \item The optimum filter satisfies the equations:
    \begin{align}
    W\left(\omega_{k}\right)
    \left[A_{d}\left(\omega_{k}\right)-A\left(\omega_{k}\right)\right]
      &=\left(-1\right)^{k+1}\rho\;,\quad k=1,2,\hdots,\left(M+2\right)
        \label{eqn:Parks-McClellan-alternation-equations}
    \end{align}
    where
    \begin{align*}
      A\left(e^{\imath\omega}\right)&=\sum_{k=0}^{M}a_{k}\left(\cos\omega\right)^{k}
    \end{align*} 
     For a lowpass filter, the approximation polynomial has values
     $A\left(\omega_{k}\right)=1\pm{}K\rho$ if
     $W\left(\omega\right)=\frac{1}{K}$ in 
     $0\le\omega_{k}\le\omega_{p}$ and $A\left(\omega_{k}\right)=\pm\rho$ if
     $W\left(\omega\right)=1$ in $\omega_{s}\le\omega_{k}\le\pi$~\cite[Equation
     7.85]{OppenheimSchafer_DiscreteTimeSignalProcessing}.
  \item Begin by guessing a set of alternation frequencies,
    $\omega_{1},\omega_{2},\hdots,\omega_{M+2}$. This set includes the pass-band
    and stop-band frequencies, $\omega_{p}$ and $\omega_{s}$. If
    $\omega_{k}=\omega_{p}$ then $\omega_{k+1}=\omega_{s}$.
  \item The required values at the extremal frequencies are given
    by~\cite[Equation 7.101]{OppenheimSchafer_DiscreteTimeSignalProcessing}:
    \begin{align*}
      \rho&=\frac{\sum^{M+2}_{k=1}b_{k}A_{d}\left(x_{k}\right)}
              {\sum^{M+2}_{k=1}\frac{b_{k}\left(-1\right)^{k+1}}
                                  {W\left(x_{k}\right)}}
    \end{align*}
    where~\cite[Equation 7.102]{OppenheimSchafer_DiscreteTimeSignalProcessing}
    \begin{align*}
      b_{k}&=\prod^{M+2}_{l=1,l\ne{}k}\frac{1}{\left(x_{k}-x_{l}\right)}
    \end{align*}
    and $x_{k}=\cos\omega_{k}$.
   \item $A\left(\omega\right)$ is an $M$-th order polynomial in $x=\cos\omega$
     so we can interpolate through $M+1$ of the $M+2$ known values of
     $A\left(x\right)$. The Lagrange interpolation formula 
     gives~\cite[Equation 7.103a]{OppenheimSchafer_DiscreteTimeSignalProcessing} 
     \begin{align*} 
      A\left(x\right)
      &=\frac{\sum^{M+1}_{k=1}\frac{d_{k}}{\left(x-x_{k}\right)}C_{k}}
        {\sum^{M+1}_{k=1}\frac{d_{k}}{\left(x-x_{k}\right)}}
    \end{align*}
    where~\cite[Equation 7.103b]{OppenheimSchafer_DiscreteTimeSignalProcessing}
    \begin{align*}
      C_{k}&=A_{d}\left(x\right)-\frac{\left(-1\right)^{k+1}\rho}
             {W\left(x_{k}\right)}
    \end{align*}
    and~\cite[Equation 7.103c]{OppenheimSchafer_DiscreteTimeSignalProcessing}
    \begin{align*}
      d_{k}&=\prod^{M+1}_{l=1,l\ne{}k}\frac{1}{\left(x_{k}-x_{l}\right)}
    \end{align*}
    \item Now $A\left(x\right)$ and the error,
      $E\left(x\right)=A\left(x\right)-A_{d}\left(x\right)$, can 
      be calculated at a dense grid of frequencies. If
      $\left|E\left(x\right)\right|\le\rho$ for all $x$ in the
      pass-band and stop-band, then the optimal filter is found. Otherwise, this
      procedure is repeated with a new set of extremal frequencies chosen at
      the $M+2$ greatest values of $\left|E\left(x\right)\right|$.
    \item The impulse response can be approximated with equally spaced samples
      of the frequency response (calculated by Lagrange interpolation) and the
      \emph{discrete Fourier transform pair}~\cite[Section
      4.5]{RobertsMullis_DigitalSignalProcessing}:
      \begin{align*}
        F\left(l\right)&=\sum^{K-1}_{k=0}f\left(k\right)W_{K}^{-kl}\\
        f\left(k\right)&=\frac{1}{K}\sum^{K-1}_{l=0}F\left(l\right)W_{K}^{kl}
      \end{align*}
      where, $f\left(k\right)$ is an even order, $N=2M$, odd length, $K=2M+1$,
      FIR filter and $W_{K}=e^{\frac{2\pi\imath}{K}}$. 
\end{enumerate}
\caption{Parks-McClellan FIR filter design~\cite[Section
7.4.3]{OppenheimSchafer_DiscreteTimeSignalProcessing}~\cite{ParksMcClellan_ChebyshevApproxNonRecursiveDigitalFilters,McClellanParks_ComputerProgramFIRLinearPhaseFilters}.} 
\label{alg:Parks-McClellan-FIR-filter-design}
\end{algorithm}
\paragraph{Design of a low-pass FIR filter with the \emph{Parks-McClellan} algorithm}
The Octave \emph{signal} package includes \emph{remez.cc}, an \emph{oct-file}
implementation of the \emph{Parks-McClellan} algorithm. Alternatively, the
Octave script \emph{mcclellanFIRsymmetric\_lowpass\_test.m} calls the Octave
function \emph{mcclellanFIRsymmetric} to design the \emph{Parks-McClellan}
low-pass filter example~\cite[Table
I]{ParksMcClellan_ChebyshevApproxNonRecursiveDigitalFilters}. The filter
specification is: 
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_lowpass_test_spec.m}
\end{small}
Figure~\ref{fig:mcclellanFIRsymmetric-lowpass-test-dual} shows the pass-band
and stop-band amplitude responses of the filter.
Figure~\ref{fig:mcclellanFIRsymmetric-lowpass-test-zeros} shows the zeros of the
filter. The stop-band ripple found is
$\rho=$\input{mcclellanFIRsymmetric_lowpass_test_rho.tab} and the distinct
filter coefficients are:
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_lowpass_test_hM_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRsymmetric_lowpass_test_dual}}
\caption{Response of a mini-max FIR low-pass filter designed with
  the \emph{Parks-McClellan} algorithm~\cite[Table
  I]{ParksMcClellan_ChebyshevApproxNonRecursiveDigitalFilters}.} 
\label{fig:mcclellanFIRsymmetric-lowpass-test-dual}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRsymmetric_lowpass_test_zeros}}
\caption{Zeros of a mini-max FIR low-pass filter designed with
  the \emph{Parks-McClellan} algorithm~\cite[Table
  I]{ParksMcClellan_ChebyshevApproxNonRecursiveDigitalFilters}.} 
\label{fig:mcclellanFIRsymmetric-lowpass-test-zeros}
\end{figure}
\clearpage
\paragraph{Design of a band-pass FIR filter with the \emph{Parks-McClellan}
  algorithm} The Octave script \newline
\emph{mcclellanFIRsymmetric\_bandpass\_test.m} designs the
band-pass filter with the specification:
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_bandpass_test_spec.m}
\end{small}
In this case, the Octave function \emph{mcclellanFIRsymmetric} does a
preliminary search for error alternation failures when finding the error
extremal frequencies. In my experience, failure of this error extremal
  amplitude alternation search indicates that the filter specification is
  unrealistic. 
Figure~\ref{fig:mcclellanFIRsymmetric-bandpass-test-dual} shows the pass-band
and stop-band amplitude responses of the
filter. Figure~\ref{fig:mcclellanFIRsymmetric-bandpass-test-zeros} shows the
zeros of the filter. The stop-band ripple found is 
$\rho=$\input{mcclellanFIRsymmetric_bandpass_test_rho.tab} and the distinct
filter coefficients are:
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_bandpass_test_hM_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRsymmetric_bandpass_test_dual}}
\caption{Response of a mini-max FIR band-pass filter designed with
  the \emph{Parks-McClellan} algorithm~\cite[Table
  I]{ParksMcClellan_ChebyshevApproxNonRecursiveDigitalFilters}.} 
\label{fig:mcclellanFIRsymmetric-bandpass-test-dual}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRsymmetric_bandpass_test_zeros}}
\caption{Zeros of a mini-max FIR band-pass filter designed with
  the \emph{Parks-McClellan} algorithm~\cite[Table
  I]{ParksMcClellan_ChebyshevApproxNonRecursiveDigitalFilters}.} 
\label{fig:mcclellanFIRsymmetric-bandpass-test-zeros}
\end{figure}
\clearpage
\paragraph{Design of a multi-band FIR filter with the \emph{Parks-McClellan}
  algorithm} The Octave script \newline
\emph{mcclellanFIRsymmetric\_multiband\_test.m} calls the
Octave function \emph{mcclellanFIRsymmetric} to design a multi-band filter with
the specification:
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_multiband_test_spec.m}
\end{small}
Figure~\ref{fig:mcclellanFIRsymmetric-multiband-test-response} shows the
amplitude response of the filter.
Figure~\ref{fig:mcclellanFIRsymmetric-multiband-test-zeros} shows the zeros of
the filter. The pass-band ripple found is
$\rho=$\input{mcclellanFIRsymmetric_multiband_test_rho.tab} and the distinct
filter coefficients are:
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_multiband_test_hM_coef.m}
\end{small}
\clearpage
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRsymmetric_multiband_test_response}}
\caption{Response of a mini-max FIR multi-band filter designed with
  the \emph{Parks-McClellan} algorithm~\cite[Table
  I]{ParksMcClellan_ChebyshevApproxNonRecursiveDigitalFilters}.} 
\label{fig:mcclellanFIRsymmetric-multiband-test-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRsymmetric_multiband_test_zeros}}
\caption{Zeros of a mini-max FIR multi-band filter designed with
  the \emph{Parks-McClellan} algorithm~\cite[Table
  I]{ParksMcClellan_ChebyshevApproxNonRecursiveDigitalFilters}.} 
\label{fig:mcclellanFIRsymmetric-multiband-test-zeros}
\end{figure}
\clearpage
\paragraph{Design of a low-pass differentiator FIR filter with the
  \emph{Parks-McClellan} algorithm} The Octave script
\emph{mcclellanFIRdifferentiator\_test.m} calls the
Octave function \emph{mcclellanFIRdifferentiator} to design a low-pass
FIR differentiator filter with the specification:
\begin{small}
\verbatiminput{mcclellanFIRdifferentiator_test_spec.m}
\end{small}
The ripple found is
$\rho=$\input{mcclellanFIRdifferentiator_test_rho.tab}.
Figure~\ref{fig:mcclellanFIRdifferentiator-test-response} shows the
amplitude and phase responses of the filter. 
Figure~\ref{fig:mcclellanFIRdifferentiator-test-dual} shows the
amplitude error responses of the filter. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRdifferentiator_test_response}}
\caption{Amplitude and phase responses of a mini-max FIR differentiator
  filter designed with the \emph{Parks-McClellan}
  algorithm.}  
\label{fig:mcclellanFIRdifferentiator-test-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRdifferentiator_test_dual}}
\caption{Amplitude error of a mini-max FIR differentiator
  filter designed with the \emph{Parks-McClellan}
  algorithm.}
\label{fig:mcclellanFIRdifferentiator-test-dual}
\end{figure}
\clearpage
\subsubsection{\emph{Selesnick-Burrus} modification to the
  \emph{Parks-McClellan} algorithm}
\emph{Selesnick} and \emph{Burrus} describe modifications to the
  \emph{Parks-McClellan} algorithm~\cite[Section
II.A]{SelesnickBurrus_ExchangeAlgorithmsParksMcClellanAlgorithm} that allow
either the pass-band or stop-band ripple, $\delta_{p}$ or $\delta_{s}$, to be
fixed and the other minimised. The user specifies $M$, $\omega_{p}$,
$\omega_{s}$, $K_{p}$, $K_{s}$, $\eta_{p}$ and $\eta_{s}$ satisfying: 
\begin{align*}
  \delta_{p}&=K_{p}\delta + \eta_{p} \\
  \delta_{s}&=K_{s}\delta + \eta_{s} \\
\end{align*}
The parameters $K_{p},K_{s}\eta_{p}$ and $\eta_{s}$ must be non-negative and
satisfy the inequalities $K_{p}+\eta_{p}>0$ and $K_{s}+\eta_{s}>0$. When
$\eta_{p}=\eta_{s}=0$ the linear relationship reduces to the usual
\emph{Parks-McClellan} algorithm. Alternatively, if $K_{s}=\eta_{p}=0$, then
the stop-band ripple, $\delta_{s}=\eta_{s}$ and the pass-band ripple,
$\delta_{p}$, is minimised.

The linear system of equations to be solved at each iteration is, in addition
to the affine equations for $\delta_{p}$ and $\delta_{s}$:
\begin{align*}
  A\left(\omega_{k}\right)&=\begin{cases}
    1+\left(-1\right)^{k+c}\delta_{p} & \text{for } 1\le{}k\le{}q \\
    \left(-1\right)^{k+c}\delta_{s} & \text{for } q+1\le{}k\le{}M+2 \\
    \end{cases}
\end{align*}
where $\omega_{p}=\omega_{q}$ and $\omega_{s}=\omega_{q+1}$ and $c$ is chosen to
be $0$ or $1$ so that $A\left(\omega_{q}\right)=1-\delta_{p}$.

If $\delta_{p}$ or $\delta_{s}$ are found to be negative then the interpolation
step should be repeated. If $\delta_{p}<0$:
\begin{align*}
  A\left(\omega_{k}\right)&=\begin{cases}
    1+\left(-1\right)^{k+c}\delta_{p} & \text{for } 1\le{}k\le{}q \\
    0 & \text{for } q+1\le{}k\le{}M+2 \\
    \end{cases}\\
    \delta_{s}&=0
\end{align*}
If $\delta_{s}<0$:
\begin{align*}
  A\left(\omega_{k}\right)&=\begin{cases}
    1 & \text{for } 1\le{}k\le{}q \\
    \left(-1\right)^{k+c}\delta_{s}& \text{for } q+1\le{}k\le{}M+2 \\
    \end{cases}\\
    \delta_{p}&=0
\end{align*}

The exchange algorithm is described as follows:
\begin{quotation}
The procedure to update the reference set from one iteration to
the next is the multiple exchange of the PM algorithm: Let \emph{S} be the
set obtained by appending $\omega_{p}$ and $\omega_{s}$ to the set of extrema of
$A\left(\omega\right)$ in $[0,\pi]$. \emph{S} will have either $M+2$ or $M+3$
frequencies and will include both $0$ and $\pi$. If \emph{S} has $M+2$
frequencies, then take the new reference set to be \emph{S}. If \emph{S} has
$M+3$ frequencies, then remove either $0$ or $\pi$ from \emph{S} according to
the following rule: If $\omega=0$ is a local maximum of $A\left(\omega\right)$
then let $\alpha=1$, otherwise set $\alpha=-1$. If $\omega=\pi$ is a local
maximum of $A\left(\omega\right)$ then let $\beta=1$, otherwise set
$\beta=-1$. If
\begin{align*}
\left[A\left(0\right)-1\right]\alpha-\delta_{p}<A\left(\pi\right)\beta-\delta_{s}
\end{align*}
then remove $0$ from \emph{S}, otherwise remove $\pi$ from \emph{S}, and take the
new reference set to be the resulting set S. The expressions on each side of the
inequality indicate the amount by which the error exceeds its intended
value. $\alpha$ and $\beta$ must be chosen appropriately because both the
magnitude and the sign of this value is important: negative values appear in the
design of filters possessing a scaled extra-ripple. The rule states that the
frequency to be retained in S is the one at which the error exceeds its intended
value the most.
\end{quotation}

A MATLAB example, \emph{faffine.m}, of low-pass filter design with this
algorithm is available~\cite{Selesnick_faffine}. 
The Octave script \emph{affineFIRsymmetric\_lowpass\_test.m} calls
\emph{affineFIRsymmetric\_lowpass.m} to design a low-pass filter
with the following specification:
\begin{small}
\verbatiminput{affineFIRsymmetric_lowpass_test_spec.m}
\end{small}
The resulting filter has
$\delta_{p}=$\input{affineFIRsymmetric_lowpass_test_deltap.tab}. 
Figure~\ref{fig:affineFIRsymmetric-lowpass-test-dual} shows the
pass-band and stop-band amplitude responses of the filter. The distinct
filter coefficients are:
\begin{small}
\verbatiminput{affineFIRsymmetric_lowpass_test_hM_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{affineFIRsymmetric_lowpass_test_dual}}
\caption{Response of a mini-max FIR low-pass filter designed with the
  \emph{Parks-McClellan} algorithm modified by \emph{Selesnick} and
  \emph{Burrus}~\cite[Section
  II.A]{SelesnickBurrus_ExchangeAlgorithmsParksMcClellanAlgorithm}.} 
\label{fig:affineFIRsymmetric-lowpass-test-dual}
\end{figure}

\clearpage
\section{Design of FIR filters with maximally-linear pass-bands and equi-ripple stop-bands using the \emph{Parks-McClellan} algorithm}
\emph{Vaidyanathan}~\cite{Vaidyanathan_DesignFIRFlatPassbandEquirippleStopband}
and \emph{Selesnick} and 
\emph{Burrus}~\cite{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}
describe the design of FIR filters with flat pass-bands and equi-ripple
stop-bands. \emph{Selesnick} and \emph{Burrus} interpret the flat pass-band FIR
filter structure proposed by \emph{Vaidyanathan}~\cite[Figure 4]
{Vaidyanathan_DesignFIRFlatPassbandEquirippleStopband} as~\cite[Figure 2]
{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}:
\begin{align*}
  H\left(z\right)&=z^{-\frac{N-1}{2}}+H_{L}\left(z\right)H_{M}\left(z\right)
\end{align*}
where:
\begin{align*}
  H_{L}\left(z\right)&=\left(\frac{1-z^{-1}}{2}\right)^{L}
\end{align*}
The filter length, $N$, is odd and $H_{M}\left(z\right)$ is a high-pass filter
with a symmetric impulse response of length $N-L$.
The frequency reponse of $H_{M}\left(\omega\right)$ is: 
\begin{align*}
  H_{M}\left(\omega\right)
  &=e^{-\imath\omega\left(\frac{N-L-1}{2}\right)}A_{M}\left(\omega\right)
\end{align*}
where $A_{M}\left(\omega\right)$ is a real valued function. When $L$ is chosen
to be even:
\begin{align*}
  \left(\frac{1-e^{-\imath\omega}}{2}\right)^{L}
  &=\left(-1\right)^{\frac{L}{2}} \left(e^{-\frac{\imath\omega}{2}}\right)^{L}
    \left(\sin\frac{\omega}{2}\right)^{L}
\end{align*}
Therefore the frequency response is:
\begin{align*}
  H\left(\omega\right)
  &=e^{-\imath\omega\left(\frac{N-1}{2}\right)}A\left(\omega\right)
\end{align*}
where the amplitude response is:
\begin{align*}
  A\left(\omega\right)
  &=1+\left(-1\right)^{\frac{L}{2}} \left(\sin\frac{\omega}{2}\right)^{L}
    A_{M}\left(\omega\right)
\end{align*}
Let $M=\left(N-L-1\right)/2$ then:
\begin{align*}
  A_{M}\left(\omega\right)
  &=h_{M}\left(M\right)+2\sum^{M-1}_{k=0}h_{M}\left(k\right)
    \cos\left[\omega\left(M-k\right)\right]
\end{align*}
where $h_{M}$ are the coefficients of $H_{M}$.
\subsection{Design of FIR low-pass filters with maximally-flat pass-bands and equi-ripple stop-bands}
\emph{Selesnick} and \emph{Burrus} describe exchange algorithms for the cases in
which the maximally-flat pass-band, low-pass, FIR filter design:
\begin{enumerate}
\item specifies $N$, $L$, $\omega_{s}$ and minimises $\delta_{s}$
\item specifies $N$, $L$, $\delta_{s}$ and minimises $\omega_{s}$
\end{enumerate}
\subsubsection{Maximally-flat pass-band and fixed $\omega_{s}$}
In the first case, $A_{M}\left(\omega\right)$ is found by
minimising~\cite[Section
II.A]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}:  
\begin{align*}
  \left\|\left[A_{M}\left(\omega\right)-
  D\left(\omega\right)\right]W\left(\omega\right)\right\|_{\infty}
\end{align*}
where:
\begin{align*}
  D\left(\omega\right)&=-\frac{\left(-1\right)^{\frac{L}{2}}}
                        {\left(\sin\frac{\omega}{2}\right)^{L}}\\
  W\left(\omega\right)&=\begin{cases}
    0 & \text{for }\omega < \omega_{s} \\
    \left(-1\right)^{\frac{L}{2}}\left(\sin\frac{\omega}{2}\right)^{L} &
    \text{for } \omega\ge\omega_{s}
    \end{cases}
\end{align*}
\begin{quotation}
  On each iteration, a reference set of stopband frequencies is updated and the
  filter $H_{M}$ is found such that $A\left(\omega\right)$ alternately
  interpolates $\delta_{s}$ and $-\delta_{s}$, over the reference set
  frequencies. The size of the reference set is $q=\left(N-L+3\right)/2$. 
\end{quotation}
The Octave script \emph{mcclellanFIRsymmetric\_flat\_lowpass\_test.m} calls the
Octave function \emph{mcclellanFIRsymmetric} to design a maximally-flat FIR
low-pass filter having fixed $\omega_{s}$ with the \emph{Parks-McClellan}
algorithm (Algorithm~\ref{alg:Parks-McClellan-FIR-filter-design}). The
specification of the filter is:    
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_flat_lowpass_test_spec.m}
\end{small}
Figure~\ref{fig:mcclellanFIRsymmetric-flat-lowpass-test-dual} shows the
pass-band and stop-band amplitude responses of the fixed $\omega_{s}$ filter. 
The distinct filter coefficients of $H_{M}\left(z\right)$ are:
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_flat_lowpass_test_hM_coef.m}
\end{small}
The distinct filter coefficients of the overall filter, $H\left(z\right)$, are:
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_flat_lowpass_test_hA_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRsymmetric_flat_lowpass_test_dual}}
\caption{Response of a mini-max FIR maximally-flat pass-band low-pass filter
  with fixed $\omega_{s}$ designed with the \emph{Parks-McClellan}
  algorithm~\cite[Section 
  II.A]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}.} 
\label{fig:mcclellanFIRsymmetric-flat-lowpass-test-dual}
\end{figure}

\subsubsection{Maximally-flat pass-band and fixed $\delta_{s}$}
In the second case~\cite[Section
II.B]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}: 
\begin{quotation}
  Like the Remez algorithm, this approach employs a set of stopband reference
  frequencies. On each iteration: 1) an interpolation problem is solved and 2)
  the reference set is updated. The reference set here, however, does not
  contain the stopband edge (indeed, it is not specified). Therefore the
  reference set contains $\left(N-L+1\right)/2$ stopband frequencies. ...
  At each iteration, the local extremal frequencies of $A\left(\omega\right)$
  in $\left(0,\pi\right]$ are found and are taken to be the reference set
  frequencies for the next iteration.
\end{quotation}
The Octave script \emph{selesnickFIRsymmetric\_flat\_lowpass\_test.m} calls the
Octave function \emph{selesnickFIRsymmetric\_flat\_lowpass} to design a 
maximally-flat FIR low-pass filter having fixed $\delta_{s}$. The specification
of the filter is: 
\begin{small}
\verbatiminput{selesnickFIRsymmetric_flat_lowpass_test_spec.m}
\end{small}
Figure~\ref{fig:selesnickFIRsymmetric-flat-lowpass-test-dual} shows  the
pass-band and stop-band amplitude responses of the fixed $\delta_{s}$ filter.
The Octave function \emph{selesnickFIRsymmetric\_flat\_lowpass} uses Lagrange
interpolation to find the filter amplitude response and removes spurious peaks
in the pass-band amplitude response that are due to numerical errors.
The distinct filter coefficients of $H_{M}\left(z\right)$ are:
\begin{small}
\verbatiminput{selesnickFIRsymmetric_flat_lowpass_test_hM_coef.m}
\end{small}
The distinct filter coefficients of the overall filter, $H\left(z\right)$, are:
\begin{small}
\verbatiminput{selesnickFIRsymmetric_flat_lowpass_test_hA_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{selesnickFIRsymmetric_flat_lowpass_test_dual}}
\caption{Response of a mini-max FIR maximally-flat pass-band low-pass filter
  with fixed $\delta_{s}$~\cite[Section 
  II.B]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}.} 
\label{fig:selesnickFIRsymmetric-flat-lowpass-test-dual}
\end{figure}
\clearpage
\subsection{Design of FIR band-pass filters with maximally-flat pass-bands and equi-ripple stop-bands}
\emph{Selesnick} and \emph{Burrus} describe the design of maximally-flat
pass-band, band-pass, FIR filters with centre frequency, $\omega_{p}$, pass-band
width $2\omega_{t}$ and upper and lower stop-band ripple $\delta_{su}$ and
$\delta_{sl}$, respectively. For maximally-flat band-pass FIR filters:
\begin{align*}
  H_{L}\left(z\right)
  &= \left[\frac{1-2z^{-1}\cos\omega_{p}+z^{-2}}{4}\right]^{\frac{L}{2}}
\end{align*}
where $L$ is a multiple of $4$, $N$ is odd. The amplitude response is:
\begin{align*}
  A\left(\omega\right)
  &= 1+ \left(-1\right)^{\frac{L}{2}}
    \left[\frac{\cos\omega_{p}-\cos\omega}{2}\right]^{\frac{L}{2}}
    A_{M}\left(\omega\right)
\end{align*}
where $A_{M}$ is the amplitude response of a symmetric FIR filter, $H_{M}$, of
length $N-L$. \emph{Selesnick} and \emph{Burrus} describe exchange algorithms
for the two cases: 
\begin{enumerate}
\item specifies $N$, $L$, $\omega_{p}$, $\omega_{t}$,
  $K=\delta_{su}/\delta_{sl}$ and minimises $\delta_{sl}$ 
\item specifies $N$, $L$, $\delta_{su}$ and $\delta_{sl}$ and maximises
  $\omega_{t}$
\end{enumerate}
The exchange algorithms described in this section place all extremal frequencies
in the stop-bands. The \emph{Remez} exchange algorithm requires that the error
alternate in sign over the set of reference frequencies. Consequently, at each
iteration, only one of the stop-band edges can be included in the set of
reference frequencies. 
\subsubsection{Maximally-flat pass-band and fixed $\omega_{p}$ and $\omega_{t}$}
For convenience, set $\omega_{a}=\omega_{p}-\omega_{t}$ and
$\omega_{b}=\omega_{p}+\omega_{t}$. In this case~\cite[Section
III]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}: 
\begin{quotation}
  The reference set is updated by the following procedure: First compute the set
  of all local extremal frequencies of $A\left(\omega\right)$ in
  $\left[0,\pi\right]$. Calling this set $R$, remove $\omega_{p}$ from $R$. $R$
  will then contain either $\left(N-L+1\right)/2$ or $\left(N-L+3\right)/2$
  frequencies. If $R$ contains $\left(N-L+3\right)/2$ frequencies, then remove
  either $0$ or $\pi$ as follows: if
  $\left|A\left(\pi\right)\right|<K\left|A\left(0\right)\right|$ then remove
  $\pi$, otherwise remove $0$. Next append either $\omega_{a}$ or $\omega_{b}$
  to $R$: if
  $\left|A\left(\omega_{b}\right)\right|<K\left|A\left(\omega_{a}\right)\right|$
  then append $\omega_{a}$, otherwise append $\omega_{b}$. $R$ is the new
  reference set and has size $\left(N-L+3\right)/2$.
  On each iteration, the filter $H_{M}$ is found such that
  $A\left(\omega\right)$ interpolates $\delta_{sl}\left(-1\right)^{k}$ over the
  reference set frequencies in the first stop-band and
  $K\delta_{sl}\left(-1\right)^{k}$ in the second stop-band.
\end{quotation}

The Octave script \emph{mcclellanFIRsymmetric\_flat\_bandpass\_test.m} calls the
Octave function \emph{mcclellanFIRsymmetric} to design a maximally-flat FIR
band-pass filter having fixed $\omega_{p}$ and $\omega_{t}$ and
$K=\delta_{su}/\delta_{sl}$. The specification of the filter is:    
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_flat_bandpass_test_spec.m}
\end{small}
\begin{comment}
Figure~\ref{fig:mcclellanFIRsymmetric-flat-bandpass-test-response} shows  the
amplitude response of the fixed $\omega_{p}$ and $\omega_{t}$ filter. 
\end{comment}
Figure~\ref{fig:mcclellanFIRsymmetric-flat-bandpass-test-dual} shows the
detailed pass-band and stop-band amplitude responses of the filter.
The distinct filter coefficients of $H_{M}\left(z\right)$ are: 
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_flat_bandpass_test_hM_coef.m}
\end{small}
The distinct filter coefficients of the overall filter, $H\left(z\right)$, are:
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_flat_bandpass_test_hA_coef.m}
\end{small}

\begin{comment}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRsymmetric_flat_bandpass_test_response}}
\caption{Response of a mini-max FIR maximally-flat pass-band band-pass filter
  with fixed $\omega_{p}$ and $\omega_{t}$~\cite[Section 
  III]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}.}
\label{fig:mcclellanFIRsymmetric-flat-bandpass-test-response}
\end{figure}
\end{comment}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRsymmetric_flat_bandpass_test_dual}}
\caption{Pass-band and stop-band responses of a mini-max FIR maximally-flat
  pass-band band-pass filter with fixed $\omega_{p}$ and
  $\omega_{t}$~\cite[Section
  III]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}.}
\label{fig:mcclellanFIRsymmetric-flat-bandpass-test-dual}
\end{figure}
\subsubsection{Maximally-flat pass-band and fixed $\delta_{su}$ and
  $\delta_{sl}$}
In the second case~\cite[Section
III]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}: 
\begin{quotation}
  A similar algorithm is used for approach (2) in which $\delta_{sl}$ and
  $\delta_{su}$ are specified and the stop-band edges are left variable. The
  reference set is updated in the same manner, except no stopband edge is
  appended to $R$. Let $\omega_{1},\hdots\omega_{q}$ denote the reference set
  frequencies ordered in increasing order. On each iteration, the filter $H_{M}$
  is found such that:
  \begin{align*}
    A\left(\omega\right)&=\delta_{sl}\left(-1\right)^{k+c}
    &\text{for }\omega_{k}<\omega_{p} \\
    A\left(\omega\right)&=\delta_{su}\left(-1\right)^{k+c+1}
    &\text{for }\omega_{k}>\omega_{p} 
  \end{align*}
  where $c$ equals $0$ or $1$, whichever gives
  $A\left(\omega\right)=-\delta_{sl}$ at the highest reference frequency less
  than $\omega_{p}$.
\end{quotation}

The Octave script \emph{selesnickFIRsymmetric\_flat\_bandpass\_test.m} calls the
Octave function \emph{selesnickFIRsymmetric\_flat\_bandpass} to design a 
maximally-flat FIR low-pass filter having fixed $\delta_{su}$ and
$\delta_{sl}$. The specification of the filter is: 
\begin{small}
\verbatiminput{selesnickFIRsymmetric_flat_bandpass_test_spec.m}
\end{small}
Figure~\ref{fig:selesnickFIRsymmetric-flat-bandpass-test-dual} shows  the
pass-band and stop-band amplitude responses of the fixed
$\delta_{su}$ and $\delta_{sl}$ filter.
The distinct filter coefficients of $H_{M}\left(z\right)$ are: 
\begin{small}
\verbatiminput{selesnickFIRsymmetric_flat_bandpass_test_hM_coef.m}
\end{small}
The distinct filter coefficients of the overall filter, $H\left(z\right)$, are:
\begin{small}
\verbatiminput{selesnickFIRsymmetric_flat_bandpass_test_hA_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{selesnickFIRsymmetric_flat_bandpass_test_dual}}
\caption{Response of a mini-max FIR maximally-flat pass-band band-pass filter
  with fixed $\delta_{su}$ and $\delta_{sl}$~\cite[Section 
  III]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}.} 
\label{fig:selesnickFIRsymmetric-flat-bandpass-test-dual}
\end{figure}
\clearpage
\subsection{Design of maximally-linear FIR low-pass differentiators with equi-ripple stop-bands}
The ideal full-band differentiator response is
$H\left(\omega\right)=\imath\omega$ where $\left|\omega\right|\le\pi$. If the
input signal contains broadband random noise then a differentiator filter with a
low-pass amplitude response is preferred. \emph{Selesnick} and
\emph{Burrus}~\cite[Section  
IV, Figure 5]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}\footnote{
The caption to Figure 5 should say ``N even''} describe the design of low-pass
FIR differentiator filters with equi-ripple stop-bands and ``a specified degree
of tangency, $L$, at $\omega=0$''. They present the design equations shown below.

\subsubsection{Even-length FIR differentiators} 
If $N$ and $L$ are even and $S\left(z\right)=-\left(1-z^{-1}\right)/2$ and
$C\left(z\right)=-\left(1-z^{-1}\right)^{2}/2$, so
that $S\left(\omega\right)=\sin\frac{\omega}{2}$ and
$C\left(\omega\right)=1-\cos\omega$, then the amplitude response is: 
\begin{align*}
  A\left(\omega\right)
  &=\sin\left(\frac{\omega}{2}\right)\left[2+d_{1}C\left(\omega\right)+
    d_{2}C^{2}\left(\omega\right)+\hdots+
    d_{\frac{L}{2}-1}C^{\frac{L}{2}-1}\left(\omega\right)+
    A_{M}C^{\frac{L}{2}}\left(\omega\right)\right]
\end{align*}
where $A_{M}\left(\omega\right)$ is an arbitrary cosine polynomial of degree
$M=\left(N-L-1\right)/2$ and:
\begin{align*}
  d_{k}&=\frac{1\cdot{}3\cdot{}5\cdots\left(2k-1\right)}
         {k!\cdot{}\left(2k+1\right)\cdot{}2^{2k-1}}
\end{align*}
For the amplitude response, $A\left(0\right)=0$, $A^{\prime}\left(0\right)=1$ and
$A^{\left(k\right)}\left(0\right)=0$ for $k=2,\ldots,L$.
\subsubsection{Odd-length FIR differentiators}
If $N$ is odd and $L$ is even and $S\left(z\right)=-\left(1-z^{-2}\right)/2$ so
that $S\left(\omega\right)=\sin\omega$, then the amplitude response is:
\begin{align*}
  A\left(\omega\right)
  &=\sin\left(\omega\right)\left[1+d_{1}C\left(\omega\right)+
    d_{2}C^{2}\left(\omega\right)+\hdots+
    d_{\frac{L}{2}-1}C^{\frac{L}{2}-1}\left(\omega\right)+
    A_{M}C^{\frac{L}{2}}\left(\omega\right)\right]
\end{align*}
where $A_{M}\left(\omega\right)$ is an arbitrary cosine polynomial and:
\begin{align*}
  d_{k}&=\frac{k!}{1\cdot{}3\cdot{}5\cdots\left(2k+1\right)}
\end{align*}

\subsubsection{Failed design of an odd length differentiator with
  \emph{mcclellanFIRsymmetric}}
The Octave script
\emph{mcclellanFIRsymmetric\_linear\_differentiator\_fail\_test.m} calls the
Octave function \emph{mcclellanFIRsymmetric} to design the stop-band filter,
$A_{M}\left(\omega\right)$, of an odd-length, even-order, maximally-linear
pass-band, equi-ripple stop-band, FIR differentiator filter. The filter
specification is similar to that of the example of \emph{Selesnick} and
\emph{Burrus}~\cite[Figure
6]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}:   
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_linear_differentiator_fail_test_spec.m}
\end{small}
Figure~\ref{fig:mcclellanFIRsymmetric-linear-differentiator-fail-test-hM-dual}
shows the response of the length $M+1$ FIR stop-band filter,
$A_{M}\left(\omega\right)$. The FIR stop-band filter has small errors. 
Figure~\ref{fig:mcclellanFIRsymmetric-linear-differentiator-fail-test-response}
shows the amplitude response of the differentiator filter. The small errors in
the response of $A_{M}$ result in very large errors in the differentiator
stop-band amplitude response.  

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRsymmetric_linear_differentiator_fail_test_hM_dual}}
\caption{Response of the $A_{M}$ filter of an odd-length, even-order,
  maximally-linear pass-band, equi-ripple stop-band, FIR
  differentiator~\cite[Section
  IV]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}.} 
\label{fig:mcclellanFIRsymmetric-linear-differentiator-fail-test-hM-dual}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRsymmetric_linear_differentiator_fail_test_response}}
\caption{Response of the failed design of an odd-length, even-order,
  maximally-linear pass-band, equi-ripple stop-band, FIR
  differentiator~\cite[Section
  IV]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}.}
\label{fig:mcclellanFIRsymmetric-linear-differentiator-fail-test-response}
\end{figure}
\clearpage
\subsubsection{Design of an odd length differentiator with
  \emph{mcclellanFIRantisymmetric\_linear\_differentiator}}
The Octave function \emph{mcclellanFIRantisymmetric\_linear\_differentiator} 
designs maximally-linear pass-band, equi-ripple stop-band, FIR differentiator
filters. It follows the MATLAB function \emph{chebdiff.m}
of \emph{Selesnick}~\cite{Selesnick_chebdiff} for even-length filters and adds
the odd-length case. The Octave script
\emph{mcclellanFIRantisymmetric\_linear\_differentiator\_test.m} exercises this
function to design an even-length, odd-order and an odd-length, even-order
filter. The filter specification for the even-length filter is similar to that
of the example of \emph{Selesnick} and \emph{Burrus}~\cite[Figure 
6]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}. The specification
of the odd-length filter is:
\begin{small}
\verbatiminput{mcclellanFIRantisymmetric_linear_differentiator_test_spec.m}
\end{small}
The coefficients of the odd-length, even-order, anti-symmetric, FIR
differentiator filter are\footnote{This truncation introduces ripple of about
  $\pm{}1e-7$ into the maximally-linear low-pass differentiator response.}:  
\begin{small} 
\verbatiminput{mcclellanFIRantisymmetric_linear_differentiator_test_hA57_coef.m}
\end{small}
Figure~\ref{fig:mcclellanFIRantisymmetric-linear-differentiator-test-dual}
shows the pass-band and stop-band amplitude responses of the odd-length
even-order FIR maximally-linear pass-band differentiator filter. The width of
the stop-band is determined by the stop-band ripple specification. There are 
$M=\left(N-1-L\right)/2$ stop-band extremal frequencies.
Figure~\ref{fig:mcclellanFIRantisymmetric-linear-differentiator-test-zeros}
shows the zeros of the differentiator filter. There are single zeros at
$z=\pm{}1$.
Figure~\ref{fig:mcclellanFIRantisymmetric-linear-differentiator-test-feasible}  
shows the values of odd or even $N$ and even $L$ with \emph{deltas=1e-4} and
\emph{tol=1e-8} for which the Octave function
\emph{mcclellanFIRantisymmetric\_linear\_differentiator} converges to a feasible
filter. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRantisymmetric_linear_differentiator_test_dual}}
\caption{Pass-band and stop-band amplitude responses of an odd-length,
  even-order, maximally-linear pass-band, equi-ripple stop-band, FIR
  differentiator~\cite[Section
  IV]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}.}  
\label{fig:mcclellanFIRantisymmetric-linear-differentiator-test-dual}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRantisymmetric_linear_differentiator_test_zeros}}
\caption{Zeros of an odd-length, even-order, maximally-linear
  pass-band, equi-ripple stop-band, FIR differentiator~\cite[Section   
  IV]{SelesnickBurrus_ExchangeAlgorithmsLinearPhaseFIRFilters}.} 
\label{fig:mcclellanFIRantisymmetric-linear-differentiator-test-zeros}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRantisymmetric_linear_differentiator_test_feasible}}
\caption{Feasible values of odd or even $N$ and even $L$ with
  \emph{deltas=1e-4} and \emph{tol=1e-8} for the maximally-linear pass-band,
  equi-ripple stop-band, FIR differentiator designed by the Octave function
  \emph{mcclellanFIRantisymmetric\_linear\_differentiator}.}
\label{fig:mcclellanFIRantisymmetric-linear-differentiator-test-feasible}
\end{figure}

\clearpage
\section{Closed-form design of maximally-linear FIR filters}
Maximally-linear filters are preferred when a signal is repeated or
re-transmitted many times. The linearity constraints allow a closed-form
solution for the filter coefficients. \emph{Samadi} and \emph{Nishihara} give a
historical survey of maximally-flat FIR
filters~\cite{SamadiNishihara_WorldOfFlatness}. They emphasise their use since
the late $19$th century by actuaries for \emph{graduation} or data-smoothing.
Maximally-linear FIR filters are typically longer than equi-ripple FIR filters
but may have fewer multipliers.

\subsection{Closed-form design of maximally-flat low-pass FIR filters}

\subsubsection{\emph{Herrmann}'s closed form design of FIR low-pass filters that are maximally-flat at $\omega=0$ and $\omega=\pi$}
\emph{Herrman}~\cite{Herrmann_ApproximationProblemNonrecursiveDigitalFilter}
describes a method of designing maximally-flat low-pass FIR filters with a closed
form expression for the coefficients. The zero-phase frequency response of the
filter is:
\begin{align*}
  A\left(\omega\right)&=\sum_{k=0}^{M}d_{k}\cos{}k\omega
\end{align*}
where the length of the filter is $N=2M+1$. The maximally-flat constraints on
the low-pass filter coefficients are: 
\begin{align*}
  \left. A\left(\omega\right) \right\vert_{\omega=0}&=1 \\
  \vspace{1.5mm}
  \left. A\left(\omega\right) \right\vert_{\omega=\pi}&=0 \\
  \vspace{1.5mm}
  \left. \frac{d^{p}}{d\omega^{p}} A\left(\omega\right)\right\vert_{\omega=0}&=0
  \quad p=1,2,\hdots,2L-1 \\
  \vspace{1.5mm}
  \left. \frac{d^{q}}{d\omega^{q}}A\left(\omega\right)\right\vert_{\omega=\pi}&=0 
  \quad q=1,2,\hdots,2K-1
\end{align*}
where $M=L+K-1$ and $L$ and $K$ represent the required degrees of ``flatness'' at
$\omega=0$ and $\omega=\pi$. \emph{Herrmann} defines a transformation
$\cos\omega =1-2x$ on the interval $\left[0,1\right]$ by which
$A\left(\omega\right)$ is transformed into: 
\begin{align*}
  P_{M,K}\left(x\right)&=\sum_{k=0}^{M}a_{k}x^{k}
\end{align*}
$P_{M,K}\left(x\right)$ has $K$ zeros at $x=1$ and $L=M-K+1$ zeros at $x=0$.
\emph{Herrmann} states that: 
\begin{align*}
  P_{M,K}\left(x\right)&= \left(1-x\right)^{K}\sum_{k=0}^{M-K}
           \left(\begin{array}{c}
                   M+k-1 \\
                   k \end{array}\right)x^{k}
\end{align*}
\emph{Herrmann} gives an empirical relation for the filter cut-off frequency,
$x_{c}$:
\begin{align*}
K &= M-\floor{Mx_{c} +0.5}
\end{align*}
\emph{Rajagopal} and \emph{Roy}~\cite{RajagopalRoy_MaxFlatFIRBernstein} derive
$P_{M,K}\left(x\right)$ from the properties of the \emph{Bernstein
  polynomial}\footnote{In computer graphics a two- or three-dimensional
  \emph{Bernstein polynomial}~\cite{CargoShisha_BernsteinFormPolynomial} is
  called a \emph{Bezier curve}. The \emph{DeCasteljau recursion} is a
  numerically stable method for calculation of the value of the Bernstein
  polynomial.} representation of a function 
$f\left(x\right)$ on the interval $\left[0,1\right]$:
\begin{align*}
  B_{M}\left(f;x\right)&=\sum_{k=0}^{M}f\left(\frac{k}{M}\right)
                         \left(\begin{array}{c}
                                 M \\
                                 k \end{array}\right)x^{k}\left(1-x\right)^{M-k}
\end{align*}
where the values of $f\left(x\right)$ at
$x=\frac{0}{M},\frac{1}{M},\hdots,\frac{M}{M}$ are known. They point out that
for a low-pass function, $f\left(x\right)$: 
\begin{align*}
  f\left(\frac{k}{M}\right) &=\begin{cases}
      1, & 0\le k \le M-K \\
      0, & M-K +1 \le k \le M \end{cases}
\end{align*}
we get:
\begin{align*}
  B_{M,K}\left(f;x\right)&=\sum_{k=0}^{M-K}
           \left(\begin{array}{c}
                   M \\
                   k \end{array}\right)x^{k}\left(1-x\right)^{M-k}
\end{align*}
Expanding and simplifying, \emph{Rajagopal} and \emph{Roy}~\cite[Appendix
A]{RajagopalRoy_MaxFlatFIRBernstein} derive \emph{Herrmann}'s
$P_{M,K}\left(x\right)$:
\begin{align}
  B_{M,K}\left(x\right)&=\left(1-x\right)^{K}\sum_{k=0}^{M-K}
           \left(\begin{array}{c}
                   M+k-1 \\
                   k \end{array}\right)x^{k}
  \label{eqn:Bernstein-M-K}
\end{align}

Identifying $x$ with $-\frac{1}{4}\left(1-z^{-1}\right)^{2}$ and $1-x$ with
$\frac{1}{4}\left(1+z^{-1}\right)^{2}$, the filter transfer function
corresponding to the \emph{Bernstein polynomial} representation of the low-pass
function, $f\left(x\right)$, is:
\begin{align*}
  H\left(z\right)
  &=\frac{1}{4^{M}}\sum_{k=0}^{M-K}\left(-1\right)^{k}
    \left(\begin{array}{c}
            M \\
            k \end{array}\right)
  \left(1-z^{-1}\right)^{2k}  \left(1+z^{-1}\right)^{2\left(M-k\right)}
\end{align*}

Alternatively, applying \emph{Bernstein interpolation} to $f\left(x\right)$:
\begin{align*}
  B_{M}\left(f;x\right)&=\sum_{k=0}^{M}\Delta^{k}f\left(0\right)
                         \left(\begin{array}{c}
                                 M \\
                                 k \end{array}\right)x^{k}              
\end{align*}
where $\Delta^{k}f\left(0\right)$ is the $k$th forward difference\footnote{The
  forward differences are:
  \begin{align*}
    \Delta^{0}f_{n}&=f_{n}\\
    \Delta^{1}f_{n}&=f_{n+1}-f_{n}\\
    \Delta^{k}f_{n}&=\Delta^{k-1}f_{n+1}-\Delta^{k-1}f_{n}\\
                   &=\sum_{p=0}^{k}\left(-1\right)^{p}\left(\begin{array}{c}
                                                                k \\
                                                                p \end{array}
                                                              \right)f_{n+p}
    \end{align*}} at $x=0$ calculated from the values of $f\left(x\right)$ at
  $x=\frac{0}{M},\frac{1}{M},\hdots,\frac{M}{M}$, \emph{Rajagopal} and
  \emph{Roy} show that~\cite[Equation 23]{RajagopalRoy_MaxFlatFIRBernstein}: 
\begin{align*}
  a_{0}&= 1 \\
  a_{k}&=\begin{cases}
    0, & k=1,\hdots,L-1 \\
    \left(-1\right)^{k-L+1}\cdot\frac{L}{k}\cdot
        \left(\begin{array}{c}
                M-L \\
                k-L \end{array}\right)\cdot
            \left(\begin{array}{c}
                    M \\
                    L \end{array}\right) , & k=L,\hdots,M \end{cases}
\end{align*}
In this case the filter transfer function is:
\begin{align*}
  H\left(z\right) &= \sum_{k=0}^{M}a_{k}
                    \left[-\frac{1}{4}\left(1-z^{-1}\right)^{2}\right]^{k}
\end{align*}

Figure~\ref{fig:herrmannFIRsymmetric-flat-lowpass-test-M-10-K-1-M} shows the
\emph{x}-domain responses of maximally-flat lowpass filters for $M=10$ and
$K=1,\hdots,M$ designed with the Octave function
\emph{herrmannFIRsymmetric\_flat\_lowpass}. It reproduces \emph{Herrmann}'s
Figure 1~\cite{Herrmann_ApproximationProblemNonrecursiveDigitalFilter}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{herrmannFIRsymmetric_flat_lowpass_test_M_10_K_1_M}}
\caption{\emph{x}-domain amplitude responses of maximally-flat low-pass filters
  designed by the method of \emph{Herrmann} with $M=10$ and
  $K=1,\hdots,M$~\cite[Figure
  1]{Herrmann_ApproximationProblemNonrecursiveDigitalFilter}.} 
\label{fig:herrmannFIRsymmetric-flat-lowpass-test-M-10-K-1-M}
\end{figure}

The distinct coefficients of the $z$-domain impulse response of
an $M=19$ and $K=11$ maximally-flat low-pass filter are:
\begin{small}
\verbatiminput{herrmannFIRsymmetric_flat_lowpass_test_hM19K11_coef.m}
\end{small}
The numerical range of the maximally-flat filter $a_{k}$ coefficients increases
rapidly with the length of the filter.
\clearpage
\subsubsection{\emph{Vl\v{c}ek et al.}'s recursive algorithm for the calculation of the coefficients of odd-length, symmetric, maximally-flat, FIR low-pass filters}
\emph{Vl\v{c}ek et al.}~\cite{Vlcek_AnalyticalDesignFIRFilter} give a recursive
algorithm for the coefficients of an odd-length, even-order, symmetric,
maximally flat, low-pass FIR filter. They begin with a length $N=2M+1$
$z$-domain impulse response~\cite[Equations 1 to
4]{Vlcek_AnalyticalDesignFIRFilter}: 
\begin{align*}
  H\left(z\right)&=\sum_{k=0}^{N-1}h_{k}z^{-k}\\
                 &=z^{-M}\left[h_{M}+ 2\sum_{k=1}^{M}
                   h_{M-n}\cdot\frac{1}{2}\left(z^{k}+z^{-k}\right)\right]
\end{align*}
The zero-phase frequency response is:
\begin{align*}
A\left(v\right)&=\left[a_{0}+\sum_{k=1}^{M}a_{k}T_{k}\left(v\right)\right]
\end{align*}
where $a_{0}=h_{M}$, $a_{k}=2h_{M-m}$, $v=\cos\omega$ and
$T_{k}\left(\omega\right)=\cos{}k\omega$ is a \emph{Chebyshev polynomial of
  the first kind}. If the impulse response has all zeros at $z=\pm{}1$ then the
zero-phase amplitude response is a \emph{Bernstein} polynomal. Re-writing
Equation~\ref{eqn:Bernstein-M-K} in terms of $v$~\cite[Equation
9]{Vlcek_AnalyticalDesignFIRFilter}\footnote{In the notation of \emph{Vl\v{c}ek
    et al.}, $p=M-K$ and $q=K-1$.}, $A\left(v\right)=C_{M,K}\left(v\right)$,
where: 
\begin{align*}
  C_{M,K} \left(v\right)&=\left(\frac{1+v}{2}\right)^{K}\;\sum_{k=0}^{M-K}
            \left(\begin{array}{c}
                    M+k-1\\
                    k\end{array}\right)\left(\frac{1-v}{2}\right)^{k}
\end{align*}
\emph{Vl\v{c}ek et al.} state that:
\begin{align}
  \frac{d}{dv}C_{M,K}\left(v\right)&=2^{-M}M\left(\begin{array}{c}
                                              M-1\\
                                              M-K\end{array}\right)
  \left(1-v\right)^{M-K}\left(1+v\right)^{K-1}
  \label{eqn:d-dv-C-p-q-v}
\end{align}
Differentiating again~\cite[Equation 11]{Vlcek_AnalyticalDesignFIRFilter}:
\begin{align*}
  \left(1-v^{2}\right)\frac{d^{2}}{dv^{}}C_{M,K}\left(v\right)
  +\left[\left(M-2K+1\right)+\left(M-1\right)v\right]\frac{d}{dv}C_{M,K}&=0
\end{align*}

 The Chebyshev polynomials of the first kind have the property:
\begin{align*}
  \frac{d}{dv}T_{k}\left(v\right)&=kU_{k-1}\left(v\right)
\end{align*}
where $U_{k}\left(v\right)$ is a \emph{Chebyshev polynomial of the second kind}.
An alternative expression of Equation~\ref{eqn:d-dv-C-p-q-v} is:
\begin{align*}
  \frac{d}{dv}C_{M,K}\left(v\right)&=\sum_{k=1}^{M}ka_{k}U_{k-1}\left(v\right)
\end{align*}
Substituting $\alpha_{k}=ka_{k}$:
\begin{align*}
  \left(1-v^{2}\right)\frac{d^{2}}{dv^{2}}C_{M,K}\left(v\right)
  &=\sum_{k=1}^{M}\alpha_{k}\left(1-v^{2}\right)\frac{d}{dv}U_{k-1}\left(v\right)\\
  &=-\sum_{k=1}^{M}\left(\frac{k-1}{2}\right)\alpha_{k}U_{k}\left(v\right)
    +\sum_{k=1}^{M}\left(\frac{k+1}{2}\right)\alpha_{k}U_{k-2}\left(v\right)
\end{align*}
The second-order differential equation becomes:
\begin{align*}
  \sum_{k=1}^{M}\frac{M-k}{2}\alpha_{k}U_{k}\left(v\right)
  +\sum_{k=1}^{M}\left(M-2K+1\right)\alpha_{k}U_{k-1}\left(v\right)
  +\sum_{k=1}^{M}\frac{M+k}{2}\alpha_{k}U_{k-2}\left(v\right) &=0
\end{align*}
Setting $\alpha_{0}=0$ and $U_{-1}\left(v\right)=0$:
\begin{align*}
  \sum_{k=1}^{M+1}\frac{M-k+1}{2}\alpha_{k-1}U_{k-1}\left(v\right)
  +\sum_{k=1}^{M}\left(M-2K+1\right)\alpha_{k}U_{k-1}\left(v\right)
  +\sum_{k=1}^{M-1}\frac{M+k+1}{2}\alpha_{k+1}U_{k-1}\left(v\right) &=0
\end{align*}
For $k=M+1$, the first sum gives:
\begin{align*}
  \frac{M-M}{2}\alpha_{M}U_{M}\left(v\right) &=0
\end{align*}
Comparing the coefficient of the highest power of $v$ in the expansion of
$\frac{d}{dv}A\left(v\right)$ in Chebyshev polynomials of the second kind,
$U_{M-1}\left(v\right)$, with that in $\frac{d}{dv}C_{M,K}\left(v\right)$:
\begin{align*}
  2^{M-1}Ma_{M}&=\left(-1\right)^{M-K}2^{-M}M\left(\begin{array}{c}
                                              M-1\\
                                              M-K\end{array}\right)\\
  \alpha_{M}&=\left(-1\right)^{M-K}2^{-2M+1}M\left(\begin{array}{c}
                                              M-1\\
                                              M-K\end{array}\right)
\end{align*}
Setting $k=M$ gives:
\begin{align*}
  \left(\frac{1}{2}\alpha_{M-1}
  +\left(M-2K+1\right)\alpha_{M}\right)U_{k-1}\left(v\right)&=0
\end{align*}
or:
\begin{align*}
  \alpha_{M-1} &=-2\left(M-2K+1\right)\alpha_{M}
\end{align*}
Finally, $a_{0}$ is given by the value of $A\left(v\right)$ at $v=1$ or
$\omega=0$:
\begin{align*}
  a_{0}&=1-\sum_{k=1}^{M}a_{M}                         
\end{align*}

Algorithm~\ref{alg:Vlcek-maximally-flat-impulse-response} summarises the
calculation. It reproduces Table I of \emph{Vl\v{c}ek et al.}.

\begin{algorithm}[htbp]
  \begin{algorithmic}
  \vspace{1.5mm}
  \vspace{1.5mm}
    \Require $M$, $K$
  \vspace{1.5mm}
  \vspace{1.5mm}
  \\
  \textit{Initialisation:}
  \State $\alpha_{M}=\left(-1\right)^{M-K}2^{-2M+1}M\left(\begin{array}{c}
                                                   M-1\\
                                                   M-K\end{array}\right)$
  \State $\alpha_{M-1}=-2\left(M-2K+1\right)\alpha_{M}$
  \vspace{1.5mm}
  \vspace{1.5mm}
  \\
  \textit{Body:}
    \For{$k=M-1$ \textbf{ down to } $2$ }\\
    \quad\quad$\frac{M-k+1}{2}\alpha_{k-1}=\left(2K-1-M\right)\alpha_{k}
    -\frac{M+k+1}{2}\alpha_{k+1}$
    \EndFor
  \vspace{1.5mm}
  \vspace{1.5mm}
\\
  \textit{Integration:}
  \For{$k=M$ \textbf{ down to } $1$}\\
  \quad\quad $a_{k}=\frac{\alpha_{k}}{k}$
  \EndFor\\
  $a_{0}=1-\sum_{k=1}^{M}a_{M}$
  \vspace{1.5mm}
  \vspace{1.5mm}
  \\
  \textit{Impulse response:}
  \For{$k=M$ \textbf{ down to } $1$}\\
  \quad\quad $h_{M\pm{}k}=\frac{a_{k}}{2}$
  \EndFor\\
  $h_{M}=a_{0}$
  \vspace{1.5mm}
  \vspace{1.5mm}
\end{algorithmic}
\caption{\emph{Vl\v{c}ek et al.}'s backwards recursion for the calculation of
  the impulse response of an odd-length, symmetric, maximally-flat, low-pass FIR
  filter~\cite[Table 1]{Vlcek_AnalyticalDesignFIRFilter}.}
\label{alg:Vlcek-maximally-flat-impulse-response}
\end{algorithm}

The backwards recursion of \emph{Vl\v{c}ek et al.} can successfully calculate
the coefficients of much longer filters than is possible with the ``direct''
calculation of
\emph{Herrman}~\cite{Herrmann_ApproximationProblemNonrecursiveDigitalFilter} or
\emph{Rajagopal} and \emph{Roy}~\cite{RajagopalRoy_MaxFlatFIRBernstein}. The
Octave function \emph{vlcekFIRsymmetric\_flat\_lowpass} calculates the distinct
coefficients of a symmetric, odd-length, maximally-flat FIR low-pass filter by
the backwards recursion.
Figure~\ref{fig:vlcekFIRsymmetric-flat-lowpass-test-response} shows
the amplitude responses of maximally-flat low-pass filters with $M=300$ and
$K=10,30,\hdots,290$.
\clearpage
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{vlcekFIRsymmetric_flat_lowpass_test_response}}
\caption{Amplitude responses of maximally-flat low-pass filters
  designed by the backwards recursion of \emph{Vl\v{c}ek et al.}~\cite[Table
  1]{Vlcek_AnalyticalDesignFIRFilter} with $M=300$ and $K=10,30,\hdots,290$.} 
\label{fig:vlcekFIRsymmetric-flat-lowpass-test-response}
\end{figure}

\paragraph{Working for \emph{Vl\v{c}ek et al.} Equation 14~\cite{Vlcek_AnalyticalDesignFIRFilter}} 
The recursion for the Chebyshev polynomials of the first kind is:
\begin{align*}
  T_{0}\left(v\right)&=1\\
  T_{1}\left(v\right)&=v\\
  T_{k}\left(v\right)&=2vT_{k-1}\left(v\right)-T_{k-2}\left(v\right)
\end{align*}
The recursion for the Chebyshev polynomials of the second kind is:
\begin{align*}
  U_{0}\left(v\right)&=1\\
  U_{1}\left(v\right)&=2v\\
  U_{k}\left(v\right)&=2vU_{k-1}\left(v\right)-U_{k-2}\left(v\right)
\end{align*}
Also:
\begin{align*}
  T_{k}\left(v\right)&=U_{k}\left(v\right)-vU_{k-1}\left(v\right)
\end{align*}

The derivatives of the Chebyshev polynomials are:
\begin{align*}
  \frac{d}{dv}T_{k}\left(v\right)&=kU_{k-1}\left(v\right)\\
  \left(v^{2}-1\right)\frac{d}{dv}U_{k}\left(v\right)
                                 &=\left(k+1\right)T_{k+1}-vU_{k}\left(v\right)
\end{align*}
Accordingly:
\begin{align*}
  \left(1-v^{2}\right)\frac{d}{dv}U_{k-1}\left(v\right)
  &=vU_{k-1}\left(v\right)-kT_{k}\\
  &=vU_{k-1}\left(v\right)-kU_{k}\left(v\right)+kvU_{k-1}\left(v\right) \\
  &=\left(k+1\right)vU_{k-1}\left(v\right)-kU_{k}\left(v\right)\\
  &=\left(k+1\right)
    \left(\frac{U_{k}\left(v\right)+U_{k-2}\left(v\right)}{2}\right)
    -kU_{k}\left(v\right)\\
  &=-\left(\frac{k-1}{2}\right)U_{k}\left(v\right)
    +\left(\frac{k+1}{2}\right)U_{k-2}\left(v\right)
\end{align*}
\clearpage
\subsubsection{\label{sec:Nuevo-closed-form-FIR-interpolation-maximally-flat}Closed-form design of FIR filters by \emph{Nuevo et al.}'s interpolation with a maximally-flat model filter}
\emph{Nuevo et al.}~\cite{NuevoDongMitra_InterpolatedFIRFilters} describe a
general method for the design of \emph{interpolated FIR filters} of the form
$H\left(z\right)=H_{M}\left(z^{P}\right)G\left(z\right)$. $H_{M}\left(z\right)$
is called the model filter, designed to meet the required frequency
specification in $z^{P}$. $H_{M}\left(z\right)$ is transformed by
interpolating $P-1$ zeros between each impulse response coefficient creating $P$
images of the desired frequency response. The $G\left(z\right)$ filter places
zeros at each of the $P-1$ unwanted images. This method is claimed to
``implement most practical FIR filters with significant savings in the number of
arithmetic operations''. 

The Octave script \emph{nuevoFIRsymmetric\_flat\_bandpass\_test.m} applies this
method to the design of a bandpass filter. The maximally flat model filter is
designed by the Octave function \emph{herrmannFIRsymmetric\_flat\_lowpass} with
$M=19$ and $fc=0.2$ giving $K=12$. The interpolation factor is $P=8$. The script
constructs an interpolator filter, $G\left(z\right)$, with double zeros at $z=1$
and $z=-1$, a pair of zeros at $z=\pm\imath$ and pairs of zeros at on the unit
circle at
$\omega=\pm{}2\pi\left[3, 29, 35, 47, 48, 50, 62\right]/\left(16P\right)$. 
The latter were adjusted ``by-eye''. The resulting filter has a model filter
with length $39$ and an overall filter length of $325$. The model filter has
$20$ distinct coefficients and the interpolator filter requires $8$ distinct
non-power-of-two
multipliers. 
Figure~\ref{fig:nuevoFIRsymmetric-flat-bandpass-test-interpolator} shows the
responses of the interpolated maximally-flat model filter and the
interpolator filter.
Figure~\ref{fig:nuevoFIRsymmetric-flat-bandpass-test-response} 
shows the overall response of the interpolated filter.
The distinct coefficients of the model filter are:
\begin{small} 
\verbatiminput{nuevoFIRsymmetric_flat_bandpass_test_hM_coef.m}
\end{small}
The coefficients of the two sections of the interpolator filter are:
\begin{small} 
\verbatiminput{nuevoFIRsymmetric_flat_bandpass_test_hza_coef.m}
\end{small}
and
\begin{small} 
\verbatiminput{nuevoFIRsymmetric_flat_bandpass_test_hzb_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{nuevoFIRsymmetric_flat_bandpass_test_interpolator}}
\caption{Amplitude response of the interpolated maximally-flat model filter and
  interpolator filter with $P=8$, $M=19$, $fc=0.2$, $K=12$.}
\label{fig:nuevoFIRsymmetric-flat-bandpass-test-interpolator}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{nuevoFIRsymmetric_flat_bandpass_test_response}}
\caption{Amplitude response of an interpolated maximally-flat band-pass filter
with $P=8$, $M=19$, $fc=0.2$, $K=12$.}
\label{fig:nuevoFIRsymmetric-flat-bandpass-test-response}
\end{figure}

Figure~\ref{fig:nuevoFIRsymmetric-flat-bandpass-test-16bit-response} shows the
overall response of the filter with $16$-bit rounded coefficients. The model
filter now has $16$ distinct coefficients, a total of $24$ multipliers are
required and the overall filter length is $261$.
The distinct $16$-bit coefficients of the model filter are:
\begin{small} 
\verbatiminput{nuevoFIRsymmetric_flat_bandpass_test_hMf_coef.m}
\end{small}
The $16$-bit coefficients of the interpolator filter are:
\begin{small} 
\verbatiminput{nuevoFIRsymmetric_flat_bandpass_test_hzbf_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{nuevoFIRsymmetric_flat_bandpass_test_16bit_response}}
\caption{Amplitude response of an interpolated maximally-flat band-pass filter
with $P=8$, $M=19$, $fc=0.2$, $K=12$ and $16$-bit rounded coefficients.}
\label{fig:nuevoFIRsymmetric-flat-bandpass-test-16bit-response}
\end{figure}
\clearpage
\subsubsection{\emph{Vaidyanathan}'s design of multiplier-less FIR filters by
  combining maximally-flat interpolators}
\emph{Vaidyanathan}~\cite{Vaidyanathan_MultiplierLessFIRSharpCutoffMaxFlat}
describes the design of monotonic (rather than maximally-flat)
FIR filters by combining maximally-flat interpolator blocks. The filters are
designed with ``closed-form'' formulas and coefficient multiplications are
implemented with shift-and-add arithmetic.

\emph{Vaidyanathan}~\cite[Section II]{Vaidyanathan_MultiplierLessFIRSharpCutoffMaxFlat} first reviews the
properties of \emph{maximally-flat} symmetric, even-order, N, FIR filters. He
writes the zero-phase transfer function as:
\begin{align*}
H_{0}\left(z\right)=
h_{0}z^{\frac{N}{2}}+h_{1}z^{\frac{N}{2}-1}+\hdots+h_{N}z^{-\frac{N}{2}}
\end{align*}
The associated linear-phase filter is
$H\left(z\right)=z^{-\frac{N}{2}}H_{0}\left(z\right)$. The corresponding frequency
response is:
\begin{align*}
H_{0}\left(e^{\imath\omega}\right)&=
h_{\frac{N}{2}}+2\sum^{\frac{N}{2}}_{k=1}h_{\frac{N}{2}-k}\cos k\omega
\end{align*}
The filter is maximally-flat if:
\begin{align*}
\left.\frac{\partial^{k}H_{0}\left(e^{\imath\omega}\right)}{\partial\omega^{k}}
\right|_{\omega=0}&=0,
\quad\text{for }k=1,2,\hdots,2L-1\\
\left.\frac{\partial^{k}H_{0}\left(e^{\imath\omega}\right)}{\partial\omega^{k}}
\right|_{\omega=\pi}
&=0, \quad\text{for }k=1,2,\hdots,2K-1\\
\end{align*}
where $N\coloneq 2\left(K+L-1\right)$. $K$ represents the degree of flatness at
$\omega=0$ and $L$ represents the degree of flatness at $\omega=\pi$. \emph{Herrmann}~\cite{Herrmann_ApproximationProblemNonrecursiveDigitalFilter}
and \emph{Rajagopal} and \emph{Roy}~\cite{RajagopalRoy_MaxFlatFIRBernstein}
show a solution for $H_{0}\left(e^{\imath\omega}\right)$ by \emph{Hermite
interpolation}:
\begin{align*}
H_{0}\left(e^{\imath\omega}\right) &= \left(\cos\frac{\omega}{2}\right)^{2K}
\;\;\sum^{L-1}_{k=0}d\left(k\right)\left(\sin\frac{\omega}{2}\right)^{2k}
\end{align*}
where:
\begin{align*}
d\left(k\right)=\frac{\left(K-1+k\right)!}{\left(K-1\right)!k!}
\end{align*}
The corresponding filter transfer functions are:
\begin{align*}
H_{0}\left(z\right) &= \left(\frac{1}{2}+\frac{1}{2}\frac{z+z^{-1}}{2}\right)^{K}
\;\;\sum^{L-1}_{k=0}d\left(k\right)
\left(\frac{1}{2}-\frac{1}{2}\frac{z+z^{-1}}{2}\right)^{k} \\
H\left(z\right) &= \left(\frac{1+z^{-1}}{2}\right)^{2K}
\;\;\sum^{L-1}_{k=0}z^{-\left(L-1-k\right)}\left(-1\right)^{k}d\left(k\right)
\left(\frac{1-z^{-1}}{2}\right)^{2k}
\end{align*}

\emph{Vaidyanathan} points out that $L$ non-trivial multipliers are needed
to implement this transfer function and that these multipliers have a large
dynamic range. In addition, the usual design of a maximally-flat linear-phase
FIR filter begins with the specification of the centre of the transition band,
$\beta$, and the width of the transition band, $\delta$, both in multiples of
$\pi$, and computes the $K$ and $L$ required so that the resulting filter has a
gain of $0.95$ at $\omega=\left(\beta-\frac{\delta}{2}\right)\pi$ and $0.05$ at 
$\omega=\left(\beta+\frac{\delta}{2}\right)\pi$. The order of such a filter,
$N=2\left(K+L-1\right)$ grows as $\delta^{2}$. 
Instead, \emph{Vaidyanathan} employs the interpolated FIR method of \emph{Nuevo
et al.}~\cite{NuevoDongMitra_InterpolatedFIRFilters}, shown in
Section~\ref{sec:Nuevo-closed-form-FIR-interpolation-maximally-flat}.

The interpolated FIR design method of \emph{Nuevo et al} first designs a filter
with $\hat{\beta}=M\beta$ and $\hat{\delta}=M\delta$, where $M$ is an integer.
This filter transfer function is expanded with $M-1$ delays between each
coefficient and the unwanted pass-bands are suppressed by a maximally-flat
interpolator. \emph{Vaidyanathan} proposes the following efficient interpolators
suitable for $M=2$. Other values of $M$ are obtained by combining these
interpolators. In the following $C\left(\omega\right)=\cos^{2}\frac{\omega}{2}$
and $S\left(\omega\right)=\sin^{2}\frac{\omega}{2}$.
\begin{enumerate}
\item Interpolator $I\left(z\right)$:
\begin{align*}
\beta&=0.5,\; \delta=0.4,\; K=3,\; L=3,\; N=10 \\
I\left(e^{\imath\omega}\right)&=
C^{3}\left(\omega\right)
\left(1+3S\left(\omega\right)+6S^{2}\left(\omega\right)\right)
\end{align*}
\item Interpolator $J\left(z\right)$:
\begin{align*}
\beta&=0.6,\; \delta=0.5,\; K=2,\; L=4,\; N=10 \\
J\left(e^{\imath\omega}\right)&=
C^{2}\left(\omega\right)\left(1+2S\left(\omega\right)+
3S^{2}\left(\omega\right)+4S^{3}\left(\omega\right)\right)
\end{align*}
\item Interpolator $K\left(z\right)$:
\begin{align*}
\beta&=0.4,\; \delta=0.4,\; K=4,\; L=2,\; N=10 \\
K\left(e^{\imath\omega}\right)&=
C^{4}\left(\omega\right)\left(1+4S\left(\omega\right)\right)
\end{align*}
\item Interpolator $L\left(z\right)$:
\begin{align*}
\beta&=0.5,\; \delta=0.5,\; K=2,\; L=2,\; N=6 \\
L\left(e^{\imath\omega}\right)&=
C^{2}\left(\omega\right)\left(1+2S\left(\omega\right)\right)
\end{align*}
\end{enumerate}

\emph{Vaidyanathan} now points out that since
$0\le C\left(e^{\imath\omega}\right)\le 1$ then each $C\left(z\right)$ can be
replaced with a function $F\left(z\right)$ for which
$0\le F\left(e^{\imath\theta}\right)\le 1,\text{ for all }\theta$. This
constitutes a frequency transformation for which
\begin{align*}
\omega =
2\cos^{-1}\left\{\left[F\left(e^{\imath\theta}\right)\right]^{\frac{1}{2}}\right\}
\end{align*}
If $F\left(z\right)$ is linear-phase then the resulting filter is linear-phase.
For example, if\footnote{Similarly
$S\left(z\right) \leftarrow 1-I^{2}\left(z\right)$.}:
\begin{align*}
I_{I}\left(z\right) \coloneq
\left.I\left(z\right)\right|_{C\left(z\right)\leftarrow I^{2}\left(z\right)}
\end{align*}
then $I_{I}\left(z\right)$ has a much sharper cutoff than $I\left(z\right)$
itself.

The Octave script \emph{vaidyanathanFIRsymmetric\_lowpass\_test.m} calculates
the amplitude response of \emph{Vaidyanathan}'s example
$H_{5}\left(z\right)$~\cite[Figure
12]{Vaidyanathan_MultiplierLessFIRSharpCutoffMaxFlat}:
\begin{align*}
H_{5}\left(z\right) =
I_{I}\left(z\right)I_{I}\left(z^{2}\right)J_{J}\left(z^{4}\right)
\end{align*}
Figure~\ref{fig:Vaidyanathan-efficient-multiplier-less-FIR-filters-H5} shows
the amplitude response for the $H_{5}\left(z\right)$ example FIR filter.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{vaidyanathanFIRsymmetric_lowpass_test_response}}
\caption{Amplitude response of \emph{Vaidyanathan}'s example
$H_{5}\left(z\right)$ of an interpolated multiplier-less low-pass
filter~\cite[Figure 12]{Vaidyanathan_MultiplierLessFIRSharpCutoffMaxFlat}.}
\label{fig:Vaidyanathan-efficient-multiplier-less-FIR-filters-H5}
\end{figure}

\emph{Vaidyanathan} states that this order $N=700$ multiplier-less FIR filter has
an amplitude response equivalent to that of an $N=174$ equi-ripple FIR filter
but with far fewer arithmetic operations.

\clearpage
\subsection{Closed-form design of maximally-flat FIR half-band filters}
\subsubsection{\emph{Gumacos}'s closed form design of FIR half-band filters that are maximally-flat at $\omega=0$}
\emph{Gumacos}~\cite[Equation
1]{Gumacos_WeightingCoeffMaxFlatNonrecursiveDigitalFilters} represents the
zero-phase amplitude response of a half-band filter, $A\left(\omega\right)$, by
a power series: 
\begin{align*}
  A\left(\omega\right)&=\sum_{k=0}^{M}a_{k}\cos\left(2k+1\right)\omega
\end{align*}
where $a_{0}=1$ and $N=4M+3$ is the length of the filter. Scaling and
mean-value are to be determined later. The condition for maximal flatness at
$\omega=0$ is: 
\begin{align*}
  \left.A^{\left(l\right)}\left(\omega\right)\right\vert_{\omega=0}
  &=0\quad l=1,\hdots{},2M
\end{align*}
resulting in a set of $M$ constraint equations:
\begin{align*}
  1+\sum_{k=1}^{M}\left(2k+1\right)^{2l}a_{k}&=0 \quad l=1,\hdots,M
\end{align*}
\emph{Gumacos} solves this system of equations algebraically~\cite[Equation
4]{Gumacos_WeightingCoeffMaxFlatNonrecursiveDigitalFilters}:
\begin{align*}
  a_{k}&=\frac{\left(-1\right)^{k}}{2k+1}\cdot
         \frac{M!\,\left(M+1\right)!}
         {\left(M-k\right)!\,\left(M+k+1\right)!} \quad k=0,1,\hdots,M
\end{align*}
Recursively:
\begin{align*}
a_{0}&=1 \\
a_{k}&=-a_{k-1}\cdot\frac{2k-1}{2k+1}\cdot\frac{M-k+1}{M+k+1}\quad k=1,\hdots,M
\end{align*}
The $z$-domain transfer function is:
\begin{align*}
  H\left(z\right)&=z^{-2M-1}\left[h_{0}
                   +\sum_{k=0}^{M}h_{2k+1}\left(z^{2k+1}+z^{-2k-1}\right)\right]
\end{align*}
where:
\begin{align*}
  h_{0}&=\frac{1}{2} \\
  h_{1}&=\left[4\sum_{k=0}^{M}a_k\right]^{-1}\\
  h_{2k+1}&=h_{1}a_{k}\quad k=2,\hdots,M
\end{align*}
The Octave script \emph{gumacosFIRsymmetric\_flat\_halfband\_test.m} calls the
Octave function \emph{gumacosFIRsymmetric\_flat\_halfband.m} to design half-band
filters with $M=5,10,15,20$ and $25$.
Figure~\ref{fig:gumacosFIRsymmetric-flat-halfband-test-response} shows the
amplitude responses of the resulting half-band filters.
Figure~\ref{fig:gumacosFIRsymmetric-flat-halfband-test-hilbert} shows
the amplitude responses of the corresponding Hilbert filters.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{gumacosFIRsymmetric_flat_halfband_test_response}}
\caption{Amplitude responses of maximally-flat half-band FIR filters designed by
  the method of
  \emph{Gumacos}~\cite{Gumacos_WeightingCoeffMaxFlatNonrecursiveDigitalFilters}
  with $M=5,10,15,20$ and $25$.}
\label{fig:gumacosFIRsymmetric-flat-halfband-test-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{gumacosFIRsymmetric_flat_halfband_test_hilbert}}
\caption{Amplitude responses of maximally-flat Hilbert FIR filters derived from
  half-band FIR filters designed by the method of
  \emph{Gumacos}~\cite{Gumacos_WeightingCoeffMaxFlatNonrecursiveDigitalFilters}
  with $M=5,10,15,20$ and $25$.}
\label{fig:gumacosFIRsymmetric-flat-halfband-test-hilbert}
\end{figure}
\clearpage
\subsection{Closed-form design of maximally-flat FIR Hilbert filters}
\subsubsection{\emph{Pei} and \emph{Wang}'s design of maximally-flat
  Hilbert FIR filters by truncated power series}
\emph{Pei} and \emph{Wang}~\cite{PeiWang_ClosedFormMaximallyFlatFIRHilbert}
describe the closed form design of maximally-flat Hilbert, differentiator
and fractional-delay FIR filters by truncation of a power series. Here I follow
their derivation of a closed form expression for a maximally-flat FIR Hilbert
filter~\cite[Section II.A]{PeiWang_ClosedFormMaximallyFlatFIRHilbert}. The
Hilbert filter frequency response is $H\left(\omega\right)=-\imath\sign\omega$
where $-\pi<\omega<\pi$ and $\sign$ is the \emph{sign} function: 
\begin{align*}
  \sign{}\omega &=\begin{cases}
    -1 & \omega < 0\\
    \phantom{-}0 & \omega = 0 \\
    \phantom{-}1 & \omega > 0
   \end{cases}
\end{align*}
\emph{Pei} and \emph{Wang} choose to represent $\sign{}x$ by:
\begin{align*}
  \sign{}x&=\frac{x}{\sqrt{x^{2}}}\quad x\ne 0
\end{align*}
If $f\left(u\right)=u^{-\frac{1}{2}}$ then:
\begin{align*}
  \sign{}x&=xf\left(x^{2}\right)\quad x\ne 0
\end{align*}
The Taylor series expansion of this representation of the $\sign{}x$ function at
$x=c$ is: 
\begin{align}
  \label{eqn:Pei-Wang-sgn-Taylor-series}
  \sign{}x &=\frac{x}{\sqrt{c}}\left[1+\sum^{\infty}_{k=1}
            \frac{\left(2k-1\right){!}{!}}{\left(2k\right){!}{!}}
            \left(1-\frac{x^{2}}{c}\right)^{k}\right]
\end{align}
where $2k{!}{!}$ and $\left(2k-1\right){!}{!}$ are the double factorial:
\begin{align*}
  \left(2k-1\right){!}{!} &= 1\cdot{}3\cdot{}5\cdot\hdots\cdot\left(2k-1\right) \\
  \left(2k\right){!}{!}   &= 2\cdot{}4\cdot{}6\cdot\hdots\cdot\left(2k\right)
\end{align*}
This series converges for $-1<\left(1-\frac{x^{2}}{c}\right)<1$ or
$c>\frac{1}{2}x^{2}$.

\emph{Pei} and \emph{Wang} observe that:
\begin{align*}
  \sign{}\omega &= \sign\sin\omega = \sign\sin\frac{\omega}{2}
\end{align*}
where $-\pi<\omega<\pi$. Consequently, if $\sign{}x$ is approximated by a
polynomial in $x$, then $\sin\omega$ or $\sin\frac{\omega}{2}$ can be
substituted for $x$. Subsituting $x=\sin\omega$ and using the first $M$ terms
of the power series, the frequency response of the Hilbert filter is
approximated by:
\begin{align*}
  H\left(\omega,c\right)
  &=-\imath\frac{\sin\omega}{\sqrt{c}}\left[1+\sum^{M}_{k=1}
    \frac{\left(2k-1\right){!}{!}}{\left(2k\right){!}{!}}
    \left(1-\frac{\sin^{2}\omega}{c}\right)^{k}\right]
\end{align*}
In the $z$-plane, substituting $\frac{\imath}{2}\left(z^{-1}-z\right)$ for
$\sin\omega$ and multiplying by $z^{-2M-1}$, the causal transfer function that
approximates a Hilbert filter is:
\begin{align*}
  H\left(z,c\right)
  &= -\frac{1-z^{-2}}{2\sqrt{c}}\left[z^{-2M}+\sum^{M}_{k=1}
    \frac{\left(2k-1\right){!}{!}}{\left(2k\right){!}{!}}z^{-2\left(M-k\right)}
    \left(z^{-2}+\frac{1}{c}\left(\frac{1-z^{-2}}{2}\right)^{2}\right)^{k}\right]
\end{align*}
In particular, if $c=1$, then $H\left(\omega\right)$ is maximally flat at
$\omega=\frac{\pi}{2}$ and:
\begin{align*}
  H\left(z\right)
  &= -\frac{1-z^{-2}}{2}\left[z^{-2M}+\sum^{M}_{k=1}
    \frac{\left(2k-1\right){!}{!}}{\left(2k\right){!}{!}}z^{-2\left(M-k\right)}
    \left(\frac{1+z^{-2}}{2}\right)^{2k}\right]
\end{align*}
\emph{Pei} and \emph{Wang}~\cite[Figure
2]{PeiWang_ClosedFormMaximallyFlatFIRHilbert} show a realisation of this
order $4M+2$ transfer function with $M$ coefficients of the form
$\frac{2k-1}{2k}$.
\clearpage

The Octave code to calculate the amplitude response for $M=1,\hdots,25$ is:
\begin{small}
\begin{verbatim}
nplot=1024;
w=(0:(nplot-1))'*pi/nplot;
kM=1:25;
AM=sin(w).*(1+cumsum(cumprod(((2*kM)-1)./(2*kM)).*(cos(w).^(2*kM)),2));
\end{verbatim}
\end{small}

Figure~\ref{fig:pei-wang-FIR-flat-hilbert-amplitude} shows the amplitude
responses of the maximally-flat at $\omega=\frac{\pi}{2}$ Hilbert filters for
$M=5,10,\hdots,25$. These Hilbert filters are identical to the \emph{Gumacos}
Hilbert filters.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{peiFIRantisymmetric_flat_hilbert_test_response}}
\caption{Amplitude responses of \emph{Pei} and \emph{Wang}~\cite[Section
  II.A]{PeiWang_ClosedFormMaximallyFlatFIRHilbert} maximally-flat at
  $\omega=\frac{\pi}{2}$ Hilbert FIR filters.}
\label{fig:pei-wang-FIR-flat-hilbert-amplitude}
\end{figure}

\paragraph{Addendum}
The Taylor series expansion of $f\left(x\right)=x^{-\frac{1}{2}}$ at $x=c$ is:
\begin{align*}
  f\left(x\right)&=f\left(c\right)+\sum^{\infty}_{k=1}
                   \frac{f^{\left(k\right)}\left(c\right)}{k!}
                   \left(x-c\right)^{k}\\
  &= c^{-\frac{1}{2}}+\sum^{\infty}_{k=1}
                   \frac{f^{\left(k\right)}\left(c\right)}{k!}
                   \left(-1\right)^{k}c^{k}\left(1-\frac{x}{c}\right)^{k}
\end{align*}
The derivatives of $f\left(x\right)$ are:
\begin{align*}
  f^{\left(1\right)}\left(x\right)
  &=-\frac{1}{2}\cdot x^{-1-\frac{1}{2}}\\
  f^{\left(2\right)}\left(x\right)
  &=\left(-1\right)^{2}\frac{1}{2}\cdot\frac{3}{2}\cdot x^{-2-\frac{1}{2}}\\
  \vdots & \\
  f^{\left(k\right)}\left(x\right)
  &=\left(-1\right)^{k}\frac{1}{2}\cdot\frac{3}{2}\cdot\hdots\cdot\frac{2k-1}{2}
    \cdot x^{-k-\frac{1}{2}}
\end{align*}
Since $k!\cdot{}2^{k}=\left(2k\right){!}{!}\;$,
Equation~\ref{eqn:Pei-Wang-sgn-Taylor-series} follows. 

\clearpage
\subsection{Closed-form design of maximally-linear FIR low-pass differentiators}
\emph{Kumar} and
\emph{Roy}~\cite{KumarRoy_CoefficientsMaxLinearFIRDifferentiatorLowFrequencies}
and \emph{Selesnick}~\cite{Selesnick_MaximallyFlatLowPassDigitalDifferentiators}
describe the closed-form design of maximally-linear low-pass FIR differentiator
filters. \emph{Yoshida et
  al.}~\cite{YoshidaSugiuraAikawa_LowPassMaxFlatFIRDifferentiators} show
formulas for an FIR differentiator that is maximally-linear at $\omega=0$ and
maximally flat at $\omega=\pi$ with a given group-delay at $\omega=0$. 
\emph{Khan et al.}~\cite{KhanOkudaOhba_FIRDifferentiatorsMaxLinearMidBand} show
formulas for the coefficients of an FIR differentiator that is maximally-linear
at the middle of the frequency band, $\omega=\frac{\pi}{2}$.
\emph{Purczy\'{n}ski} and
\emph{Pawelczak}~\cite{PurczynskiPawelczak_MaxLinearDifferentiatorFrequenciesP}  
extend the work of \emph{Kumar et
  al.}~\cite{KumarRoyShah_FIRDifferentiatorMaxLinearPionP} to show formulas for
the weighting coefficients of FIR differentiators that are maximally-linear at
frequencies $\pi/p$, where $p$ is a positive integer. 

The derivation of the coefficients of the maximally-linear FIR differentiator
begins with the constraints on the zero-phase amplitude response,
$A\left(\omega\right)$. When the constraint is at $\omega=0$~\cite[Equations 6 to
8]{Selesnick_MaximallyFlatLowPassDigitalDifferentiators}:
\begin{align*}
  \left. A\left(\omega\right) \right\vert_{\omega=0}&=0 \\
  \vspace{1.5mm}
  \left. \frac{d}{d\omega} A\left(\omega\right)\right\vert_{\omega=0}&=1 \\
  \vspace{1.5mm}
  \left. \frac{d^{k}}{d\omega^{k}}A\left(\omega\right)\right\vert_{\omega=0}&=0 
  \quad k=2,\hdots,2L
\end{align*}
\emph{Kumar etal.}~\cite{KumarRoyShah_FIRDifferentiatorMaxLinearPionP} define
similar constraints at $\omega=\frac{\pi}{p}$. \emph{Selesnick}~\cite[Equation
9]{Selesnick_MaximallyFlatLowPassDigitalDifferentiators} adds a constraint on
the amplitude response at $\omega=\pi$:
\begin{align*}
  \left. \frac{d^{k}}{d\omega^{k}}A\left(\omega\right)\right\vert_{\omega=\pi}&=0
  \quad k=0,\hdots,2M
\end{align*}
\emph{Yoshida et al.}~\cite[Equation
3d]{YoshidaSugiuraAikawa_LowPassMaxFlatFIRDifferentiators} add a constraint on
the group-delay of the frequency response, $H\left(\omega\right)$, at $\omega=0$:
\begin{align*}
  \left. -\frac{d}{d\omega}\arg{}H\left(\omega\right)\right\vert_{\omega=0}&=\tau
\end{align*}

\subsubsection{\emph{Kumar} and \emph{Roy} closed form design of FIR low-pass differentiators that are maximally-linear at $\omega=0$}

\emph{Kumar} and \emph{Roy}~\cite[Equation
2]{KumarRoy_CoefficientsMaxLinearFIRDifferentiatorLowFrequencies} approximate the
zero-phase amplitude response, $A\left(\omega\right)$, of an FIR differentiator
filter, by a power series: 
\begin{align*}
  A\left(\omega\right)&=\sum_{k=1}^{n}d_{k}\sin{}k\omega
\end{align*}
where $n=\frac{N-1}{2}$ and $N$ is the order of the filter, assumed to be
odd. Applying the maximally-linear constraints at $\omega=0$, the system of
constraint equations is~\cite[Equation
4]{KumarRoy_CoefficientsMaxLinearFIRDifferentiatorLowFrequencies}: 
\begin{align*}
  \left[\begin{array}{ccccc}
          1 & 1 & 1 & \hdots & 1 \\
          1 & 2^{2} & 3^{2} & \hdots & n^{2} \\
          1 & 2^{4} & 3^{4} & \hdots & n^{4} \\
          \vdots & & & & \vdots \\
          1 & 2^{2n-2} & 3^{2n-2} & \hdots & n^{2n-2} \\
        \end{array}\right]\left[\begin{array}{c}
                                  D_{1} \\
                                  D_{2} \\
                                  D_{3} \\
                                  \vdots \\
                                  D_{n} \\
                                \end{array}\right]&=\left[\begin{array}{c}
                                                            1 \\
                                                            0 \\
                                                            0 \\
                                                            \vdots \\
                                                            0
                                                            \end{array}\right]
\end{align*}
where $D_{k}=kd_{k}$. As $n$ increases, this system of equations rapidly becomes
numerically unstable. \emph{Kumar} and \emph{Roy} solve this system of
constraint equations algebraically as~\cite[Equation 
14]{KumarRoy_CoefficientsMaxLinearFIRDifferentiatorLowFrequencies}: 
\begin{align*}
  d_{k}&=\left[k\left(\begin{array}{c}
                        2n-1 \\
                        n-1 \end{array}\right)\right]^{-1}
  \sum_{l=0}^{n-1}\left(-1\right)^{l}\left(\begin{array}{c}
                        n \\
                        l \end{array}\right)
  \sum_{m=0}^{2l}\left(-1\right)^{m}\left(\begin{array}{c}
                        2l \\
                        m \end{array}\right)\left(\begin{array}{c}
                        2n-2l \\
                        n-k-m \end{array}\right)
\end{align*}
This appears to be a misprint. $\left(\begin{array}{c} 
    2n-2l\\
    n-k-m\end{array}\right)$ is not defined for $n-k-m<0$. For example, when
$k=n$, $l=n-1$ and $m=2n-2$. 
\clearpage
\subsubsection{\emph{Selesnick} closed form design of FIR low-pass
  differentiators that are maximally-linear at $\omega=0$ and maximally-flat at $\omega=\pi$}
\emph{Selesnick}~\cite[Equations 10 and
11]{Selesnick_MaximallyFlatLowPassDigitalDifferentiators} derives the $z$-domain
transfer function, $H\left(z\right)$, of a maximally-linear differentiator from
a transformation of the interval $[0,1]$ to polynomials on the upper half-circle
of $\left|z\right|=1$:
\begin{align*}
  P\left(x\right)&=\sum^{n}_{k=0}p_{k}x^{k} \\
  H\left(z\right)&=P\left(\frac{-z+2-z^{-1}}{4}\right)
\end{align*}
\emph{Selesnick}~\cite[Section
IV]{Selesnick_MaximallyFlatLowPassDigitalDifferentiators} gives the following
equation for the $z$-domain transfer function of \emph{Type
  III}\footnote{\label{foot:Schafer-Oppenheim-FIR-filter-types}\emph{Selesnick}
  uses the terminology of \emph{Oppenheim} and \emph{Schafer}~\cite[Section
  5.7.3]{OppenheimSchafer_DiscreteTimeSignalProcessing}: \emph{Type I} filters
  are symmetric and have even order, \emph{Type II} filters are symmetric and
  have odd order, \emph{Type III} filters are anti-symmetric and have even order
  and \emph{Type IV} filters are anti-symmetric and have odd order.} and
\emph{Type IV} FIR differentiators that are maximally-linear at $\omega=0$ and
maximally-flat at $\omega=\pi$:
\begin{align*}
  H\left(z\right)&=\left(\frac{1-z^{-1}}{2}\right)
                   \left(\frac{1+z^{-1}}{2}\right)^{K}
                   z^{-L}\sum_{n=0}^{L}c_{n}\left[\frac{-z+2-z^{-1}}{4}\right]^{n}
\end{align*}
where the $c_{n}$ are defined recursively:
\begin{align*}
c_{0}&=2\\
c_{1}&=K+\frac{1}{3} \\
c_{n}&=\frac{\left(8n^{2}+4Kn-10n-K+3\right)c_{n-1}-\left(2n+K-3\right)^{2}c_{n-2}}
       {2n\left(2n+1\right)}
\end{align*}
The length of the impulse response is $N=K+2L+2$. When $K$ is even
$H\left(z\right)$ is a \emph{Type IV} transfer function and when $K$ is odd
$H\left(z\right)$ is \emph{Type III} transfer function. When $K=0$, the
differentiator is ``full-band''. The Octave script
\emph{selesnickFIRantisymmetric\_linear\_differentiator\_test.m} 
calls the Octave function
\emph{selesnickFIRantisymmetric\_linear\_differentiator} to design a series of
differentiator filters. 
Figure~\ref{fig:selesnickFIRantisymmetric-linear-differentiator-test-N30-response}
shows the differentiator filters for length $N=30$ and $K=0,4,8,12,16,20$ and
$24$~\cite[Figure 1]{Selesnick_MaximallyFlatLowPassDigitalDifferentiators}.
Figure~\ref{fig:selesnickFIRantisymmetric-linear-differentiator-test-N31-response}
shows the differentiator filters for length $N=31$ and $K=1,5,9,13,17,21$ and
$25$~\cite[Figure 2]{Selesnick_MaximallyFlatLowPassDigitalDifferentiators}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{selesnickFIRantisymmetric_linear_differentiator_test_N30_response}}
\caption{Amplitude response of length $N=30$, maximally-linear
  pass-band, maximally-flat stop-band, FIR differentiators with
  $K=0,4,8,12,16,20$ and $24$~\cite[Figure
  1]{Selesnick_MaximallyFlatLowPassDigitalDifferentiators}.} 
\label{fig:selesnickFIRantisymmetric-linear-differentiator-test-N30-response}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{selesnickFIRantisymmetric_linear_differentiator_test_N31_response}}
\caption{Amplitude response of length $N=31$, maximally-linear
  pass-band, maximally-flat stop-band, FIR differentiators with
  $K=1,5,9,13,17,21$ and $25$~\cite[Figure
  2]{Selesnick_MaximallyFlatLowPassDigitalDifferentiators}.} 
\label{fig:selesnickFIRantisymmetric-linear-differentiator-test-N31-response}
\end{figure}
\clearpage
\subsubsection{\emph{Kumar et al.} closed form design of FIR low-pass
  differentiators that are maximally-linear at $\omega=\frac{\pi}{p}$}
\emph{Kumar et al.}~\cite[Equation
9]{KumarRoyShah_FIRDifferentiatorMaxLinearPionP}\footnote{See
  also \emph{Khan et al.}~\cite[Equation
1]{KhanOkudaOhba_FIRDifferentiatorsMaxLinearMidBand} for design of
differentiators that are maximally-linear at $\omega=\frac{\pi}{2}$} approximate
the amplitude response of an FIR differentiator that is maximally-linear at
$\omega=\frac{\pi}{p}$ by:
\begin{align*}
  \left|H\left(\omega\right)\right|
  &=\frac{\pi}{2p}\sum_{k=1}^{m}d_{2k-1}
    \sin\left(\left(2k-1\right)\cdot\frac{p}{2}\cdot\omega\right)
 +\frac{1}{2p}\sum_{k=1}^{m}d_{2k}\sin\left(2k\cdot\frac{p}{2}\cdot\omega\right)
\end{align*}
where $p$ is a positive integer, $m=\frac{n}{2}$, $n=\frac{N-1}{2}$, $n$ is
even, and $N$ is the length of the filter, assumed to be
odd. They show a realisation of the filter~\cite[Figure
1]{KumarRoyShah_FIRDifferentiatorMaxLinearPionP}. \emph{Purczy\'{n}ski} and
\emph{Pawelczak} solve the resulting system of constraint equations
algebraically to find the following recursive closed-form solutions for the
coefficients~\cite[Equation
7]{PurczynskiPawelczak_MaxLinearDifferentiatorFrequenciesP}:
\begin{align*}
  d_{1}&=\frac{m}{4^{2m-1}} \left(\begin{array}{c}
                                    2m \\
                                    m \end{array}\right)^{2}  \\
  d_{2k-1}&=d_{2k-3}\cdot{}\frac{2k-3}{2k-1}\cdot{}\frac{m-k+1}{m+k-1}
            \quad k=2,\hdots,m
\end{align*}
and
\begin{align*}
  d_{2}&=-\frac{2m}{m+1} \\
  d_{2k}&=d_{2k-2}\cdot{}\frac{k-1}{k}\cdot{}\frac{m-k+1}{m+k}\quad k=2,\hdots,m
\end{align*}
The Octave script
\emph{purczynskiFIRantisymmetric\_linear\_differentiator\_test.m} calls the
Octave  function \emph{purczynskiFIRantisymmetric\_linear\_differentiator} to
design FIR differentiators that are maximally linear at $\omega=\frac{\pi}{p}$
where $p$ is a multiple of $2$.
Figure~\ref{fig:purczynskiFIRantisymmetric-linear-differentiator-test-response}
shows the amplitude responses of the differentiators for $p=2,4,8$ and $16$.
Figure~\ref{fig:purczynskiFIRantisymmetric-linear-differentiator-test-error}
shows the corresponding amplitude errors,
$\left|H_{p}\left(\omega\right)\right|-\omega$, of the differentiators.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{purczynskiFIRantisymmetric_linear_differentiator_test_response}}
\caption{Amplitude responses of FIR differentiators that are
  maximally-linear at $\frac{\pi}{p}$ with length $N=101$ and $p=2,4,8$ and $16$
  designed by the method of \emph{Kumar et
    al.}~\cite{KumarRoyShah_FIRDifferentiatorMaxLinearPionP} and with the
  recursive calculation of the $d_{k}$ performed by the method of
  \emph{Purczy\'{n}ski} and \emph{Pawelczak}~\cite[Equation 
  7]{PurczynskiPawelczak_MaxLinearDifferentiatorFrequenciesP}.} 
\label{fig:purczynskiFIRantisymmetric-linear-differentiator-test-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{purczynskiFIRantisymmetric_linear_differentiator_test_error}}
\caption{Amplitude response errors,
  $\left|H_{p}\left(\omega\right)\right|-\omega$, of FIR differentiators that
  are maximally-linear at $\frac{\pi}{p}$ with length $N=101$ and $p=2,4,8$ and
  $16$ designed by the method of \emph{Kumar et
    al.}~\cite{KumarRoyShah_FIRDifferentiatorMaxLinearPionP} and with the 
  recursive calculation of the $d_{k}$ performed by the method of
  \emph{Purczy\'{n}ski} and \emph{Pawelczak}~\cite[Equation 
  7]{PurczynskiPawelczak_MaxLinearDifferentiatorFrequenciesP}.} 
\label{fig:purczynskiFIRantisymmetric-linear-differentiator-test-error}
\end{figure}

\clearpage
\section{\label{app:LMI-design-symmetric-FIR-filters}Linear Matrix Inequality(LMI) design of symmetric FIR filters}
This section follows the peak-constrained LMI design of even-order symmetric FIR
filters described by \emph{Tuan et
al.}~\cite{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}. They use 
arguments from convex optimisation to derive results similar to those of
\emph{Davidson et al.}~\cite{Davidson_LMISpectralConstraints}. In particular,
they derive a version of the \emph{Markov-Lukacs} theorem for trigonometric
curves. The primal form of the SDP solution of the LMI FIR frequency constraints
requires $\mathcal{O}\left(n^{2}\right)$ variables. \emph{Tuan et al.} derive
a dual form of the SDP with $\mathcal{O}\left(n\right)$ variables. 

\subsection{The \emph{Markov-Lukacs} theorem}
\emph{Despr\'{e}s}~\cite{Despres_PositivePolynomials}
shows the following version of the \emph{Markov-Lukacs} theorem:
\begin{framed}
$P_{n}$ is the set of $n$th order polynomials. The convex set
$P^{+}_{n}=\left\{p\left(x\right)\in P_{n}\;:\;
p\left(x\right)\ge0\;\forall\;x\in\left[0,1\right]\right\}$.
\begin{align*}
&p\left(x\right)\in P^{+}_{n} \Leftrightarrow 
\begin{cases}
\exists\; a\left(x\right)\in P_{k}, b\left(x\right)\in P_{k-1}\text{ such that }
p\left(x\right) =a\left(x\right)^{2}+x\left(1-x\right)b\left(x\right)^{2},&n=2k\\
\exists\; a\left(x\right)\in P_{k}, b\left(x\right)\in P_{k\phantom{-1}}\text{ such that }
p\left(x\right)=xa\left(x\right)^{2}+\left(1-x\right)b\left(x\right)^{2},&n=2k+1
\end{cases}
\end{align*}
\end{framed}
\emph{Proof:}~ By induction:

$n=2$:
\begin{align*}
p\left(x\right)&=\left(\left(1-x\right)\sqrt{p\left(0\right)}
-x\sqrt{p\left(1\right)}\right)^{2}+x\left(1-x\right)b^{2}
\end{align*}

$n\in 2\mathbb{N}$:
\begin{align*}
p\left(x\right)&=\prod^{\frac{n}{2}}_{k=1}p_{k}\left(x\right),\;
p_{k}\in P^{+}_{2}\\
&=\prod^{\frac{n}{2}}_{k=1}\left|a_{k}\left(x\right)+
\imath\;b_{k}\sqrt{x\left(1-x\right)}\right|^{2} \\
&=\left|\prod^{\frac{n}{2}}_{k=1}\left(a_{k}\left(x\right)+
\imath\;b_{k}\sqrt{x\left(1-x\right)}\right)\right|^{2} \\
&=\left|a\left(x\right)+
\imath b\left(x\right)\sqrt{x\left(1-x\right)}\right|^{2} \\
&=a\left(x\right)^{2}+x\left(1-x\right)b\left(x\right)
\end{align*}

$n\in 2\mathbb{N}+1$:
\begin{align*}
xp\left(x\right)=\hat{p}\left(x\right)
&=\hat{a}\left(x\right)^{2}+x\left(1-x\right)\hat{b}\left(x\right)^{2}\\
&=\left(xa\left(x\right)\right)^{2}+x\left(1-x\right)b\left(x\right)^{2}\\
p\left(x\right)&=xa\left(x\right)^{2}+\left(1-x\right)b\left(x\right)^{2}
\end{align*}

Note that $p\left(x\right)$ is not unique:
\begin{align*}
1 &= 1^{2}+x\left(1-x\right)0^{2}=\left(1-2x\right)^{2}+x\left(1-x\right)2^{2}
\end{align*}

\subsection{Trigonometric curves}
\emph{Tuan et al.}~\cite[Section
I]{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric} define the
trigonometric curve, $C_{a,b}$:
\begin{align*}
\varphi\left(\omega\right)&=\left(1,\cos\omega,\hdots,\cos n\omega\right)^{\top}\\
C_{a,b}&\coloneq\left\{\varphi\left(\omega\right)\; :\;
\cos\omega\in\left[\cos a,\cos b\right]\right\}\subset\mathbb{R}^{n+1}
\end{align*}
and its polar, $C^{\star}_{a,b}$:
\begin{align*}
C^{\star}_{a,b}&=\left\{u\in\mathbb{R}^{n+1}\; :\;
\langle u,v\rangle\ge 0\;\forall\;v\in C_{a,b}\right\}
\end{align*}
A linear constraint on the variable $x\in\mathbb{R}^{m}$ is: 
\begin{align*}
Ax+d\in C^{\star}_{a,b}, \;
A\in\mathbb{R}^{\left(n+1\right)\times m},\; d\in\mathbb{R}^{n+1}
\end{align*}
or:
\begin{align*}
\langle Ax+d,\varphi_{n}\left(\omega\right)\rangle\ge 0,\;
\cos\omega\in\left[\cos a,\cos b\right]
\end{align*}

\subsection{Moment matrix of trigonometric curves}
Let $\phi_{k}\left(t\right)=\left(1,t,\hdots,t^{k}\right)^{\top}$. The $k$-th
order moment matrix of $\phi_{k}\left(t\right)$ is:
\begin{align*}
\mathcal{M}_{k}\left(t\right)&=
\phi_{k}\left(t\right)\phi^{\top}_{k}\left(t\right)\\
&=\left[\begin{array}{cccc}
1 & t & \cdots & t^{k} \\
t & t^{2} & \cdots & t^{k+1} \\
\cdots &\cdots &\cdots & \cdots \\
t^{k} & t^{k+1} & \cdots & t^{2k}\end{array}\right]
\end{align*}

Similarly, define the matrix $\mathcal{T}_{k}\left(\omega\right)$:
\begin{align*}
\mathcal{T}_{k}\left(\omega\right)
&=\varphi_{k}\left(\omega\right)\varphi^{\top}_{k}\left(\omega\right)\\
&=\left[\begin{array}{cccc}
1 & \cos\omega & \cdots & \cos k\omega \\
\cos\omega & \frac{1}{2}\left(1+\cos 2\omega\right) & \cdots &
\frac{1}{2}\left(\cos\left(k-1\right)\omega+\cos\left(k+1\right)\omega\right) \\
\cdots &\cdots &\cdots & \cdots \\
\cos k\omega &
\frac{1}{2}\left(\cos\left(k-1\right)\omega+\cos\left(k+1\right)\omega\right) &
\cdots & \frac{1}{2}\left(1+\cos 2k\omega\right)\end{array}\right]
\end{align*}

The matrix $T_{k}\left(y\right)$ is created from
$\mathcal{T}_{k}\left(\omega\right)$ with a change of variable,
$\cos l\omega\rightarrow y_{l}$:
\begin{align*}
T_{k}\left(y\right)&=\left[\begin{array}{cccc}
y_{0} & y_{1} & \cdots & y_{k} \\
y_{1} & \frac{1}{2}\left(y_{0}+y_{2}\right) & \cdots &
\frac{1}{2}\left(y_{k-1}+y_{k+1}\right)\\
\cdots &\cdots &\cdots & \cdots \\
y_{k} & \frac{1}{2}\left(y_{k-1}+y_{k+1}\right)
 & \cdots & \frac{1}{2}\left(y_{0}+y_{2k}\right)\end{array}\right]
\end{align*}
For convenience, also define:
\begin{align*}
\mathcal{T}_{l,k}\left(\omega\right)&=
\cos l\omega\;\mathcal{T}_{k}\left(\omega\right) \\
T_{l,k}\left(y\right)&=T_{k}\left(y_{l},y_{l+1},\hdots,y_{l+2k}\right) \\
&=\left[\begin{array}{cccc}
y_{l} & \cdots & & \\
\frac{1}{2}\left(y_{\mathabs{l-1}}+y_{l+1}\right) &
\frac{1}{4}\left(y_{\mathabs{l-2}}+2y_{l}+y_{l+2}\right) & \cdots & \\
\cdots & \cdots & \cdots & \cdots \\
\frac{1}{2}\left(y_{\mathabs{l-k}}+y_{l+k}\right) &
\frac{1}{4}\left(y_{\mathabs{l-k-1}}+y_{\mathabs{l-k+1}}+y_{\mathabs{l+k-1}}
+y_{l+k+1}\right) & \cdots &
\frac{1}{4}\left(y_{\mathabs{l-2k}}+2y_{l}+y_{l+2k}\right)\end{array}\right]
\end{align*}

\emph{Tuan et
al}~\cite[Appendix I]{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}
give a basis for $T_{l,k}\left(y\right)$ comprised of symmetric matrixes:
\begin{align*}
\left[\mathcal{E}^{m}_{l,k}\right]_{i,j} &=
\frac{1}{4}\left(\delta_{m-\mathabs{i+j-l-2}}+\delta_{m-\mathabs{i+j+l-2}}+
\delta_{m-\mathabs{i-j-l}}+\delta_{m-\mathabs{i-j+l}}\right)
\end{align*}
where $\delta_{m}$ is the \emph{Kronecker delta
function}. Thus:
\begin{align*}
T_{l,k}\left(y\right) &=\sum^{l+2k}_{m=0}y_{m}\mathcal{E}^{m}_{l,k} 
\end{align*}

\subsection{A \emph{Markov-Lukacs} theorem for trigonometric curves}
\emph{Tuan et
al}~\cite[Appendix 1]{TuanHoangNgoTuyVo_DualFrequencySelectiveBoundedRealLemma}
prove the following version of the \emph{Markov-Lukacs} theorem:
\begin{framed}
Any algebraic polynomial, $P\left(t\right)=\phi^{\top}_{n}\left(t\right)x$, that
is non-negative on $\left[a,b\right]\subset \left(-\infty,\infty\right)$ can
be written as:
\begin{align}
\label{eqn:Markov-Lukacs}
P\left(t\right)&=\begin{cases}
\langle X,\mathcal{M}_{k}\left(t\right)\rangle+
\left(b-t\right)\left(t-a\right)\langle Z,\mathcal{M}_{k-1}\left(t\right)\rangle,
 & n=2k \\
\left(t-a\right)\langle X,\mathcal{M}_{k}\left(t\right)\rangle+
\left(b-t\right)\langle Z,\mathcal{M}_{k-1}\left(t\right)\rangle, & n=2k+1
\end{cases}
\end{align}
where there exist $X,Z\succeq 0$.
\end{framed}
\emph{Tuan et
al}~\cite[Theorem 2]{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}
prove the following version of the \emph{Markov-Lukacs} theorem for
trigonometric polynomials:
\begin{framed}
Any algebraic polynomial,
$P\left(\omega\right)=\varphi^{\top}_{n}\left(\omega\right)x$, that is
non-negative on $\left[\cos a,\cos b\right]$ can be written as:
\begin{align}
\label{eqn:Markov-Lukacs-trigonometric}
P\left(\omega\right)&=\begin{cases}
\langle X,\mathcal{T}_{k}\left(\omega\right)\rangle+
\langle Z,\mathcal{F}^{a,b}_{k}\left(\omega\right)\rangle, & n=2k \\
\langle \cos b\;Z -\cos a\;X,\mathcal{T}_{k}\left(\omega\right)\rangle+
\langle X-Z,\mathcal{T}_{1,k1}\left(\omega\right)\rangle, & n=2k+1
\end{cases}
\end{align}
where there exist $X,Z\succeq 0$ and
\begin{align*}
\mathcal{F}^{a,b}_{k}\left(\omega\right)&=
\left(\cos b +\cos a\right)\mathcal{T}_{1,k-1}\left(\omega\right)
-\frac{1}{2}\mathcal{T}_{2,k-1}\left(\omega\right)
-\left(\frac{1}{2}+\cos a\cos b\right)\mathcal{T}_{k-1}\left(\omega\right)
\end{align*}
\end{framed}
The Chebyshev polynomials of the first kind are:
\begin{align*}
\cos l\omega&=\sum^{l}_{m=0}b_{lm}\cos^{m}\omega
\end{align*}
Hence there is a triangular, non-singular transformation, $B_{k}$, such that:
\begin{align*}
\varphi_{k}\left(\omega\right)&=B_{k}\phi_{k}\left(\cos\omega\right)
\end{align*}
and:
\begin{align*}
\mathcal{M}_{k}\left(\cos\omega\right)
&=B^{-1}_{k}\mathcal{T}_{k}\left(\omega\right)B^{-\top}_{k}
\end{align*}
Equation~\ref{eqn:Markov-Lukacs-trigonometric} is found by substitution of
$\mathcal{M}_{k}\left(\cos\omega\right)$ into Equation~\ref{eqn:Markov-Lukacs}.

\emph{Tuan et
al}~\cite[Lemma 1]{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}
prove the following lemma:
\begin{framed}
If $P\left(\omega\right)=\varphi^{\top}_{n}\left(\omega\right)x$
can be represented as shown in Equation~\ref{eqn:Markov-Lukacs-trigonometric},
then for every $y=\left(y_{0},y_{1},\hdots,y_{n}\right)^{\top}\in\mathbb{R}^{n+1}$:
\begin{align*}
y^{\top}x&=\begin{cases}
\langle X,T_{k}\left(y\right)\rangle+\langle Z,F^{a,b}_{k}\left(y\right)\rangle,
&n=2k \\
\langle X,T_{1,k}\left(y\right)-\cos a\;T_{k}\left(y\right)\rangle+
\langle Z,\cos b\;T_{k}\left(y\right)-T_{1,k}\left(y\right)\rangle, &n=2k+1
\end{cases}
\end{align*}
where $X,Z\succeq 0$ and:
\begin{align*}
F^{a,b}_{k}\left(y\right)=\left(\cos b+\cos a\right)T_{1,k-1}\left(y\right)
-\frac{1}{2}T_{2,k-1}\left(y\right)
-\left(\frac{1}{2}+\cos a\cos b\right)T_{k-1}\left(y\right)
\end{align*}
\end{framed}

\subsection{The conic hull of \texorpdfstring{$C_{a,b}$}{Cab}}
The \emph{convex hull} of a set $C\subset\mathbb{R}^{n}$ is the smallest convex
set in $\mathbb{R}^{n}$ that contains $C$. Likewise, The \emph{conic hull} of a
set $C\subset\mathbb{R}^{n}$ is the smallest cone in $\mathbb{R}^{n}$ that
contains $C$. The polar set of $C$ is the
cone $C^{\star}=\left\{x\;:\:\langle x,y\rangle\ge 0\;\forall\;y\in C\right\}$.
\emph{Tuan et
al}~\cite[Theorem 3]{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}
prove the following version of the \emph{Markov-Lukacs} theorem for the conic
hull of trigonometric polynomials:
\begin{framed}
For the variables $y=\left(y_{0},y_{1},\hdots,y_{2k}\right)\in\mathbb{R}^{n+1}$
define the following LMI constraints:
\begin{align}
\label{eqn:Markov-Lukacs-trigonometric-LMI}
&\begin{cases}
T_{k}\left(y\right)\succeq 0, F^{a,b}_{k}\left(y\right)\succeq 0, & n=2k \\
\cos b\;T_{k}\left(y\right)\succeq T_{1,k}\left(y\right)\succeq
\cos a\;T_{k}\left(y\right), & n=2k+1 \\
\end{cases}
\end{align}
The convex hull of the set $C_{a,b}$ is characterised by the LMI constraints:
\begin{align*}
\mathcohull{C_{a,b}}&=\left\{\left(y_{0},y_{1},\cdots,y_{n}\right)\; :\;
\text{Equation }\ref{eqn:Markov-Lukacs-trigonometric-LMI},\; y_{0}=1\right\}
\end{align*}
The conic hull of $C_{a,b}$ is defined by:
\begin{align*}
\mathcone{C_{a,b}}&=\left\{\left(y_{0},y_{1},\cdots,y_{n}\right)\; :\;
\text{Equation }\ref{eqn:Markov-Lukacs-trigonometric-LMI}\right\}
\end{align*}
\end{framed}
Substituting the $\mathcal{E}^{m}_{l,k}$ basis matrixes~\cite[Theorem
4]{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}:
\begin{framed}
The trigonometric polynomial,
$P\left(\omega\right)=\sum^{n}_{m=0}x_{m}\cos m\omega$ is non-negative on
$\left[\cos a,\cos b\right]$ if-and-only-if there are positive semi-definite
matrixes $X$ and $Z$ such that:
\begin{align}
\label{eqn:Markov-Lukacs-trigonometric-LMI-basis-x-m}
x_{m}&=\begin{cases}
\langle X,\mathcal{E}^{m}_{0,k}\rangle+\langle Z,\mathcal{F}^{a,b}_{m,k}\rangle,
& n=2k \\
\langle X,\mathcal{E}^{m}_{1,k}\rangle-\cos a\;\mathcal{E}^{m}_{0,k}+
\langle Z,\cos b\;\mathcal{E}^{m}_{0,k}-\mathcal{E}^{m}_{1,k}\rangle,& n=2k+1
\end{cases}
\end{align}
When $n=2k$:
\begin{align*}
\mathcal{F}^{a,b}_{m,k}&=\left(\cos b+\cos a\right)\mathcal{E}^{m}_{1,k-1}
-\frac{1}{2}\mathcal{E}^{m}_{2,k-1}
-\left(\frac{1}{2}+\cos a\cos b\right)\mathcal{E}^{m}_{0,k-1} \\
F^{a,b}_{k}\left(y\right)&=\sum^{2k}_{m=0}y_{m}\mathcal{F}^{a,b}_{m,k}
\end{align*}
\end{framed}

If $e_m$ is the unit vector in $\mathbb{R}^{n+1}$ with $1$ at the $m$-th
component, then the LMI constraint over $\left[\cos a_{i},\cos b_{i}\right]$ is:
\begin{align}
\label{eqn:Markov-Lukacs-trigonometric-LMI-basis-constraint}
e^{\top}_{m+1}\left(A_{i}x+d_{i}\right)&=\begin{cases}
\langle X_{i},\mathcal{E}^{m}_{0,k}\rangle+
\langle Z_{i},\mathcal{F}^{a_{i},b_{i}}_{m,k}\rangle,& n=2k \\
\langle X_{i},\mathcal{E}^{m}_{1,k}-\cos a_{i}\;\mathcal{E}^{m}_{0,k}\rangle+
\langle Z_{i},\cos b_{i}\;\mathcal{E}^{m}_{0,k}-\mathcal{E}^{m}_{1,k}\rangle,& n
=2k=1
\end{cases}
\end{align}
where $X_{i},Z_{i}\succeq 0$.

\subsection{Optimisation of the dual of a convex quadratic objective function}
The convex quadratic optimisation problem over a set of trigonometric
polynomials is:
\begin{align*}
\textbf{minimise}\quad &x^{\top}Qx+q^{\top}x \\
\textbf{subject to}\quad &
\text{Equation }\ref{eqn:Markov-Lukacs-trigonometric-LMI-basis-constraint}
\end{align*}
where $Q\succeq 0$. The dual problem is
\begin{comment}
\footnote{Suppose the primal problem is:
\begin{align*}
\textbf{minimise}\quad & \langle C,X\rangle \\
\textbf{subject to}\quad & X\succ 0,\;\langle A_{i},X\rangle=b_{i} 
\end{align*}
where $\langle C,X\rangle = \sum_{i,j}C_{i,j}X^{\top}_{i,j}$. If $C\succeq 0$
and $X=xx^{\top}$ then $\langle C,X\rangle=x^{\top}Cx$. The Lagrangian function is:
\begin{align*}
L\left(X,y\right)&=
\langle C,X\rangle -\sum_{i}y_{i}\left(\langle A_{i},X\rangle-b_{i}\right)\\
&=\langle C-\sum_{i}y_{i}A_{i},X\rangle+y^{\top}b
\end{align*}
The dual problem is:
\begin{align*}
\textbf{maximise}\quad & y^{\top}b \\
\textbf{subject to}\quad & C-\sum_{i}y_{i}A_{i}\succeq 0
\end{align*}
}
\end{comment}
:
\begin{align*}
\max_{y^{i}\in C_{i}}\min_{x}\left[x^{\top}Qx+q^{\top}x-
\sum_{i}\left(A_{i}x+d_{i}\right)^{\top}y^{i}\right]
&=\max_{y^{i}\in C_{i}}\min_{x}\left[x^{\top}Qx+
x^{\top}\left(q-\sum_{i}A_{i}^{\top}y^{i}\right)
-\sum_{i}d_{i}^{\top}y^{i}\right]\\
&=\max_{y^{i}\in C_{i}}\left[-\sum_{i}d_{i}^{\top}y^{i}
-\frac{1}{4}\left(q-\sum_{i}A_{i}^{\top}y^{i}\right)^{\top}Q^{-1}
\left(q-\sum_{i}A_{i}^{\top}y^{i}\right)\right] 
\end{align*}

\begin{samepage}
Using Equation~\ref{eqn:Markov-Lukacs-trigonometric-LMI} the dual problem
becomes:
\begin{align}
\textbf{maximise}\quad & \left[-\sum_{i}d_{i}^{\top}y^{i}
-\frac{1}{4}\left(q-\sum_{i}A_{i}^{\top}y^{i}\right)^{\top}Q^{-1}
\left(q-\sum_{i}A_{i}^{\top}y^{i}\right)\right] \nonumber \\
\label{eqn:Markov-Lukacs-trigonometric-LMI-constraints}
\textbf{subject to}\quad & 
\begin{cases}
T_{k}\left(y^{i}\right)\succeq 0, F^{a_{i},b_{i}}_{k}\left(y^{i}\right)\succeq 0,
 & n=2k \\
\cos b_{i}\;T_{k}\left(y^{i}\right)\succeq T_{1,k}\left(y^{i}\right)\succeq
\cos a_{i}\;T_{k}\left(y^{i}\right), & n=2k+1
\end{cases}
\end{align}
\end{samepage}

In SDP form:
\begin{align*}
\textbf{maximise}\quad & -\nu-\sum_{i}d_{i}^{\top}y^{i} \\
\textbf{subject to}\quad &\left[\begin{array}{cc}
\nu & \left(q-\sum_{i}A_{i}^{\top}y^{i}\right)^{\top} \\
\left(q-\sum_{i}A_{i}^{\top}y^{i}\right) & 4Q\end{array}\right] \succeq 0\\
&\text{Equation }\ref{eqn:Markov-Lukacs-trigonometric-LMI-constraints}
\end{align*}

The optimal solution of the dual problem, $x_{\star}$ and $y^{i}_{\star}$, requires
finding the $n+1$ scalar variables for each constraint, $y^{i}_{\star}$, that
satisfy:
\begin{align*}
&\sum_{i}\left(A_{i}x_{\star}+d_{i}\right)^{\top}y^{i}_{\star}=0\\
& x_{\star}=-\frac{1}{2}Q^{-1}\left(q-\sum_{i}A^{\top}_{i}y^{i}_{\star}\right)
\end{align*}

\subsection{Example of LMI design of a low pass symmetric FIR filter}
The low pass filter design primal problem is:
\begin{align*}
\textbf{minimise}\quad x^{\top}Qx+q^{\top}x \;\;\; & \\
\textbf{subject to}\quad 
 x+\left(\delta_{p}-1\right)e_{1} &\in C^{\star}_{\omega_{p},0} \\
-x+\left(\delta_{p}+1\right)e_{1}&\in C^{\star}_{\omega_{p},0} \\
 x+\delta_{s}e_{1}&\in C^{\star}_{\pi,\omega_{s}} \\
-x+\delta_{s}e_{1}&\in C^{\star}_{\pi,\omega_{s}}
\end{align*}

The Octave script \emph{directFIRsymmetric\_sdp\_lowpass\_test.m} uses
YALMIP and SeDuMi to solve the dual problem of designing a low pass filter
by the method of \emph{Tuan et
al.}~\cite{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}. I only
 allow solutions for which YALMIP and SeDuMi do not report numerical
 problems. The filter specification is\footnote{\emph{Tuan et al.} define the
 pass-band peak-to-peak ripple as:
\begin{align*}
dBap &= 20\log_{10}\frac{1+\delta_{p}}{1-\delta_{p}}
\end{align*}}: 
\begin{small}
\verbatiminput{directFIRsymmetric_sdp_lowpass_test_hM031_spec.m}
\end{small}

Figure~\ref{fig:Direct-FIR-symmetric-SDP-hM031-low-pass-response}
shows the zero-phase amplitude responses in the pass band and the stop band.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_sdp_lowpass_test_hM031_dual_response}}
\caption{Pass band and stop band zero-phase amplitude responses of an
$M=31$ symmetric low pass FIR filter designed with the LMI procedure of 
\emph{Tuan et al.}~\cite{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}.}
\label{fig:Direct-FIR-symmetric-SDP-hM031-low-pass-response}
\end{figure}

In addition, the Octave script \emph{directFIRsymmetric\_sdp\_lowpass\_test.m} 
attempts to design a low pass filter with a specification similar to that of the
example of \emph{Tuan et al.}~\cite[Figure
3]{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}:
\begin{small}
\verbatiminput{directFIRsymmetric_sdp_lowpass_test_hM200_spec.m}
\end{small}

I could not reproduce the stop-band edge specification of $fas=0.0358$ given by
\emph{Tuan et al.}~\cite[Table 1, Figure
3]{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}. The amplitude 
response specification $dBap=0.5,fas=0.0358$ gives a ``reasonable'' response 
despite numerical warning messages from SeDuMi.

Figure~\ref{fig:Direct-FIR-symmetric-SDP-hM200-low-pass-response}
shows the zero-phase amplitude responses in the pass band and the stop band.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_sdp_lowpass_test_hM200_dual_response}}
\caption{Pass band and stop band zero-phase amplitude responses of an
$M=200$ symmetric low pass FIR filter designed with the LMI procedure
of \emph{Tuan et 
al.}~\cite[Figure 3]{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}.}
\label{fig:Direct-FIR-symmetric-SDP-hM200-low-pass-response}
\end{figure}

For comparison, the Octave script
\emph{mcclellanFIRsymmetric\_lowpass\_alternate\_test.m} uses the
\emph{Parks-McClellan} 
algorithm~\cite{ParksMcClellan_ChebyshevApproxNonRecursiveDigitalFilters}
implemented in the Octave function \emph{mcclellanFIRsymmetric} to design a
filter similar to that of \emph{Tuan et al.}'s Figure 3: 
\begin{small}
\verbatiminput{mcclellanFIRsymmetric_lowpass_alternate_test_spec.m}
\end{small}
Figure~\ref{fig:mcclellanFIRsymmetric-lowpass-alternate-test-dual} shows the
pass band and stop band zero-phase amplitude responses.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{mcclellanFIRsymmetric_lowpass_alternate_test_dual}}
\caption{Pass band and stop band zero-phase amplitude responses of a mini-max
FIR low-pass filter designed with the \emph{Parks-McClellan} algorithm. The
  filter specification is similar to that of the example of \emph{Tuan et
  al.}~\cite[Figure 3]{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}.}
\label{fig:mcclellanFIRsymmetric-lowpass-alternate-test-dual}
\end{figure}

As another comparison, the Octave script
\emph{selesnickFIRsymmetric\_lowpass\_alternate\_test.m} uses \emph{Hofstetter}'s
algorithm~\cite{Hofstetter_DesignNonRecursiveDigitalFilters}
with the \emph{Selesnick-Burrus}
modification~\cite{SelesnickBurrus_ExchangeAlgorithmsParksMcClellanAlgorithm},
implemented in the Octave function \emph{selesnickFIRsymmetric\_lowpass}, to
design an FIR filter similar to that of \emph{Tuan et al.}'s Figure 4:
\begin{small}
\verbatiminput{selesnickFIRsymmetric_lowpass_alternate_test_spec.m}
\end{small}
Figure~\ref{fig:selesnickFIRsymmetric-lowpass-alternate-test-dual} shows the
zero-phase pass band and stop band amplitude responses. The transition frequency
is set to $f_{as}$. The actual pass band edge frequency is
$f_{ap}=$~\input{selesnickFIRsymmetric_lowpass_alternate_test_fapx.tab}.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{selesnickFIRsymmetric_lowpass_alternate_test_dual}}
\caption{Pass band and stop band responses of a mini-max FIR low-pass filter
designed with the \emph{Selesnick-Burrus} modification
  to \emph{Hofstetter}'s algorithm. The filter specification is similar to the
  example of \emph{Tuan et
  al.}~\cite[Figure 4]{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}.}
\label{fig:selesnickFIRsymmetric-lowpass-alternate-test-dual}
\end{figure}

\subsection{Example of LMI design of a band-pass symmetric FIR filter}
The Octave script \emph{directFIRsymmetric\_sdp\_bandpass\_test.m} uses the LMI
procedure of \emph{Tuan et al.} to design a band-pass symmetric FIR filter with 
the specification:
\begin{small}
\verbatiminput{directFIRsymmetric_sdp_bandpass_test_hM80_spec.m}
\end{small}

In this case the frequency bands are not weighted (i.e.: $Wasl=1$, etc.).

The distinct filter coefficients are:
\begin{small}
\verbatiminput{directFIRsymmetric_sdp_bandpass_test_hM80_coef.m}
\end{small}

Figure~\ref{fig:Direct-FIR-symmetric-SDP-hM80-band-pass-response}
shows the zero-phase amplitude responses in the pass band and the stop bands.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_sdp_bandpass_test_hM80_dual_response}}
\caption{Pass band and stop band zero-phase amplitude responses of an
$M=80$ symmetric band pass FIR filter designed with the LMI procedure
of \emph{Tuan et 
al.}~\cite{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}.}
\label{fig:Direct-FIR-symmetric-SDP-hM80-band-pass-response}
\end{figure}

In addition, the Octave script \emph{directFIRsymmetric\_sdp\_bandpass\_test.m}
designs a band-pass symmetric FIR filter with a specification similar to that of
the example of \emph{Pipeleers et al.}~\cite[Figure
4]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals}: 
\begin{small}
\verbatiminput{directFIRsymmetric_sdp_bandpass_test_hM15_spec.m}
\end{small}

The distinct filter coefficients are:
\begin{small}
\verbatiminput{directFIRsymmetric_sdp_bandpass_test_hM15_coef.m}
\end{small}

Figure~\ref{fig:Direct-FIR-symmetric-SDP-hM15-band-pass-response}
shows the zero-phase amplitude responses in the pass band and the stop bands.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_sdp_bandpass_test_hM15_dual_response}}
\caption{Pass band and stop band zero-phase amplitude responses of an
$M=15$ symmetric band pass FIR filter designed with the LMI procedure
of \emph{Tuan et 
al.}~\cite{TuanSonVoNguyen_EfficientFilterDesignLMITrigonometric}.}
\label{fig:Direct-FIR-symmetric-SDP-hM15-band-pass-response}
\end{figure}

For comparison, the Octave script
\emph{directFIRsymmetric\_socp\_slb\_bandpass\_test.m} designs a band-pass
symmetric FIR filter using the PCLS algorithm of \emph{Selesnick et 
al.}~\cite{SelesnickLangBurrus_ConstrainedLeastSquareFIRFilters} with the
specification:
\begin{small}
\verbatiminput{directFIRsymmetric_socp_slb_bandpass_test_spec.m}
\end{small}

The distinct coefficients of this filter are:
\begin{small}
\verbatiminput{directFIRsymmetric_socp_slb_bandpass_test_hM1_coef.m}
\end{small}

Figure~\ref{fig:Direct-FIR-symmetric-SOCP-SLB-band-pass-response}
shows the zero-phase amplitude response.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_socp_slb_bandpass_test_dual_response}}
\caption{Zero-phase amplitude response of an $M=15$ symmetric band pass FIR
filter designed with the PCLS optimisation procedure of \emph{Selesnick et
al.}~\cite{SelesnickLangBurrus_ConstrainedLeastSquareFIRFilters}.}
\label{fig:Direct-FIR-symmetric-SOCP-SLB-band-pass-response}
\end{figure}

Similarly, the Octave script
\emph{directFIRnonsymmetric\_socp\_slb\_bandpass\_test.m} designs a
non-symmetric FIR filter using the PCLS algorithm of \emph{Selesnick et al.}
with the specification:
\begin{small}
\verbatiminput{directFIRnonsymmetric_socp_slb_bandpass_test_spec.m}
\end{small}

The coefficients of this filter are:
\begin{small}
\verbatiminput{directFIRnonsymmetric_socp_slb_bandpass_test_h_coef.m}
\end{small}

Figure~\ref{fig:Direct-FIR-non-symmetric-SOCP-SLB-band-pass-pass-stop-response}
shows the amplitude and delay responses in the pass band and the stop band
amplitude response.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRnonsymmetric_socp_slb_bandpass_test_pass_stop}}
\caption{Pass band amplitude and delay responses and stop band amplitude
response of an $M=15$ non-symmetric band pass FIR filter designed with the PCLS
optimisation procedure of \emph{Selesnick et
al.}~\cite{SelesnickLangBurrus_ConstrainedLeastSquareFIRFilters}.} 
\label{fig:Direct-FIR-non-symmetric-SOCP-SLB-band-pass-pass-stop-response}
\end{figure}
\clearpage
\section{\label{app:Design-of-FIR-half-band-filters}Design of half-band FIR filters}
\subsection{\label{app:Vaidyanathan-FIR-half-band-trick}Vaidyanathan's ``TRICK'' for the design of FIR half-band filters}
\emph{Vaidyanathan} and \emph{Nguyen}~\cite{Vaidyanathan_TRICK_HalfBand_FIR}
describe a method for the design of half-band FIR filters with pass-band edge
$f_{p}$ and length $4M+3$:
\begin{enumerate}
  \item Design a low-pass FIR filter, $G\left(z\right)$ with odd order
    $2M+1$, pass band edge $2f_{p}$ and transition band $2f_{p}$ to $0.5$
  \item Construct the half-band FIR filter:
\begin{align*}
  h\left(n\right)&=\begin{cases}
    \frac{1}{2}g\left(\frac{n}{2}\right), & n=0,2,\hdots,4M+2 \\
    0, &n=1,3,\hdots,4M+1, \quad n\neq{}2M+1 \\
    \frac{1}{2} &n=2M+1 \\
    \end{cases}
\end{align*}
\end{enumerate}

The $z$-domain transfer function of $H\left(z\right)$ is:
\begin{align*}
  H\left(z\right)&=\frac{G\left(z^{2}\right)+z^{-\left(2M+1\right)}}{2}
\end{align*}

The Octave script \emph{vaidyanathan\_trick\_test.m} designs a half-band filter
with pass-band edge $fp=0.24$ and $M=80$ using \emph{Vaidyanathan}'s
``TRICK''. The script calls the Octave \emph{remez} function to design a
low-pass filter with pass-band edge $2fp=0.48$ and stop-band edge $0.499$. The
\emph{remez} function fails to converge for
$M>81$. Figure~\ref{fig:Vaidyanathan-FIR-half-band-TRICK-response} shows the 
frequency response of the filter.

\begin{figure}[H]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{vaidyanathan_trick_test_response}}
\caption{FIR half-band filter with $fp=0.24$ and $M=80$ designed with
Vaidyanathan's ``TRICK''~\cite{Vaidyanathan_TRICK_HalfBand_FIR}.}
\label{fig:Vaidyanathan-FIR-half-band-TRICK-response}
\end{figure}

\clearpage
\subsection{\label{app:Equiripple-FIR-half-band-design}Design of equi-ripple FIR half-band filters}
\emph{Zahradn\'{i}k}, \emph{Vl\v{c}ek} and
\emph{Unbehauen}~\cite{Zahradnik_AlmostEquirippleApproxHalfBandFIR} describe the
closed-form design of almost-equiripple half-band FIR filters. The impulse
response, $h$, of a length $4n+3$ half-band FIR filter is defined by the
transfer function: 
\begin{align}
  H\left(z\right)&=\sum_{k=0}^{4n+2}h_{k}z^{-k}
\label{eqn:Zahradnik-half-band-impulse-response-definition}
\end{align}
where:
\begin{align*}
  h_{2n+1}&=\frac{1}{2}\\
  h_{2n+1\pm 2k}&=0\;\text{,}\quad{}k=1,\hdots,n
\end{align*}
Substituting $v=\frac{1}{2}\left(z+\frac{1}{z}\right)$, the frequency response
is:
\begin{align*}
  H\left(e^{\imath\omega{}T}\right)
  &=e^{-\imath\left(2n+1\right)\omega{}T}Q\left(\cos\omega{}T\right)
\end{align*}
In particular, the pass-band edge is at $v_{p}=\cos\omega_{p}T$. Here
$Q\left(v\right)$, the \emph{zero-phase frequency response}, is:
\begin{align}
  Q\left(v\right)
  &=\frac{1}{2}+\sum_{k=0}^{n}c_{2k+1}T_{2k+1}\left(v\right)
    \label{eqn:Q-zero-phase-T-expansion}
\end{align}
Where the $T_{k}\left(v\right)$ are the Chebyshev polynomials of the first kind
and the coefficients, $c_{2k+1}$, of the expansion of $Q$ are the distinct
symmetric FIR coefficients of the impulse response of
$H$. Appendix~\ref{app:Review-of-Chebyshev-polynomials} reviews the
  properties of the Chebyshev polynomials of the first and second kinds. The
  latter are written $U_{k}\left(v\right)$. 

\emph{Vl\v{c}ek} and \emph{Unbehauen}~\cite[Section
IV]{Vlcek_AnalyticalSolutionsIIRFilter} show that the equivalent zero-phase
response of an IIR filter is:
\begin{align*}
 Q\left(v\right)&=\frac{1}{1+\varepsilon^{2}F^{2}\left(v\right)}
\end{align*}
The equiripple properties of $F\left(v\right)$ correspond to a differential
equation that can be solved by elliptic integrals, giving a set of parametric
equations for $F$ and $v$ in terms of Jacobian elliptic functions of a complex
variable, $u$. With the choice of half-band FIR filter order, the solution of
interest here is~\cite[Equations 33 and 34]{Vlcek_AnalyticalSolutionsIIRFilter}:
\begin{align*}
  F(u)&=\jcd\left(\frac{Mu}{\kappa_{1}},\kappa_{1}\right) \\
  v&=\jdn\left(u,\kappa\right)
\end{align*}
where $F\left(v\right)=\pm\frac{1}{\kappa_{1}}$ are the stop-band extremal values
and $\kappa_{1}$ is the elliptic modulus~\cite[Equation
16]{Vlcek_AnalyticalSolutionsIIRFilter}. The complex parameter $u$ follows the 
path shown in~\cite[Figure 8]{Vlcek_AnalyticalSolutionsIIRFilter}.

\emph{Zahradn\'{i}k et al.} use the elliptic function identity
\begin{align*}
  \jdn^{2}\left(u,\kappa\right)&=\kappa^{\prime{}2}+\left(1-\kappa^{\prime{}2}\right)
                            \jcn^{2}\left(u,\kappa\right)
\end{align*}
to give:
\begin{align*}
  x&=\frac{2v^{2}-1-\kappa^{\prime{}2}}{1-\kappa^{\prime{}2}}=2\jcn^{2}\left(u,\kappa\right)-1
\end{align*}

Returning to the case of an almost-equiripple half-band FIR filter,
\emph{Zahradn\'{i}k et al.}~\cite[Section
II]{Zahradnik_AlmostEquirippleApproxHalfBandFIR} use the relation
 between the Chebyshev polynomials of the first and second kinds:
\begin{align*}
\frac{dT_{2n+1}\left(v\right)}{dv} &=\left(2n+1\right)U_{2n}\left(v\right)
\end{align*}
to define $G\left(v\right)=U_{2n}\left(v\right)$ as the generating function for
$Q\left(v\right)$: 
\begin{align*}
  Q\left(v\right)
  &=\frac{1}{2}+\frac{1}{\mathcal{N}}\int{}G\left(v\right)dv
\end{align*}
where $\mathcal{N}$ is a normalising factor. Apparently by analogy with the
equiripple IIR filter, \emph{Zahradn\'{i}k et al.}~\cite[Equation
13]{Zahradnik_AlmostEquirippleApproxHalfBandFIR}  substitute $x$ into the double
angle identity for $U_{2n}\left(\cos\omega\right)$\footnote{\begin{align*}
    U_{2n}\left(\cos\omega\right)
  &=\frac{\sin\left[\left(2n+1\right)\omega\right]\cos\omega+
    \sin\omega\cos\left[\left(2n+1\right)\omega\right]}
    {2\sin\omega\cos\omega}+
    \frac{\sin\left[\left(2n+1\right)\omega\right]\cos\omega-
    \sin\omega\cos\left[\left(2n+1\right)\omega\right]}
    {2\sin\omega\cos\omega} \\
  &=U_{n}\left(\cos2\omega\right)+ U_{n-1}\left(\cos2\omega\right)\\
  &=U_{n}\left(2\cos^{2}\omega-1\right)+U_{n-1}\left(2\cos^{2}\omega-1\right)
  \end{align*}} and redefine the generating function as: 
\begin{align*}
  G\left(v\right)
  &=U_{n}\left(\frac{2v^{2}-1-\kappa^{\prime{}2}}{1-\kappa^{\prime{}2}}\right)+
  U_{n-1}\left(\frac{2v^{2}-1-\kappa^{\prime{}2}}{1-\kappa^{\prime{}2}}\right)
\end{align*}

\emph{Zahradn\'{i}k} and \emph{Vl\v{c}ek}~\cite[Equation
10]{Zahradnik_EquirippleApproxHalfBandFIR} modify this to give a better
equiripple approximation:
\begin{align*}
  G\left(v\right)
  &=AU_{n}\left(\frac{2v^{2}-1-\kappa^{\prime{}2}}{1-\kappa^{\prime{}2}}\right)+
  BU_{n-1}\left(\frac{2v^{2}-1-\kappa^{\prime{}2}}{1-\kappa^{\prime{}2}}\right)
\end{align*}

\emph{Zahradn\'{i}k} and \emph{Vl\v{c}ek}~\cite[Equations 11 to
14]{Zahradnik_EquirippleApproxHalfBandFIR} provide numerical approximations for
$n$, $\kappa^{\prime}$, $A$ and $B$:
\begin{align*}
  n&=\frac{a_{s}-18.18840664\omega_{p}T+33.64775300}
     {18.54155181\omega_{p}T-29.13196871}\\
  \kappa^{\prime}&=\frac{n\omega_{p}T-1.57111377n+0.00665857}
              {-1.01927560n+0.37221484}\\
  A&=\left(0.01525753n+0.03682344+\frac{9.24760314}{n}\right)\kappa^{\prime}
     +1.01701407+\frac{0.73512298}{n}\\
  B&=\left(0.00233667n-1.35418408+\frac{5.75145813}{n}\right)\kappa^{\prime}
     +1.02999650-\frac{0.72759508}{n}
\end{align*}
where $a_{s}<0$ is the stop-band attenuation in $dB$.
Alternatively, $A$ and $B$ can be obtained numerically by solving:
\begin{align*}
  Q\left(v_{p}\right)&=\begin{cases}
    Q\left(1\right)\text{,}&\text{if n is odd}\\
    Q\left(v_{01}\right)\text{,}&\text{if n is even}
  \end{cases}
\end{align*}
and:
\begin{align*}
  Q\left(v_{01}\right)&=1\text{,}\quad\text{if n is odd}\\
  Q\left(1\right)&=1\text{,}\quad\text{if n is even}
\end{align*}
where $v_{01}$ is the first zero of the generating function
$U_{2n}\left(\jcn\left(u,\kappa\right)\right)$ (ie: the first extremal value of
$Q\left(v\right)$ as $1\rightarrow{}v$)~\cite[Equation
15]{Zahradnik_AlmostEquirippleApproxHalfBandFIR}:
\begin{align*}
  v_{01}&=\sqrt{\kappa^{\prime{}2}+\left(1-\kappa^{\prime{}2}\right)\cos^{2}\frac{\pi}{2n+1}}
\end{align*}
Writing:
\begin{align*}
  \mathcal{U}_{n}\left(v\right)
  &=\int{}U_{n}\left(\frac{2v^{2}-1-\kappa^{\prime{}2}}{1-\kappa^{\prime{}2}}\right)dv
\end{align*}
the zero-phase transfer function is:
\begin{align*}
  Q\left(v\right)&=\frac{1}{2}+\frac{A}{\mathcal{N}}\mathcal{U}_{n}\left(v\right)
                   +\frac{B}{\mathcal{N}}\mathcal{U}_{n-1}\left(v\right)
\end{align*}
The normalisation factor $\mathcal{N}$ is~\cite[Equation
17]{Zahradnik_EquirippleApproxHalfBandFIR}:
\begin{align*}
  \mathcal{N}&=\begin{cases}
    2\left[A\mathcal{U}_{n}\left(v_{01}\right)+
      B\mathcal{U}_{n-1}\left(v_{01}\right)\right]\text{,}&\text{if $n$ is odd}\\
    2\left[A\mathcal{U}_{n}\left(1\right)+B\mathcal{U}_{n-1}\left(1\right)\right]
    \text{,}&\text{if $n$ is even} \\
    \end{cases}
\end{align*}

\emph{Zahradn\'{i}k} and \emph{Vl\v{c}ek}~\cite[Figures 1 and
2]{Zahradnik_EquirippleApproxHalfBandFIR} show plots of the generating function,
$G\left(v\right)$ and zero-phase frequency response, $Q\left(v\right)$ for
$n=20$, $\kappa^{\prime}=0.03922835$, $A=1.08532371$, $B=0.95360863$ and
$\mathcal{N}=0.55091994$. 
The Octave script \emph{zahradnik\_halfband\_test.m} an reproduces these as
Figure~\ref{fig:Zahradnik-Vlcek-halfband-Figure-1} and
Figure~\ref{fig:Zahradnik-Vlcek-halfband-Figure-2}.
Figure~\ref{fig:Zahradnik-Vlcek-halfband-frequency-response} shows the
corresponding frequency response.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zahradnik_halfband_test_fig1}}
\caption{Equiripple FIR half-band filter generating function, $G\left(v\right)$,
  for $n=20$, $\kappa^{\prime}=0.03922835$, $A=1.08532371$, $B=0.95360863$ and
  $N=0.55091994$~\cite[Figure 1]{Zahradnik_EquirippleApproxHalfBandFIR}.}
\label{fig:Zahradnik-Vlcek-halfband-Figure-1}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zahradnik_halfband_test_fig2}}
\caption{Equiripple FIR half-band filter zero-phase frequency response,
  $Q\left(v\right)$, for $n=20$, $\kappa^{\prime}=0.03922835$, $A=1.08532371$,
  $B=0.95360863$ and $N=0.55091994$~\cite[Figure
  2]{Zahradnik_EquirippleApproxHalfBandFIR}.} 
\label{fig:Zahradnik-Vlcek-halfband-Figure-2}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zahradnik_halfband_test_fig2_response}}
\caption{Equiripple FIR half-band filter frequency response for $n=20$,
  $\kappa^{\prime}=0.03922835$, $A=1.08532371$, $B=0.95360863$ and
  $N=0.55091994$.}  
\label{fig:Zahradnik-Vlcek-halfband-frequency-response}
\end{figure}

The Chebyshev polynomials of the second kind satisfy the differential equation:
\begin{align}
  \left(1-v^{2}\right)\frac{d^{2}U_{n}\left(v\right)}{dv^{2}}-
  3v\frac{dU_{n}\left(v\right)}{dv}+n\left(n+2\right)U_{n}\left(v\right)&=0
\label{eqn:Zahradnik-half-band-Chebyshev-type2-in-x}
\end{align}
Substituting $x$~\cite[Equation 8]{Zahradnik_EquirippleApproxHalfBandFIR}:
\begin{align}
\begin{split}
  v\left(v^{2}-\kappa^{\prime{}2}\right)\left[
  \left(1-v^{2}\right)\frac{d^{2}U_{n}\left(v\right)}{dv^{2}}-
  3v\frac{dU_{n}\left(v\right)}{dv}\right]+ % \hdots\\
  \left[\left(\kappa^{\prime{}2}+2v^{2}\right)\left(1-v^{2}\right)
  \right]\frac{dU_{n}\left(v\right)}{dv}+
  4v^{3}n\left(n+2\right)U_{n}\left(v\right)&=0
\end{split}
\label{eqn:Zahradnik-half-band-Chebyshev-type2-in-v}
\end{align}
Equation~\ref{eqn:Zahradnik-half-band-Chebyshev-type2-in-v} is arranged so that
its solution is simplified by using
Equation~\ref{eqn:Zahradnik-half-band-Chebyshev-type2-in-x}.
Equation~\ref{eqn:Zahradnik-half-band-Chebyshev-type2-in-v} is solved by the
series expansion:
\begin{align}
  U_{n}\left(\frac{2v^{2}-1-\kappa^{\prime{}2}}{1-\kappa^{\prime{}2}}\right)
  &=\sum^{n}_{l=0}\alpha_{2l}U_{2l}\left(v\right)
   \label{eqn:Zahradnik-half-band-series-expansion-in-U2l}
\end{align}
Integrating this expansion results in an expression of the form shown in
Equation~\ref{eqn:Q-zero-phase-T-expansion}.
\emph{Zahradn\'{i}k} and \emph{Vl\v{c}ek}~\cite[Table
1]{Zahradnik_EquirippleApproxHalfBandFIR} show an algorithm for the evaluation
of the coefficients, $a_{l}$, of $\mathcal{U}_{n}$, reproduced here, with
a correction to $\alpha_{2n-4}$, as
Algorithm~\ref{alg:Zahradnik-U-n-impulse-response}.

\begin{algorithm}[htbp]
  \begin{algorithmic}
  \vspace{1.5mm}
  \vspace{1.5mm}
    \Require $n$, $\kappa^{\prime}$
  \vspace{1.5mm}
  \vspace{1.5mm}
  \\
  \textit{Initialisation:}
    \State $\alpha_{2n} = \left(1-\kappa^{\prime{}2}\right)^{-n}$
  \vspace{1.5mm}
    \State
    $\alpha_{2n-2}=-\left[1+2n\kappa^{\prime{}2}\right]\alpha_{2n}$
  \vspace{1.5mm}
    \State $\alpha_{2n-4}=-\frac{4n+1+\left(n-1\right)\left(2n-1\right)\kappa^{\prime{}2}}{2n}\alpha_{2n-2} -\frac{\left(2n+1\right)\left[\left(n+1\right)\kappa^{\prime{}2}+1\right]}{2n}\alpha_{2n}$
  \vspace{1.5mm}
  \vspace{1.5mm}
  \\
  \textit{Body:}
    \For{$l=n$ \textbf{ down to } $3$ }
  \begin{align*}
    \alpha_{2l-6} =
    &\left\{
      -\left[3\left(n\left(n+2\right)-\left(l-2\right)l\right)+2l-3+
      2\left(l-2\right)\left(2l-3\right)\kappa^{\prime{}2}\right]
      \alpha_{2l-4} \right. \quad\hdots \\
    & \phantom{\{}\left.
      -\left[3\left(n\left(n+2\right)-\left(l-1\right)\left(l+1\right)\right)+
      2\left(2l-1\right) + 2l\left(2l-1\right)\kappa^{\prime{}2}\right]
      \alpha_{2l-2} \right. \quad\hdots \\
    & \phantom{\{} \left.
      -\left[n\left(n+2\right)-\left(l-1\right)\left(l+1\right)\right]
      \alpha_{2l}
      \right\}
      \; /\; \left[n\left(n+2\right)-\left(l-3\right)\left(l-1\right)\right]
  \end{align*}
  \EndFor
  \vspace{1.5mm}
  \vspace{1.5mm}
\\
  \textit{Integration:}
  \For{$l=0$ \textbf{ to } $n$}\\
  \quad\quad$a_{2l+1}=\frac{\alpha_{2l}}{2l+1}$
  \EndFor
  \vspace{1.5mm}
  \vspace{1.5mm}
  \\
  \textit{Impulse response:}\\
  $h_{2n+1}=0$
  \vspace{1.5mm}
  \For{$l=0$ \textbf{ to } $n$}\\
\quad\quad$h_{2n+1\pm\left(2l+1\right)}=\frac{a_{2l+1}}{2}$
  \EndFor
  \vspace{1.5mm}
  \vspace{1.5mm}
\end{algorithmic}
\caption{\emph{Zahradn\'{i}k} and \emph{Vl\v{c}ek}'s algorithm~\cite[Table
  1]{Zahradnik_EquirippleApproxHalfBandFIR} for the evaluation of 
  the coefficients, $a_{l}$, of $\mathcal{U}_{n}$.}
\label{alg:Zahradnik-U-n-impulse-response}
\end{algorithm}

The Octave script \emph{zahradnik\_halfband\_test.m} implements the design of
an equiripple FIR half-band filter using
Algorithm~\ref{alg:Zahradnik-U-n-impulse-response}. The pass-band edge is
$f_{p}=0.240$, the stop-band attenuation is $a_{s}=-140dB$ and $n=118$ for a
filter length of $475$. The value of $n$ given by Equation 11 of
\emph{Zahradn\'{i}k} and
\emph{Vl\v{c}ek}\cite{Zahradnik_EquirippleApproxHalfBandFIR} is increased  
slightly. The values of $A$ and $B$ are found by a ``brute-force'' search of
all the extremal values in the pass-band.
Figure~\ref{fig:Zahradnik-Vlcek-half-band-fp-0-240-as-140-dB}
shows the amplitude response of the half-band FIR filter.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zahradnik_halfband_test_fp_0_240_as_140}}
\caption{Equiripple FIR half-band filter with $f_{p}=0.240$ and $a_{s}=-140dB$
  and $n=118$ calculated by
  Algorithm~\ref{alg:Zahradnik-U-n-impulse-response}~\cite[Table 
  1]{Zahradnik_EquirippleApproxHalfBandFIR}.}
\label{fig:Zahradnik-Vlcek-half-band-fp-0-240-as-140-dB}
\end{figure}
\clearpage
The distinct coefficients of the half-band filter are (see
Equation~\ref{eqn:Zahradnik-half-band-impulse-response-definition}):
\begin{small}
\verbatiminput{zahradnik_halfband_test_fp_0_240_as_140_coef.m}
\end{small}
Reconstruct $h$ with:
\begin{small}
\begin{verbatim}
n=118;
h=zeros(1,(4*n)+3);
h(1:2:((2*n)+1))=h_distinct(1:(n+1));
h(end:-2:((2*n)+3))=h_distinct(1:(n+1));
h((2*n)+2)=0.5;
\end{verbatim}
\end{small}
\clearpage
\subsubsection{Addendum}
\subsubsection{Working for \emph{Zahradn\'{i}k} and \emph{Vl\v{c}ek} Equation 8~\cite{Zahradnik_EquirippleApproxHalfBandFIR}}
The chain rule gives:
\begin{align*}
  \frac{dU}{dv}&=\frac{dU}{dx}\frac{dx}{dv}\\
  \frac{d^{2}U}{dv^{2}} &=\frac{d^{2}U}{dx^{2}}\left(\frac{dx}{dv}\right)^{2}+
                          \frac{dU}{dx}\frac{d^{2}x}{dv^{2}}
\end{align*}
where:
\begin{align*}
  \frac{dx}{dv} &= \frac{4v}{1-\kappa^{\prime{}2}} \\
  \frac{d^{2}x}{dv^{2}} &= \frac{4}{1-\kappa^{\prime{}2}}
\end{align*}
Rearranging:
\begin{align*}
  x\frac{dU}{dx} &= x\left(\frac{dx}{dv}\right)^{-1}\frac{dU}{dv} 
                =\frac{2v^{2}-1-\kappa^{\prime{}2}}{4v}\frac{dU}{dv} \\
  \left(1-x^{2}\right)\frac{d^{2}U}{dx^{2}}
&= \left(1-x^{2}\right)\left(\frac{dx}{dv}\right)^{-2}\left[\frac{d^{2}U}{dv^{2}}-
\left(\frac{dx}{dv}\right)^{-1}\frac{d^{2}x}{dv^{2}}\frac{dU}{dv}\right]\\
&=\frac{\left(1-v^{2}\right)\left(v^{2}-\kappa^{\prime{}2}\right)}{4v^{2}}
  \left[\frac{d^{2}U}{dv^{2}}-\frac{1}{v}\frac{dU}{dv}\right]
\end{align*}
Substituting into Equation~\ref{eqn:Zahradnik-half-band-Chebyshev-type2-in-x}
gives Equation~\ref{eqn:Zahradnik-half-band-Chebyshev-type2-in-v}.
\subsubsection{Working for \emph{Zahradn\'{i}k} and \emph{Vl\v{c}ek} Table 1~\cite[Appendix and Table 1]{Zahradnik_EquirippleApproxHalfBandFIR}}
Equations 18 to 25 are experimentally confirmed in the Octave script
\emph{chebyshevU\_test.m} under the assumption that $U_{l}\left(v\right)=0$
for $l\le{}0$.
\paragraph{\label{app:Equiripple-Approx-Half-Band-FIR-Working-for-Equation-25}Working for Equation 25}
\begin{align*}
  U_{l+3}\left(v\right)
  &=2vU_{l+2}\left(v\right)-U_{l+1}\left(v\right)\\
  &=2v\left(2vU_{l+1}\left(v\right)-U_{l}\left(v\right)\right)
    -U_{l+1}\left(v\right)\\
  &=4v^{2}\left(2vU_{l}\left(v\right)-U_{l-1}\left(v\right)\right)-
    \left(2vU_{l}\left(v\right)-U_{l-1}\left(v\right)\right)
    -U_{l+1}\left(v\right)-U_{l-1}\left(v\right)\\
  &=8v^{3}U_{l}\left(v\right)-4v^{2}U_{l-1}\left(v\right)
    -2U_{l+1}\left(v\right)-U_{l-1}\left(v\right)\\
  4v^{2}U_{l-1}\left(v\right)
  &=2v\left(2vU_{l-1}\left(v\right)-U_{l-2}\left(v\right)\right)+
    2vU_{l-2}\left(v\right)\\
  &=2vU_{l}\left(v\right)-U_{l-1}+U_{l-1}+
    2vU_{l-2}\left(v\right)-U_{l-3}\left(v\right)+U_{l-3}\left(v\right)\\
  &=U_{l+1}\left(v\right)+2U_{l-1}\left(v\right)+U_{l-3}\left(v\right)
\end{align*}
Finally,
\begin{align*}
  8v^{3}U_{l}\left(v\right)&= U_{l+3}\left(v\right)+3U_{l+1}\left(v\right)
                             +3U_{l-1}\left(v\right)+U_{l-3}\left(v\right)
\end{align*}
Substituting Equation~\ref{eqn:Zahradnik-half-band-series-expansion-in-U2l}
gives the result.

\paragraph{Working for Equation 23}
Equation 23 is simplified by applying Equation 6.
\begin{align*}
  -v\left[\left(1-v^{2}\right)\frac{d^{2}U_{2l}\left(v\right)}{dv^{2}}-
  3v\frac{dU_{2l}\left(v\right)}{dv}\right]
  &=4l\left(l+1\right)vU_{2l}\left(v\right)\\
 &=2l\left(l+1\right)\left[U_{2l+1}\left(v\right)+U_{2l-1}\left(v\right)\right]\\
v^{3} \left[ \left( 1-v^{2} \right)\frac{d^{2}U_{2l}\left(v\right)}{dv^{2}}-
3v\frac{dU_{2l}\left(v\right)}{dv} \right]
&=-4l\left(l+1\right)v^{3}U_{2l}\left(v\right)\\
  &=-\frac{1}{2}l\left(l+1\right)
    \left[U_{2l+3}\left(v\right)+3U_{2l+1}\left(v\right)
      +3U_{2l-1}\left(v\right)+U_{2l-3}\left(v\right)\right]
\end{align*}
\paragraph{Working for Equation 24}
For the $\kappa^{\prime{}2}$ part of Equation 24:
\begin{align*}
  4v^{2}U_{l}\left(v\right)
  &= 2v\left(2vU_{l}\left(v\right)-U_{l-1}\left(v\right)\right)
    +2vU_{l-1}\left(v\right)-U_{l-2}\left(v\right)+U_{l-2}\left(v\right)\\
  &= 2vU_{l+1}\left(v\right)-U_{l}\left(v\right)+
    2U_{l}\left(v\right)+U_{l-2}\left(v\right)\\
  &=U_{l+2}\left(v\right)+2U_{l}\left(v\right)+U_{l-2}\left(v\right)\\
  4\left(1-v^{2}\right)U_{l}\left(v\right)
&=-\left[U_{l+2}\left(v\right)-2U_{l}\left(v\right)+U_{l-2}\left(v\right)\right]
\end{align*}
Using Equation 20:
\begin{align*}
  \left(1-v^{2}\right)\frac{dU_{2l}\left(v\right)}{dv}
  &= \sum^{l}_{p=0}4p\left(1-v^{2}\right)U_{2p-1}\left(v\right)\\
  &= -\sum^{l}_{p=0}p
\left[U_{2p+1}\left(v\right)-2U_{2p-1}\left(v\right)+U_{2p-3}\left(v\right)\right]\\
  &=-\left[\sum^{l+1}_{p=1}\left(p-1\right)U_{2p-1}\left(v\right)
    -\sum^{l}_{p=0}2pU_{2p-1}\left(v\right)
    +\sum^{l-1}_{p=-1}\left(p+1\right)U_{2p-1}\left(v\right)\right]\\
  &=-\left[lU_{2l+1}\left(v\right)+
    \left(l-1\right)U_{2l-1}\left(v\right)-2lU_{2l-1}\left(v\right)\right]\\
  &=\left(l+1\right)U_{2l-1}\left(v\right)-lU_{2l+1}\left(v\right)
\end{align*}

Similarly, for the $2v^{2}\left(1-v^{2}\right)$ part of Equation 24:
\begin{align*}
  2v^{2}\left(1-v^{2}\right)\frac{dU_{2l}\left(v\right)}{dv}
  &= 2v^{2}\sum^{l}_{p=0}4p\left(1-v^{2}\right)U_{2p-1}\left(v\right)\\
  &=2v^{2}\left[\left(l+1\right)U_{2l-1}\left(v\right)-
    lU_{2l+1}\left(v\right)\right]\\
  &=\frac{l+1}{2}\left[U_{2l+1}\left(v\right)+
    2U_{2l-1}\left(v\right)+U_{2l-3}\left(v\right)\right]-
  \frac{l}{2}\left[U_{2l+3}\left(v\right)+
    2U_{2l+1}\left(v\right)+U_{2l-1}\left(v\right)\right]\\
\end{align*}

\paragraph{Working for Equation 26}
Collecting terms in $U_{2l+3}\left(v\right)$ from Equation 23:
\begin{align*}
  -\frac{1}{2}l\left(l+1\right)\alpha_{2l}
\end{align*}
Collecting terms in $U_{2l+3}\left(v\right)$ from Equation 24:
\begin{align*}
  -\frac{1}{2}l\alpha_{2l}
\end{align*}
Collecting terms in $U_{2l+3}\left(v\right)$ from Equation 25:
\begin{align*}
  \frac{1}{2}n\left(n+2\right)\alpha_{2l}
\end{align*}
Giving:
\begin{align*}
  U_{2l+3}\left(v\right) \text{:}
  \frac{1}{2}\left[n\left(n+2\right)-l\left(l+2\right)\right]\alpha_{2l}
\end{align*}
\paragraph{Working for Equation 27}
Collecting terms in $U_{2l+1}\left(v\right)$ from Equation 23:
\begin{align*}
  -\frac{3}{2}l\left(l+1\right)\alpha_{2l}
  +2l\left(l+1\right)\kappa^{\prime{}2}\alpha_{2l}
\end{align*}
Collecting terms in $U_{2l+1}\left(v\right)$ from Equation 24:
\begin{align*}
  -l\kappa^{\prime{}2}\alpha_{2l}
  +\frac{1}{2}\left[\left(l+1\right)-2l\right]\alpha_{2l}
\end{align*}
Collecting terms in $U_{2l+1}\left(v\right)$ from Equation 25:
\begin{align*}
  \frac{3}{2}n\left(n+2\right)\alpha_{2l}
\end{align*}
Giving:
\begin{align*}
  U_{2l+1}\left(v\right) \text{:}
  \frac{1}{2}\left[3\left(n\left(n+2\right)-l\left(l+2\right)\right)+2l+1
  \right]\alpha_{2l}+
  l\left(2l+1\right)\kappa^{\prime{}2}\alpha_{2l}
\end{align*}

\paragraph{Working for Equation 28}
Collecting terms in $U_{2l-1}\left(v\right)$ from Equation 23:
\begin{align*}
  -\frac{3}{2}l\left(l+1\right)\alpha_{2l}
  +2l\left(l+1\right)\kappa^{\prime{}2}\alpha_{2l}
\end{align*}
Collecting terms in $U_{2l-1}\left(v\right)$ from Equation 24:
\begin{align*}
  \left(l+1\right)\kappa^{\prime{}2}\alpha_{2l}
  +\frac{1}{2}\left[2\left(l+1\right)-l\right]\alpha_{2l}
\end{align*}
Collecting terms in $U_{2l-1}\left(v\right)$ from Equation 25:
\begin{align*}
  \frac{3}{2}n\left(n+2\right)\alpha_{2l}
\end{align*}
Giving:
\begin{align*}
  U_{2l-1}\left(v\right) \text{:}
  \frac{1}{2}\left[3\left(n\left(n+2\right)-l\left(l+2\right)\right)+
  2\left(2l+1\right)\right]\alpha_{2l}+
  \left(l+1\right)\left(2l+1\right)\kappa^{\prime{}2}\alpha_{2l}
\end{align*}

\paragraph{Working for Equation 29}
Collecting terms in $U_{2l-3}\left(v\right)$ from Equation 23:
\begin{align*}
  -\frac{1}{2}l\left(l+1\right)\alpha_{2l}
\end{align*}
Collecting terms in $U_{2l-3}\left(v\right)$ from Equation 24:
\begin{align*}
  \frac{1}{2}\left(l+1\right)\alpha_{2l}
\end{align*}
Collecting terms in $U_{2l-3}\left(v\right)$ from Equation 25:
\begin{align*}
  \frac{1}{2}n\left(n+2\right)\alpha_{2l}
\end{align*}
Giving:
\begin{align*}
  U_{2l-3}\left(v\right) \text{:}
  \frac{1}{2}\left[n\left(n+2\right)-\left(l-1\right)\left(l+1\right)\right]
  \alpha_{2l}
\end{align*}

\paragraph{Working for Equations 30 to 33}
Changing the summation variables:
\begin{align*}
  \begin{split}
  &\sum^{n+3}_{l=3} \frac{1}{2}\left[n\left(n+2\right)-
  \left(l-3\right)\left(l-1\right)\right]
  \alpha_{2l-6}U_{2l-3}\left(v\right) \quad\hdots\\
  +&\sum^{n+2}_{l=2}\left\{\frac{1}{2}\left[3\left(n\left(n+2\right)-
     \left(l-2\right)l\right)+2l-3\right]+
     \left(l-2\right)\left(2l-3\right)\kappa^{\prime{}2}\right\}
     \alpha_{2l-4}U_{2l-3}\left(v\right) \quad\hdots\\
  +&\sum^{n+1}_{l=1}\left\{\frac{1}{2}\left[
     3\left(n\left(n+2\right)-\left(l-1\right)\left(l+1\right)\right)+
2\left(2l-1\right)\right] + l\left(2l-1\right)\kappa^{\prime{}2}\right\}
     \alpha_{2l-2}U_{2l-3}\left(v\right)\quad\hdots\\
  +&\sum^{n}_{l=0} \frac{1}{2}
     \left[n\left(n+2\right)-\left(l-1\right)\left(l+1\right)\right]
     \alpha_{2l}U_{2l-3}\left(v\right)\\
  &=0
  \end{split}
\end{align*}
Assuming that $U_{l}\left(v\right)=0$ for $l\le{}0$:
\begin{align}
  \begin{split}
  &\sum^{n+3}_{l=3} \left[n\left(n+2\right)-
  \left(l-3\right)\left(l-1\right)\right]
  \alpha_{2l-6} \quad\hdots\\
  +&\sum^{n+2}_{l=2}\left[3\left(n\left(n+2\right)-
     \left(l-2\right)l\right)+2l-3+
     2\left(l-2\right)\left(2l-3\right)\kappa^{\prime{}2}\right]
     \alpha_{2l-4} \quad\hdots\\
  +&\sum^{n+1}_{l=2}\left[
     3\left(n\left(n+2\right)-\left(l-1\right)\left(l+1\right)\right)+
     2\left(2l-1\right) + 2l\left(2l-1\right)\kappa^{\prime{}2}\right]
     \alpha_{2l-2}\quad\hdots\\
  +&\sum^{n}_{l=2}
     \left[n\left(n+2\right)-\left(l-1\right)\left(l+1\right)\right]
     \alpha_{2l}\\
  &=0
  \end{split}
\label{eqn:Zahradnik-half-band-recurrence-summation}
\end{align}
The recurrence is initialised by calculating $\alpha_{2n}$ from
the $n+3$ term, $\alpha_{2n-2}$ from the $n+2$ term and
$\alpha_{2n-4}$ from the $n+1$ term in
Equation~\ref{eqn:Zahradnik-half-band-recurrence-summation}. The remaining terms
$\alpha_{2n-6}\hdots\alpha_{0}$ are calculated by backwards
recurrence for $l=n,n-1,\hdots,3$.
Equation~\ref{eqn:Zahradnik-half-band-recurrence-summation} is implemented in
the \emph{body} of Table 1.
\paragraph{Working for Equations 34 and 35}
The $n+3$ term in~\ref{eqn:Zahradnik-half-band-recurrence-summation} gives:
\begin{align*}
  \left[n\left(n+2\right)-l\left(l+2\right)\right]\alpha_{2n}=0
\end{align*}
$\alpha_{2n}$ is a free variable. \emph{Zahradn\'{i}k} and
\emph{Vl\v{c}ek} choose $\alpha_{2n}=\left(1-\kappa^{\prime{}2}\right)^{-n}$.
\paragraph{Working for Equation 36}
The $n+2$ term in~\ref{eqn:Zahradnik-half-band-recurrence-summation} gives:
\begin{align*}
  \frac{1}{2}\left[n\left(n+2\right)-
  \left(n-1\right)\left(n+1\right)\right]\alpha_{2n-2}+
  \left\{\frac{1}{2}\left[3\left(n\left(n+2\right)-
     n\left(n+2\right)\right)+2n+1\right]+
     n\left(2n+1\right)\kappa^{\prime{}2}\right\}\alpha_{2n}&=0\\
  \left[n\left(n+2\right)-\left(n-1\right)\left(n+1\right)\right]
  \alpha_{2n-2}+
  \left[2n+1+2n\left(2n+1\right)\kappa^{\prime{}2}\right]\alpha_{2n}&=0\\
  \left(2n+1\right)\alpha_{2n-2}+
  \left[2n+1+2n\left(2n+1\right)\kappa^{\prime{}2}\right]\alpha_{2n}&=0\\
  \alpha_{2n-2}+\left[1+2n\kappa^{\prime{}2}\right]\alpha_{2n}&=0\\
\end{align*}
\paragraph{Working for Equation 37}
The $n+1$ term in~\ref{eqn:Zahradnik-half-band-recurrence-summation} gives:
\begin{align*}
     \frac{1}{2}\left[n\left(n+2\right)- \left(n-2\right)n\right]
  &\alpha_{2n-4} +\quad\hdots \\
  \left\{\frac{1}{2}\left[3\left(n\left(n+2\right)-
     \left(n-1\right)\left(n+1\right)\right)+2n-1\right]+
  \left(n-1\right)\left(2n-1\right)\kappa^{\prime{}2}\right\}
  &\alpha_{2n-2}+\quad\hdots\\
  \left\{\frac{1}{2}\left[
     3\left(n\left(n+2\right)-n\left(n+2\right)\right)+
2\left(2n+1\right)\right] + \left(n+1\right)\left(2n+1\right)\kappa^{\prime{}2}\right\}
  &\alpha_{2n}=0\\
  2n\alpha_{2n-4} +
  \left[4n+1+\left(n-1\right)\left(2n-1\right)\kappa^{\prime{}2}\right]
  \alpha_{2n-2}+
  \left(2n+1\right)\left[\left(n+1\right)\kappa^{\prime{}2}+1\right]
  &\alpha_{2n}=0  
\end{align*}
\clearpage
\section{\label{app:FIR-design-Zolotarev}Design of equi-ripple FIR filters with Zolotarev polynomials}
The \emph{Zolotarev} polynomials are an extension of the \emph{Chebyshev}
polynomials that have found applications in the design of narrow-band FIR
filters~\cite{Vlcek_ZolotarevOptimalFIR,ChenParks_AnalyticNarrowBandFIRZolotarev,
  Zahradnik_EquirippleApproxLowPassFIR}.
\emph{Zahradn\'{i}k}~\cite{Zahradnik_EquirippleApproxLowPassFIR} shows that the
Zolotarev polynomials can provide a closed-form design of an FIR low-pass filter
with an ``almost'' equi-ripple approximation in two separate frequency bands.
Appendix~\ref{app:Review-of-elliptic-integrals-and-functions}
reviews the notation for \emph{Legendre}'s elliptic integrals and
\emph{Jacobi}'s elliptic functions.

\subsection{The Zolotarev polynomials}
\emph{Chen} and \emph{Parks}~\cite[Section
II]{ChenParks_AnalyticNarrowBandFIRZolotarev}, define ``a
Zolotarev polynomial of degree $N$, with $L$ zeros in the interval
$\left(\alpha,\beta\right)$ and $N-L$ zeros in the interval $\left(-1,1\right)$.
The function value oscillates between $-1$ and $+1$ in both intervals
$\left[\alpha,\beta\right]$ and $\left[-1,1\right]$, and is larger than unity in
the interval $\left(1,\alpha\right)$. It has $N-L+1$ extremal points of value
$+1$ or $-1$ in $\left[-1,1\right]$ and $L+1$ extremal points of value
$+1$ or $-1$ in $\left[\alpha,\beta\right]$. The closed-form expression for a
Zolotarev polynomial uses elliptic functions. It has three independent
parameters: degree $N$, the number of zeros $L$ in $\left(\alpha,\beta\right)$,
and the elliptic function modulus
$\kappa$''. Denoting such a polynomial by $f_{N,L}\left(u,\kappa\right)$, in parametric
form~\cite[Equations 3 and 4]{Vlcek_ZolotarevOptimalFIR}:
\begin{align}
  x&=\frac{\jsn^{2}\left(u,\kappa\right)+\jsn^{2}\left(\frac{LK}{N},\kappa\right)}
     {\jsn^{2}\left(u,\kappa\right)-\jsn^{2}\left(\frac{LK}{N},\kappa\right)}\\
  f_{N,L}\left(u,\kappa\right)
  &=\frac{\left(-1\right)^{L}}{2}
    \left[\left\{\frac{H\left(u-\frac{LK}{N},\kappa\right)}
                      {H\left(u+\frac{LK}{N},\kappa\right)}\right\}^{N}+
          \left\{\frac{H\left(u+\frac{LK}{N},\kappa\right)}
                      {H\left(u-\frac{LK}{N},\kappa\right)}\right\}^{N}
    \right]
    \label{eqn:Zolotarev-function-parametric-equation}
\end{align}
where $\kappa$ is the \emph{elliptic modulus},
$K=F\left(\frac{\pi}{2},\kappa\right)$ and $H\left(u,\kappa\right)$ is the
\emph{Jacobi Eta} function. 
The complex variable $u$ follows the path~\cite[Figure
2]{ChenParks_AnalyticNarrowBandFIRZolotarev}:
\begin{itemize}
  \item $u\in\left[0,\imath{}K^{\prime}\right]$ maps to $x\in\left[-1,1\right]$
  \item $u\in\left[\imath{}K^{\prime},K+\imath{}K^{\prime}\right]$ maps to
    $x\in\left[1,\alpha\right]$
  \item $u\in\left[K+\imath{}K^{\prime},K\right]$ maps to
    $x\in\left[\alpha,\beta\right]$ 
\end{itemize}
  
\emph{Vl\v{c}ek} and \emph{Unbehauen}~\cite{Vlcek_ZolotarevOptimalFIR} prefer
the notation $Z_{p,q}\left(w,\kappa\right)$ where $p$ counts the number of zeros
to the right of the maximum, $q$ counts the number of zeros to the left and
\emph{Vl\v{c}ek} and \emph{Unbehauen} introduce the independent variable
$w$, related to the discrete-time $z$-domain by: 
\begin{align*}
w=\frac{1}{2}\left(z+z^{-1}\right)\vert_{z=e^{\imath\omega{}T}}=\cos\omega{}T
\end{align*}

The intervals $x\in\left(-1,1\right)\cup\left(\alpha,\beta\right)$ are
transformed from the $x$-domain to the $w$-domain intervals
$\left(-1,w_{s}\right)\cup\left(w_{p},1\right)$ by~\cite[Equation
6]{Vlcek_ZolotarevOptimalFIR}:
\begin{align}
  w&=x\jcn^{2}\left(u_{0},\kappa\right)-\jsn^{2}\left(u_{0},\kappa\right)\\
   &=\frac{\jsn^{2}\left(u,\kappa\right)\jcn^{2}\left(u_{0},\kappa\right)+
     \jcn^{2}\left(u,\kappa\right)\jsn^{2}\left(u_{0},\kappa\right)}
     {\jsn^{2}\left(u,\kappa\right)-\jsn^{2}\left(u_{0},\kappa\right)}
\label{eqn:u-to-w-conformal-transformation}
\end{align}
where $u_{0}=\frac{p}{p+q}K\left(\kappa\right)$. The inverse transformation 
is~\cite[Equation 2]{ChenParks_AnalyticNarrowBandFIRZolotarev}~\cite[Section
 22.6(iv)]{NIST_DigitalLibraryMathematicalFunctions}:
\begin{align}
  \begin{split}
  u&=\jarcsc\left(\imath\jsc\left(u_{0},\kappa\right)\sqrt{\frac{1+w}{1-w}},\kappa\right)\\
  &=\imath\jarcsn\left(\jsc\left(u_{0},\kappa\right)
    \sqrt{\frac{1+w}{1-w}},\sqrt{1-\kappa^{2}}\right)
  \end{split}
  \label{eqn:w-to-u-conformal-transformation}
\end{align}

The extremal values of the Zolotarev polynomial $Z_{p,q}\left(w,\kappa\right)$ of
degree $n=p+q$ alternate between $-1$ and $1$ $p+1$ times in the interval
$\left(-1,w_{s}\right)$ and $q+1$ times in the interval $\left(w_{p},1\right)$.

For convenience, \emph{Zahradnik et al.}~\cite[Equation
7]{ZahradnikSusta_DegreeEquirippleBandpassFIR} rewrite
Equation~\ref{eqn:Zolotarev-function-parametric-equation} as:
\begin{align*}
  Z_{p,q}\left(u,\kappa\right)
  &=\left(-1\right)^{p}\cosh\left\{n\log\left[\frac{H\left(u+u_{0},\kappa\right)}
    {H\left(u-u_{0},\kappa\right)}\right]\right\}
\end{align*}

Alternatively, the Zolotarev polynomials can be expressed in terms of the
Chebyshev polynomials of the first kind,
$T_{n}\left(\cos\Phi\right)=\cos n\Phi$~\cite[Equations 26 and
27]{Vlcek_ZolotarevOptimalFIR}:
\begin{align}
\begin{split}
  Z_{p,q}\left(u,\kappa\right)
  &=\left(-1\right)^{p}T_{p+q}\left(\cos\Phi\left(u,\kappa\right)\right)\\
  \cos\Phi\left(u,\kappa\right)&=\frac{1}{2}\left[
            \frac{H\left(u+u_{0},\kappa\right)}{H\left(u-u_{0},\kappa\right)}+
            \frac{H\left(u-u_{0},\kappa\right)}{H\left(u+u_{0},\kappa\right)}
                            \right]
\end{split}
\label{eqn:Zolotarev-Chebyshev-first-kind}
\end{align}

\emph{Whittaker} and \emph{Watson}~\cite[Page
480]{WhittakerWatson_CourseModernAnalysis} define the \emph{Jacobi Eta}
function as:
\begin{align}
  H\left(u,\kappa\right)
  &=-\imath{}q^{-\frac{1}{4}}e^{\frac{\imath\pi{}u}{2K}}
    \Theta\left(u+\imath{}K^{\prime},\kappa\right)
\label{eqn:Whittaker-Watson-Jacobi-Eta-definition}
\end{align}
where $\Theta\left(u,\kappa\right)$ is the \emph{Jacobi Theta} function, an
even function with period $2K+\imath2K^{\prime}$. \emph{Chen} and
\emph{Parks}~\cite[Appendix, Equation
A3]{ChenParks_AnalyticNarrowBandFIRZolotarev} show (with confusing typesetting)
that in the central lobe of the Zolotarev polynomial, for which
$u=\sigma+\imath{}K^{\prime}$ with $\sigma\in\left[0,K\right]$: 
\begin{align*}
  \left\{\frac{H\left(u+u_{0},\kappa\right)}
    {H\left(u-u_{0},\kappa\right)}\right\}^{n}
  &=\left(-1\right)^{p}\left\{\frac{\Theta\left(\sigma+u_{0},\kappa\right)}
    {\Theta\left(\sigma-u_{0},\kappa\right)}\right\}^{n}
\end{align*}

The maximiser of the Zolotarev polynomial in the central lobe
is~\cite[Appendix]{ChenParks_AnalyticNarrowBandFIRZolotarev}:
\begin{align*}
  u_{m}&=\sigma_{m}+\imath{}K^{\prime}
\end{align*}
where:
\begin{align}
  \begin{split}
    \kappa^{\prime}&=\sqrt{1-\kappa^{2}} \\
    K^{\prime}&=F\left(\frac{\pi}{2},\kappa^{\prime}\right) \\
    \sigma_{m}&=\jarcsn\left(\left[\frac{Z\left(u_{0},\kappa\right)}
        {\kappa^{2}\jsn\left(u_{0},\kappa\right)\left[
            \jcn\left(u_{0},\kappa\right)\jdn\left(u_{0},\kappa\right)+
            \jsn\left(u_{0},\kappa\right)Z\left(u_{0},\kappa\right)\right]}
      \right]^{\frac{1}{2}},\kappa\right)
  \end{split}
  \label{eqn:Zolotarev-kp-Kp-sigmam}
\end{align}
and $Z\left(u,\kappa\right)$ is the \emph{Jacobi Zeta} function. The
corresponding maximum value is:
\begin{align}
  f_{m}&=\left(-1\right)^{p}\cosh\left[
         n\log\frac{\Theta\left(\sigma_{m}+u_{0},\kappa\right)}
         {\Theta\left(\sigma_{m}-u_{0},\kappa\right)}\right]
\label{eqn:Zolotarev-kp-Kp-fm}
\end{align}

The Octave script \emph{zolotarev\_vlcek\_unbehauen\_test.m} calculates
$Z_{5,9}\left(w,0.78\right)$, shown as Figure 1 by
\emph{Vl\v{c}ek} and \emph{Unbehauen}~\cite{Vlcek_ZolotarevOptimalFIR} and shown
here as Figure~\ref{fig:Zolotarev-Vlcek-Unbehauen-Z-p-5-q-9-k-0-78}.

\begin{figure}[H]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_vlcek_unbehauen_test_w_5_9}}
\caption{Zolotarev polynomial $Z_{5,9}\left(u,0.78\right)$.}
\label{fig:Zolotarev-Vlcek-Unbehauen-Z-p-5-q-9-k-0-78}
\end{figure}

Following \emph{Levy}~\cite[Equation 28]{Levy_RationalApproximationZolotarev} or
\emph{Vl\v{c}ek} and \emph{Unbehauen}~\cite[Equations 22 and
23]{Vlcek_AnalyticalSolutionsIIRFilter},
\emph{Vl\v{c}ek} and \emph{Unbehauen} assert that, by inspection, the Zolotarev
polynomials, $Z_{p,q}\left(w,\kappa\right)$, satisfy the following differential
equation~\cite[Equation 7]{Vlcek_ZolotarevOptimalFIR}:
\begin{align}
  \left(1-w^{2}\right)\left(w-w_{p}\right)\left(w-w_{s}\right)
  \left(\frac{df}{dw}\right)^{2}
  &= n^{2}\left(1-f^{2}\right)\left(w-w_{m}\right)^{2}
    \label{eqn:Zolotarev-non-linear-differential-equation}
\end{align}
Quoting \emph{Vl\v{c}ek} and \emph{Zahradn\'{i}k}~\cite[Section
III]{VlcekZahradnik_AlmostEquirippleApproxLowPassFIR}: ``This nonlinear
differential equation expresses the fact that the first derivative
$Z^{\prime}_{p,q}\left(w,\kappa\right)$ does not vanish at the points $w=\pm{}1$,
$w_{p}$, $w_{s}$, where $Z_{p,q}\left(w,\kappa\right)=\pm{}1$ for which the right hand
side of eq. (3) vanishes, and that $w=w_{m}$ is a turning point corresponding to
the local extrema at which $Z_{p,q}\left(w,\kappa\right)\ne\pm{}1$.''
\emph{Levy}~\cite{Levy_RationalApproximationZolotarev} and \emph{Vl\v{c}ek} and
\emph{Unbehauen}~\cite{Vlcek_ZolotarevOptimalFIR} show the solution of this
non-linear differential equation with elliptic functions. Alternatively,
differentiating Equation~\ref{eqn:Zolotarev-non-linear-differential-equation}
gives the following linear second-order differential equation~\cite[Equation
63]{Vlcek_ZolotarevOptimalFIR}: 
\begin{align}
  g_{2}\left(w\right)\left[\left(1-w^{2}\right)\frac{d^{2}f}{dw^{2}}-
  w\frac{df}{dw}\right]-\left(1-w^{2}\right)g_{1}\left(w\right)\frac{df}{dw}+
n^{2}g_{0}\left(w\right)f&=0
\label{eqn:Zolotarev-linear-second-order-differential-equation}
\end{align}
where:
\begin{align}
  \begin{split}
  g_{2}\left(w\right)&=\left(w-w_{p}\right)\left(w-w_{s}\right)
  \left(w-w_{m}\right)\\
  g_{1}\left(w\right)&=\left(w-w_{p}\right)\left(w-w_{s}\right)
  -\left(w-w_{m}\right)\left(w-\frac{w_{p}+w_{s}}{2}\right)\\
  g_{0}\left(w\right)&=\left(w-w_{m}\right)^{3}
\end{split}
\label{eqn:Zolotarev-linear-differential-equation-factors}
\end{align}

This differential equation can be solved by substituting the power series: 
\begin{align*}
  f\left(w\right)&=\sum^{n}_{m=0}b_{m}w^{m}
\end{align*}

\emph{Vl\v{c}ek} and \emph{Unbehauen} summarise the resulting recurrence
relations in~\cite[Table IV]{Vlcek_ZolotarevOptimalFIR}, reproduced here (with
corrections~\cite{Vlcek_ZolotarevOptimalFIRcorrections}) as 
Algorithm~\ref{alg:Zolotarev-power-sum-recurrence}.

\begin{algorithm}
\begin{algorithmic}
  \Require $p$, $q$ and $\kappa$
  \vspace{1.5mm}
  \vspace{1.5mm}
  \State \emph{Initialisation}:
  \vspace{1.5mm}
  \State $n=p+q$
  \vspace{1.5mm}
  \State $u_{0}=\frac{p}{p+q}K\left(\kappa\right)$
  \vspace{1.5mm}
  \State $w_{p}=2\jcd^{2}\left(u_{0},\kappa\right)-1$
  \vspace{1.5mm}
  \State $w_{s}=2\jcn^{2}\left(u_{0},\kappa\right)-1$
  \vspace{1.5mm}
  \State $w_{q}=\frac{w_{p}+w_{s}}{2}$
  \vspace{1.5mm}
  \State $w_{m}=w_{s}+2\frac{\jsn\left(u_{0},\kappa\right)\jcn\left(u_{0},\kappa\right)}{\jdn\left(u_{0},\kappa\right)}Z\left(u_{0},\kappa\right)$
  \vspace{1.5mm}
  \State $\beta_{n}=1$, $\beta_{n+1}=\beta_{n+2}=\beta_{n+3}=\beta_{n+4}=0$
  \vspace{1.5mm}
  \vspace{1.5mm}
  \State \emph{Body}:
  \vspace{1.5mm}
  \For {$m=n+2$ \textbf{ down to } $3$ }
  \vspace{1.5mm}
  \State $d_{1}=\left(m+2\right)\left(m+1\right)w_{p}w_{s}w_{m}$
  \vspace{1.5mm}
  \State $d_{2}=-\left(m+1\right)\left(m-1\right)w_{p}w_{s}-\left(m+1\right)\left(2m+1\right)w_{m}w_{q}$
  \vspace{1.5mm}
  \State $d_{3} = w_{m}\left(n^{2}w^{2}_{m}-m^{2}w_{p}w_{s}\right)+m^{2}\left(w_{m}-w_{q}\right)+3m\left(m-1\right)w_{q}$
  \vspace{1.5mm}
  \State $d_{4}=\left(m-1\right)\left(m-2\right)\left(w_{p}w_{s}-w_{m}w_{q}-1\right)-3w_{m}\left[n^{2}w_{m}-\left(m-1\right)^{2}w_{q}\right]$
  \vspace{1.5mm}
  \State $d_{5}=\left(2m-5\right)\left(m-2\right)\left(w_{m}-w_{q}\right)+3w_{m}\left[n^{2}-\left(m-2\right)^{2}\right]$
  \vspace{1.5mm}
  \State $d_{6}=n^{2}-\left(m-3\right)^{2}$
  \vspace{1.5mm}
  \State $\beta_{m-3}=\frac{1}{d_{6}}\sum_{\mu=1}^{5}d_{\mu}\beta_{m+3-\mu}$
  \vspace{1.5mm}
  \EndFor
  \vspace{1.5mm}
  \vspace{1.5mm}
  \State \emph{Normalisation}:
  \vspace{1.5mm}
  \State $s_{n}=\sum_{m=0}^{n}\beta_{m}$
  \vspace{1.5mm}
  \For{$m=0$ \textbf{ to } $n$ }
  \vspace{1.5mm}
  \State $b_{m}=\left(-1\right)^{p}\frac{\beta_{m}}{s_{n}}$
  \vspace{1.5mm}
  \EndFor
\end{algorithmic}
\caption{\emph{Vl\v{c}ek} and \emph{Unbehauen}'s backwards recursion for 
  $Z_{p,q}\left(w\right)=\sum^{n}_{m=0}b_{m}w^{m}\left(w\right)$~\cite[Table
  IV]{Vlcek_ZolotarevOptimalFIR},~\cite{Vlcek_ZolotarevOptimalFIRcorrections}.}
\label{alg:Zolotarev-power-sum-recurrence}
\end{algorithm}

The power series $b_{m}$ coefficients of $Z_{5,15}\left(u,0.77029\right)$ found
with Algorithm~\ref{alg:Zolotarev-power-sum-recurrence} are:
\begin{small}
\verbatiminput{zolotarev_vlcek_unbehauen_test_b_5_15_coef.m}
\end{small}

The corresponding $z$-domain discrete-time impulse response coefficients are:
\begin{small}
\verbatiminput{zolotarev_vlcek_unbehauen_test_h_5_15_coef.m}
\end{small}

\emph{Vl\v{c}ek} and \emph{Unbehauen} also show the expansion of
$Z_{p,q}\left(w,\kappa\right)$ in Chebyshev polynomials of the first kind,
$T_{m}\left(w\right)$:
\begin{align*}
f\left(w\right)&=\sum^{n}_{m=0}a_{m}T_{m}\left(w\right)
\end{align*}
The resulting recurrence relations are shown in
Algorithm~\ref{alg:Zolotarev-Chebyshev-sum-recurrence}~\cite[Table V with 
 corrections]{Vlcek_ZolotarevOptimalFIR}\footnote{The Maxima script 
  \emph{zolotarev\_vlcek\_unbehauen\_table\_v.max} and my working by hand did
  not reproduce Table V of \emph{Vl\v{c}ek} and
  \emph{Unbehauen}~\cite{Vlcek_ZolotarevOptimalFIR,
    Vlcek_ZolotarevOptimalFIRcorrections}. However, the Octave script
\emph{zolotarev\_vlcek\_unbehauen\_test.m} shows that, for $\kappa=0.78$, $p=5$
and $q=9$, my Algorithm~\ref{alg:Zolotarev-power-sum-recurrence} and
Algorithm~\ref{alg:Zolotarev-Chebyshev-sum-recurrence} produce, to within
round-off error, the same Zolotarev polynomial as the calculation using
elliptic functions in the Octave function \emph{zolotarev\_chen\_parks.m}.}.

The Chebyshev polynomial expansion coefficients of the example shown by
\emph{Vl\v{c}ek} and
\emph{Unbehauen}~\cite[Table VI]{Vlcek_ZolotarevOptimalFIRcorrections} are: 
\begin{small}
\verbatiminput{zolotarev_vlcek_unbehauen_test_a_3_6_coef.m}
\end{small}
\clearpage
\begin{algorithm}[H]
\begin{algorithmic}
  \Require $p$, $q$ and $\kappa$
  \vspace{1.5mm}
  \vspace{1.5mm}
  \State \emph{Initialisation}:
  \vspace{1.5mm}
  \State $n=p+q$
  \vspace{1.5mm}
  \State $u_{0}=\frac{p}{p+q}K\left(\kappa\right)$
  \vspace{1.5mm}
  \State $w_{p}=2\jcd^{2}\left(u_{0},\kappa\right)-1$
  \vspace{1.5mm}
  \State $w_{s}=2\jcn^{2}\left(u_{0},\kappa\right)-1$
  \vspace{1.5mm}
  \State $w_{q}=\frac{w_{p}+w_{s}}{2}$
  \vspace{1.5mm}
  \State $w_{m}=w_{s}+2\frac{\jsn\left(u_{0},\kappa\right)\jcn\left(u_{0},\kappa\right)}{\jdn\left(u_{0},\kappa\right)}Z\left(u_{0},\kappa\right)$
  \vspace{1.5mm}
  \State $\alpha_{n}=1$, $\alpha_{n+1}=\alpha_{n+2}=\alpha_{n+3}=\alpha_{n+4}=\alpha_{n+5}=0$
  \vspace{1.5mm}
  \vspace{1.5mm}
  \State \emph{Body}:
  \vspace{1.5mm}
  \For {$m=n+2$ \textbf{ down to } $3$ }
  \vspace{1.5mm}
  \State $c_{7}=n^{2}-\left(m-3\right)^{2}$
  \vspace{1.5mm}
  \State $c_{6}=2\left[\left(m-2\right)\left(m-3\right)w_{p}+\left(m-2\right)\left(m-3\right)w_{s} +\left(\left(m-2\right)\left(m-1\right)-3n^{2}\right)w_{m}+\left(m-2\right)w_{q}\right]$
  \vspace{1.5mm}
  \State $c_{5}=3\left[n^{2}-\left(m-1\right)^{2}\right]+\quad\hdots$\\
  \quad\quad\quad\quad$4\left[3n^{2}w_{m}^{2}-\left(m-1\right)^{2}w_{m}w_{p}-\left(m-1\right)^{2}w_{m}w_{s}-\left(m-1\right)\left(m-2\right)w_{p}w_{s}-\left(m-1\right)w_{m}w_{q}\right]$
  \vspace{1.5mm}
  \State $c_{4}=4\left[m^{2}w_{p}+m^{2}w_{s}+\left(m^{2}-3n^{2}\right)w_{m}\right]+8\left[-n^{2}w_{m}^{3}+m^{2}w_{m}w_{p}w_{s}\right]$
  \vspace{1.5mm}
  \State $c_{3}=3\left[n^{2}-\left(m+1\right)^{2}\right] +\quad\hdots$\\
  \quad\quad\quad\quad$4\left[3n^{2}w_{m}^{2}-\left(m+1\right)^{2}w_{m}w_{p}-\left(m+1\right)^{2}w_{m}w_{s}-\left(m+1\right)\left(m+2\right)w_{p}w_{s}+\left(m+1\right)w_{m}w_{q}\right]$
  \vspace{1.5mm}
  \State $c_{2}=2\left[\left(m+2\right)\left(m+3\right)w_{p} +\left(m+2\right)\left(m+3\right)w_{s} +\left(\left(m+2\right)\left(m+1\right)-3n^{2}\right)w_{m}-\left(m+2\right)w_{q}\right]$
  \vspace{1.5mm}
  \State $c_{1}=n^{2}-\left(m+3\right)^{2}$
  \vspace{1.5mm}
  \State $\alpha_{m-3}=-\frac{\sum_{\mu=1}^{6}c_{\mu}\alpha_{m+4-\mu}}{c_{7}}$
  \vspace{1.5mm}
  \EndFor
  \vspace{1.5mm}
  \vspace{1.5mm}
  \State \emph{Normalisation}:
  \vspace{1.5mm}
  \State $s_{n}=-\frac{\alpha_{0}}{2}+\sum_{m=1}^{n}\alpha_{m}$
  \vspace{1.5mm}
  \State $a_{0}=\left(-1\right)^{p}\frac{\alpha_{0}}{2s_{n}}$
  \vspace{1.5mm}
  \For{$m=1$ \textbf{ to } $n$ }
  \vspace{1.5mm}
  \State $a_{m}=\left(-1\right)^{p}\frac{\alpha_{m}}{s_{n}}$
  \vspace{1.5mm}
  \EndFor
\end{algorithmic}
\caption{Modified \emph{Vl\v{c}ek} and \emph{Unbehauen} backwards recursion for 
  $Z_{p,q}\left(w\right)=\sum^{n}_{m=0}a_{m}T_{m}\left(w\right)$~\cite[Table
  V]{Vlcek_ZolotarevOptimalFIR},~\cite{Vlcek_ZolotarevOptimalFIRcorrections}.}
\label{alg:Zolotarev-Chebyshev-sum-recurrence}
\end{algorithm}
\clearpage
\subsubsection{Addendum}
\paragraph{Working for Equation~\ref{eqn:w-to-u-conformal-transformation}}
Re-writing Equation~\ref{eqn:u-to-w-conformal-transformation}:
\begin{align}
\begin{split}
  w&=\frac{\jsn^{2}\left(u,\kappa\right)\jcn^{2}\left(u_{0},\kappa\right)+
     \jcn^{2}\left(u,\kappa\right)\jsn^{2}\left(u_{0},\kappa\right)}
     {\left(1-\jsn^{2}\left(u_{0},\kappa\right)\right)\jsn^{2}\left(u,\kappa\right)
     -\left(1-\jsn^{2}\left(u,\kappa\right)\right)\jsn^{2}\left(u_{0},\kappa\right)}\\
     &=\frac{\jsn^{2}\left(u,\kappa\right)\jcn^{2}\left(u_{0},\kappa\right)+
     \jcn^{2}\left(u,\kappa\right)\jsn^{2}\left(u_{0},\kappa\right)}
     {\jcn^{2}\left(u_{0},\kappa\right)\jsn^{2}\left(u,\kappa\right)-
       \jcn^{2}\left(u,\kappa\right)\jsn^{2}\left(u_{0},\kappa\right)}\\
    &=\frac{\jsc^{2}\left(u,\kappa\right)+\jsc^{2}\left(u_{0},\kappa\right)}
    {\jsc^{2}\left(u,\kappa\right)-\jsc^{2}\left(u_{0},\kappa\right)}
  \end{split}
\label{eqn:u-to-w-conformal-transformation-in-sc}
\end{align}
Rearranging:
\begin{align*}
  -\left(1-w\right)\jsc^{2}\left(u,\kappa\right)
  &=\left(1+w\right)\jsc^{2}\left(u_{0},\kappa\right)\\
  \jsc\left(u,\kappa\right)
  &=\pm\imath\jsc\left(u_{0},\kappa\right)\sqrt{\frac{1+w}{1-w}}
\end{align*}
Using the \emph{Jacobi imaginary transformation}~\cite[Table
22.6.1]{NIST_DigitalLibraryMathematicalFunctions},
$\jsn\left(\imath{}u,\kappa^{\prime}\right)=\imath\jsc\left(u,\kappa\right)$, and selecting
the ``positive'' value:
\begin{align*}
  u&=\imath\jarcsn\left(\jsc\left(u_{0},\kappa\right)
     \sqrt{\frac{1+w}{1-w}},\sqrt{1-\kappa^{2}}\right)
\end{align*}
The $\jsc\left(u,\kappa\right)$ function has a zero at $u=0$, a pole at
$u=K$, period $2K+\imath{}4K^{\prime}$,
$\jsc\left(\imath{}K^{\prime},\kappa\right)=\imath$ and 
$\jsc\left(K+\imath{}K^{\prime},\kappa\right)=\imath{}\kappa^{\prime{}-1}$~\cite[Tables
22.4.1, 22.4.2 and 22.5.1]{NIST_DigitalLibraryMathematicalFunctions}.

Substituting $\varphi_{s}=\frac{\omega_{s}T}{2}$,
$\varphi_{p}=\frac{\pi-\omega_{p}T}{2}$~\cite[Page 726]{Vlcek_ZolotarevOptimalFIR}
and $\sin\varphi_{s}=\jsn\left(u_{0},\kappa\right)$~\cite[Equation
82]{Vlcek_ZolotarevOptimalFIR} into
Equation~\ref{eqn:u-to-w-conformal-transformation-in-sc} and recalling that
$w_{p}=\cos\omega_{p}T$, at $u=K+\imath{}K^{\prime}$:
\begin{align*}
  w_{p}&=\frac{-\frac{1}{\kappa^{\prime{}2}}+\tan^{2}\varphi_{s}}
         {-\frac{1}{\kappa^{\prime{}2}}-\tan^{2}\varphi_{s}}
\end{align*}
Rearranging:
\begin{align*}
  \kappa^{\prime{}2}&=\cot^{2}\varphi_{s}\frac{1-w_{p}}{1+w_{p}}\\
       &=\cot^{2}\varphi_{s}\tan^{2}\frac{\omega_{p}T}{2}\\
         &=\cot^{2}\varphi_{s}\cot^{2}\varphi_{p}
\end{align*}
That is, the complementary elliptic modulus,
$\kappa^{\prime}=\cot\varphi_{s}\cot\varphi_{p}$.
\paragraph{Working for linearising Equation 7~\cite{Vlcek_ZolotarevOptimalFIR}}
Rearrange Equation 7 as:
\begin{align*}
  \frac{df}{dw}&=g\sqrt{1-f^{2}}
\end{align*}
where:
\begin{align*}
  g\left(w\right)
  &=\frac{n\left(w-w_{m}\right)}
    {\sqrt{\left(1-w^{2}\right)\left(w-w_{p}\right)\left(w-w_{s}\right)}}
\end{align*}
Differentiating both sides:
\begin{align*}
  \frac{d^{2}f}{dw^{2}}&=\frac{dg}{dw}\sqrt{1-f^{2}}-
                         g\frac{1}{2}\frac{1}{\sqrt{1-f^{2}}}2f\frac{df}{dw}
\end{align*}
Substituting $\frac{df}{dw}$:
\begin{align*}
  \frac{d^{2}f}{dw^{2}} &=\frac{1}{g}\frac{dg}{dw}\frac{df}{dw}-g^{2}f
\end{align*}
If $w_{q}=\frac{w_{p}+w_{s}}{2}$:
\begin{align*}
  \frac{1}{g}\frac{dg}{dw}
  &=\frac{1}{w-w_{m}}+\frac{w}{1-w^{2}}
    -\frac{w-w_{q}}{\left(w-w_{p}\right)\left(w-w_{s}\right)}
\end{align*}
Rearranging:
\begin{align*}
  \begin{split}
&  \left[\left(1-w^{2}\right)\left(w-w_{m}\right)
  \left(w-w_{p}\right)\left(w-w_{s}\right)\right]\frac{d^{2}f}{dw^{2}}\quad\hdots\\
&  -\left[\left(1-w^{2}\right)\left(w-w_{p}\right)\left(w-w_{s}\right)
  +w\left(w-w_{m}\right)\left(w-w_{p}\right)\left(w-w_{s}\right)
  -\left(1-w^{2}\right)\left(w-w_{m}\right)\left(w-w_{q}\right)\right]
  \frac{df}{dw} \quad\hdots \\
& +n^{2}\left(w-w_{m}\right)^{3}f=0
  \end{split}
\end{align*}
\paragraph{Working for Equation 73~\cite{Vlcek_ZolotarevOptimalFIR}}
The Chebyshev polynomial of the first kind satisfies the differential equation:
\begin{align*}
  \left(1-w^{2}\right)\frac{d^{2}T_{n}\left(w\right)}{dw^{2}}-
  w\frac{dT_{n}\left(w\right)}{dw}+n^{2}T_{n}\left(w\right)&=0
\end{align*}
Equation~\ref{eqn:Zolotarev-linear-second-order-differential-equation} is
deliberately written in a form that can be solved with an expansion of
$Z_{p,q}\left(w\right)$ in Chebyshev polynomials of the first kind,
$T_{m}\left(w\right)$:
\begin{align*}
  f\left(w\right)&=\sum^{n}_{m=0}a_{m}T_{m}\left(w\right)
\end{align*}
so that:
\begin{align*}
  \left(1-w^{2}\right)\frac{d^{2}f}{dw^{2}}-w\frac{df}{dw}
  &= -\sum^{n}_{m=0}m^{2}a_{m}T_{m}\left(w\right) 
\end{align*}
\paragraph{Working for Equation 74~\cite{Vlcek_ZolotarevOptimalFIR}}
Equation 74 uses the following properties of the Chebyshev polynomials:
\begin{align*}
  \frac{dT_{m}\left(w\right)}{dw}&=mU_{m-1}\left(w\right)\\
  \left(1-w^{2}\right)U_{m-1}\left(w\right)&=wT_{m}\left(w\right)-
                                             T_{m+1}\left(w\right)\\
  T_{m-1}\left(w\right)-wT_{m}\left(w\right)&=wT_{m}\left(w\right)-
                                             T_{m+1}\left(w\right)
\end{align*}
so that:
\begin{align*} 
  \left(1-w^{2}\right)\frac{df}{dw}
  &= \sum^{n}_{m=0}ma_{m}\left[T_{m-1}\left(w\right)-wT_{m}\left(w\right)\right]
\end{align*}
\paragraph{Working for Equation 75~\cite{Vlcek_ZolotarevOptimalFIR}}
Equation 75 results directly from substituting Equations 72, 73 and 74 into
Equation 63 (shown above as
Equation~\ref{eqn:Zolotarev-linear-second-order-differential-equation}):
\begin{align*}
  -\sum^{n}_{m=0}m^{2}a_{m}g_{2}\left(w\right)T_{m}\left(w\right)
  -\sum^{n}_{m=0}ma_{m}g_{1}\left(w\right)\left[T_{m-1}\left(w\right)-
  wT_{m}\left(w\right)\right]
  +\sum^{n}_{m=0}a_{m}n^{2}g_{0}\left(w\right)T_{m}\left(w\right) &=0
\end{align*} 
\paragraph{Working for Table V~\cite{Vlcek_ZolotarevOptimalFIR}}
Expanding $g_{0}\left(w\right)$, $g_{1}\left(w\right)$ and $g_{2}\left(w\right)$
in Equation 75 and setting $w_{q}=\frac{w_{p}+w_{s}}{2}$:
\begin{align*}
  -&\sum^{n}_{m=0}m^{2}\alpha_{m}
     \left[\left(w-w_{p}\right)\left(w-w_{s}\right)
     \left(w-w_{m}\right)\right]T_{m}\left(w\right)\quad\hdots\\
  -&\sum^{n}_{m=0}m\alpha_{m}\left[\left(w-w_{p}\right)
     \left(w-w_{s}\right)-\left(w-w_{m}\right)\left(w-w_{q}\right)\right]
     \left[T_{m-1}\left(w\right)-wT_{m}\left(w\right)\right]\quad\hdots\\
  +&\sum^{n}_{m=0}\alpha_{m}\left[ n^{2}\left(w-w_{m}\right)^{3}\right]
     T_{m}\left(w\right) =0\\
  \\
  -&\sum^{n}_{m=0}m^{2}\alpha_{m}
     \left[w^{3}-w_{p}w^{2}-w_{s}w^{2}-w_{m}w^{2}+w_{m}w_{p}w+w_{m}w_{s}w+
     w_{p}w_{s}w-w_{p}w_{m}w_{s}\right]T_{m}\left(w\right)\quad\hdots\\
  -&\sum^{n}_{m=0}m\alpha_{m}\left[w^{2}-w_{p}w-w_{s}w+w_{p}w_{s}
     -w^{2}+w_{m}w+w_{q}w-w_{q}w_{m}\right]
     \left[T_{m-1}\left(w\right)-
  wT_{m}\left(w\right)\right]\quad\hdots\\
  +&\sum^{n}_{m=0}n^{2}\alpha_{m}
     \left[w^{3}-3w_{m}w^{2}+3w_{m}^{2}w-w_{m}^{3}\right]
     T_{m}\left(w\right) =0\\
\end{align*}
After much algebra (shown in the Octave script
\emph{zolotarev\_vlcek\_unbehauen\_table\_v\_test.m}) I arrived at:
\begin{align*}
   &\sum^{n+3}_{m=3}\left[n^{2}-\left(m-3\right)^{2}\right]
     \alpha_{m-3}T_{m}\left(w\right)\quad\hdots\\
  +&\sum^{n+2}_{m=2}2\left[\left(m-2\right)\left(m-3\right)w_{p}
     +\left(m-2\right)\left(m-3\right)w_{s}\right.\quad\hdots\\
   &\left.\quad\quad\quad+\left(\left(m-2\right)\left(m-1\right)
     -3n^{2}\right)w_{m}+\left(m-2\right)w_{q}\right]
     \alpha_{m-2}T_{m}\left(w\right)\quad\hdots\\
  +&\sum^{n+1}_{m=1}3\left[n^{2}-\left(m-1\right)^{2}\right]+\quad\hdots\\
   &\quad\quad\quad 4\left[ 3n^{2}w_{m}^{2}-\left(m-1\right)^{2}w_{m}w_{p}
     -\left(m-1\right)^{2}w_{m}w_{s}
     -\left(m-1\right)\left(m-2\right)w_{p}w_{s}-\left(m-1\right)w_{m}w_{q}\right]
     \alpha_{m-1}T_{m}\left(w\right)\quad\hdots\\
  +&\sum^{n}_{m=0}4\left[m^{2}w_{p}+m^{2}w_{s}
     +\left(m^{2}-3n^{2}\right)w_{m}\right]+
     8\left[-n^{2}w_{m}^{3}+m^{2}w_{m}w_{p}w_{s}\right]
     \alpha_{m}T_{m}\left(w\right)\quad\hdots\\
  +&\sum^{n-1}_{m=-1}3\left[n^{2}-\left(m+1\right)^{2}\right]+\quad\hdots\\
   &\quad\quad\quad 4\left[3n^{2}w_{m}^{2}-\left(m+1\right)^{2}w_{m}w_{p}
     -\left(m+1\right)^{2}w_{m}w_{s}-\left(m+1\right)\left(m+2\right)w_{p}w_{s}
     +\left(m+1\right)w_{m}w_{q}\right]\alpha_{m+1}T_{m}\left(w\right)\quad\hdots\\
  +&\sum^{n-2}_{m=-2}2\left[\left(m+2\right)\left(m+3\right)w_{p}
     +\left(m+2\right)\left(m+3\right)w_{s}
     +\left(\left(m+2\right)\left(m+1\right)-3n^{2}\right)w_{m}
     -\left(m+2\right)w_{q}\right]
     \alpha_{m+2}T_{m}\left(w\right)\quad\hdots\\
  +&\sum^{n-3}_{m=-3}\left[n^{2}-\left(m+3\right)^{2}\right]
     \alpha_{m+3}T_{m}\left(w\right)=0
\end{align*}
Algorithm~\ref{alg:Zolotarev-Chebyshev-sum-recurrence} follows by collecting
terms in the Chebyshev polynomials of equal order. The recursion is
initialised by setting $\alpha_{n}=1$. At each backwards recursion,
$m=n+2,\hdots,3$, the next coefficient calculated is $\alpha_{m-3}$.
\clearpage
\subsection{Narrow-band FIR filter design with the Zolotarev polynomials}
\subsubsection{Degree equations for the Zolotarev polynomials}
If the Zolotarev polynomial is scaled to lie in the range $[0,1]$ and
the stop-band specification is $a_{s_{dB}}=20\log_{10}a_{s}<0$:
\begin{align}
  \frac{2}{1+f_{m}} \le{} & 10^{a_{s_{dB}}/20}
\end{align}
Rearranging:
\begin{align}
  f_{m}\ge{} &y_{m}=2\times{}10^{-a_{s_{dB}}/20}-1
\end{align}
Recalling Equation~\ref{eqn:Zolotarev-kp-Kp-fm}, the scaled maximum value is:
\begin{align}
  \cosh\left[n\log\frac{\Theta\left(\sigma_{m}+u_{0},\kappa\right)}
  {\Theta\left(\sigma_{m}-u_{0},\kappa\right)}\right]\ge{}y_{m}
\end{align}
and the stop-band degree equation is:
\begin{align*}
  n\ge & \frac{\arccosh y_{m}}{\log\frac{\Theta\left(\sigma_{m}+u_{0},\kappa\right)}
         {\Theta\left(\sigma_{m}-u_{0},\kappa\right)}}
\end{align*}
Alternatively, solving for $y_{m}$ with $\lambda=e^{x}$:
\begin{align}
  \frac{1}{2}\left[\lambda+\lambda^{-1}\right]&\ge{}y_{m}\\
  \lambda^{2}-2y_{m}\lambda+1&\ge{}0\\
\end{align}
The stop-band degree equation becomes~\cite[Equation
85]{Vlcek_ZolotarevOptimalFIR}:
\begin{align}
  n\ge & \frac{\log\left(y_{m}+\sqrt{y_{m}^{2}-1}\right)}
         {\log\frac{\Theta\left(\sigma_{m}+u_{0},\kappa\right)}
                   {\Theta\left(\sigma_{m}-u_{0},\kappa\right)}}
  \label{eqn:Zolotarev-scaled-stop-band-degree-equation} 
\end{align}

\emph{Zahradn\'{i}k et al.}~\cite{ZahradnikSusta_DegreeEquirippleBandpassFIR}
derive a degree equation for narrow band-pass Zolotarev polynomial FIR filters
in terms of the pass-band attenuation specification,
$a_{p_{dB}}=20\log_{10}a_{p}<0$ and the pass-band bandwidth,
$\Delta_{p}T=\omega_{p2}T-\omega_{p1}T$. Their procedure selects the elliptic
function modulus, $\kappa$, by setting~\cite[Equation 
13]{ZahradnikSusta_DegreeEquirippleBandpassFIR}:
\begin{align*}
  \frac{\Theta\left(\sigma_{p1}+u_{0},\kappa\right)}
    {\Theta\left(\sigma_{p1}-u_{0},\kappa\right)}
  &=\frac{\Theta\left(\sigma_{p2}+u_{0},\kappa\right)}
    {\Theta\left(\sigma_{p2}-u_{0},\kappa\right)}
\end{align*}
The response is scaled so that the pass-band degree equation is~\cite[Equation
14]{ZahradnikSusta_DegreeEquirippleBandpassFIR}(with
corrections\footnote{\emph{Zahradnik et al.} use the Jacobi \emph{Eta} function,
  the ratio of Jacobi \emph{Eta} functions is claimed to be real at $w_{p1}$
  and $\log$ is missing.}):
\begin{align*}
  n\ge
&\frac{\arccosh\left(2\times{}10^{\left(a_{p_{dB}}-a_{s_{dB}}\right)/20}-1\right)}
 {\log\frac{\Theta\left(\sigma_{p1}+u_{0},\kappa\right)}
           {\Theta\left(\sigma_{p1}-u_{0},\kappa\right)}}
\end{align*}
Unfortunately, the pass-band bandwidth relationship usually does not hold after
the elliptic function quarter-period, $K\left(\kappa\right)$, is translated to
integral values of $n$, $p$ and $q$,

\subsubsection{The Zolotarev polynomial FIR filter design procedure of
  \emph{Vl\v{c}ek} and \emph{Unbehauen}}
\emph{Vl\v{c}ek} and \emph{Unbehauen}~\cite[Section
VII]{Vlcek_ZolotarevOptimalFIR} give the following procedure for the design of
narrow-band FIR filters based on the Zolotarev polynomials with specified
stop-band bandwidth and stop-band attenuation:

\begin{enumerate}
  \item Specify the desired pass-band and stop-band edges at angular frequencies
    $\omega_{p}T<\omega_{s}T$, and the stop-band attenuation,
    $a_{s_{dB}}=20\log_{10}a_{s}<0$
  \item Evaluate the elliptic function modulus, $\kappa$, for
    $\varphi_{p}=\frac{\pi-\omega_{p}T}{2}$ and
    $\varphi_{s}=\frac{\omega_{s}T}{2}$,
    $\kappa^{\prime}=\cot{\varphi_{p}}\cot{\varphi_{s}}$
  \item Use the degree equation,
    Equation~\ref{eqn:Zolotarev-scaled-stop-band-degree-equation}, to find the
    degree, $n$, that satisfies the attenuation requirement
    \begin{align*}
      f_{m}>y_{m}=2\times{}10^{-a_{s_{dB}}/20}-1
      \end{align*}
      corresponding to the maximum of the scaled Zolotarev polynomial.
  \item Determine integer values of $p$ and $q$ corresponding to:
    \begin{align*}
      \frac{q}{n}K\left(\kappa\right)=F\left(\varphi_{p},\kappa\right)\;\text{,}\quad
      \frac{p}{n}K\left(\kappa\right)=F\left(\varphi_{s},\kappa\right)
    \end{align*}
  \item Calculate the resulting values of $w_{p}$, $w_{s}$ and $w_{m}$:
    \begin{align*}
      u_{0}&=\frac{p}{n}K\left(\kappa\right)\;\text{,}\quad
             u_{q}=\frac{q}{n}K\left(\kappa\right) \\
      w_{p}&=\cos\omega_{p}T=2\jsn^{2}\left(u_{q},\kappa\right)-1\\
      w_{s}&=\cos\omega_{s}T=1-2\jsn^{2}\left(u_{0},\kappa\right)\\
      w_{m}&=\cos\omega_{m}T=
         w_{s}+2\frac{\jsn\left(u_{0},\kappa\right)\jcn\left(u_{0},\kappa\right)}
         {\jdn\left(u_{0},\kappa\right)}Z\left(u_{0},\kappa\right) \\
      u_{m}&=\sigma_{m}+\imath{}K^{\prime} \\
      f_{m}&=Z_{p,q}\left(u_{m},\kappa\right)
    \end{align*}
  \item Perform Algorithm~\ref{alg:Zolotarev-Chebyshev-sum-recurrence} to find
    the Chebyshev polynomial coefficients, $a_{m}$, and convert these to the
    impulse response~\cite[Equation 87]{Vlcek_ZolotarevOptimalFIR}:
    $a_{0}=h_{M}$ and $a_{m}=2h_{M-m}$.
\end{enumerate}

The Octave script \emph{zolotarev\_vlcek\_unbehauen\_test.m} designs an FIR
filter that approximates that shown in Figure 4 of \emph{Vl\v{c}ek} and
\emph{Unbehauen}~\cite{Vlcek_ZolotarevOptimalFIR}. The initial specification is
$fp=0.1$, $fs=0.15$ and $a_{s_{dB}}=-20dB$. The final filter has:
\begin{small}
\verbatiminput{zolotarev_vlcek_unbehauen_test_fir_spec.m}
\end{small}

The $z$-domain impulse reponse coefficients of the FIR filter are:
\begin{small}
\verbatiminput{zolotarev_vlcek_unbehauen_test_fir_coef.m}
\end{small}

Figure~\ref{fig:Zolotarev-Vlcek-Unbehauen-fir-zptf} shows the normalised
Zolotarev polynomial of the FIR filter.
Figure~\ref{fig:Zolotarev-Vlcek-Unbehauen-fir-response} shows the 
frequency response of the FIR filter.
Figure~\ref{fig:Zolotarev-Vlcek-Unbehauen-fir-pz} shows the zeros of the FIR
filter. Note that these are all \emph{double} zeros. 

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_vlcek_unbehauen_test_fir_zptf}}
\caption{Normalised Zolotarev polynomial approximating that of Figure 4
  in \emph{Vl\v{c}ek} and \emph{Unbehauen}~\cite{Vlcek_ZolotarevOptimalFIR}.}
\label{fig:Zolotarev-Vlcek-Unbehauen-fir-zptf}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_vlcek_unbehauen_test_fir_response}}
\caption{FIR filter response approximating that of Figure 4 in \emph{Vl\v{c}ek}
  and \emph{Unbehauen}~\cite{Vlcek_ZolotarevOptimalFIR}.}
\label{fig:Zolotarev-Vlcek-Unbehauen-fir-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_vlcek_unbehauen_test_fir_pz}}
\caption{Zeros of an FIR filter approximating that of Figure 4 in
  \emph{Vl\v{c}ek} and \emph{Unbehauen}~\cite{Vlcek_ZolotarevOptimalFIR}.}
\label{fig:Zolotarev-Vlcek-Unbehauen-fir-pz}
\end{figure}

The Octave script \emph{zolotarev\_zahradnik\_degree\_test.m} attempts to
reproduce the examples given by \emph{Zahradn\'{i}k et
  al.}~\cite{ZahradnikSusta_DegreeEquirippleBandpassFIR}.
Figure~\ref{fig:Zolotarev-Zahradnik-Z-p-100-q-37-k-0-4} shows the normalised  
Zolotarev polynomial, $Z_{100,37}\left(w,0.4\right)$, calculated with Equation
7 of \emph{Zahradn\'{i}k et al.} The Octave script
\emph{zolotarev\_zahradnik\_degree\_test.m} checks the inverse transformation of
$w$ to $u$ shown in Equation~\ref{eqn:w-to-u-conformal-transformation}. Both the
$\jarcsc$ and $\jarccn$ Octave functions accurately invert $w$ to $u$ over the
range of the pass-band in Example 1 of \emph{Zahradn\'{i}k et al.}. A 3rd-order
polynomial fit over that range is accurate to $4$ decimal places.
I failed to reproduce the results of \emph{Zahradn\'{i}k et al.} for their
Example 1 with a pass-band constraint.
Figure~\ref{fig:Zolotarev-Zahradnik-fmax-275-asdB-140} shows a filter 
designed with the stop-band bandwidth and attenuation of \emph{Zahradn\'{i}k et
  al.}'s Example 2.
Figure~\ref{fig:Zolotarev-Zahradnik-fmax-275-asdB-140-detail} shows the
main lobe of the response.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_zahradnik_degree_test_p_100_q_37}}
\caption{Normalised Zolotarev polynomial $Z_{100,37}\left(w,0.4\right)$
  calculated with Equation 7 of \emph{Zahradn\'{i}k et
    al.}~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR}.} 
\label{fig:Zolotarev-Zahradnik-Z-p-100-q-37-k-0-4}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_zahradnik_degree_test_fmax_275_asdB_140}}
\caption{Normalized Zolotarev polynomial FIR filter approximating Example 2 of
  \emph{Zahradn\'{i}k et al.}~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR}
  with stop-band constraints.}
\label{fig:Zolotarev-Zahradnik-fmax-275-asdB-140}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_zahradnik_degree_test_fmax_275_asdB_140_detail}}
\caption{Main lobe of the response of a normalized Zolotarev polynomial FIR
  filter approximating Example 2 of \emph{Zahradn\'{i}k et
    al.}~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR} with stop-band
  constraints.} 
\label{fig:Zolotarev-Zahradnik-fmax-275-asdB-140-detail}
\end{figure}
\clearpage
\subsubsection{The Zolotarev polynomial FIR filter cascade structure design
  procedure of \emph{Zahradn\'{i}k} et al.}
It is often convenient to express an FIR filter polynomial as the cascade
product of
sub-filters~\cite{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters,
Shiung_ImprovingFIRFiltersCascadeTechniques,
Smith_DecompositionFIRCascadeSubFilters,
SmithHenderson_RoundoffNoiseCascadeFIRFilters,
LimLiu_CascadeFIRDiscreteCoefficients}. As I show in the
\hyperlink{sec:Introduction}{Introduction}, it may be difficult to accurately
determine the roots of the FIR filter polynomial and so determine the
sub-filters. For example, see
\emph{Smith}~\cite{Smith_DecompositionFIRCascadeSubFilters}. \emph{Zahradn\'{i}k,
  \v{S}usta  et 
  al.}~\cite{ZahradnikSusta_CascadeNarrowEquirippleFIR} derive an 
expression for the double-roots of the normalised Zolotarev polynomial:
\begin{align*}
  Q_{p,q}\left(w,\kappa\right)
  &=\frac{1+Z_{p,q}\left(w,\kappa\right)}{1+Z_{p,q}\left(w_{max},\kappa\right)}
\end{align*}
where $w_{max}$ is the centre-frequency of the main lobe. Their Figure 2 shows
that $Q_{p,q}\left(w,\kappa\right)$ has $\floor{\frac{p}{2}}$ double zeros to the
right of the maximum ($u\in\left[K+\imath{}K^{\prime},K\right]$ and
$w\in\left[w_{p},1\right]$), $\floor{\frac{q}{2}}$ double zeros to the left of
the maximum, ($u\in\left[0,\imath{}K^{\prime}\right]$ or
$w\in\left[-1,w_{s}\right]$), for a total of $\frac{p+q-2}{2}$ double zeros as
well as:
\begin{itemize}
\item zeros at $w=\pm{}1$ if $p$ is odd and $q$ is odd
\item one zero at $w=1$ if $p$ is odd and $q$ is even
\item one zero at $w=-1$ if $p$ is even and $q$ is odd
\item no other zeros if $p$ is even and $q$ is even
\end{itemize}

Recall Equation~\ref{eqn:Zolotarev-Chebyshev-first-kind}:
\begin{align*}
  Z_{p,q}\left(u,\kappa\right)
  &=\left(-1\right)^{p} T_{p+q}\left(\cos \Phi\left(u,\kappa\right)\right)\\
  \cos\Phi\left(u,\kappa\right)&=\frac{1}{2}\left[
  \frac{H\left(u+u_{0},\kappa\right)}{H\left(u-u_{0},\kappa\right)}
  +\frac{H\left(u-u_{0},\kappa\right)}{H\left(u+u_{0},\kappa\right)}\right]
\end{align*}

On the ``vertical'' sections of the path of $u$ corresponding to the locations
of the zeros of $Q\left(w,\kappa\right)$, substituting $u-u_{0}$ into
Equation~\ref{eqn:Whittaker-Watson-Jacobi-Eta-definition}:
\begin{align}
  H\left(u-u_{0},\kappa\right)&=\begin{cases}
   -H^{\mathconj}\left(u+u_{0},\kappa\right)& u\in\left[0,\imath{}K^{\prime}\right]\\ 
   \phantom{-}H^{\mathconj}\left(u+u_{0},\kappa\right)
     & u\in\left[K+\imath{}K^{\prime},K\right]
     \end{cases}
\label{eqn:Jacobi-Eta-conjugate-function-values}
\end{align}
where $H^{\mathconj}$ is the complex conjugate transpose of $H$. The
$\Phi\left(u,\kappa\right)$ function of
Equation~\ref{eqn:Zolotarev-Chebyshev-first-kind} becomes:  
\begin{align*}
  \Phi\left(u,\kappa\right)&=\begin{cases}
    -2 \arg H\left(u+u_{0},\kappa\right)+\pi
    & u\in\left[0,\imath{}K^{\prime}\right]\\ 
    \phantom{-}2 \arg H\left(u+u_{0},\kappa\right)
    & u\in\left[K+\imath{}K^{\prime},K\right]
  \end{cases}
\end{align*}

The double-zero locations can be found by interpolation of the
multiples of $\frac{\pi}{n}$ into $2\arg{}H\left(u+u_{0},\kappa\right)$.
Figure~\ref{fig:Zolotarev-odd-even-p-and-q-Q} shows the locations of the double
zeros of $Q_{p,q}\left(w,0.75\right)$ for pairs of odd and even $p$ and
  $q$~\cite[Figure 2]{ZahradnikSusta_CascadeNarrowEquirippleFIR}.
Figure~\ref{fig:Zolotarev-odd-even-p-and-q-argH} shows the locations of the
double zeros of $Q_{p,q}\left(w,0.75\right)$ for pairs of odd and even $p$ and
$q$ superimposed on $2\arg{}H\left(u+u_{0},0.75\right)$, normalised to
$\frac{n}{\pi}$, in the regions on either side of the central lobe.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarevFIRcascade_test_Q_p_q}}
\caption{Double-zero locations of $Q_{p,q}\left(w,0.75\right)$~\cite[Figure
  2]{ZahradnikSusta_CascadeNarrowEquirippleFIR}.} 
\label{fig:Zolotarev-odd-even-p-and-q-Q}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarevFIRcascade_test_argHupu0_p_q}}
\caption{Double-zero locations of $Q_{p,q}\left(w,0.75\right)$ superimposed on
  $2\arg{}H\left(u+u_{0},0.75\right)$ normalised to $\frac{n}{\pi}$.}
\label{fig:Zolotarev-odd-even-p-and-q-argH}
\end{figure}

\emph{Zahradn\'{i}k, \v{S}usta et al.}~\cite[Table
I]{ZahradnikSusta_CascadeNarrowEquirippleFIR} show an algorithm, reproduced
below as Algorithm~\ref{alg:Zahradnik-evaluation-of-coefficients-ZPTF}, for the 
calculation of the coefficients of the expansion in Chebyshev polynomials
of the first kind of the product of the factors, $\left(w-w_{l}\right)$, of a
polynomial. They recommend ordering the roots in ascending order of $z$-domain
angular frequency and the $m$ sub-filters select the roots with the ordering
$\rho\left(l\right),\;l=1,\hdots,m$~\cite[Equation
8]{ZahradnikSusta_CascadeNarrowEquirippleFIR}:
\begin{align*}
  \rho\left(l\right)&=\begin{cases}
    \frac{m+l}{2} & m \text{ and } l \text{ both odd or both even}\\
    \frac{m-l+1}{2} & \text{otherwise}\\
  \end{cases}
\end{align*}
In addition, they recommend normalising each sub-filter to the value at the
frequency of the central lobe maximum of the overall filter~\cite[Equation
14]{ZahradnikSusta_CascadeNarrowEquirippleFIR}.

\begin{algorithm}
\begin{algorithmic}
  \Require $w_{0},\;\hdots\;,w_{n-1}$
  \vspace{1.5mm}
  \vspace{1.5mm}
  \State \emph{Initialisation}:
  \vspace{1.5mm}
  \State $\alpha^{\left(0\right)}_{0}=-w_{0}$, $\alpha^{\left(0\right)}_{1}=1$
  \vspace{1.5mm}
  \vspace{1.5mm}
  \State \emph{Body}:
  \vspace{1.5mm}
  \For {$m=1$ \textbf{ to } $n-1$ }
  \vspace{1.5mm}
  \State $\alpha^{\left(m-1\right)}_{m+1}=0$
  \vspace{1.5mm}
  \State $\alpha^{\left(m\right)}_{0}=\alpha^{\left(m-1\right)}_{1}-2w_{m}\alpha^{\left(m-1\right)}_{0}$ 
  \vspace{1.5mm}
  \State $\alpha^{\left(m\right)}_{1}=\alpha^{\left(m-1\right)}_{2}+2\alpha^{\left(m-1\right)}_{0}-2w_{m}\alpha^{\left(m-1\right)}_{1}$
  \vspace{1.5mm}
  \For {$l=2$ \textbf{ to } $m$ }  
  \vspace{1.5mm}
  \State $\alpha^{\left(m\right)}_{l}=\alpha^{\left(m-1\right)}_{l-1}+\alpha^{\left(m-1\right)}_{l+1}-2w_{m}\alpha^{\left(m-1\right)}_{l}$
  \vspace{1.5mm}
  \EndFor 
  \vspace{1.5mm}
  \State $\alpha^{\left(m\right)}_{m+1}=1$
  \vspace{1.5mm}
  \EndFor
  \vspace{1.5mm} 
  \vspace{1.5mm}
  \State \emph{Output}:
  \vspace{1.5mm}
  \State $a_{k}=\alpha^{\left(n\right)}_{k}\quad{}k=0,\hdots,n$
\end{algorithmic}
\caption{Recursion of \emph{Zahradn\'{i}k, \v{S}usta et al.} for the calculation
  of the scaled coefficients of the expansion, in Chebyshev polynomials of
  the first kind, of the product of the $n$ factors, $\left(w-w_{m}\right)$, of a
  polynomial~\cite[Table I]{ZahradnikSusta_CascadeNarrowEquirippleFIR}.}
\label{alg:Zahradnik-evaluation-of-coefficients-ZPTF}
\end{algorithm}

The Octave script \emph{zolotarevFIRcascade\_test.m} attempts to reproduce
\emph{Zahradn\'{i}k, \v{S}usta et al.}'s Examples 1 and 2. As mentioned
previously, I do not understand their method of calculating the degree of the
filter from the required pass-band bandwidth.
Figure~\ref{fig:Zolotarev-cascade-p-22-q-49-subfilters} reproduces Figure 4
of \emph{Zahradn\'{i}k, \v{S}usta et al.}, illustrating their Example 1.
Sub-filters $1$ and $2$ are identical, as expected after examining
\emph{Zahradn\'{i}k, \v{S}usta et al.}'s Figure 3. However, the sub-filter $1$
and sub-filter $2$ shown in their Figure 4 appear to have a similar shape but
a different gain, the filter impulse responses shown in their Table II are all
different and I do not understand how their Equation 15 corresponds to the
numbering shown in their Figure 3. I tried randomly rearranging the roots with
the Octave \emph{randperm} function and found that the range of the responses of
the resulting sub-filters was far greater. 

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarevFIRcascade_test_Q_22_49_subfilters}}
\caption{Amplitude responses of the $4$ sub-filters and the partial cascades
  of the sub-filters of a normalised Zolotarev band-pass filter with
  zero-phase response $Q_{22,49}\left(w,0.46850107\right)$~\cite[Figure
4]{ZahradnikSusta_CascadeNarrowEquirippleFIR}.} 
\label{fig:Zolotarev-cascade-p-22-q-49-subfilters}
\end{figure}

\begin{comment}
Figure~\ref{fig:Zolotarev-cascade-p-22-q-49}, showing the overall response,
reproduces \emph{Zahradn\'{i}k, \v{S}usta et al.}'s Figure 3.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarevFIRcascade_test_Q_22_49}}
\caption{Overall amplitude response normalised Zolotarev band-pass filter with
  zero-phase response $Q_{22,49}\left(w,0.46850107\right)$~\cite[Figure
3]{ZahradnikSusta_CascadeNarrowEquirippleFIR}.} 
\label{fig:Zolotarev-cascade-p-22-q-49}
\end{figure}

The overall impulse response calculated with the Octave function
\emph{zolotarev\_vlcek\_unbehauen(p,q,k)} is:
\begin{small}
\verbatiminput{zolotarevFIRcascade_test_h_22_49_coef.m}
\end{small}

The impulse responses of the $4$ sub-filters are:
\begin{small}
\verbatiminput{zolotarevFIRcascade_test_h_22_49_subfilter_2_coef.m}
\end{small}
\begin{small}
\verbatiminput{zolotarevFIRcascade_test_h_22_49_subfilter_3_coef.m}
\end{small}
\begin{small}
\verbatiminput{zolotarevFIRcascade_test_h_22_49_subfilter_1_coef.m}
\end{small}
\begin{small}
\verbatiminput{zolotarevFIRcascade_test_h_22_49_subfilter_4_coef.m}
\end{small}
\end{comment}

Figure~\ref{fig:Zolotarev-p-2159-q-540-Q}  
shows the double-zero locations near $\pm{}1$ and the central lobe of
$Q_{2159,540}\left(w,0.16238959\right)$ for \emph{Zahradn\'{i}k, \v{S}usta et
  al.}'s Example 2~\cite{ZahradnikSusta_CascadeNarrowEquirippleFIR}.
Figure~\ref{fig:Zolotarev-cascade-p-2159-q-540} attempts to reproduce
\emph{Zahradn\'{i}k, \v{S}usta et al.}s Figure 5 showing 
$Q_{2159,540}\left(w,0.16238959\right)$ with $3$ sub-filters. 
Algorithm~\ref{alg:Zahradnik-evaluation-of-coefficients-ZPTF}, 
the calculation of the coefficients of the Chebyshev polynomials of the first
kind, is implemented with the \emph{MPFR}~\cite{Fousse:2007:MMB:1236463.1236468} 
 library in the Octave \emph{octfile} \emph{roots2T.cc}.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarevFIRcascade_test_Q_2159_540_detail}}
\caption{Detailed view of the double-zero locations of
  $Q_{2159,540}\left(w,0.16238959\right)$ near $\pm{}1$ and the central lobe for
\emph{Zahradn\'{i}k, \v{S}usta et al.}'s
Example 2~\cite{ZahradnikSusta_CascadeNarrowEquirippleFIR}.}
\label{fig:Zolotarev-p-2159-q-540-Q}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarevFIRcascade_test_Q_2159_540_subfilters}}
\caption{Amplitude responses of the $3$ sub-filters cascade
  of the sub-filters of a normalised Zolotarev band-pass filter with
  zero-phase response $Q_{2159,540}\left(w,0.16238959\right)$~\cite[Figure
5]{ZahradnikSusta_CascadeNarrowEquirippleFIR}.} 
\label{fig:Zolotarev-cascade-p-2159-q-540}
\end{figure}

\subsubsection{Addendum}
\paragraph{Working for Equation~\ref{eqn:Jacobi-Eta-conjugate-function-values}}
Substituting $u=-u_{0}+\imath{}yK^{\prime}$, where $y\in\left[0,1\right]$, into
Equation~\ref{eqn:Whittaker-Watson-Jacobi-Eta-definition}:
\begin{align*}
  H^{\mathconj}\left(-u_{0}+\imath{}yK^{\prime},\kappa\right)
  &=\imath{}q^{-\frac{1}{4}}e^{\frac{\imath\pi{}\left(u_{0}+\imath{}yK^{\prime}\right)}{2K}}
    \Theta\left(-u_{0}-\imath{}yK^{\prime}-\imath{}K^{\prime},\kappa\right)\\
  &=-H\left(u_{0}+\imath{}yK^{\prime},\kappa\right)
\end{align*}

Substituting $u=K-u_{0}+\imath{}yK^{\prime}$, where $y\in\left[0,1\right]$, into
Equation~\ref{eqn:Whittaker-Watson-Jacobi-Eta-definition}:
\begin{align*}
    H^{\mathconj}\left(K-u_{0}+\imath{}yK^{\prime},\kappa\right)
  &=\imath{}q^{-\frac{1}{4}}
    e^{\frac{\imath\pi{}\left(-K+u_{0}+\imath{}yK^{\prime}\right)}{2K}}
    \Theta\left(K-u_{0}-\imath{}yK^{\prime}-\imath{}K^{\prime},\kappa\right) \\
  &=-\imath{}q^{-\frac{1}{4}}
    e^{\frac{\imath\pi{}\left(K+u_{0}+\imath{}yK^{\prime}\right)}{2K}}
    \Theta\left(-K-u_{0}-\imath{}yK^{\prime}-\imath{}K^{\prime},\kappa\right) \\
  &=H\left(K+u_{0}+\imath{}yK^{\prime},\kappa\right)
\end{align*}

\paragraph{Working for
  Algorithm~\ref{alg:Zahradnik-evaluation-of-coefficients-ZPTF}}
This is an application of the recurrence relations of the Chebyshev polynomials
of the first kind:
\begin{align*}
  T_{0}\left(w\right)=\;&1\\
  T_{1}\left(w\right)=\;&w\\
  T_{n+1}\left(w\right)=\;&2wT_{n}\left(w\right)-T_{n-1}\left(w\right)
\end{align*}
For the first zero (dropping the argument, $w$, of $T_{0}$ etc.):
\begin{align*}
  \left(w-w_{0}\right)=\;&\alpha^{\left(0\right)}_{1}T_{1}+
                        \alpha^{\left(0\right)}_{0}T_{0}\\
\end{align*}
so that $\alpha^{\left(0\right)}_{1}=1$ and $\alpha^{\left(0\right)}_{0}=-w_{0}$.
Multiplying by the second zero:
\begin{align*}
  \left(w-w_{1}\right)\left[\alpha^{\left(0\right)}_{1}T_{1}
  +\alpha^{\left(0\right)}_{0}T_{0}\right]
  =\;&\frac{\alpha^{\left(0\right)}_{1}}{2}\left(2wT_{1}-T_{0}\right)
    +\frac{\alpha^{\left(0\right)}_{1}}{2}T_{0}+\alpha^{\left(0\right)}_{0}wT_{0}
    -w_{1}\alpha^{\left(0\right)}_{1}T_{1}-w_{1}\alpha^{\left(0\right)}_{0}T_{0}\\
  =\;&\alpha^{\left(0\right)}_{1}\frac{T_{2}}{2}
    +\left(2\alpha^{\left(0\right)}_{0}
    -2w_{1}\alpha^{\left(0\right)}_{1}\right)\frac{T_{1}}{2}
    +\left(\alpha^{\left(0\right)}_{1}
    -2w_{1}\alpha^{\left(0\right)}_{0}\right)\frac{T_{0}}{2}
\end{align*}
so that
$\alpha^{\left(1\right)}_{2}=1$, 
$\alpha^{\left(1\right)}_{1}=2\alpha^{\left(0\right)}_{0}-2w_{1}\alpha^{\left(0\right)}_{1}$
and
$\alpha^{\left(1\right)}_{0}=\alpha^{\left(0\right)}_{1}-2w_{1}\alpha^{\left(0\right)}_{0}$
. For the third zero, ignoring the scaling by $2$: 
\begin{align*}
  \left(w-w_{2}\right)
  \left[\alpha^{\left(1\right)}_{2}T_{2}+\alpha^{\left(1\right)}_{1}T_{1}
  +\alpha^{\left(1\right)}_{0}T_{0}\right]
  =\;&\frac{\alpha^{\left(1\right)}_{2}}{2}\left(2wT_{2}-T_{1}\right)
    +\frac{\alpha^{\left(1\right)}_{2}}{2}T_{1}
    +\frac{\alpha^{\left(1\right)}_{1}}{2}\left(2wT_{1}-T_{0}\right)+
    \frac{\alpha^{\left(1\right)}_{1}}{2}T_{0}
    +\alpha^{\left(1\right)}_{0}wT_{0}\quad\hdots\\
  &-w_{2}\alpha^{\left(1\right)}_{2}T_{2}
    -w_{2}\alpha^{\left(1\right)}_{1}T_{1}
    -w_{2}\alpha^{\left(1\right)}_{0}T_{0}\\
  =\;&\alpha^{\left(1\right)}_{2}\frac{T_{3}}{2}
    +\left(\alpha^{\left(1\right)}_{1}
    -2w_{2}\alpha^{\left(1\right)}_{2}\right)\frac{T_{2}}{2}\quad\hdots\\
  &+\left(\alpha^{\left(1\right)}_{2}+2\alpha^{\left(1\right)}_{0}
    -2w_{2}\alpha^{\left(1\right)}_{1}\right)\frac{T_{1}}{2}
    +\left(\alpha^{\left(1\right)}_{1}
    -2w_{2}\alpha^{\left(1\right)}_{0}\right)\frac{T_{0}}{2}
\end{align*}

In general, for $m=1,2,\hdots\;$:
\begin{align*}
  \left(w-w_{m}\right)\sum^{m}_{l=0}\alpha^{\left(m-1\right)}_{l}T_{l}
  =\;&\sum^{m}_{l=1}\frac{\alpha^{\left(m-1\right)}_{l}}{2}\left(2wT_{l}-T_{l-1}\right)
    +\sum^{m}_{l=1}\frac{\alpha^{\left(m-1\right)}_{l}}{2}T_{l-1}
     +\alpha^{\left(m-1\right)}_{0}wT_{0}
     -\sum^{m}_{l=0}w_{m}\alpha^{\left(m-1\right)}_{l}T_{l}\\
  =\;&\sum^{m}_{l=1}\alpha^{\left(m-1\right)}_{l}\frac{T_{l+1}}{2}
     +\sum^{m}_{l=1}\alpha^{\left(m-1\right)}_{l}\frac{T_{l-1}}{2}
     +2\alpha^{\left(m-1\right)}_{0}\frac{T_{1}}{2}
     -\sum^{m}_{l=0}2w_{m}\alpha^{\left(m-1\right)}_{l}\frac{T_{l}}{2}\\
  =\;&\sum^{m+1}_{l=2}\alpha^{\left(m-1\right)}_{l-1}\frac{T_{l}}{2}
     +\sum^{m-1}_{l=0}\alpha^{\left(m-1\right)}_{l+1}\frac{T_{l}}{2}
     +2\alpha^{\left(m-1\right)}_{0}\frac{T_{1}}{2}
     -\sum^{m}_{l=0}2w_{m}\alpha^{\left(m-1\right)}_{l}\frac{T_{l}}{2} \\
  =\;&\alpha^{\left(m-1\right)}_{m}\frac{T_{m+1}}{2}
     +\alpha^{\left(m-1\right)}_{m-1}\frac{T_{m}}{2}
     +\sum^{m-1}_{l=2}\alpha^{\left(m-1\right)}_{l-1}\frac{T_{l}}{2}\quad\hdots\\
   &+\sum^{m-1}_{l=2}\alpha^{\left(m-1\right)}_{l+1}\frac{T_{l}}{2}
     +\alpha^{\left(m-1\right)}_{2}\frac{T_{1}}{2}
     +\alpha^{\left(m-1\right)}_{1}\frac{T_{0}}{2}
     +2\alpha^{\left(m-1\right)}_{0}\frac{T_{1}}{2}\quad\hdots\\
   &-2w_{m}\alpha^{\left(m-1\right)}_{m}\frac{T_{m}}{2}
     -\sum^{m-1}_{l=2}2w_{m}\alpha^{\left(m-1\right)}_{l}\frac{T_{l}}{2}
     -2w_{m}\alpha^{\left(m-1\right)}_{1}\frac{T_{1}}{2}
     -2w_{m}\alpha^{\left(m-1\right)}_{0}\frac{T_{0}}{2}\\
  =\;&\alpha^{\left(m-1\right)}_{m}\frac{T_{m+1}}{2}
       +\left[\alpha^{\left(m-1\right)}_{m-1}
       -2w_{m}\alpha^{\left(m-1\right)}_{m}\right]\frac{T_{m}}{2}\quad\hdots\\
   &+\sum^{m-1}_{l=2}\left[\alpha^{\left(m-1\right)}_{l-1}
       +\alpha^{\left(m-1\right)}_{l+1}
       -2w_{m}\alpha^{\left(m-1\right)}_{l}\right]\frac{T_{l}}{2}\quad\hdots\\
   &+\left[\alpha^{\left(m-1\right)}_{2}
     +2\alpha^{\left(m-1\right)}_{0}
     -2w_{m}\alpha^{\left(m-1\right)}_{1}\right]\frac{T_{1}}{2}
     +\left[\alpha^{\left(m-1\right)}_{1}
     -2w_{m}\alpha^{\left(m-1\right)}_{0}\right]\frac{T_{0}}{2}
\end{align*}

\clearpage
\subsection{Almost equi-ripple low-pass FIR filter design with the Zolotarev polynomials}
\emph{Vl\v{c}ek} and
\emph{Zahradn\'{i}k}~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR,
  VlcekZahradnik_AlmostEquirippleApproxLowPassFIR}
describe the use of modified Zolotarev polynomials to design ``almost
equi-ripple'' low-pass FIR filters. They assume a solution of the form
$\sqrt{1-w^{2}}S_{p,q}\left(w,\kappa\right)$\footnote{See
  \emph{Riblet}~\cite{Riblet_EquiRippleFunctionsTransmissionLine}, ``If one uses
  $x=-\cos\theta$ for a frequency variable instead of $\omega$, ... the problem
  of designing for equal-ripple performance reduces to finding even and odd
  polynomials $P_{n}\left(x\right)$ so that $P_{n}\left(x\right)/\sqrt{1-x^{2}}$
  oscillates between $\pm{}1$   exactly $n+1$ times in a prescribed interval
  $-1<-x_{c}\le{}x\le{}x_{c}<1$. ...  $P_{n}\left(x\right)$ is given then by
$2P_{n}\left(x\right)=\left(1+\sqrt{1-x_{c}^{2}}\right)T_{n}\left(\frac{x}{x_{c}}
\right)-\left(1-\sqrt{1-x_{c}^{2}}\right)T_{n-2}\left(\frac{x}{x_{c}}\right)$''}
and use $S_{p,q}\left(w,\kappa\right)$ as the generating polynomial of a
low-pass FIR filter\footnote{The normalisation is shown in \emph{Vl\v{c}ek} and
  \emph{Zahradn\'{i}k}~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR,
    VlcekZahradnik_AlmostEquirippleApproxLowPassFIR} as:
  \begin{align*}
    Q\left(w\right)&=-\mathcal{N}_{1}+\frac{1}{\mathcal{N}_{2}-\mathcal{N}_{1}}
                     \mathcal{S}\left(w\right)
  \end{align*}
  }:
\begin{align*}
  S_{p,q}\left(w,\kappa\right)&=\sum_{m=0}^{n}a^{+}_{m}U_{m}\left(w\right)\\
  \mathcal{S}\left(w\right)&=\int{}S_{p,q}\left(w,\kappa\right)dw\\
  Q\left(w\right)&=\frac{\mathcal{S}\left(w\right)-\mathcal{N}_{1}}
                   {\mathcal{N}_{2}-\mathcal{N}_{1}}
\end{align*}
where $U_{m}\left(w\right)$ is the $m$'th Chebyshev polynomial of the second
kind, $Q\left(w\right)$ is the zero-phase transfer function of the FIR
filter and the normalising constants $\mathcal{N}_{1}$ and
$\mathcal{N}_{2}$ are: 
\begin{align*}
  \mathcal{N}_{1}&=\begin{cases}
    \mathcal{S}\left(w=-1\right)&\text{for q even} \\
    \mathcal{S}\left(w=\cos\frac{n\pi}{n+1}\right)&\text{for q odd} \\
    \end{cases}\\
  \mathcal{N}_{2}&=\begin{cases}
    \mathcal{S}\left(w=1\right)&\text{for p even} \\
    \mathcal{S}\left(w=\cos\frac{\pi}{n+1}\right)&\text{for p odd} \\
    \end{cases}
\end{align*}

The frequency response of a symmetric FIR filter of length $2n+3$ is:
\begin{align*}
  H\left(\omega\right)&=\sum^{2n+2}_{m=0}h_{m}e^{-\imath{}m\omega{}T}
\end{align*}
where the impulse response, $h_{m}=h_{2n+2-m}\;\text{,}\quad m=0,\hdots,n$. The
zero-phase frequency response, $Q\left(\omega\right)$, is related to the
frequency response, $H\left(\omega\right)$, by:
\begin{align*}
  H\left(\omega\right)
  &=e^{-\imath{}\left(n+1\right)\omega{}T}\left[ h_{n+1}
    +\sum^{n}_{m=0}h_{m}e^{-\imath{}\left[m-\left(n+1\right)\right]\omega{}T}
    +\sum^{2n+2}_{m=n+2}h_{m}e^{-\imath{}\left[m-\left(n+1\right)\right]\omega{}T}\right]\\
  &=e^{-\imath{}\left(n+1\right)\omega{}T}\left[ h_{n+1}
    +\sum^{n}_{m=0}h_{m}e^{-\imath{}\left[m-\left(n+1\right)\right]\omega{}T}
    +\sum^{n}_{m=0}h_{2n+2-m}e^{-\imath{}\left[2n+2-m-\left(n+1\right)\right]\omega{}T}
    \right]\\
  &=e^{-\imath{}\left(n+1\right)\omega{}T}\left[ h_{n+1}
    +\sum^{n}_{m=0}h_{m}e^{-\imath{}\left[m-\left(n+1\right)\right]\omega{}T}
    +\sum^{n}_{m=0}h_{2n+2-m}e^{\imath{}\left[m-\left(n+1\right)\right]\omega{}T}
    \right]\\
  &=e^{-\imath{}\left(n+1\right)\omega{}T}\left[
    h_{n+1}+2\sum^{n}_{m=0}h_{m}\cos\left[\left(n+1\right)-m\right]\omega{}T
    \right]\\
  &=e^{-\imath{}\left(n+1\right)\omega{}T}Q\left(\omega\right)
\end{align*}

\emph{Vl\v{c}ek} and \emph{Zahradn\'{i}k}~\cite[Tables
4 and 5]{VlcekZahradnik_AlmostEquirippleLowPassFIR} provide an algorithm for
calculating the $2\left(p+q\right)+3$ coefficients of the impulse response of
the FIR filter, reproduced here (with altered normalisation) as
Algorithm~\ref{alg:Zolotarev-almost-equiripple-low-pass-FIR}. I have combined
\emph{Vl\v{c}ek} and \emph{Zahradn\'{i}k}'s Tables 4 and 5 because the
normalisation step in Table 4 normalises the $a^{+}$ coefficients as if they are
coefficients of $\frac{d}{dw}T_{m}\left(w\right)$ rather than
$U_{m}\left(w\right)$. 
\begin{algorithm}
\begin{algorithmic}
  \Require $p$, $q$ and $\kappa$
  \vspace{1.5mm}
  \vspace{1.5mm}
  \State \emph{Initialisation}:
  \vspace{1.5mm}
  \State $n=p+q$
  \vspace{1.5mm}
  \State $u_{0}=\frac{2p+1}{2n+2}K\left(\kappa\right)$
  \vspace{1.5mm}
  \State $w_{p}=2\jcd^{2}\left(u_{0},\kappa\right)-1$
  \vspace{1.5mm}
  \State $w_{s}=2\jcn^{2}\left(u_{0},\kappa\right)-1$
  \vspace{1.5mm}
  \State $w_{q}=\frac{w_{p}+w_{s}}{2}$
  \vspace{1.5mm}
  \State $w_{m}=w_{s}+2\frac{\jsn\left(u_{0},\kappa\right)\jcn\left(u_{0},\kappa\right)}{\jdn\left(u_{0},\kappa\right)}Z\left(u_{0},\kappa\right)$
  \vspace{1.5mm}
  \State $\alpha_{n}=1$, $\alpha_{n+1}=\alpha_{n+2}=\alpha_{n+3}=\alpha_{n+4}=\alpha_{n+5}=0$
  \vspace{1.5mm}
  \vspace{1.5mm}
  \State \emph{Body}:
  \vspace{1.5mm}
  \For {$m=n+2$ \textbf{ down to } $3$ }
  \vspace{1.5mm}
  \State $8c_{1}=n\left(n+2\right)-\left(m+3\right)\left(m+5\right)$
  \vspace{1.5mm}
  \State $4c_{2}=3w_{m}\left[n\left(n+2\right)-\left(m+2\right)\left(m+4\right)\right]+\left(m+3\right)\left(2m+7\right)\left(w_{m}-w_{q}\right)$
  \vspace{1.5mm}
  \State
  $8c_{3}=3\left[n\left(n+2\right)-\left(m+1\right)\left(m+3\right)\right]+12w_{m}\left[\left(n+1\right)^{2}w_{m}-\left(m+2\right)^{2}w_{q}\right]\hdots$\\
\quad\quad\quad\quad$-4\left(m+2\right)\left(m+3\right)\left(w_{p}w_{s}-w_{m}w_{q}\right)$
  \vspace{1.5mm}
  \State
  $2c_{4}=3\left[\left(n+1\right)^{2}w_{m}-\left(m+1\right)^{2}w_{q}\right]-\left(m+1\right)^{2}\left(w_{m}-w_{q}\right)\quad\hdots$\\
\quad\quad\quad\quad$+2w_{m}\left[\left(n+1\right)^{2}w_{m}^{2}-\left(m+1\right)^{2}w_{p}w_{s}\right]$
  \vspace{1.5mm}
  \State $8c_{5}=3\left[n\left(n+2\right)-\left(m-1\right)\left(m+1\right)\right]+12w_{m}\left[\left(n+1\right)^{2}w_{m}-m^{2}w_{q}\right]\quad\hdots$\\
\quad\quad\quad\quad$-4m\left(m-1\right)\left(w_{p}w_{s}-w_{m}w_{q}\right)$
  \vspace{1.5mm}
  \State $4c_{6}=3w_{m} \left[n\left(n+2\right)-\left(m-2\right)m\right]+\left(m-1\right)\left(2m-3\right)\left(w_{m}-w_{q}\right)$
  \vspace{1.5mm}
  \State $8c_{7}=n\left(n+2\right)-\left(m-3\right)\left(m-1\right)$
  \vspace{1.5mm}
  \State $\alpha_{m-3}=\frac{1}{c_{7}}\sum_{l=1}^{6}\left(-1\right)^{l}c_{l}\alpha_{m+4-l}$
  \vspace{1.5mm}
  \EndFor
  \vspace{1.5mm}
  \vspace{1.5mm}
  \State \emph{Normalisation}:
  \vspace{1.5mm}
  \State $s_{n}=\sum_{m=0}^{n}\left(m+1\right)\alpha_{m}$
  \vspace{1.5mm}
  \For{$m=0$ \textbf{ to } $n$ }
  \vspace{1.5mm}
  \State $a^{+}_{m}=\left(-1\right)^{p}\left(n+1\right)\frac{\alpha_{m}}{s_{n}}$
  \vspace{1.5mm}
  \EndFor
  \vspace{1.5mm}
  \vspace{1.5mm}
  \State \emph{Integration}:
  \vspace{1.5mm}
  \For{$m=0$ \textbf{ to } $n$ }
  \vspace{1.5mm}
  \State $a_{m+1}=\frac{a^{+}_{m}}{m+1}$
  \vspace{1.5mm}
  \EndFor
  \vspace{1.5mm}
  \vspace{1.5mm}
  \State \emph{Impulse response}:
  \vspace{1.5mm}
  \State $h_{n+1}=-\frac{\mathcal{N}_{1}}{\mathcal{N}_{2}-\mathcal{N}_{1}}$
  \vspace{1.5mm}
  \For{$m=1$ \textbf{ to } $n+1$ }
  \vspace{1.5mm}
  \State $h_{n+1\pm{}m}=\frac{1}{2}\frac{a_{m}}{\mathcal{N}_{2}-\mathcal{N}_{1}}$
  \vspace{1.5mm}
  \EndFor
\end{algorithmic}
\caption{\emph{Vl\v{c}ek} and \emph{Zahradn\'{i}k}'s algorithm for the
  evaluation of the impulse response, $h\left(m\right)$, of an ``almost
  equi-ripple'' low-pass FIR filter~\cite[Tables
  4 and 5]{VlcekZahradnik_AlmostEquirippleLowPassFIR}.}.
\label{alg:Zolotarev-almost-equiripple-low-pass-FIR}
\end{algorithm}
\clearpage
\emph{Vl\v{c}ek} and \emph{Zahradn\'{i}k}~\cite[Section
7]{VlcekZahradnik_AlmostEquirippleLowPassFIR} provide the following
design procedure:

\begin{enumerate}
\item Specify the minimum attenuation in the stop-band,
  $a_{s_{dB}}=20\log_{10}a_{s}<0$. Specify the pass-band frequency $\omega_{p}T$
  and the stop-band frequency $\omega_{s}T$. The maximum width of the transition
  band is $\Delta\omega{}T=\left(\omega_{s}-\omega_{p}\right)T$.
  \item Calculate the degree, $n=p+q$, of the generating polynomial,
    $S_{p,q}\left(w\right)$, using the approximation\footnote{I found that, for
      a filter with $a_{s_{dB}}=-100$, $f_{p}=0.24$ and $f_{s}=0.25$, the degree
      equation of \emph{Vl\v{c}ek} and \emph{Zahradn\'{i}k}~\cite[Equation
      23]{VlcekZahradnik_AlmostEquirippleLowPassFIR} grossly over-estimates 
      the required $n$ as $n=336$ when $n=198$ is sufficient.}:
    \begin{align*}
      \frac{\left(\xi_{1}n+\xi_{2}\right)\Delta\omega{}T}{\pi}+\xi_{3}+
      \frac{\xi_{4}}{\left(n+\xi_{5}\right)^{\xi_{6}}}&=a_{s_{dB}}
    \end{align*}
    where $\xi_{1}=-14.02925485$, $\xi_{2}=-32.86119410$, $\xi_{3}=-5.80117336$,
    $\xi_{4}=2.99564719$, $\xi_{5}=-21.24188066$ and
    $\xi_{6}=0.28632078$. 
  \item Determine integer values
    $p=\nint{n\frac{\left(\omega_{s}+\omega_{p}\right)T}{2\pi}}$, $q=n-p$ 
  \item Calculate the elliptic function modulus
    $\kappa=\sqrt{1-\left(\frac{1-\hat{\kappa}}{1+\hat{\kappa}}\right)^{2}}$,
    where $\hat{\kappa}$ is given by the approximation:
    \begin{align*} 
      \hat{\kappa}&=\left\{\left[\chi_{1}+
                  \frac{\chi_{2}}{\left(p+\chi_{3}\right)^{\chi_{4}}}\right]n+
                  \chi_{5}p+\chi_{6}\right\}w_{p}+
                  \chi_{7}+\frac{\chi_{8}}{\left(p+\chi_{9}\right)^{\chi_{10}}}+
                  \frac{1}{\left(n+\chi_{11}p+\chi_{12}\right)^{\chi_{13}p+\chi_{14}}}
    \end{align*}
    for $w_{p}=\cos\frac{\pi-\Delta\omega{}T}{2}$ and $\chi_{1}=-0.00452871$,
$\chi_{2}=0.51350112$, $\chi_{3}=2.56407699$, $\chi_{4}=1.12297611$,
$\chi_{5}=0.01473844$, $\chi_{6}=0.14824220$, $\chi_{7}=0.00245539$,
$\chi_{8}=0.52499043$, $\chi_{9}=0.75104615$, $\chi_{10}=1.29448910$,
$\chi_{11}=-1.06038228$, $\chi_{12}=0.64247743$, $\chi_{13}=-0.00932499$,
$\chi_{14}=1.88486768$. 
  \item Perform Algorithm~\ref{alg:Zolotarev-almost-equiripple-low-pass-FIR} to
    find the impulse response, $h_{m}$.
\end{enumerate}
  
The Octave script \emph{zolotarev\_vlcek\_zahradnik\_test.m} reproduces
\emph{Vl\v{c}ek} and \emph{Zahradn\'{i}k}'s Figures $1$ to
$4$~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR}, illustrating the
design of of an almost equi-ripple FIR filter with $p=4$, $q=11$ and
$\kappa=0.75$. Figure~\ref{fig:Zolotarev-Vlcek-Zahradnik-p-4-q-11-zolotarev}
shows the iso-extremal function, $\sqrt{1-w^{2}}S_{4,11}\left(w,0.75\right)$,
Figure~\ref{fig:Zolotarev-Vlcek-Zahradnik-p-4-q-11-generator} shows 
the generating function,
Figure~\ref{fig:Zolotarev-Vlcek-Zahradnik-p-4-q-11-zero-phase} shows zero-phase
transfer function and
Figure~\ref{fig:Zolotarev-Vlcek-Zahradnik-p-4-q-11-response} shows the 
amplitude frequency response.
The coefficients of the expansion of the zero-phase response in Chebyshev
polynomials of the first kind found with
Algorithm~\ref{alg:Zolotarev-almost-equiripple-low-pass-FIR}~\cite[Table
  4]{VlcekZahradnik_AlmostEquirippleLowPassFIR} are:
\begin{small}
\verbatiminput{zolotarev_vlcek_zahradnik_test_p_4_q_11_a_coef.m}
\end{small}
The corresponding $z$-domain discrete-time impulse response coefficients are:
\begin{small}
\verbatiminput{zolotarev_vlcek_zahradnik_test_p_4_q_11_h_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_vlcek_zahradnik_test_p_4_q_11_isoextremal}}
\caption{Iso-extremal function $\sqrt{1-w^{2}}S_{4,11}\left(w,0.75\right)$,
  corresponding to Figure 1 of \emph{Vl\v{c}ek} and
  \emph{Zahradn\'{i}k}~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR}, 
  $p=4$, $q=11$, $\kappa=0.75$.} 
\label{fig:Zolotarev-Vlcek-Zahradnik-p-4-q-11-zolotarev}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_vlcek_zahradnik_test_p_4_q_11_generator}}
\caption{FIR filter generating function corresponding to Figure 2 of 
  \emph{Vl\v{c}ek} and
  \emph{Zahradn\'{i}k}~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR}, 
  $p=4$, $q=11$, $\kappa=0.75$.} 
\label{fig:Zolotarev-Vlcek-Zahradnik-p-4-q-11-generator}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_vlcek_zahradnik_test_p_4_q_11_zero_phase}}
\caption{FIR filter zero-phase response corresponding to Figure 3 of 
  \emph{Vl\v{c}ek} and
  \emph{Zahradn\'{i}k}~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR}, 
  $p=4$, $q=11$, $\kappa=0.75$.} 
\label{fig:Zolotarev-Vlcek-Zahradnik-p-4-q-11-zero-phase}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_vlcek_zahradnik_test_p_4_q_11_response}}
\caption{FIR filter amplitude response corresponding to Figure 4 of 
  \emph{Vl\v{c}ek} and
  \emph{Zahradn\'{i}k}~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR}, 
  $p=4$, $q=11$, $\kappa=0.75$.} 
\label{fig:Zolotarev-Vlcek-Zahradnik-p-4-q-11-response}
\end{figure}

The Octave script \emph{zolotarev\_vlcek\_zahradnik\_test.m} reproduces
\emph{Vl\v{c}ek} and \emph{Zahradn\'{i}k}'s Figure $5$, shown here as
Figure~\ref{fig:Zolotarev-Vlcek-Zahradnik-p-100-q-300-response}.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_vlcek_zahradnik_test_p_100_q_300_response}}
\caption{FIR filter amplitude response corresponding to Figure 5 of 
  \emph{Vl\v{c}ek} and
  \emph{Zahradn\'{i}k}~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR},
  $p=100$, $q=300$, $\kappa=0.25$.}  
\label{fig:Zolotarev-Vlcek-Zahradnik-p-100-q-300-response}
\end{figure}

Finally, the Octave script \emph{zolotarev\_vlcek\_zahradnik\_test.m} 
follows the procedure of \emph{Vl\v{c}ek} and \emph{Zahradn\'{i}k} to design a
low-pass FIR filter with $a_{s_{dB}}=-120$, $fp=0.15$ and
$fs=0.175$~\cite[Section 8]{VlcekZahradnik_AlmostEquirippleLowPassFIR}. For this
filter $n=162$, $p=53$, $q=109$ and the filter length is $327$. The value of the
elliptic modulus calculated in the script, $\kappa=0.5605516759$, differs
slightly from that reported by \emph{Vl\v{c}ek} and \emph{Zahradn\'{i}k},
$\kappa=0.55830966$. This may be due to round-off error in the given values of
$\chi$. The frequency response of the filter is shown in 
Figure~\ref{fig:Zolotarev-Vlcek-Zahradnik-as-120-fp-0-15-response}. 
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_vlcek_zahradnik_test_as_120_fp_0_15_response}}
\caption{FIR filter amplitude response of a low-pass FIR filter with
  $a_{s_{dB}}=-120$, $fp=0.15$ and $fs=0.175$ designed with the procedure of
  \emph{Vl\v{c}ek} and \emph{Zahradn\'{i}k}~\cite[Section 
8]{VlcekZahradnik_AlmostEquirippleLowPassFIR}.}
\label{fig:Zolotarev-Vlcek-Zahradnik-as-120-fp-0-15-response}
\end{figure}
\clearpage
\subsubsection{Addendum}
I can successfully design filters with Table 4 of \emph{Vl\v{c}ek} and
\emph{Zahradn\'{i}k}~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR}. On the
other hand, I find that the generating function, $S_{p,q}\left(w,\kappa\right)$,
calculated by Table 4, does not satisfy their Equation 17.
Figure~\ref{fig:Zolotarev-Vlcek-Zahradnik-comparison-generating-function},
created by the Octave script \emph{zolotarev\_vlcek\_zahradnik\_test.m},
compares the Zolotarev polynomial, $Z_{4,11}\left(w,0.75\right)$, found by direct
calculation~\cite{ChenParks_AnalyticNarrowBandFIRZolotarev}, the modified
Zolotarev polynomial, $Z_{4,11}\left(w,0.75\right)/\sqrt{1-w^{2}}$, the function,
$\sqrt{1-w^{2}}S_{4,11}\left(w,0.75\right)$, and the generating
polynomial $S_{4,11}\left(w,0.75\right)$.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{zolotarev_vlcek_zahradnik_test_p_4_q_11_chen_parks}}
\caption{Comparison of the iso-extremal function,
  $\sqrt{1-w^{2}}S_{4,11}\left(w,0.75\right)$, the Zolotarev polynomial,
  $Z_{4,11}\left(w,0.75\right)$, 
  calculated by the Chebyshev expansion by \emph{Vl\v{c}ek} and
  \emph{Unbehauen}~\cite{Vlcek_ZolotarevOptimalFIR}, the generating function,
  $S_{4,11}\left(w,0.75\right)$, of \emph{Vl\v{c}ek} and 
  \emph{Zahradn\'{i}k}~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR} and
  the modified Zolotarev polynomial,
  $Z_{4,11}\left(w,0.75\right)/\sqrt{1-w^{2}}$.} 
\label{fig:Zolotarev-Vlcek-Zahradnik-comparison-generating-function}
\end{figure}

I am not sure what \emph{Vl\v{c}ek} and
\emph{Zahradn\'{i}k}~\cite[p.747]{VlcekZahradnik_AlmostEquirippleLowPassFIR}
mean by ``the second solution of $\left(14\right)$ in the form
 $\sqrt{1-w^{2}}S_{p,q}\left(w,\kappa\right)$''. Initially, I assumed that
 they are referring to the possibility of a second, linearly independent
 solution of
 Equation~\ref{eqn:Zolotarev-linear-second-order-differential-equation}\footnote{
 For example, see \emph{Morse} and \emph{Feshbach}~\cite[Section
 5.2]{MorseFeshbach_MethodsOfTheoreticalPhysics}.}. However, after examining
 Figure~\ref{fig:Zolotarev-Vlcek-Zahradnik-p-4-q-11-zolotarev}~\cite[Figure
 1]{VlcekZahradnik_AlmostEquirippleLowPassFIR}, it is clear that
 $\sqrt{1-w^{2}}S_{p,q}\left(w,\kappa\right)$ is not a solution of
 Equation~\ref{eqn:Zolotarev-non-linear-differential-equation}, as it is 
 zero rather than $\pm{}1$ at $w=\pm{}1$, as shown for
 $Z_{5,9}\left(w,0.78\right)$ in
 Figure~\ref{fig:Zolotarev-Vlcek-Unbehauen-Z-p-5-q-9-k-0-78}. \emph{Vl\v{c}ek}
 and \emph{Zahradn\'{i}k}'s Table 4 shows that the main lobe edge is modified to
 $u_{0}=\frac{p+\frac{1}{2}}{n+1}K\left(\kappa\right)$. This suggests that the
 $n^2$  term in
 Equation~\ref{eqn:Zolotarev-linear-second-order-differential-equation} should
 be replaced by $\left(n+1\right)^{2}$. The Maxima script 
 \emph{zolotarev\_vlcek\_zahradnik\_test\_table\_4.max} substitutes
 $\sqrt{1-w^{2}}f\left(w\right)$  into  
 Equation~\ref{eqn:Zolotarev-linear-second-order-differential-equation} 
 with this modification. The resulting differential equation
 is\footnote{Consistent with
   Equation~\ref{eqn:Zolotarev-linear-differential-equation-factors} rather than
   following the changes in notation from \emph{Vl\v{c}ek} and 
   \emph{Unbehauen}~\cite[Equation 64]{Vlcek_ZolotarevOptimalFIR} to
   \emph{Vl\v{c}ek} and \emph{Unbehauen}~\cite[Equation
   15]{VlcekZahradnik_AlmostEquirippleLowPassFIR}.}:  
 \begin{align}
   g_{2}\left(w\right)\left[\left(1-w^{2}\right)\frac{d^{2}f}{dw^{2}}
  -3w\frac{df}{dw}\right]-g_{1}\left(w\right)\left(1-w^{2}\right)\frac{df}{dw}+
   \left[\left(n+1\right)^{2}g_{0}\left(w\right)
   +wg_{1}\left(w\right)-g_{2}\left(w\right)\right]f&=0
\label{eqn:Modified-Zolotarev-second-order-linear-differential-equation}
\end{align}
 The Octave script \emph{zolotarev\_vlcek\_zahradnik\_test.m} shows that the
 $S_{p,q}\left(w,\kappa\right)$ function calculated by Table 4 of
 \emph{Vl\v{c}ek} and \emph{Zahradn\'{i}k} satisfies this differential equation. 
 

The Chebyshev polynomials of the second kind, $U_{m}\left(w\right)$, satisfy the
differential equation: 
\begin{align*}
  \left(1-w^{2}\right)\frac{d^{2}U_{m}\left(w\right)}{dw^{2}}
  -3w\frac{dU_{m}\left(w\right)}{dw}+m\left(m+2\right)U_{m}\left(w\right)&=0
\end{align*}
Differentiating $U_{m}\left(w\right)$ gives:
\begin{align*}
  \left(1-w^{2}\right)\frac{dU_{m}\left(w\right)}{dw}
  &=\left(m+2\right)wU_{m}\left(w\right)-\left(m+1\right)U_{m+1}\left(w\right)
\end{align*}

The Chebyshev polynomials of the second kind obey the following relations:
\begin{align*}
  2wU_{m}\left(w\right)&= U_{m+1}\left(w\right)+U_{m-1}\left(w\right)\\
  4w^{2}U_{m}\left(w\right)&= U_{m+2}\left(w\right)+2U_{m}\left(w\right)
                             +U_{m-2}\left(w\right)\\
  8w^{3}U_{m}\left(w\right)&= U_{m+3}\left(w\right)+3U_{m+1}\left(w\right)
                             +3U_{m-1}\left(w\right)+U_{m-3}\left(w\right)\\
  &\vdots
\end{align*}

The linear differential equation for $S_{p,q}\left(w,\kappa\right)$ can be
solved by substituting an expansion in Chebyshev polynomials of the second kind: 
\begin{align*}
  S_{p,q}\left(w\right)&=\sum^{n}_{m=0}a^{+}_{m}U_{m}\left(w\right)
\end{align*}
so that:
\begin{align}
  \begin{split}
    & -g_{2}\left(w\right)\sum^{n}_{m=0}
    m \left(m+2\right)a^{+}_{m}U_{m}\left(x\right)\quad\hdots \\
    & -g_{1}\left(w\right)\sum^{n}_{m=0}a^{+}_{m}
    \left[\left(m+2\right)wU_{m}\left(w\right)
      -\left(m+1\right)U_{m+1}\left(w\right)\right]\quad\hdots \\
    & +\left[\left(n+1\right)^2g_{0}\left(w\right)+wg_{1}\left(w\right)
      -g_{2}\left(w\right)\right]\sum^{n}_{m=0}a^{+}_{m}U_{m}\left(w\right) =0
  \end{split}
\label{eqn:Modified-Zolotarev-linear-ode-Chebyshev-2-substitution}
\end{align}
The Maxima script \emph{zolotarev\_vlcek\_zahradnik\_table\_4.max} calculates
the recurrence relations from
Equation~\ref{eqn:Modified-Zolotarev-linear-ode-Chebyshev-2-substitution}. The
results agree with Table 4 of \emph{Vl\v{c}ek} and
\emph{Zahradn\'{i}k}~\cite{VlcekZahradnik_AlmostEquirippleLowPassFIR} when
inserted into the Octave function \emph{zolotarev\_vlcek\_zahradnik.m}.

\begin{comment}
\paragraph{The \emph{second solution} of a second order linear homogeneous differential equation}
\emph{Morse} and \emph{Feshbach}~\cite[Section
 5.2]{MorseFeshbach_MethodsOfTheoreticalPhysics} discuss the existence of
solutions of second order, linear, homogeneous, differential equations of the
form: 
\begin{align}
  \mathcal{L}\left(z\right)
  &=\frac{d^{2}y}{dz^{2}}+p\left(z\right)\frac{dy}{dz}+q\left(z\right)y=0 
\label{eqn:Second-order-linear-homogeous-differential-equation}
\end{align} 
Alternatively:
\begin{align*} 
  \mathcal{L}\left(z\right)
  &=\frac{1}{f}\frac{d}{dz}\left(f\frac{dy}{dz}\right)+qy=0
\end{align*}
where:
\begin{align*}
  p&=\frac{d}{dz}\log{f}=\frac{1}{f}\frac{df}{dz}
\end{align*}
If $p\left(z\right)$ and $q\left(z\right)$ are continuous functions on an open
interval containing the initial conditions, $z_{0}$, then the differential
equation has a unique solution~\cite[Section
2.8]{Kreyszig_AdvancedEngineeringMathematics}. The differential equation has at
most two independent solutions. If solutions $y_{1}\left(z\right)$ and
$y_{2}\left(z\right)$ are independent then the \emph{Wronskian},
$\Delta\left(y_{1},y_{2}\right)=y_{1}y_{2}^{\prime}-y_{1}^{\prime}y_{2}$ will
be not be zero everywhere. Differentiating the Wronskian:
\begin{align*}
  \frac{d\Delta}{dz} &=y_{1}y_{2}^{\prime\prime}-y_{1}^{\prime\prime}y_{2}\\
                     &=-y_{1}\left(py^{\prime}_{2}+qy_{2}\right)
                       +y_{1}\left(py^{\prime}_{1}+qy_{1}\right) \\
                     &= -p\Delta \\
                     &= -\Delta\frac{d}{dz}\log{f}
\end{align*}
Integrating:
\begin{align*}
  \Delta\left(z\right)&=\Delta\left(z_{0}\right)e^{-\int^{z}_{z_{0}}pdz}\\
                      &=\Delta\left(z_{0}\right)\frac{f\left(z_{0}\right)}
                        {f\left(z\right)}
\end{align*}
where we assume $f\left(z_{0}\right)\ne{}0$. Since:
\begin{align*}
  \Delta\left(z\right)&=y_{1}y_{2}^{\prime}-y_{1}^{\prime}y_{2}\\
                      &=   y_{1}^{2}\left(z\right)\frac{d}{dz}
                        \frac{y_{2}\left(z\right)}{y_{1}\left(z\right)}
\end{align*}
the \emph{second solution} of the differential equation is:
\begin{align*}
  y_{2}\left(z\right)
  &=y_{1}\left(z\right)\int^{z}_{z_{0}}
    \frac{\Delta\left(z_{0}\right)}{y^{2}_{1}\left(z\right)}du\\
  &=\Delta\left(z_{0}\right)y_{1}\left(z\right)\int^{z}_{z_{0}}
    \frac{e^{-\int^{u}_{z_{0}}p\left(w\right)dw}}{y^{2}_{1}\left(u\right)}du\\
  &=\Delta\left(z_{0}\right)f\left(z_{0}\right)y_{1}\left(z\right)
    \int^{z}_{z_{0}}\frac{du}{f\left(u\right)y^{2}_{1}\left(u\right)}
\end{align*}

We can verify that $y_{2}\left(z\right)$ is a solution of
Equation~\ref{eqn:Second-order-linear-homogeous-differential-equation} by
setting $y=uv$:
\begin{align}
  v\mathcal{L}\left(u\right)+uv^{\prime\prime}+puv^{\prime}+2u^{\prime}v^{\prime}=0
  \label{eqn:Second-order-linear-homogeous-differential-equation-uv} 
\end{align}
Letting $u=y_{1}$, $\mathcal{L}\left(u\right)=0$, and
$v=\int\frac{\Delta}{y^{2}_{1}}dz$, then, since $\Delta^{\prime}+p\Delta=0$,
Equation~\ref{eqn:Second-order-linear-homogeous-differential-equation-uv}
follows. 

\paragraph{\emph{Reducing to quadratures} to find the second solution}
\emph{Morse} and \emph{Feshbach} describe the method of \emph{reducing to
quadratures}, by the use of an integrating factor. Given the identities:
\begin{align*}
y^{\prime\prime}v-v^{\prime\prime}y&=\frac{d}{dz}\left(y^{\prime}v-yv^{\prime}\right)\\
\frac{d}{dz}pyv&=vpy^{\prime}+y\left(vp\right)^{\prime}
\end{align*}
then, for any reasonable functions $y$ and $v$ of $z$:
\begin{align*}
  v\left[y^{\prime\prime}+py^{\prime}+q\right]
  -y\left[v^{\prime\prime}-\left(vp\right)^{\prime}+qv\right]=
  \frac{d}{dz}\left[vy^{\prime}-v^{\prime}y +vpy\right]
\end{align*}
or:
\begin{align*}
  v\mathcal{L}\left(y\right)-y\tilde{\mathcal{L}}\left(v\right)
  &=\frac{d}{dz}P\left(v,y\right)
\end{align*}
$\tilde{\mathcal{L}}\left(v\right)$ is said to be \emph{adjoint} to
$\mathcal{L}\left(y\right)$ and $P\left(z\right)$ is called the \emph{bilinear
  concommitant} function. If $v$ is a solution of
$\tilde{\mathcal{L}}\left(v\right)=0$, then the solution of
$\mathcal{L}\left(y\right)$ is equivalent to solving the first-order
differential equation:
\begin{align*}
  P&=vy\left[\frac{y^{\prime}}{y}-\frac{v^{\prime}}{v}+p\right]=\text{constant}
\end{align*}
Choosing the constant to be zero:
\begin{align*}
  \frac{dy}{y}&=\frac{dv}{v}-pdz
\end{align*}
and
\begin{align*}
  y_{1}&=ve^{-\int{}pdz}
\end{align*}
The second solution is:
\begin{align*}
  y_{2}&=ve^{-\int{}pdz}\int{}e^{\int{}pdz}\frac{dz}{v^{2}}
\end{align*}

\paragraph{Solution by series expansion about ordinary points}
The general solution of $\mathcal{L}\left(y\right)=0$ has its singularities at
the points where the function $p$ and $q$ have their poles. All other values of
$z$, where $p$ and $q$ are analytic functions, are called \emph{ordinary points}
for the equation. The points where $p$ or $q$ (or both) have singularities are
called \emph{singular points} of the equation. Suppose $z=a$ is an ordinary
point, then both $p$ and $q$ can be expanded in Taylor's series about $z=a$:
\begin{align*}
  p\left(z\right)
  &=p\left(a\right)+p^{\prime}\left(a\right)\left(z-a\right)+
    \frac{1}{2}p^{\prime\prime}\left(a\right)\left(z-a\right)^{2}+\quad\hdots\\
  q\left(z\right)
  &=q\left(a\right)+q^{\prime}\left(a\right)\left(z-a\right)+
    \frac{1}{2}q^{\prime\prime}\left(a\right)\left(z-a\right)^{2}+\quad\hdots
\end{align*}
If the solution, $y$, is also analytic, then it, too, can be expressed as a
series: 
\begin{align*}
  y\left(z\right)
  &=a_{0}+a_{1}\left(z-a\right)+a_{2}\left(z-a\right)^{2}+\quad\hdots
\end{align*}
Substituting into
Equation~\ref{eqn:Second-order-linear-homogeous-differential-equation}:
\begin{align*}
  \begin{split}
  0=&\phantom{+}2a_{2}+6a_{3}\left(z-a\right)+\hdots\\
  &+\left[p\left(a\right)+p^{\prime}\left(a\right)\left(z-a\right)+
    \hdots\quad\right]\left[a_{1}+2a_{2}\left(z-a\right)+\hdots\quad\right]
  +\quad\hdots\\
  &+\left[q\left(a\right)+q^{\prime}\left(a\right)\left(z-a\right)+
  \hdots\quad\right]\left[a_{0}+a_{1}\left(z-a\right)+\hdots\quad\right]
  +\quad\hdots
  \end{split}\\
   =&\left[2a_{2}+a_{1}p\left(a\right)+a_{0}q\left(a\right)\right]+
     \left[6a_{3}+2a_{2}p\left(a\right)+a_{1}p^{\prime}\left(a\right)+
     a_{0}q^{\prime}\left(a\right)+a_{1}q\left(a\right)\right]
     \left(z-a\right)+\quad\hdots
\end{align*}
$p\left(a\right)$ and $q\left(a\right)$ are known and $a_{1}$ and $a_{0}$ are
free parameters. The remaining $a_{2},a_{3},\hdots$ can be found by equating the
coefficients of $z-a$ to zero:
\begin{align*}
  a_{2}&=-\frac{a_{0}}{2}q\left(a\right)-\frac{a_{1}}{2}p\left(a\right)\\
  a_{3}&=\frac{a_{0}}{6}
         \left[q\left(a\right)p\left(a\right)-q^{\prime}\left(a\right)\right]+
         \frac{a_{1}}{6}
         \left[p^{2}\left(a\right)p\left(a\right)-p^{\prime}\left(a\right)
         -q\left(a\right)\right]\\
  a_{4}&=\quad\hdots
\end{align*}

The series expansion for $y$ can be written $y=a_{0}y_{1}+a_{1}y_{2}$, where:
\begin{align*}
  y_{1}&=1-\frac{1}{2}q\left(a\right)\left(z-a\right)^{2}+
         \frac{1}{6}\left[q\left(a\right)p\left(a\right)-
         q^{\prime}\left(a\right)\right]\left(z-a\right)^{3}\quad\hdots\\
  y_{2}&=\left(z-a\right)-\frac{1}{2}p\left(a\right)\left(z-a\right)^{2}+
         \frac{1}{6}\left[p^{2}\left(a\right)-p^{\prime}\left(a\right)-
         q\left(a\right)\right]\left(z-a\right)^{3}\quad\hdots
\end{align*}
If $p$ has a pole at $z=a$ but $q$ is analytic at $a$, then one solution is
analytic and the other has a singularity. 

Re-writing
Equation~\ref{eqn:Zolotarev-linear-second-order-differential-equation} in the
form of Equation~\ref{eqn:Second-order-linear-homogeous-differential-equation}:
\begin{align*}
  p\left(w\right)=&\frac{w_{q}-w_{p}}{w_{s}-w_{p}}\frac{1}{w-w_{p}}
     +\frac{w_{s}-w_{q}}{w_{s}-w_{p}}\frac{1}{w-w_{s}}
     -\frac{1}{w-w_{m}}
     +\frac{1}{2}\frac{1}{w+1}
     +\frac{1}{2}\frac{1}{w-1}\\
  q\left(w\right)=
  &-\frac{n^{2}\left(w_{s}-w_{m}\right)^{2}}
         {\left(w_{s}^{2}-1\right)\left(w_{s}-w_{p}\right)}\frac{1}{w-w_{s}}
   +\frac{n^{2}\left(w_{p}-w_{m}\right)^{2}}
         {\left(w_{p}^{2}-1\right)\left(w_{s}-w_{p}\right)}
    \frac{1}{w-w_{p}}\quad\hdots\\
  &+\frac{n^{2}\left(w_{m}+1\right)^{2}}{2\left(w_{p}+1\right)\left(w_{s}+1\right)}
    \frac{1}{w+1}
   -\frac{n^2\left(w_{m}-1\right)^{2}}{2\left(w_{p}-1\right)\left(w_{s}-1\right)}
    \frac{1}{w-1}
\end{align*}
The points $w=-1,w_{s},w_{m},w_{p},1$ are the \emph{singular} points of the
Zolotarev differential equation.
\end{comment}
\clearpage
\section{\label{app:FIR-tapped-cascaded}Design of FIR filters as a tapped cascade of sub-filters}
This chapter describes the design of FIR filters as a series cascade of
sub-filters. See, for example,
\emph{Saram\"{a}ki}~\cite{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters},
\emph{Shiung et al.}~\cite{Shiung_ImprovingFIRFiltersCascadeTechniques},
\emph{Smith}~\cite{Smith_DecompositionFIRCascadeSubFilters} or
\emph{Lim} and \emph{Liu}~\cite{LimLiu_CascadeFIRDiscreteCoefficients}. The
cascade connection permits an improved response and/or reduced complexity by
partition of the FIR filter or the use of fewer multipliers.

\emph{Saram\"{a}ki}~\cite{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters}
describes a the design of a tapped cascade of identical sub-filters by ``mapping
a prototype filter into a composite filter by means of a frequency
travsformation. The transformation determines the sub-filter, whereas the
prototype filter determines the tap coefficients.'' He claims that his proposed
approach results in an overall filter order that is approximately $30$\%
higher than the order, $L$, of the correponding mini-max direct-form FIR filter
but has approximately $\sqrt{2.6L}$
multipliers. \emph{Saram\"{a}ki}~\cite[Section
V]{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters} gives experimental
results for the effect of the number of sub-filters on performance measures such
as overall filter order, number of distinct multipliers, number of delay
elements, round-off error and coefficient sensitivity.  

\subsection{Transformations of linear-phase FIR filters}
The transfer function, $H\left(Z\right)$, of a linear-phase FIR filter with
impulse response $h_{n}$ of length $2N+1$, and symmetry $h_{N-n}=h_{n}$ can be
expressed in terms of the \emph{zero-phase} transfer function,
$\tilde{H}_{0}\left(Z\right)$, as: 
\begin{align*}
 \tilde{H}_{0}\left(Z\right)&=z^{-N}H\left(Z\right)\\
                            &=h_{N}+\sum^{N}_{n=1}h_{N-n}\left[Z^{n}+Z^{-n}\right]
\end{align*}

This can be re-written as:
\begin{align*}
  \tilde{H}_{0}\left(v\right) &=h_{N}+\sum^{N}_{n=1}2h_{N-n}T_{n}\left(v\right)\\
                              &=\sum^{N}_{n=0}a_{n}v^{n}
\end{align*}
where $v=\frac{1}{2}\left(Z+Z^{-1}\right)$ and $T_{n}\left(v\right)$ are the
Chebychev polynomials of the first kind, defined by
$T\left(\cos\theta\right)=\cos{}n\theta$. In the following, 
$\tilde{H}_{0}\left(v\right)$ is also called the \emph{prototype} filter. 

$\tilde{H}_{0}\left(v\right)$ can be converted to another transfer function by
substitution of a zero-phase sub-filter, $v=\bar{H}_{M}\left(z\right)$, where:
\begin{align*}
  H_{M}\left(z\right)&=\sum^{2M}_{r=0}\bar{h}_{r}z^{-r}\\
  \bar{H}_{M}\left(z\right)&=z^{M}H_{M}\left(z\right)\\
       &=\left[\bar{h}_{M}+
         \sum^{M}_{r=0}\bar{h}_{M-r}\left(z^{r}+z^{-r}\right)\right]\\
\end{align*}
The overall zero-phase transfer function is then:
\begin{align}
  \label{eqn:FIR-tapped-cascade-hM}
  H_{0}\left(z\right)&=\sum^{N}_{n=0}a_{n}\left[\bar{H}_{M}\left(z\right)\right]^{n}
\end{align}
This is an order $NM$ polynomial in $\frac{1}{2}\left(z+z^{-1}\right)$ with a
corresponding impulse response of length $2NM+1$.

\subsubsection{Implementations of transformed FIR filters}
\emph{Saram\"{a}ki}~\cite[Figure
1]{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters} shows several 
implementations of Equation~\ref{eqn:FIR-tapped-cascade-hM}. The 
first is~\cite[Figure 1a and Equation
6]{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters}: 
\begin{align}
\begin{split}
  H\left(z\right)
  &=z^{-NM}H_{0}\left(z\right)\\
  &=\sum^{N}_{n=0}a_{n}z^{-\left(N-n\right)M}\left[H_{M}\left(z\right)\right]^{n}
\end{split}
\label{eqn:FIR-tapped-cascade-sub-filters-tap-coefficients}
\end{align}

An alternative implementation is derived from the recursion relation for
Chebychev polynomials of the first kind:
\begin{align*}
  T_{0}\left(x\right)&=1\\
  T_{1}\left(x\right)&=x\\
  \vdots\\
  T_{n}\left(x\right)&=2xT_{n-1}\left(x\right)-T_{n-2}\left(x\right)
\end{align*}
Substitution gives~\cite[Figure 1c and Equation
9]{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters}:
\begin{align*}
   H\left(z\right)
  &=h_{N}z^{-NM}G_{0}\left(z\right)+
    \sum^{N}_{n=1}2h_{N-n}z^{-\left(N-n\right)M}G_{n}\left(z\right)\\
  G_{n}\left(z\right)&=z^{-nM}T_{n}\left(z^{M}H_{M}\left(z\right)\right)
\end{align*}
The transfer functions $G_{n}\left(z\right)$ can be implemented recursively as:
\begin{align*}
  G_{0}\left(z\right)&=1\\
  G_{1}\left(z\right)&=H_{M}\left(z\right)\\
  G_{n}\left(z\right)&=2H_{M}\left(z\right)G_{n-1}\left(z\right)-
                       z^{-2M}G_{n-2}\left(x\right)
\end{align*}
  
\subsubsection{Frequency domain relations}
Setting $Z=e^{\imath\Omega}$ and $z=e^{\imath\omega}$, the zero-phase frequency
responses of the prototype filter, $\tilde{H_{0}}\left(Z\right)$, and transformed
filter, $H_{0}\left(z\right)$, are:
\begin{align*}
  \tilde{H_{0}}\left(e^{\imath\Omega}\right)
  &=\sum^{N}_{n=0}a_{n}\left[\cos\Omega\right]^{n}\\
  H_{0}\left(e^{\imath\omega}\right)
  &=\sum^{N}_{n=0}a_{n}\left[P_{M}\left(\omega\right)\right]^{n}
\end{align*}
where the zero-phase frequency response of the
sub-filter, $H_{M}\left(z\right)$, is: 
\begin{align*}
  P_{M}\left(\omega\right)&=\bar{h}_{M}+\sum^{M}_{r=1}2\bar{h}_{M-r}\cos{}r\omega
\end{align*}
$\tilde{H_{0}}\left(e^{\imath\Omega}\right)$ and $H_{0}\left(e^{\imath\omega}\right)$
are related by:
\begin{align*}
  \Omega&=g_{M}\left(\omega\right)=\arccos{}P_{M}\left(\omega\right)  
\end{align*}
If $0\le{}g_{M}\left(\omega\right)\le\pi$ and $0\le\omega\le\pi$ this
transformation preserves the amplitude characteristics of 
$\tilde{H_{0}}\left(e^{\imath\Omega}\right)$ and distorts the frequency
axis~\cite[Figure 2]{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters}.
\subsection{Frequency-domain constraints on the prototype and sub-filter}
\subsubsection{Specifications Based on a Normalized Prototype Filter}
Let the specifications of $H_{0}\left(e^{\imath\omega}\right)$ in the pass-bands,
$I_{p}$, and stop-bands, $I_{s}$, be:
\begin{align}
  \begin{split}
  1-\delta_{p}\le H_{0}\left(e^{\imath\omega}\right) \le 1+\delta_{p}
  &\quad \omega\in I_{p} \\
    -\delta_{s}\le H_{0}\left(e^{\imath\omega}\right) \le \delta_{s}
  &\quad \omega\in I_{s}
  \end{split}
    \label{eqn:FIR-tapped-cascade-composite-specification}
\end{align}
The specifications for the prototype filter,
$\tilde{H_{0}}\left(e^{\imath\Omega}\right)$, are:
\begin{align}
  \begin{split}
  1-\delta_{p}\le \tilde{H}_{0}\left(e^{\imath\Omega}\right) \le 1+\delta_{p}
  &\quad 0\le\Omega\le\Omega_{p}\\
  -\delta_{s}\le \tilde{H}_{0}\left(e^{\imath\Omega}\right) \le \delta_{s}
  &\quad \Omega_{s}\le\Omega\le\pi
  \end{split}
    \label{eqn:FIR-tapped-cascade-prototype-specification}
\end{align}

The requirements for $g_{M}\left(\omega\right)$ are:
\begin{align*}
  0\le g_{M}\left(\omega\right) \le \Omega_{p}
  &\quad \text{for }\omega\in I_{p}\\
  \Omega_{s}\le g_{M}\left(\omega\right) \le \pi
  &\quad \text{for }\omega\in I_{s}
\end{align*}
The requirements for the zero-phase response of the sub-filter are:
\begin{align}
  \begin{split}
  \cos\Omega_{p}\le P_{M}\left(\omega\right) \le 1
  &\quad \text{for }\omega\in I_{p}\\
  -1\le P_{M}\left(\omega\right) \le\cos\Omega_{s}
  &\quad \text{for }\omega\in I_{s}
  \end{split}
    \label{eqn:FIR-tapped-cascade-subfilter-specification}
\end{align}
For fixed values of $\Omega_{p}$, and $\Omega_{s}$, both the prototype filter
and the sub-filter can be designed using minimax FIR design
software. \emph{Saram\"{a}ki} calls this type of specification ``normalised-prototype-filter-based''(NPFB).
\subsubsection{General specifications}
The same overall frequency response can be obtained by replacing
the sub-filter, $H_{M}\left(z\right)$, with:
\begin{align*}
  \hat{H}_{M}\left(z\right)&=AH_{M}\left(z\right)+Bz^{-M}
\end{align*}
which has the zero-phase response:
\begin{align}
  \hat{P}_{M}\left(\omega\right)&=AP_{M}\left(\omega\right)+B
\label{eqn:FIR-tapped-cascade-transformation-subfilter-zero-phase}
\end{align}
The overall zero-phase frequency response becomes:
\begin{align*}
  \hat{H}_{0}\left(e^{\imath\omega}\right)
  &=\sum^{N}_{n=0}\hat{a}_{n}\left[\hat{P}_{M}\left(\omega\right)\right]^{n}
\end{align*}
which corresponds to a frequency transformation:
\begin{align}
  x&=A\cos\Omega+B
\label{eqn:FIR-tapped-cascade-transformation-x-to-Omega}
\end{align}
The prototype frequency response becomes:
\begin{align*}
  \hat{H}_{0}\left(x\right)
  &=\tilde{H}_{0}\left(e^{\imath\omega}\right)\rvert_{x=A\cos\Omega+B}
    =\sum^{N}_{n=0}\hat{a}_{n}x^{n}
\end{align*}
The zero-phase frequency response is obtained from $\hat{H}_{0}\left(x\right)$ by
the substitution $x=\frac{1}{2}\left(z+z^{-1}\right)$. Likewise, the prototype
filter frequency response is obtained by the substitution $x=\cos\Omega$.
$H_{0}\left(e^{\imath\omega}\right)$ and $\hat{H}_{0}\left(x\right)$ are related
by $x=\hat{P}_{M}\left(\omega\right)$. If $A>0$, then
Equation~\ref{eqn:FIR-tapped-cascade-transformation-x-to-Omega} maps the
pass-band, $\left[0,\Omega_{p}\right]$, and the stop-band,
$\left[\Omega_{s},\pi\right]$, of the $\Omega$-plane onto the $x$-plane regions
$\left[x_{p1},x_{p2}\right]$ and $\left[x_{s1},x_{s2}\right]$, respectively, where:
\begin{align}
  \begin{split}
  x_{p1}&=\phantom{-}A\cos\Omega_{p}+B\\
  x_{p2}&=\phantom{-}A+B\\
  x_{s1}&=-A+B\\
  x_{s2}&=\phantom{-}A\cos\Omega_{s}+B
  \end{split}
          \label{eqn:FIR-tapped-cascade-x-plane-A-B}
\end{align}
If $\tilde{H}_{0}\left(e^{\imath\Omega}\right)$ satisfies
Equation~\ref{eqn:FIR-tapped-cascade-prototype-specification}, then
$1-\delta_{p}\le\tilde{H}_{0}\left(x\right)\le 1+\delta_{p}$ on
$\left[x_{p1},x_{p2}\right]$ and
$-\delta_{s}\le\tilde{H}_{0}\left(x\right)\le\delta_{s}$ on
$\left[x_{s1},x_{s2}\right]$~\cite[Figure
3]{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters}. Similarly, if $P_{M}$
satisfies Equation~\ref{eqn:FIR-tapped-cascade-subfilter-specification}, then
the new sub-filter frequency response $\hat{P}_{M}\left(\omega\right)$ is within
the limits $x_{p1}$ and $x_{p2}$ on $I_{p}$ and within the limits $x_{s1}$ and
$x_{s2}$ on $I_{s}$. The simultaneous specifications for the prototype filter
and sub-filter are~\cite[Figure
4]{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters}:
\begin{align}
  \begin{split}
  1-\delta_{p}\le\hat{H}_{0}\left(x\right)\le 1+\delta_{p}
  &\quad\text{for }x\in\left[x_{p1},x_{p2}\right]\\
  \delta_{s}\le\hat{H}_{0}\left(x\right)\le\delta_{s}
  &\quad\text{for }x\in\left[x_{s1},x_{s2}\right]\\
  x_{p1}\le\hat{P}_{M}\left(\omega\right)\le x_{p2}
  &\quad\text{for }\omega\in I_{p}\\
  x_{s1}\le\hat{P}_{M}\left(\omega\right)\le x_{s2}
  &\quad\text{for }\omega\in I_{s}
  \end{split}
   \label{eqn:FIR-tapped-cascade-general-specification}
\end{align}
The design of the sub-filter $\hat{P}_{M}\left(\omega\right)$ can be performed
by standard FIR filter design algorithms. The design of the prototype filter,
$\hat{H}_{0}\left(x\right)$ can be performed by using the transformation of
Equation~\ref{eqn:FIR-tapped-cascade-transformation-x-to-Omega} to map the
problem to the $\Omega$-plane, designing the filter to meet the specifications
of Equation~\ref{eqn:FIR-tapped-cascade-prototype-specification}, then mapping
the result back to the $x$-plane.
\subsubsection{Specifications based on the normalised sub-filter}
For the special case of $x_{p1}=1-\hat{\delta}_{p}$, $x_{p2}=1+\hat{\delta}_{p}$,
$x_{s1}=-\hat{\delta}_{s}$ and $x_{s2}=\hat{\delta}_{s}$, \emph{Saram\"{a}ki}
refers to the ``normalised-sub-filter-based'' (NFSB) specifications:
\begin{align}
  \begin{split}
    1-\delta_{p}\le\hat{H}_{0}\left(x\right)\le 1+\delta_{p}
  &\quad\text{for }x\in\left[1-\hat{\delta}_{p},1+\hat{\delta}_{p}\right]\\
  \delta_{s}\le\hat{H}_{0}\left(x\right)\le\delta_{s}
  &\quad\text{for }x\in\left[-\hat{\delta}_{s},\hat{\delta}_{s}\right]\\
  1-\hat{\delta}_{p}\le\hat{P}_{M}\left(\omega\right)\le 1+\hat{\delta}_{p}
  &\quad\text{for }\omega\in I_{p}\\
  -\hat{\delta}_{s}\le\hat{P}_{M}\left(\omega\right)\le \hat{\delta}_{s}
  &\quad\text{for }\omega\in I_{s}
  \end{split}
\label{eqn:FIR-tapped-cascade-NSFB-specifications}    
\end{align}
The NPFB and NSFB specifications are related by the transformation of 
Equation~\ref{eqn:FIR-tapped-cascade-transformation-x-to-Omega} and the
subsitution of Equation~\ref{eqn:FIR-tapped-cascade-x-plane-A-B} with
$x_{p2}-x_{s1}$ and $x_{p2}+x_{s1}$ giving:
\begin{align*}
  A&=\frac{1+\hat{\delta}_{p}+\hat{\delta}_{s}}{2}\\
  B&=\frac{1+\hat{\delta}_{p}-\hat{\delta}_{s}}{2}
\end{align*}

$\cos\Omega_{p}$ and $\cos\Omega_{s}$ are related to $\hat{\delta}_{p}$ and
$\hat{\delta}_{p}$ by the relative proportions:
\begin{align*}
  \frac{1-\cos\Omega_{p}}{2}&=\frac{2\hat{\delta}_{p}}
                  {1+\hat{\delta}_{p}+\hat{\delta}_{s}}\\
  \frac{1+\cos\Omega_{s}}{2}&=\frac{2\hat{\delta}_{s}}
                  {1+\hat{\delta}_{p}+\hat{\delta}_{s}}
\end{align*}
so that:
\begin{align*}
  \cos\Omega_{p}&=\frac{1+\hat{\delta}_{s}-3\hat{\delta}_{p}}
                  {1+\hat{\delta}_{p}+\hat{\delta}_{s}}\\
  \cos\Omega_{s}&=\frac{3\hat{\delta}_{s}-\hat{\delta}_{p}-1}
                  {1+\hat{\delta}_{p}+\hat{\delta}_{s}}\\
\end{align*}
Alternatively, given $\cos\Omega_{p}$ and $\cos\Omega_{s}$:
\begin{align*}
  \left[\begin{array}{cc}
          3+\cos\Omega_{p} & -1+\cos\Omega_{p}\\
          1+\cos\Omega_{s} & -3+\cos\Omega_{s}\end{array}\right]
  \left[\begin{array}{c}
          \hat{\delta}_{p} \\
          \hat{\delta}_{s}\end{array}\right] &=
  \left[\begin{array}{c}
          \phantom{-}1-\cos\Omega_{p} \\
          -1-\cos\Omega_{s}\end{array}\right]
\end{align*}

\subsection{Filter design}
\emph{Saram\"{a}ki}~\cite[Section
IV]{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters} considers four separate
design problems. 

\subsubsection{Approximation Problem I}
Given the composite filter specifications of
Equation~\ref{eqn:FIR-tapped-cascade-composite-specification} and $N$, the 
number of sub-filters, find the tap coefficients and the sub-filter such that the
sub-filter order $2M$ is minimised.

\emph{Saram\"{a}ki} suggests that this approximation problem may be solved by:
\begin{enumerate}
\item Given the prototype filter order, $2N$, find the minimum sub-filter order,
  $2M$, which is required by the overall filter to meet the specification of
  Equation~\ref{eqn:FIR-tapped-cascade-composite-specification}. This can be
  done by choosing the prototype filter pass-band edge, $\Omega_{p}$ as the
  unknown and, for each $\Omega_{p}$ finding the prototype filter with the
  minimum $\Omega_{s}$ that satisfies
  Equation~\ref{eqn:FIR-tapped-cascade-prototype-specification}. 
\item Find the coefficients of the sub-filter of the resulting order $2M$ and the
  coefficients of the prototype filter of the given order $2N$ to minimise the
  absolute value of the error function on $I_{p}\cup I_{s}$.
\end{enumerate}

Minimising $\Omega_{s}$ maximises the allowable variation of
$P_{M}\left(\omega\right)$ on $I_{s}$ and, consequently, the minimum required
sub-filter order to meet
Equation~\ref{eqn:FIR-tapped-cascade-prototype-specification}. The solution is
obtained by reducing $\Omega_{s}$ until the given ripple ratio
$\frac{\delta_{p}}{\delta_{s}}$ attains the specified maximum
value. Alternatively, the \emph{Selesnik-Burrus} modification to the
\emph{Hofstetter} low-pass filter design method, shown in
Section~\ref{sec:Selesnick-Burrus-modification-Hofstetter-low-pass}, finds 
the filter that minimises $\Omega_{s}$ for the given $\Omega_{p}$, $\delta_{p}$
and $\delta_{s}$.

\subsubsection{Approximation Problem II}
Given the composite filter specifications of
Equation~\ref{eqn:FIR-tapped-cascade-composite-specification} and the sub-filter
order $2M$, find the tap coefficients and the sub-filter such that $N$, the
number of sub-filters, is minimised.

\emph{Saram\"{a}ki} suggests this approximation problem may be solved by:
\begin{enumerate}
\item Given the NPFB specifications of
  Equations~\ref{eqn:FIR-tapped-cascade-subfilter-specification}
  and~\ref{eqn:FIR-tapped-cascade-prototype-specification}, increase $N$ until,
  at least at one extraripple solution of the prototype sub-filter, the given
  sub-filter order, $2M$, is large enough to meet the specification of
  Equation~\ref{eqn:FIR-tapped-cascade-subfilter-specification}. Denote by
  $\Omega^{\left(i\right)}_{p}$ and $\Omega^{\left(i\right)}_{s}$,
  $i=1,2,\hdots,r$, the pass-band and stop-band edge angles of those
  extra-ripple solutions at which the sub-filter meets the criteria. At this
  point, the minimum number of sub-filters is known and both the prototype filter
  and sub-filter orders $2N$ and $2M$ are known.
\item Given the NSFB specifications of
  Equation~\ref{eqn:FIR-tapped-cascade-NSFB-specifications}, consider the
  ripple ratio $k=\frac{\hat{\delta}_{p}}{\hat{\delta}_{s}}$ as a primary unknown.
  Find the value of $k$ near each of the points
  \begin{align*}
    k^{\left(i\right)}_{0}
    &=\frac{1-\cos\Omega^{\left(i\right)}_{p}}
      {1+\cos\Omega^{\left(i\right)}_{s}}\;,\quad i=1,\hdots,r
  \end{align*}
  that minimises the passband ripple, $\delta_{p}$, of $\hat{H}_{0}\left(x\right)$
  for the given ripple ratio $\frac{\delta_{p}}{\delta_{s}}$. Select the
  resulting value of $k^{\left(i\right)}_{0}$ giving the smallest pass-band ripple.
\end{enumerate}

\subsubsection{Prescribed Subfilter}
The sub-filter may be determined in advance, perhaps to reduce hardware
requirements. In this case, \emph{Saram\"{a}ki} suggests that the tap
coefficients be optimised to reduce the number of sub-filters, $N$, by:
\begin{enumerate}
\item Determine the maximum and minimum values of the sub-filter frequency
  response $\hat{P}_{M}\left(\omega\right)$ on $I_{p}$, denoted by $x_{p1}$ and
  $x_{p2}$. Similarly, determine the maximum and minimum
  values $x_{s1}$ and $x_{s2}$ on $I_{s}$.
\item Determine $\hat{H}_{0}\left(x\right)$ to satisfy the specifications of
  Equation~\ref{eqn:FIR-tapped-cascade-general-specification} with the minimum
  value of $N$:
  \begin{enumerate}
  \item Determine $A$ and $B$  and then $\Omega_{p}$ and $\Omega_{s}$ from
    Equation~\ref{eqn:FIR-tapped-cascade-x-plane-A-B}.
  \item Design the prototype filter of minimum even-order $2N$ to meet the
    specification of
    Equation~\ref{eqn:FIR-tapped-cascade-prototype-specification}. 
  \item Transform the resulting frequency response to the $x$-plane with
    Equation~\ref{eqn:FIR-tapped-cascade-transformation-x-to-Omega}.
    \end{enumerate}
\end{enumerate}

\subsubsection{Prescribed tap coefficients}
\emph{Saram\"{a}ki} suggests that if the prototype frequency response,
$\hat{H}_{0}\left(x\right)$ is given:
\begin{enumerate}
  \item Determine the regions $X_{p}$ and $X_{s}$ where
    $1-\delta_{p}\le\hat{H}_{0}\left(x\right)\le 1+\delta_{p}$ and
    $\delta_{s}\le\hat{H}_{0}\left(x\right)\le \delta_{s}$, respectively. Let
    $x_{p1}$ and $x_{p2}$ ($x_{s1}$ and $x_{s2}$) denote the maximum (minimum)
    values of $X_{p}$ ($X_{s}$). 
  \item Find the minimum even-order sub-filter to satisfy the specification of
    Equation~\ref{eqn:FIR-tapped-cascade-general-specification}.
\end{enumerate}
\clearpage
\subsection{Filter design examples}

\subsubsection{Approximation Problem I low-pass filter example}
\emph{Saram\"{a}ki}'s Approximation Problem I assumes that the prototype
filter order, $2N$, or number of sub-filters, $N$, is given. First, given the
prototype filter pass-band edge, 
$\Omega_{p}$, search for the minimum  prototype filter transition width,
$\Delta\Omega$, that satisfies the amplitude specifications, $\delta_{p}$ and
$\delta_{s}$. Next, search for the minimum sub-filter order, $2M$, that, given
$\Omega_{p}$ and $\Delta\Omega$, satisfies the overall filter frequency 
specifications $\omega\in I_{p}$ and $\omega\in I_{p}$. The Octave script
\emph{saramakiFIRcascade\_ApproxI\_lowpass\_test.m} attempts to reproduce the
design shown in \emph{Saram\"{a}ki}'s Figure 5~\cite[Figure 
5]{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters}\footnote{The plot
  shown in \emph{Saram\"{a}ki}'s Figure 6 has the same filter parameters except
  for $N=7$.}. In this script, both searches are made with the Octave function
\emph{selesnickFIRsymmetric\_lowpass}, an implementation of \emph{Hofstetter}'s 
low-pass filter design method with the \emph{Selesnik-Burrus} modification
shown in Section~\ref{sec:Selesnick-Burrus-modification-Hofstetter-low-pass}.
Table~\ref{tab:Saramaki-FIR-cascade-Approximation-I-example} shows the
specifications and derived parameters for this example of Approximation Problem
I. The minimum sub-filter order found is $M=23$ and the overall filter impulse
response length is $2NM+1=277$.
Figure~\ref{fig:Saramaki-FIR-cascade-Figure-5-transition-width-M} compares the
minimum sub-filter order, $2M$, and the minimum prototype filter transition
width, $\Delta\Omega$, found with \emph{selesnickFIRsymmetric\_lowpass}. 
Figure~\ref{fig:Saramaki-FIR-cascade-Approx-I-threeway-response}
is a plot, similar to that of \emph{Saram\"{a}ki}'s Figure 6, showing the
mapping of the prototype filter to the sub-filter and the overall response.
Figure~\ref{fig:Saramaki-FIR-cascade-Approx-I-response-detail} shows the
pass-band and stop-band of the filter.  

\input{saramakiFIRcascade_ApproxI_lowpass_test.tab}

The $N+1$ distinct coefficients of the prototype filter are:
\begin{small}
\verbatiminput{saramakiFIRcascade_ApproxI_lowpass_test_prototype_coef.m}
\end{small}

The $N+1$ tap coefficients, $a_{n}$ in
Equation~\ref{eqn:FIR-tapped-cascade-sub-filters-tap-coefficients}, are:
\begin{small}
\verbatiminput{saramakiFIRcascade_ApproxI_lowpass_test_tap_coef.m}
\end{small}

The $M+1$ distinct coefficients of the sub-filter are:
\begin{small}
\verbatiminput{saramakiFIRcascade_ApproxI_lowpass_test_subfilter_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{saramakiFIRcascade_ApproxI_lowpass_test_trans_width_M}}
\caption{Comparison of the minimum sub-filter order, $2M$, and the minimum
  prototype filter transition width, $\Delta\Omega$, found with
  \emph{selesnickFIRsymmetric\_lowpass}~\cite[Figure
  5]{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters}.}
\label{fig:Saramaki-FIR-cascade-Figure-5-transition-width-M}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{saramakiFIRcascade_ApproxI_lowpass_test_threeway_response}}
\caption{Approximation problem I solution mapping the prototype filter to the
  sub-filter and the overall response.} 
\label{fig:Saramaki-FIR-cascade-Approx-I-threeway-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{saramakiFIRcascade_ApproxI_lowpass_test_response_detail}}
\caption{Detailed view of the pass-band and stop-band response of the
  Approximation Problem I low-pass filter example.} 
\label{fig:Saramaki-FIR-cascade-Approx-I-response-detail}
\end{figure}
\clearpage
\subsubsection{Approximation Problem II multi-band filter example}
\emph{Saram\"{a}ki}'s Approximation Problem II assumes that the sub-filter
order, $2M$, is given. The Octave script
\emph{saramakiFIRcascade\_ApproxII\_multiband\_test.m} attempts to reproduce 
\emph{Saram\"{a}ki}'s multi-band example~\cite[Figure 17 and
Section VI]{Saramaki_FIRFiltersTappedCascadeIdenticalSubFilters}.
Table~\ref{tab:Saramaki-FIR-cascade-Approximation-II-example} shows the 
specifications and derived parameters for this example of Approximation Problem
II.

\input{saramakiFIRcascade_ApproxII_multiband_test.tab}

The script sets the ratio of stop-band to pass-band weights
$K=\frac{W_{s}}{W_{p}}$ and calls the Octave function
\emph{mcclellanFIRsymmetric} to design an order $2M=50$ multi-band sub-filter
that satisfies the frequency specifications, $\omega_{su1}$ etc., of the
filter pass-bands and stop-bands. If the sub-filter is feasible then the script
next searches for the minimum order $2N$ prototype filter that satisfies the
overall filter $\delta_{p}$ and $\delta_{s}$ amplitude response ripple
specifications. The script does this by calling the Octave function
\emph{selesnickFIRsymmetric\_lowpass} with fixed prototype filter pass-band edge
frequency, $\Omega_{p}$ at $1-\delta_{p}$, and increasing $N$ until the resulting
prototype filter stop-band edge frequency, $\Omega_{sN}$, satisfies the value of
$\Omega_{s}$ corresponding to the stop-band ripple of the sub-filter. A final
design is selected from the set of feasible designs by choosing the design with
the lowest RMS error in the amplitude response. The sub-filter order is given as
$2M=50$. The minimum prototype filter order found is $2N=12$ and the overall
filter impulse response length is $2NM+1=301$.  
Figure~\ref{fig:Saramaki-FIR-cascade-Approx-II-threeway-response}
is a plot, similar to that of \emph{Saram\"{a}ki}'s Figure 17, showing the
mapping of the prototype filter to the sub-filter and the overall response.
Figure~\ref{fig:Saramaki-FIR-cascade-Approx-II-response-detail} shows the
pass-band and stop-band of the filter.  

The $N+1$ distinct coefficients of the prototype filter are:
\begin{small}
\verbatiminput{saramakiFIRcascade_ApproxII_multiband_test_prototype_coef.m}
\end{small}

The $N+1$ tap coefficients, $a_{n}$ in
Equation~\ref{eqn:FIR-tapped-cascade-sub-filters-tap-coefficients}, are:
\begin{small}
\verbatiminput{saramakiFIRcascade_ApproxII_multiband_test_tap_coef.m}
\end{small}

The $M+1$ distinct coefficients of the sub-filter are:
\begin{small}
\verbatiminput{saramakiFIRcascade_ApproxII_multiband_test_subfilter_coef.m}
\end{small}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{saramakiFIRcascade_ApproxII_multiband_test_threeway_response}}
\caption{Approximation problem II solution mapping the prototype filter to the
  sub-filter and the overall response.} 
\label{fig:Saramaki-FIR-cascade-Approx-II-threeway-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{saramakiFIRcascade_ApproxII_multiband_test_response_detail}}
\caption{Detailed view of the pass-band and stop-band response of the
  Approximation Problem II multi-band filter example.} 
\label{fig:Saramaki-FIR-cascade-Approx-II-response-detail}
\end{figure}

\chapter{\label{app:Kalman-Yakubovic-Popov-Lemma-IIR-Filter-Design}Application of the \emph{Kalman-Yakubovi\u{c}-Popov} lemma to digital filter design}
\section{The continuous-time KYP lemma}
The \emph{Kalman-Yakubovi\u{c}-Popov} (KYP)
lemma~\cite{Kalman_LyapunovFunctions} is a fundamental result from the theory
of control systems. The continuous time KYP states that, for a state-variable
system with $A\in\mathbb{C}^{n\times{}n}$, $B\in\mathbb{C}^{n\times{}m}$ and
$\left(A,B\right)$ controllable, the frequency domain inequality(FDI): 
\begin{align}
  \label{eqn:KYPlemmaFDI}
  \left[\begin{array}{c}
  \left(\imath\omega{}I-A\right)^{-1}B \\
  I\end{array}\right]^{\mathconj}\Theta\left[\begin{array}{c}
  \left(\imath\omega{}I-A\right)^{-1}B \\
  I\end{array}\right]<0\quad\omega\in\mathbb{R}\cup\left\{\infty\right\} 
\end{align}
(where $M^{\mathconj}$ means complex conjugate transpose of $M$) holds
if-and-only-if the following linear matrix inequality(LMI) is feasible for a
solution $P\in{}\mathbb{H}^{n}$, the set of Hermitian $n\times{}n$ matrixes:  
\begin{align}
   \label{eqn:KYPlemmaLMI}
   \left[\begin{array}{cc}
          A & B \\
          I & 0\end{array}\right]^{\mathconj}
   \left[\begin{array}{cc}
          0 & P \\
          P & 0\end{array}\right]
   \left[\begin{array}{cc}
          A & B \\
          I & 0\end{array}\right]
          +\Theta\prec{}0
\end{align}
or:
\begin{align}
   \label{eqn:KYPlemmaLMI_expanded}
   \left[\begin{array}{cc}
          A^{\mathconj}P+PA & PB \\
          B^{\mathconj}P    & 0\end{array}\right]
          +\Theta\prec{}0
\end{align}
 
For the purposes of filter design, the lemma states that an infinite
dimension frequency response constraint is equivalent to a constraint on
the coefficients of the state variable description. If 
$H\left(\omega\right)=C\left(\imath\omega{}I-A\right)^{-1}B+D$ is the
transfer function of the filter, then we can write:
\begin{align}
\label{eqn:ContinuousKYPThetaCDPi}
  \Theta&=\left[\begin{array}{cc}
                  C & D \\
                  0 & I \end{array}\right]^{\mathconj}
                      \Pi
                  \left[\begin{array}{cc}
                  C & D \\
                  0 & I \end{array}\right]
\end{align}

For example, if
\begin{align}
\label{eqn:KYP_PI_stop_band}
\Pi=\left[\begin{array}{cc} I & 0 \\
0 &-\varepsilon^{2}I\end{array}\right]
\end{align}
then the corresponding frequency domain constraint is
$\mathabs{H\left(\omega\right)}^{2}\le\varepsilon^{2}$ for all $\omega$. If the
state-space description, $\left[\begin{array}{cc}
    A & B \\
    C & D\end{array}\right]$, is known, then a feasible solution of
Equation~\ref{eqn:KYPlemmaLMI_expanded} with this $\Pi$ also shows
$\varepsilon$.
Similarly, if 
\begin{align}
\Pi=\left[\begin{array}{cc} 0 & -I \\
-I &2\varepsilon I\end{array}\right]
\end{align}
and a feasible solution for $\varepsilon$ exists, then
$\frac{1}{2}\left[H\left(\omega\right)+H\left(\omega\right)^{\mathconj}\right]
\le \varepsilon$ for all $\omega$\footnote{For
  example, see the Octave script \emph{yalmip\_kyp\_epsilon\_test.m}~.}.

\emph{Iwasaki}, \emph{Meinsma} and
\emph{Fu}~\cite{Iwasaki_GeneralizedSProcFiniteFreqKYP} extend the continuous
time KYP lemma to restricted frequency regions. In addition, the KYP lemma has
been generalised to discrete time state variable systems  over restricted
frequency regions~\cite{Pipeleers_GeneralisedKYPRealData,
Iwasaki_GeneralizedKYPFrequencyDomainInequalitiesReport,
Iwasaki_GeneralizedKYPFrequencyDomainInequalities,
Davidson_LMISpectralConstraints,
Iwasaki_GeneralizedSProcFiniteFreqKYP,
Pipeleers_GeneralizingKYPMultipleFrequencyIntervals}.
In the remainder of this section I follow the discussion of a finite-frequency
continuous-time KYP lemma described by \emph{Iwasaki}, \emph{Meinsma} and
\emph{Minyue Fu}~\cite{Iwasaki_GeneralizedSProcFiniteFreqKYP}.

\subsection{A generalised S-procedure}
The \emph{S-procedure}\footnote{Also see Section~\ref{app:Jonsson-S-procedure}}
is the basis of proofs of the KYP lemma. \emph{Iwasaki}, \emph{Meinsma} and
\emph{Minyue Fu}~\cite[Section 1]{Iwasaki_GeneralizedSProcFiniteFreqKYP}
first define a set, $\mathcal{G}$, of vectors, $\zeta$, and matrixes, $S_{i}$,
such that:
\begin{align*}
\mathcal{G}\coloneq\left\{\zeta\in\mathbb{C}^{n}:
\zeta\ne{}0,\zeta^{\mathconj}S_{k}\zeta\le 0, \forall k=1,\hdots,m\right\}
\end{align*}
Then, assuming $\Theta,S_{k}\in{}\mathbb{H}^{n}$, according to \emph{Iwasaki et
al.}, the ``classical'' version of the S-procedure considers the following
statements:  
\begin{align}
\zeta^{\dagger}\Theta\zeta<0,\; \forall \zeta\in \mathcal{G}
\label{eqn:ClassicSProcedure_constrained}\\
\exists\tau_{k}\in\mathbb{R}\text{ such that } \tau_{k}>0\text{ and }
\Theta{} \prec \sum^{m}_{k=1}\tau_{k}S_{k}
\label{eqn:ClassicSProcedure_unconstrained} 
\end{align}
The S-procedure replaces the multiple constraints of
Equation~\ref{eqn:ClassicSProcedure_constrained} with the single linear
constraint of Equation~\ref{eqn:ClassicSProcedure_unconstrained}. The latter
condition is easier to satisfy as it is a search for the scalar multipliers,
$\tau_{k}$, satisfying convex constraints. \emph{Iwasaki et al.} comment that
``In general, the S-procedure on $\mathbb{C}^{n}$ is conservative,
i.e. Equation~\ref{eqn:ClassicSProcedure_unconstrained} is only sufficient for
Equation~\ref{eqn:ClassicSProcedure_constrained} and may not be
necessary``\footnote{In this context, the logical statement $S\rightarrow N$
means that N is \emph{necessary} for S and that S is \emph{sufficient} for N.}.

\emph{Iwasaki et al.}~\cite[Equation
4]{Iwasaki_GeneralizedSProcFiniteFreqKYP} generalise the S-procedure by
re-defining $\mathcal{G}$:
\begin{align*}
\mathcal{G}\coloneq\left\{\zeta\in\mathbb{C}^{n}:
\zeta\ne{}0,\zeta^{\mathconj}S_{k}\zeta\le 0, \forall S\in\mathcal{S}\right\}
\end{align*}
where:
\begin{align*}
\mathcal{S}\coloneq\left\{ \sum^{m}_{k=1}\tau_{k}S_{k} :
\tau_{k}>0, \forall k=1,\hdots,m \right\}
\end{align*}

In the following, \emph{Iwasaki et al.} show the conditions on $\mathcal{S}$
for which the S-procedure is ``exact'' or ``non-conservative'' (i.e.:
Equation~\ref{eqn:ClassicSProcedure_unconstrained} is necessary and sufficient
for Equation~\ref{eqn:ClassicSProcedure_constrained}).

First, \emph{Iwasaki et al.} define \emph{loss-less sets}~\cite[Section
2]{Iwasaki_GeneralizedSProcFiniteFreqKYP}:
\begin{framed}
Definition 1: $\mathcal{S}\in\mathbb{H}^{n\times{}n}$ is said to be
\emph{loss-less} if:
\begin{enumerate}
\item $\mathcal{S}$ is convex
\item $S\in\mathcal{S}\Rightarrow\tau S \in \mathcal{S}, \forall\tau>0$
\item For each non-zero matrix $H\in\mathbb{C}^{n\times n}$ such that
\begin{align*}
H=H^{\mathconj}\succeq 0 , \mathtrace \left(SH\right)\le 0, \forall S\in\mathcal{S}
\end{align*}
there exist vectors $\zeta_{k}\in\mathbb{C}^{n}, k=1,\hdots,r$ such that
\begin{align*}
H=\sum^{r}_{k=1}\zeta_{k}\zeta^{\mathconj}_{k} \text{  and  } 
\zeta^{\mathconj}_{k}S\zeta_{k}\le 0, \forall S\in\mathcal{S}
\end{align*}
where $r$ is the \emph{rank} of $H$.
\end{enumerate}
\end{framed}
and give an alternative version of the separating hyperplane
theorem\footnote{See Section~\ref{sec:Separating-hyperplane-theorem}.}:
\begin{framed}
Lemma 1 : Let $\mathcal{X}$ be a convex subset of $\mathbb{C}^{m}$, and
$F\; : \; \mathcal{X}\rightarrow\mathbb{C}^{n\times n}$ be a Hermitian-valued affine
function, then the following statements are equivalent:
\begin{enumerate}
\item The set $\left\{x : x\in \mathcal{X}, F\left(x\right)<0\right\}$ is empty.
\item $\exists$ non-zero $H=H^{\mathconj}\succeq 0$ such that
$\mathtrace\left(F\left(x\right)H\right)\ge 0, \forall x\in \mathcal{X}$.
\end{enumerate}
\end{framed}

\emph{Iwasaki et al.}~\cite[Theorem 1]{Iwasaki_GeneralizedSProcFiniteFreqKYP}
now prove that their generalised S-procedure is exact if $\mathcal{S}$ is
loss-less:
\begin{framed}
Theorem 1 (Generalised S-procedure) : Let a Hermitian matrix, $\Theta$, and a
subset, $\mathcal{S}$, of the Hermitian matrixes be given. Suppose $\mathcal{S}$
is loss-less, then the following statements are equivalent:
\begin{enumerate}
\item $\zeta^{\mathconj}\Theta\zeta < 0, \forall \zeta\in
\mathcal{G}\coloneq\left\{\zeta\in\mathbb{C}^{n}:
\zeta\ne{}0, \zeta^{\mathconj}S_{k}\zeta\le 0, \forall S\in\mathcal{S}\right\}$.
\item There exists $S\in\mathcal{S}$ such that $\Theta\prec S$.
\end{enumerate}

\emph{Proof:}~ The first statement follows from the second. The converse is
proved by contradiction. Assume that there is no $S\in\mathcal{S}$ such that
$\Theta\prec S$. Then, from Lemma 1, there is a non-zero matrix, $H$, such that:
\begin{align*}
H=H^{\mathconj}\succeq 0, \quad \mathtrace\left(\left(\Theta-S\right)H\right)\ge
0,\; \forall S\in\mathcal{S}
\end{align*}
Since $\mathcal{S}$ is lossless, from the second property of Definition 1:
\begin{align*}
\mathtrace\left(SH\right)\le 0, \forall S\in\mathcal{S},
\mathtrace\left(\Theta H\right)\ge 0 
\end{align*}
The first condition implies the existence of vectors $\zeta_{k}$ so that:
\begin{align*}
\mathtrace\left(\Theta H\right)=
\sum^{r}_{k=1}\zeta^{\mathconj}_{k}\Theta\zeta_{k}\ge 0 
\end{align*}
Hence there exists $\zeta_{k}$ so that $\zeta_{k}^{\mathconj}\Theta\zeta\ge 0$.
Noting that $\zeta_{k}\in\mathcal{G}$, the first statement does not hold.
\end{framed}

\subsection{A finite-frequency continuous-time KYP lemma}
\emph{Iwasaki et al.}~\cite[Section
3]{Iwasaki_GeneralizedSProcFiniteFreqKYP} now define the set $\mathcal{G}$ as:
\begin{align*}
\mathcal{G}\coloneq\left\{\left[\begin{array}{c}
f \\
g
\end{array}\right]\in\mathbb{C}^{2n} :
f=\imath\omega g, \omega\in\mathbb{R}, \mathabs{\omega}\le\omega_{0}\right\}
\end{align*}
where $\omega_{0}$ is a given real scalar. \emph{Iwasaki et al.}~\cite[Lemma
2]{Iwasaki_GeneralizedSProcFiniteFreqKYP} prove the following lemma\footnote{From
\emph{Meinsma et al.}~\cite{Meinsma_DualFormulationLosslessDGScaling}:

Lemma III.4 (Three Little Lemmas) : Let $f$, $g$ be two column vectors of the
same dimension.
\begin{enumerate}
\item $\left(f-g\right)\left(f-g\right)^{\mathconj}$ is Hermitian and
$\succeq 0$ if-and-only-if $g=\delta f$ for some $\delta\in\left[-1,1\right]$.
\item The Hermitian part of $\left(f-g\right)\left(f-g\right)^{\mathconj}$ is
$\succeq 0$ if-and-only-if $g=\delta f$ for some $\delta\in\mathbb{C}$ with
$\mathabs{\delta}\le 1$.
\item $\Re\left[\mathtrace\left(f-g\right)\left(f-g\right)^{\mathconj}\right]=
\mathnorm{f}_{2}-\mathnorm{g}_{2}$. Hence
$\Re\left[\mathtrace\left(f-g\right)\left(f-g\right)^{\mathconj}\right]\ge 0$
if-and-only-if $g=\Delta f$ for some matrix $\Delta$ with $\mathnorm{\Delta}\le
1$. 
\end{enumerate}}:
\begin{framed}
Lemma 2 : Let a real scalar $\omega_{0}$ and complex vectors $f$ and $g$ be
given, then the following statements are equivalent:
\begin{enumerate}
\item There exists a real scalar $\omega$ such that 
$f=\imath\omega g,\mathabs{w}\le\omega_{0}$.
\item $\left[\begin{array}{c}
f \\
g \end{array}\right]^{\mathconj}\left[\begin{array}{cc}
Q & P\\
P & -\omega_{0}^{2}Q \end{array}\right]\left[\begin{array}{c}
f \\
g \end{array}\right]\le 0, \forall P,Q\in\mathbb{H} \text{ and } Q\succ 0$
\end{enumerate}

\emph{Proof:}~ Suppose the first statement holds. Then:
\begin{align*}
\left[\begin{array}{c}
f \\
g \end{array}\right]^{\mathconj}\left[\begin{array}{cc}
Q & P\\
P & -\omega^{2}Q \end{array}\right]\left[\begin{array}{c}
f \\
g \end{array}\right]&=
\left(\omega^{2}-\omega_{0}^{2}\right)\left(g^{\mathconj}Qg\right)\le 0
\end{align*}
so that the second statement holds. Conversely, if the second statement holds,
then:
\begin{align*}
\mathtrace\left(ff^{\mathconj}-\omega^{2}_{0}gg^{\mathconj}\right)Q +
\mathtrace\left(gf^{\mathconj}+fg^{\mathconj}\right)P \le 0
\end{align*}
holds for all $P=P^{\mathconj}$ and $Q=Q^{\mathconj}\succ 0$. This implies
\begin{align*}
ff^{\mathconj}-\omega^{2}_{0}gg^{\mathconj}\preceq 0 \\
gf^{\mathconj}+fg^{\mathconj}\le 0
\end{align*}
\emph{Iwasaki et al.} claim that the first statement now follows from
Lemma III.4 of \emph{Meinsma et
al.}~\cite{Meinsma_DualFormulationLosslessDGScaling}.
\end{framed}

Next, \emph{Iwasaki et al.}~\cite[Lemma
3,Section 5]{Iwasaki_GeneralizedSProcFiniteFreqKYP} prove the following lemma:
\begin{framed}
Lemma 3 : Let a scalar $\omega_{0}>0$ and a matrix $F\in\mathbb{C}^{2n\times k}$
be given. Define a subset of Hermitian matrixes by:
\begin{align*}
\mathcal{S}\coloneq\left\{F^{\mathconj}\left[\begin{array}{cc}
Q & P \\
P & -\omega^{2}_{0}Q\end{array}\right]F : P=P^{\mathconj},
Q=Q^{\mathconj}\succ 0 \right\}
\end{align*}
Then the set $\mathcal{S}$ is loss-less.
\end{framed}
\emph{Iwasaki et al.}~\cite[Theorem 2]{Iwasaki_GeneralizedSProcFiniteFreqKYP}
now state a KYP lemma generalised to a finite frequency domain:
\begin{framed}
Theorem 2 : Let a scalar $\omega_{0}>0$ and matrixes $A\in\mathbb{C}^{n\times n}$
and $B\in\mathbb{C}^{n\times m}$ and a Hermitian matrix
$\Theta\in\mathbb{C}^{\left(n+m\right)\times\left(n+m\right)}$ be given. Assume
that
$A$ has no eigenvalues on the imaginary axis, then the following statements are
equivalent:
\begin{enumerate}
\item This finite frequency condition holds:
\begin{align*}
\left[\begin{array}{c}
\left(\imath\omega I -A\right)^{-1}B \\
I\end{array}\right]^{\mathconj}\Theta\left[\begin{array}{c}
\left(\imath\omega I -A\right)^{-1}B \\
I\end{array}\right]<0, \forall\mathabs{\omega}\le\omega_{0}
\end{align*}
\item There exist Hermitian matrixes $P,Q\in\mathbb{C}^{n\times n}$ such that
$Q\succ 0$ and
\begin{align*}
\left[\begin{array}{cc}
A & B \\
I & 0 \end{array}\right]^{\mathconj} \left[\begin{array}{cc}
-Q & P \\
\phantom{-}P & \omega^{2}_{0}Q\end{array}\right]\left[\begin{array}{cc}
A & B \\
I & 0 \end{array}\right]+\Theta \prec 0
\end{align*}
\end{enumerate}
If matrixes $A$, $B$ and $\Theta$ are real, then the equivalence still holds when
restricting $P$ and $Q$ to be real.

\emph{Proof:}~ The first statement holds if-and-only-if
\begin{align*}
\zeta^{\mathconj}\Theta\zeta < 0, \forall\zeta\in\mathcal{G}
\end{align*}
where
\begin{align*}
\mathcal{G}\coloneq\left\{\left[\begin{array}{c}
x \\
u\end{array}\right]\in\mathbb{C}^{n+m} : u\ne 0,
\imath\omega x = Ax+Bu\text{ for some }\omega\in\mathbb{R},
\mathabs{\omega}\le\omega_{0}\right\}
\end{align*}
Defining
\begin{align*}
\left[\begin{array}{c}
f \\
g\end{array}\right]\coloneq F\left[ \begin{array}{c}
x \\
u\end{array}\right], F\coloneq\left[\begin{array}{cc}
A & B \\
I & 0 \end{array} \right]
\end{align*}
and applying Lemma 2, the set $\mathcal{G}$ can be characterised as
\begin{align*}
\mathcal{G}=\left\{\zeta\ne 0 : \zeta^{\mathconj}S\zeta\le 0, \forall
S\in\mathcal{S} \right\} 
\end{align*}
where
\begin{align*}
\mathcal{S}\coloneq\left\{F^{\mathconj}\left[\begin{array}{cc}
Q & P \\
P & -\omega^{2}_{0}Q\end{array}\right]F : P=P^{\mathconj},
Q=Q^{\mathconj}\succ 0\right\} 
\end{align*}
From Lemma 3, the set $\mathcal{S}$ is loss-less and hence the S-procedure in
Theorem 1 yields statements $\left(1\right)\Leftrightarrow\left(2\right)$.

To prove the real case result, assume that there exist complex Hermitian
matrixes $P$ and $Q$ satisfying the first statement. Then:
\begin{align*}
\left(M+\imath N\right) = \left(M+\imath N\right)^{\mathconj} \succ 0
\Leftrightarrow \left[\begin{array}{cc}
M & -N \\
N &  M\end{array}\right]=\left[\begin{array}{cc}
M & -N \\
N &  M\end{array}\right]^{\top}\succ 0
\end{align*}
holds for any real square matrixes $M$ and $N$, one can show that the real parts
of $P$ and $Q$ also satisfy the statement.
\end{framed}

\emph{Iwasaki et al.}~\cite{Iwasaki_GeneralizedSProcFiniteFreqKYP} prove two
corollaries to Theorem 2. The first shows how to extend Theorem 2 to an
arbitrary finite frequency interval by a change of variables. For a bandpass
response $\omega_{1}\le\omega\le\omega_{2}$ define a new variable $\hat{\omega}$,
such that $\mathabs{\hat{\omega}}\le\omega_{m}$ where:
\begin{align*}
\omega_{m}&=\frac{\omega_{2}-\omega_{1}}{2}\\
\omega_{c}&=\frac{\omega_{1}+\omega_{2}}{2} \\
\hat{\omega}&=\omega-\omega_{c}\\
\imath\omega I &= \imath \hat{\omega}I - \hat{A} \\
\hat{A} & =A-\imath\omega_{c}I
\end{align*}
The LMI becomes:
\begin{align*}
\left[\begin{array}{cc}
A & B \\
I & 0 \end{array}\right]^{\mathconj} \left[\begin{array}{cc}
-Q & P+\imath\omega_{c}Q\\
P-\imath\omega_{c}Q &  -\omega_{1}\omega_{2}Q\end{array}\right]
\left[\begin{array}{cc}
A & B \\
I & 0 \end{array}\right]+\Theta \prec 0
\end{align*}
This can be seen by multiplying out the LMI:
\begin{align*}
\begin{split}
&\left[\begin{array}{cc}
\hat{A} & B \\
I & 0 \end{array}\right]^{\mathconj} \left[\begin{array}{cc}
-Q & P\\
\phantom{-}P&  \omega^{2}_{m}Q\end{array}\right]
\left[\begin{array}{cc}
\hat{A} & B \\
I & 0 \end{array}\right] = ...\\
&\left[\begin{array}{cc}
-\hat{A}^{\mathconj}Q\hat{A}+P\hat{A}+\hat{A}^{\mathconj}P+\omega^{2}_{m}Q &
-\hat{A}^{\mathconj}QB+PB \\
-B^{\mathconj}Q\hat{A}+B^{\mathconj}P & -B^{\mathconj}QB \end{array}\right] = ...\\
&\left[\begin{array}{cc}
-\left(A-\imath\omega_{c}I\right)^{\mathconj}Q\left(A-\imath\omega_{c}I\right)
+P\left(A-\imath\omega_{c}I\right)+\left(A-\imath\omega_{c}I\right)^{\mathconj}P
+\omega^{2}_{m}Q & -\left(A-\imath\omega_{c}I\right)^{\mathconj}QB+PB \\
-B^{\mathconj}Q\left(A-\imath\omega_{c}I\right)+B^{\mathconj}P &
-B^{\mathconj}QB \end{array}\right] = ...\\
&\left[\begin{array}{cc}
-A^{\mathconj}QA + A^{\mathconj}\left(P+\imath\omega_{c}Q\right)
+\left(P-\imath\omega_{c}Q\right)A+
\left(\omega^{2}_{m}-\omega^{2}_{c}\right)Q &
-A^{\mathconj}QB+\left(P-\imath\omega_{c}Q\right)B \\
-B^{\mathconj}QA+B^{\mathconj}\left(P+\imath\omega_{c}Q\right)
&-B^{\mathconj}QB\end{array}\right]
\end{split}
\end{align*}

The second corollary shows how to express the Linear Matrix Inequality (LMI) of
Theorem 2 in terms of real matrixes that represent the real and imaginary parts
of $P$ and $Q$. 

\clearpage
\section{\emph{Iwasaki} and \emph{Hara}'s generalised KYP lemma for
discrete-time systems}
\emph{Iwasaki} and \emph{Hara}~\cite{Iwasaki_KYPlemmaFrequencyInequalities}
prove a generalised KYP lemma for discrete-time systems by first making a
frequency transformation in the complex plane from the unit-circle to the
imaginary axis and then applying the continuous-time KYP lemma.

\emph{Cheng}~\cite{ChengYiping_ProofDiscreteTimeKYPusingSDPduality} shows
proofs of the discrete- and continuous-time KYP lemmas by the properties of the
dual problems.

\subsection{Frequency transformations in the complex plane}
\emph{Iwasaki} and \emph{Hara}~\cite[Section
2.1]{Iwasaki_KYPlemmaFrequencyInequalities} review transformations of frequency
variables in the complex plane.

The quadratic function
$\sigma~:~\mathbb{C}\times\mathbb{H}^{2\times{}2}\rightarrow\mathbb{R}$ is
defined as:
\begin{align*}
\sigma\left(\lambda,\Pi\right)\coloneq\left[\begin{array}{c}
\lambda \\
I\end{array}\right]^{\mathconj}\Pi\left[\begin{array}{c}
\lambda \\
I\end{array}\right]
\end{align*}

Note that
\begin{align*}
\sigma\left(s,\left[\begin{array}{cc}
0 & 1 \\
1 & 0 \end{array}\right]\right)=0
\end{align*}
implies $s^{\ast}+s=0$ or $s\in\imath\mathbb{R}$. Similarly,
\begin{align*}
\sigma\left(z,\left[\begin{array}{cc}
1 & 0 \\
0 & -1 \end{array}\right]\right)=0
\end{align*}
implies $z^{\ast}z=1$ or $z=e^{\imath\phi}$.


A frequency variable transformation
$\mathcal{T}~:~\mathbb{C}\rightarrow\mathbb{C}$ is defined by
\begin{align*}
\mathcal{T}\left(s\right)&\coloneq\frac{b-ds}{cs-a}\\
M&\coloneq\left[\begin{array}{cc}
a & b \\
c & d \end{array}\right]
\end{align*}
where $M\in\mathbb{C}^{2\times{}2}$ and $s\in\mathbb{C}$. The following lemma
shows how $\mathcal{T}$ transforms a region of the complex plane:
\begin{framed}
  \emph{Lemma 1}~\cite[Lemma 1]{Iwasaki_KYPlemmaFrequencyInequalities}:
  Given $\Omega,\;\Sigma\in\mathbb{H}^{2\times{}2}$ and
  $M\in\mathbb{C}^{2\times{}2}$, define:
\begin{align*}
\boldsymbol{S}&\coloneq\left\{s\in\mathbb{C}\;:\;\sigma\left(s,\Omega\right)=0,
\sigma\left(s,\Sigma\right)\ge 0\right\} \\
\boldsymbol{\Lambda}&\coloneq\left\{\lambda\in\mathbb{C}\;:\;
\sigma\left(\lambda,M^{\mathconj}\Omega{}M\right)=0,
\sigma\left(\lambda,M^{\mathconj}\Sigma{}M\right)\ge 0\right\}
\end{align*}
then:
\begin{align*}
\left\{\lambda\in\mathbb{C}\;:\:
\lambda\in\boldsymbol{\Lambda},c\lambda+d\ne{}0\right\}=
\left\{\mathcal{T}\left(s\right)\in\mathbb{C}\;:\:
s\in\boldsymbol{S},cs\ne a \right\}
\end{align*}
\end{framed}
The lemma is proved for arbitrary $\Omega$ by multiplying out
$\sigma\left(\lambda, M^{\mathconj}\Omega M\right)$. For the right-hand side:
\begin{align*}
M\left[\begin{array}{c}
\lambda \\
1 \end{array}\right] =
\left[\begin{array}{c}
a\lambda +b\\
c\lambda +d\end{array}\right]
\end{align*}

Dividing by $c\lambda+d$ and solving for $s$ gives
$\lambda=\mathcal{T}\left(s\right)$.

The following lemma gives a state space formula for systems obtained
through the frequency transformation $\mathcal{T}$ of continuous-time systems:
\begin{framed}
  \emph{Lemma 2}~\cite[Lemma 2]{Iwasaki_KYPlemmaFrequencyInequalities}:
  Let $A\in\mathbb{C}^{n\times{}n}$, $B\in\mathbb{C}^{n\times{}m}$,
  $M\in\mathbb{C}^{2\times{}2}$ be given. Suppose $M$ is non-singular and $A$
  has no eigenvalues, $\lambda$, such that:
\begin{align*}  
  \sigma\left(\lambda,M^{\mathconj}\left[\begin{array}{cc}
  0 & 1 \\
  1 & 0 \end{array}\right]M\right)=0
\end{align*}
then $\det\left(dI+cA\right)\ne 0$ and the following matrixes are well
defined:
\begin{align*}  
\left[\begin{array}{cc}
\mathcal{A} & \mathcal{B} \\
\mathcal{C} & \mathcal{D}\end{array}\right]&\coloneq\left[\begin{array}{cc}
\left(bI+aA\right)\Gamma & \left(ad-bc\right)\Gamma B \\
\Gamma & -c\Gamma B \end{array}\right] \\
\Gamma &\coloneq\left(dI+cA\right)^{-1}
\end{align*}
In this case, we have:
\begin{align*}
\det\left(sI-\mathcal{A}\right)\ne 0, \quad  \text{ for all }
s\in\imath\mathbb{R} \\
\left(A,B\right) \text{ controllable } \Rightarrow
\left(\mathcal{A},\mathcal{B}\right) \text{ controllable }
\end{align*}
Moreover, for any $s\in\imath\mathbb{R}$ such that $cs\ne a$, both
$\mathcal{T}\left(s\right)$ and $\left(\mathcal{T}\left(s\right)I-A\right)^{-1}$
exist and 
\begin{align*}
\left(\mathcal{T}\left(s\right)I-A\right)^{-1}B=
\mathcal{C}\left(sI-\mathcal{A}\right)^{-1}\mathcal{B}+\mathcal{D}
\end{align*}
\end{framed}

The final result can be justified as follows. Firstly:
\begin{align*}
\left(\mathcal{T}\left(s\right)I-A\right)
&=\left[\frac{b-ds}{cs-a}I-A\right] \\
&=\frac{1}{cs-a}\left[\left(b-ds\right)I-\left(cs-a\right)A\right] \\
&=\frac{1}{cs-a}\left[bI-dsI-csA+aA\right] \\
&=\frac{1}{cs-a}\left[\left(bI+aA\right)-s\left(dI+cA\right)\right] \\
&=\frac{1}{cs-a}\left[\left(bI+aA\right)\Gamma-sI\right]\Gamma^{-1}
\end{align*}
Then:
\begin{align*}
\left(sI-\mathcal{A}\right)\mathcal{C}^{-1}
\left(\mathcal{T}\left(s\right)I-A\right)^{-1}B
&=\mathcal{B}+\left(sI-\mathcal{A}\right)\mathcal{C}^{-1}\mathcal{D} \\
\left[sI-\left(bI+aA\right)\Gamma\right]\Gamma^{-1}\left(cs-a\right)\Gamma
\left[\left(bI+aA\right)\Gamma-sI\right]^{-1}B
&= \left(ad-bc\right)\Gamma B
-\left[sI-\left(bI+aA\right)\Gamma\right]\Gamma^{-1}c\Gamma B\\
-\left(cs-a\right)
&=\left(ad-bc\right)\Gamma-c\left[sI-\left(bI+aA\right)\Gamma\right]\\
-\left(cs-a\right)\left(dI+cA\right)
&=\left(ad-bc\right)I-cs\left(dI+cA\right)+c\left(bI+aA\right)\\
-cdsI+adI-c^{2}sA+acA&=adI-bcI-cdsI-c^{2}sA+bcI+acA
\end{align*}

\subsection{\label{sec:Generalised_discrete_time_KYP_theorem}A generalised discrete-time KYP lemma}
\emph{Iwasaki} and \emph{Hara}~\cite[Section 2.2]{Iwasaki_KYPlemmaFrequencyInequalities} prove the following generalised KYP
lemma for discrete-time state variable systems:
\begin{framed}
\emph{Theorem 1}~\cite[Section 2.2]{Iwasaki_KYPlemmaFrequencyInequalities}: Let
complex matrixes $A$, $B$, $\Theta=\Theta^{\mathconj}$ and
$\left(\Phi,\Psi\right)\in\boldsymbol{\Omega}$  be given where
\begin{align}
\label{eqn:IwasakiHaraDiscreteTimeKYPOmega}
\begin{split}
\boldsymbol{\Omega}\coloneq & \left\{ \right. \\
\left(\Phi,\Psi\right) &: \left.\text{ there exists }
\alpha,\beta\in\mathbb{R},M\in\mathbb{C}^{2\times{}2}
\text{ such that: }\right. \\
\Phi &= \left. M^{\mathconj} \left[\begin{array}{cc}
0 & \alpha \\
\alpha & 0 \end{array}\right] M,
\text{ where } \alpha\det\left(M\right)\ne 0, \right. \\
\Psi &= \left. M^{\mathconj}\left[\begin{array}{cc}
-1 & \beta \\
\beta & 1 \end{array} \right]M \right. \\
& \left.  \right\}
\end{split}
\end{align}

Define
\begin{align}
\label{eqn:IwasakiHaraDiscreteTimeKYPLambda}
\boldsymbol{\Lambda}\coloneq\left\{\lambda\in\mathbb{C} : \sigma\left(\lambda,\Phi\right) = 0,
\sigma\left(\lambda,\Psi\right) \ge 0\right\}
\end{align}

Suppose $\left(A,B\right)$ is controllable and that $A$ has no eigenvalues, $\lambda$, such that $\sigma\left(\lambda,\Phi\right) = 0$. Then the following
statements are equivalent:
\begin{enumerate}
\item The following frequency domain condition holds for all $\lambda\in\boldsymbol{\Lambda}$:
\begin{align}
\label{eqn:Iwasaki-Hara-Generalised-KYP-FDI}
\left[\begin{array}{c}
\left(\lambda I - A\right)^{-1}B \\
I \end{array}\right]^{\mathconj} \Theta \left[\begin{array}{c}
\left(\lambda I - A\right)^{-1}B \\
I \end{array}\right]\le 0
\end{align}
\item There exist Hermitian matrixes $P$ and $Q\succeq 0$ such that:
\begin{align}
\label{eqn:Iwasaki-Hara-Generalised-KYP-LMI}
\left[\begin{array}{cc}
A & B \\
I & 0\end{array}\right]^{\mathconj}
L\left(P,Q\right)
\left[\begin{array}{cc}
A & B\\
I & 0 \end{array}\right]+\Theta \preceq 0
\end{align}
where $L\left(P,Q\right)=\Phi\otimes P + \Psi\otimes Q$.
\end{enumerate}

\emph{Proof:}~ Equation~\ref{eqn:Iwasaki-Hara-Generalised-KYP-FDI} holds for all
$\lambda\in\boldsymbol{\Lambda}$ such that $c\lambda+d\ne 0$. By Lemma 1, the
condition is equivalent to:
\begin{align*}
\left[\begin{array}{c}
\left(\mathcal{T}\left(s\right)I-A\right)^{-1}B\\
I\end{array}\right]^{\mathconj}\Theta\left[\begin{array}{c}
\left(\mathcal{T}\left(s\right)I-A\right)^{-1}B\\
I\end{array}\right]\le 0
\end{align*}
for all $s\in\boldsymbol{S}$ such that $cs\ne a$ where:
\begin{align*}
\boldsymbol{S}\coloneq \left\{\imath\omega : \omega\in\mathbb{R}, \mathabs{\omega}\le 1 \right\}
\end{align*}

From Lemma 2:
\begin{align*}
\left[\begin{array}{c}
\mathcal{C}\left(sI-\mathcal{A}\right)^{-1}\mathcal{B}+\mathcal{D}\\
I\end{array}\right]^{\mathconj}\Theta\left[\begin{array}{c}
\mathcal{C}\left(sI-\mathcal{A}\right)^{-1}\mathcal{B}+\mathcal{D}\\
I\end{array}\right]\le 0
\end{align*}
where:
\begin{align*}
\left[\begin{array}{c}
\mathcal{C}\left(sI-\mathcal{A}\right)^{-1}\mathcal{B}+\mathcal{D}\\
 I\end{array}\right]  &= \left[\begin{array}{cc}
                               \mathcal{C}&\mathcal{D}\\
                                 0 &I\end{array}\right]
                        \left[\begin{array}{c}
                                \left(sI-\mathcal{A}\right)^{-1}\mathcal{B}\\
                                I\end{array}\right]
\end{align*}

Lemma 2 also implies that $\mathcal{A}$ has no eigenvalues on $\imath\mathbb{R}$
and that $\left(\mathcal{A},\mathcal{B}\right)$ is controllable. The continuous
time finite frequency KYP lemma implies that this condition is equivalent to the
existence of Hermitian matrixes $X$ and $Q\succeq 0$ such that:
\begin{align*}
\left[\begin{array}{cc}
\mathcal{A} & \mathcal{B} \\
I & 0\end{array}\right]^{\mathconj}
\left[\begin{array}{cc}
-Q & X \\
X & Q\end{array}\right]
\left[\begin{array}{cc}
\mathcal{A} & \mathcal{B}\\
I & 0 \end{array}\right]+
\left[\begin{array}{cc}
\mathcal{C} & \mathcal{D} \\
0 & I\end{array}\right]^{\mathconj}
\Theta
\left[\begin{array}{cc}
\mathcal{C} & \mathcal{D} \\
0 & I\end{array}\right]\preceq 0
\end{align*}
The result follows by noting that:
\begin{align*}
\left[\begin{array}{cc}
\mathcal{A} & \mathcal{B} \\
I & 0\end{array}\right]
\left[\begin{array}{cc}
\mathcal{C} & \mathcal{D} \\
0 & I\end{array}\right]^{-1} &=
\left[\begin{array}{cc}
aI & bI \\
cI & dI\end{array}\right]
\left[\begin{array}{cc}
A & B\\
I & 0 \end{array}\right] = \left(M\otimes I\right)\left[\begin{array}{cc}
A & B\\
I & 0 \end{array}\right]
\end{align*}
where:
\begin{align*} 
\left[\begin{array}{cc}
\mathcal{C} & \mathcal{D} \\
0 & I\end{array}\right]^{-1} &=
\left[\begin{array}{cc}
\Gamma^{-1} & c\Gamma{}B \\
0 & I\end{array}\right]
\end{align*}
and:
\begin{align*}
\left[\begin{array}{cc}
aI & bI \\
cI & dI\end{array}\right]^{\mathconj}
\left[\begin{array}{cc}
-Q & X \\
X & Q\end{array}\right]
\left[\begin{array}{cc}
aI & bI \\
cI & dI\end{array}\right] &= \left(\Phi\otimes P + \Psi\otimes Q\right)
\end{align*}
with:
\begin{align*}
P&\coloneq \frac{X-\beta Q}{\alpha}
\end{align*}
\end{framed}
The Octave script \emph{yalmip\_kyp\_check\_iir\_lowpass\_test.m} uses the
generalised KYP lemma to check the frequency response of various implementations
of an elliptic low-pass filter.

The Octave script
\emph{schurOneMPAlatticeDoublyPipelined2Abcd\_kyp\_symbolic\_test.m} shows
the KYP lemma for an IIR filter implemented as the combination of parallel
doubly pipelined all pass one multiplier Schur lattice filters.

\subsubsection{Characterisation of $\boldsymbol{\Omega}$}
\emph{Iwasaki} and \emph{Hara}~\cite[Section
2.3]{Iwasaki_KYPlemmaFrequencyInequalities} next consider the choice of
$\alpha$, $\beta$ and $M$ such that
$\left(\Phi,\Psi\right)\in\boldsymbol{\Omega}$. First they state
the following lemmas:
\begin{framed}
\emph{Lemma 3}: Let $N\in\mathbb{C}^{2\times 2}$ and $\gamma\in\mathbb{R}$ be
given such that $\det\left(N\right)\ne 0$. Then:

\begin{align*}
N^{\mathconj}\left[\begin{array}{cc}
0 & 1 \\
1 & 0\end{array}\right]N &= \left[\begin{array}{cc}
0 & \gamma \\
\gamma & 0\end{array}\right]
\end{align*}
holds if-and-only-if $N\in\boldsymbol{N}_{\gamma}$, where:
\begin{align*}
\boldsymbol{N}_{\gamma}&\coloneq \left\{J^{\mathconj}FJe^{\imath\omega} :
F\in\mathbb{R}^{2\times 2}, \omega\in\mathbb{R}, \det\left(F\right)=\gamma\right\}
\\
J &\coloneq \left[\begin{array}{cc}
1 & 0 \\
0 & \imath\end{array}\right]
\end{align*}
\emph{Proof:}~ Choose an arbitrary $F=\left[\begin{array}{cc}
p & q \\
r & s\end{array}\right]$, substitute and multiply out.
\end{framed}

\begin{framed}
\emph{Lemma 4}: Let $\Phi\in\mathbb{H}$ be given such that
$\det\left(\Phi\right)< 0$. Then the set of all $\alpha\in\mathbb{R}$ and
$M\in\mathbb{C}^{2\times 2}$ such that:
\begin{align*}
\Phi &= M^{\mathconj}\left[\begin{array}{cc}
0 & \alpha \\
\alpha & 0\end{array}\right]M
\end{align*}
is parameterised by
\begin{align*}
M&=NK,\quad N\in\boldsymbol{N}_{\gamma}
\end{align*}
where $\gamma\coloneq\frac{1}{\alpha}$ and $K$ is an arbirary matrix satisfying
\begin{align}
\label{eqn:Lemma4_Phi_K}
\Phi&=K^{\mathconj}\left[\begin{array}{cc}
0 & 1 \\
1 & 0\end{array}\right]K
\end{align}
\end{framed}

\begin{framed}
\emph{Lemma 5}: Given $\Upsilon\in\mathbb{H}$, there exists $\beta,\gamma\in\mathbb{R}$ and $N\in\boldsymbol{N}_{\gamma}$, such that $\gamma\ne 0$ and
\begin{align*}
N^{\mathconj}\left[\begin{array}{cc}
-1 & \beta \\
\phantom{-}\beta & 1\end{array}\right]N &=\Upsilon
\end{align*}
if-and-only-if $\Upsilon\in\boldsymbol{\Upsilon}\coloneq \left\{\Upsilon\in\mathbb{H} :
\det\left(\Re\left[J\Upsilon J^{\mathconj}\right]\right)<0\right\}$.

\emph{Proof:}~ For the previously defined $F$ and $\gamma$, multiplying out gives
$\det\left(\Re\left[J\Upsilon J^{\mathconj}\right]\right) = -\beta\gamma^{2}$
\end{framed}

\begin{framed}
\emph{Lemma 6}: Let $\Phi,\Psi\in\mathbb{H}$, then $\left(\Phi,\Psi\right)\in\boldsymbol{\Omega}$ if-and-only-if:
\begin{align*}
\det\left(\Phi\right)\le 0, \quad\det\left(\Psi_{o}\right)\le 0
\end{align*}
hold where:
\begin{align*}
\Psi_{o}\coloneq \Re\left[\left(JK\right)^{-\mathconj}\Psi\left(JK\right)^{-1}\right]
\end{align*}
where $K$ is an arbitrary matrix as in Equation~\ref{eqn:Lemma4_Phi_K}.

\emph{Proof:}~ Note that, by Lemma 4, $\det\left(\Phi\right)$ is negative if
$\left(\Phi,\Psi\right)\in\boldsymbol{\Omega}$ and there exist $\beta,\gamma\in\mathbb{R}$ and $N\in\boldsymbol{N}_{\gamma}$ such that
$\gamma\ne 0$ and:
\begin{align*}
\Psi = \left(NK\right)^{\mathconj}\left[\begin{array}{cc}
-1 & \beta \\
\phantom{-}\beta & 1\end{array}\right]\left(NK\right)
\end{align*}
From Lemma 5, this condition is equivalent to $K^{-\mathconj}\Psi{}K^{-1}\in\boldsymbol{\Upsilon}$.
\end{framed}

\subsubsection{Frequency restrictions for discrete-time filters}
See \emph{Iwasaki} and \emph{Hara}~\cite[Section
3.2]{Iwasaki_KYPlemmaFrequencyInequalities}. The Octave script \emph{kyp\_symbolic\_frequency\_transformation\_test.m}
uses the \emph{symbolic} package to confirm the following transformations of
a frequency interval on the unit-circle to the imaginary
axis\footnote{Section~\ref{sec:Union-of-frequency-intervals} extends these
  results to the union of frequency intervals.}.

The discrete-time frequency variable $z=e^{\imath\omega}$ can be characterised
by\footnote{I do not know why \emph{Iwasaki} and
\emph{Hara}~\cite[p.3831]{Iwasaki_KYPlemmaFrequencyInequalities} use $-\Phi$ for
the low-pass and band-pass cases of $L\left(P,Q\right)$. The only constraint on
$P$ is that it be Hermitian. Experiments with the Octave script
\emph{directFIRnonsymmetric\_kyp\_lowpass\_test.m} confirmed that $\Phi$ and
$-\Phi$ produce the same filters.}:
\begin{align}
\label{eqn:Lambda-sigma-unit-circle}
\begin{split}
 \Phi=\left[\begin{array}{cc}
1 & \phantom{-}0 \\
0 & -1\end{array}\right]\\
\sigma\left(z,\Phi\right)\coloneq z^{\mathconj}z-1=0
\end{split}
\end{align}
and $K$ can be chosen as:
\begin{align*}
K&=\frac{1}{\sqrt{2}}\left[\begin{array}{cc}
1 & -1 \\
1 & \phantom{-} 1\end{array}\right]
\end{align*}
with:
\begin{align*}
 \Phi_{o}=\left[\begin{array}{cc}
              0 & 1 \\
              1 & 0\end{array}\right]
\end{align*}

\paragraph{Low-pass} The low frequency condition is :
\begin{align*}
\boldsymbol{\Lambda}_{dl}\coloneq\left\{e^{\imath\omega}: \omega\in\mathbb{R},\mathabs{\omega}\le \omega_{l} \right\}
\end{align*}
where $\mathabs{\omega}\le\omega_{l}$ if-and-only-if
$ z+z^{\mathconj}\ge 2\cos\omega_{l}$ and we choose:
\begin{align*}
\gamma &= 2\cos\omega_{l}\\
\Psi&=\left[\begin{array}{cc}
0 & \phantom{-}1 \\
1 &  -\gamma\end{array}\right]
\end{align*}
In this case:
\begin{align*}
\Psi_{o}&=\frac{1}{2}\left[\begin{array}{cc}
-2-\gamma & 0 \\
0 &  2-\gamma\end{array}\right]
\end{align*}
and $\det\left(\Psi_{o}\right)<0$ if-and-only-if $\mathabs{\gamma}<2$ or
$0<\omega_{l}<\pi$. The state space condition is:
\begin{align*}
L\left(P,Q\right)&=\left[\begin{array}{cc}
P & Q\\
Q &  -P-\gamma{}Q\end{array}\right]
\end{align*}

\paragraph{High-pass} The high frequency condition is :
\begin{align*}
\boldsymbol{\Lambda}_{dh}\coloneq\left\{e^{\imath\omega}: \omega\in\mathbb{R},\omega_{h}\le \mathabs{\omega}\le \pi\right\}
\end{align*}
where:
\begin{align*}
 \gamma&\coloneq 2\cos\omega_{h}\\
 \Psi&=\left[\begin{array}{cc}
\phantom{-}0 & -1 \\
-1 &  \phantom{-}\gamma\end{array}\right]\\
\Psi_{o}&=\frac{1}{2}\left[\begin{array}{cc}
2+\gamma & 0 \\
0 &  \gamma-2\end{array}\right]
\end{align*}
Again $\det\left(\Psi_{o}\right)<0$ if-and-only-if $\mathabs{\gamma}<2$ or
$0<\omega_{h}<\pi$ and the state space condition is:
\begin{align*}
L\left(P,Q\right)&=\left[\begin{array}{cc}
\phantom{-}P & -Q\\
-Q &  -P+\gamma{}Q\end{array}\right]
\end{align*}

\paragraph{Band-pass} The middle frequency condition is :
\begin{align*}
\boldsymbol{\Lambda}_{dm}\coloneq\left\{e^{\imath\omega}: \omega\in\mathbb{R},\omega_{1}\le \mathabs{\omega}\le \omega_{2}\right\}
\end{align*}
Alternatively:
\begin{align*}
\mathabs{\omega-\omega_{c}}\le \omega_{m}\text{ or }
\cos\left(\omega -\omega_{c}\right)\ge\cos\omega_{m}
\end{align*}
where $0\le\omega\le\pi$ and:
\begin{align*}
\omega_{c}\coloneq\frac{\omega_{2}+\omega_{1}}{2}\\
\omega_{m}\coloneq\frac{\omega_{2}-\omega_{1}}{2}
\end{align*}
This condition can be rewritten as $\sigma\left(e^{\imath\omega},\Psi\right)\ge 0$
with\footnote{Note the correction to $\Psi_{o}$, demonstrated in the Octave
script \emph{kyp\_symbolic\_frequency\_transformation\_test.m}.}:
\begin{align*}
 \gamma&\coloneq 2\cos\omega_{m}\\
\Psi&\coloneq\left[\begin{array}{cc}
0 & e^{\imath\omega_{c}}  \\
e^{-\imath\omega_{c}} &  -\gamma\end{array}\right]\\
\Psi_{o}&=\left[\begin{array}{cc}
-\cos\omega_{c}-\cos\omega_{m} & \sin\omega_{c}  \\
\sin\omega_{c} &  \cos\omega_{c}-\cos\omega_{m}
\end{array}\right] \\
\end{align*}
In this case $\det\left(\Psi_{o}\right)=-\sin^{2}\omega_{m}\le 0$. The state space
condition is:
\begin{align*}
L\left(P,Q\right)&=\left[\begin{array}{cc}
P & e^{\imath\omega_{c}}Q\\
e^{-\imath\omega_{c}}Q &  -P-\gamma{}Q\end{array}\right]
\end{align*}

\subsubsection{Gain and phase}
See \emph{Iwasaki} and \emph{Hara}~\cite[Section 3.1]{Iwasaki_KYPlemmaFrequencyInequalities}.
The gain and phase of the filter transfer function,
$H\left(\lambda\right)\coloneq C\left(\lambda I -A\right)^{-1}B+D$, are
determined by the choice of the $\Theta$ matrix in
Equation~\ref{eqn:Iwasaki-Hara-Generalised-KYP-FDI}. As for
Equation~\ref{eqn:ContinuousKYPThetaCDPi}:
\begin{align}
\Theta &= \left[\begin{array}{cc}
C & D \\
0 & I\end{array}\right]^{\mathconj} \Pi \left[\begin{array}{cc}
C & D \\
0 & I\end{array}\right] 
\label{eqn:Discrete-time-KYP-Theta}
\end{align}

Equation~\ref{eqn:Iwasaki-Hara-Generalised-KYP-FDI} now becomes:
\begin{align*}
\left[\begin{array}{c}
 H\left(\lambda\right)\\
I\end{array}\right]^{\mathconj} \Pi \left[\begin{array}{c}
H\left(\lambda\right) \\
I\end{array}\right] &\le 0
\end{align*}

For example, if $\mathabs{H\left(\lambda\right)}\le\varepsilon$:
\begin{align*}
\Pi &= \left[\begin{array}{cc}
I & 0 \\
0 & -\varepsilon^{2}I\end{array}\right]
\end{align*}

\subsubsection{Linearising the generalised discrete-time KYP lemma}
The expansion of $\Theta$ in Equation~\ref{eqn:Discrete-time-KYP-Theta} is
bi-linear in the $C$ and $D$ state variable matrixes. \emph{Iwasaki} and
\emph{Hara}~\cite[Section VII, 
p.52]{Iwasaki_GeneralizedKYPFrequencyDomainInequalities} add a lemma:
\begin{framed}
  \emph{Lemma 8: }For a transfer function
  $H\left(\lambda\right)=C\left(\lambda{}I-A\right)^{-1}B+D$, with $m$ inputs
  and $p$ outputs, $\sigma\left(H\left(\lambda\right),\Pi\right)\le{}0$ for all
  $\lambda\in\boldsymbol{\Lambda}$ holds if-and-only-if there exist Hermitian
  matrices $P$ and $Q\succeq{}0$ such that
\begin{align}
\label{eqn:Iwasaki_Hara_KYP_Lemma_8}
  \left[\begin{array}{cc}
\Gamma\left(P,Q,A,B,C,D\right)& \left[C\;D\right]^{\mathconj}\Pi_{11}^{\mathconj}\\
\Pi_{11}\left[C\;D\right]      & -\Pi_{11}^{\mathconj}\end{array}\right] \preceq 0
\end{align}
holds, where the matrix $\Pi\in\mathbb{H}^{m+p}$ is such that
\begin{align*}
  \Pi &= \left[\begin{array}{cc}
             \Pi_{11} & \Pi_{12} \\
                 \Pi_{12}^{\mathconj}& \Pi_{22} \end{array}\right] \text{, }
               \Pi_{11}\in \mathbb{H}^{p} \text{ and } \Pi_{11}\succeq 0
\end{align*}
and
\begin{align*}
  \Gamma\left(P,Q,A,B,C,D\right)
  &= \left[\begin{array}{cc}
             A & B \\
             I& 0 \end{array}\right]^{\mathconj}
                \left(\Phi\otimes P + \Psi\otimes Q\right)
      \left[\begin{array}{cc}
              A & B \\
              I& 0 \end{array}\right]
       + \left[\begin{array}{cc}
0 & C^{\mathconj}\Pi_{12} \\
\Pi_{12}^{\mathconj}C & D^{\mathconj}\Pi_{12}+
\Pi_{12}^{\mathconj}D+\Pi_{22}\end{array}\right]
\end{align*}
\end{framed}

This lemma follows from the generalised discrete-time KYP theorem shown in
Section~\ref{sec:Generalised_discrete_time_KYP_theorem}. Multiplying
out $\Theta$:
\begin{align*} 
\Theta=\left[\begin{array}{cc}
C & D \\
0 & I \end{array}\right]^{\mathconj}\Pi\left[\begin{array}{cc}
C & D \\
0 & I \end{array}\right] &= \left[\begin{array}{cc}
C^{\mathconj} & 0 \\
D^{\mathconj} & I \end{array}\right]\left[\begin{array}{cc}
\Pi_{11} & \Pi_{12} \\
\Pi_{12}^{\mathconj} & \Pi_{22} \end{array}\right]\left[\begin{array}{cc}
C & D \\
0 & I \end{array}\right] \\
&=\left[\begin{array}{cc}
C^{\mathconj}\Pi_{11} & C^{\mathconj}\Pi_{12} \\
D^{\mathconj}\Pi_{11}+\Pi_{12}^{\mathconj} & D^{\mathconj}\Pi_{12}+\Pi_{22}
\end{array}\right]
\left[\begin{array}{cc}
C & D \\
0 & I \end{array}\right] \\
&=\left[\begin{array}{cc}
C^{\mathconj}\Pi_{11}C & C^{\mathconj}\Pi_{12}+C^{\mathconj}\Pi_{11}D \\
\Pi_{12}^{\mathconj}C+D^{\mathconj}\Pi_{11}C &
D^{\mathconj}\Pi_{11}D+D^{\mathconj}\Pi_{12}+\Pi_{12}^{\mathconj}D +\Pi_{22}
\end{array}\right] \\
&=\left[\begin{array}{cc}
0 & C^{\mathconj}\Pi_{12} \\
\Pi_{12}^{\mathconj}C & D^{\mathconj}\Pi_{12}+\Pi_{12}^{\mathconj}D+\Pi_{22}
\end{array}\right]
+ \left[\begin{array}{cc}
C^{\mathconj}\Pi_{11}C & C^{\mathconj}\Pi_{11}D \\
D^{\mathconj}\Pi_{11}C & D^{\mathconj}\Pi_{11}D\end{array}\right] \\
&=\left[\begin{array}{cc}
0 & C^{\mathconj}\Pi_{12} \\
\Pi_{12}^{\mathconj}C & D^{\mathconj}\Pi_{12}+\Pi_{12}^{\mathconj}D+\Pi_{22}
\end{array}\right]
+ \left[\begin{array}{cc}
C & D\end{array}\right]^{\mathconj}\Pi_{11}\left[\begin{array}{cc}
C & D \end{array}\right]
\end{align*}

If $\Pi\in\mathbb{H}^{p}$, $\Pi_{11}$ is invertible, and $\Pi_{11}\succeq 0$
then the lemma is demonstrated by applying the \emph{Schur
complement}\footnote{See
Appendix~\ref{app:Linear-algebra-Schur-complement-positive-definite}} to: 
\begin{align*}
 \Gamma\left(P,Q,A,B,C,D\right)-\left(\Pi_{11}\left[\begin{array}{cc}
 C & D\end{array}\right]\right)^{\mathconj}\left(-\Pi^{-{\mathconj}}_{11}\right)
 \left(\Pi_{11}\left[\begin{array}{cc}
 C & D\end{array}\right]\right) \preceq 0
\end{align*}

\subsection{Examples of FIR filter design with the generalised KYP lemma}
The Octave script \emph{directFIRnonsymmetric\_kyp\_lowpass\_alternate\_test.m}
experiments with various combinations of constraints and objective functions.
I concluded that the best approach is to optimise with an empty objective
function and amplitude constraints found by trial and error.

\subsubsection{Preliminaries}

\paragraph{Frequency response}
The frequency response of an order $n$ single-input-single-output FIR filter is:
\begin{align*}
  H\left(\omega\right)&=\sum_{k=0}^{n}h_{k}e^{-\imath{}k\omega}
\end{align*}

\paragraph{State variable description}
For direct-form FIR filter implementations, the $A$ and $B$ matrixes are constant
representations of the successive delays and the $C$ and $D$ matrixes represent
the impulse response response coefficients. The state variable description is:
\begin{align*}
  \left[\begin{array}{cc}
A & B \\
C & D\end{array}\right]
  &=\left[\begin{array}{cc}
            \left[\begin{array}{cc}
            \boldsymbol{0}_{\left(n-1\right)\times{}1} & \boldsymbol{I}_{n-1} \\
            0 & \boldsymbol{0}_{1\times{}\left(n-1\right)}\end{array}\right]
                      &
            \left[\begin{array}{c}
                    \boldsymbol{0}_{\left(n-1\right)\times{}1}\\
                    1\end{array}\right] \\
& \\
            \left[\begin{array}{ccccc}
                    h_{n}&\hdots&h_{d}-\Delta&\hdots&h_{1}\end{array}\right]
                          & 
                            \left[h_{0} \right]\end{array}\right]              
\end{align*}
where the desired pass band delay is $d$ samples and the desired amplitude
response is $\Delta=1$ in the pass-band and $\Delta=0$ otherwise.

\paragraph{Squared error calculation}
The Octave function \emph{directFIRnonsymmetricEsqPW.m} calculates the
piece-wise weighted mean-squared-error of the response of a non-symmetric FIR
filter. Naturally, this function also applies to symmetric FIR filters. In
this case the state transition matrix $A$ has the same order and structure for
symmetric and non-symmetric direct FIR filters. The function is described in
Section~\ref{app:Unconstrained-opt-FIR-digital-filters-SOCP}.

\paragraph{Amplitude constraints}
The desired response errors for each filter frequency band are encoded in the
corresponding $\Pi$ matrix. For example, see
Equation~\ref{eqn:KYP_PI_stop_band}. For a low-pass filter, the pass-band and
stop-band errors are: 
\begin{align*}
\mathabs{H\left(e^{\imath\omega}\right)^{2}-H_{D}\left(e^{\imath\omega}\right)}^{2}
  &\le\varepsilon^{2}_{p} \quad 0\le\mathabs{\omega}\le\omega_{p}\le\pi\\
\mathabs{H\left(e^{\imath\omega}\right)}^{2}
  &\le\varepsilon_{s}^{2} \quad 0\le\omega_{s}\le\mathabs{\omega}\le\pi
\end{align*}

where $\varepsilon_{p}$ and $\varepsilon_{s}$ are the pass-band and stop-band
errors and $\omega_{p}$ and $\omega_{s}$ are the pass-band and stop-band edge
angular frequencies respectively. If the desired filter pass-band delay is $d$
samples then a constraint on the maximum pass-band response error is: 
\begin{align*}
\mathabs{H\left(e^{\imath\omega}\right)-e^{-\imath{}d\omega}}^{2}
  &\le\varepsilon_{z}^{2} \quad 0\le\mathabs{\omega}\le\omega_{p}\le\pi
\end{align*}
This constraint is implemented by modifying the $C$ state variable matrix to
subtract the response of a delayed input signal from the response of the desired
filter.

A constraint on the maximum pass-band amplitude  is:
\begin{align*}
\mathabs{H\left(e^{\imath\omega}\right)}^{2}
      &\le A^{2}_{p} \quad 0\le\mathabs{\omega}\le\omega_{p}\le\pi
  \end{align*}

An additional specification prevents over-shoot in the transition band:
\begin{align*}
  \mathabs{H\left(e^{\imath\omega}\right)}^{2}
  &\le A_{t}^{2} \quad 0\le\omega_{p}\le\mathabs{\omega}\le\omega_{s}\le\pi
\end{align*}

Alternatively, apply an overall maximum amplitude constraint:
\begin{align*}
  \mathabs{H\left(e^{\imath\omega}\right)}^{2}
  &\le A_{max}^{2} \quad 0\le\mathabs{\omega}\le\pi
\end{align*}
The Octave script \emph{yalmip\_kyp\_lowpass\_test.m} demonstrates each of these
amplitude constraints.

The minimum passband amplitude constraint for a single-input single-output
filter, $\left|H\left(\omega\right)\right|\ge A_{pl}^{2}$,
cannot use Equation~\ref{eqn:Iwasaki_Hara_KYP_Lemma_8} because it requires
$\Pi_{11}\succeq 0$ and in this case $\Pi_{11}=-1$. The Octave script
\emph{yalmip\_kyp\_lowpass\_test.m} uses
Equation~\ref{eqn:Iwasaki-Hara-Generalised-KYP-LMI} to check the minimum
pass-band amplitude response of an FIR filter.

\paragraph{SDP constraints}
Assuming $\Psi_{11}=0$, $\Psi_{21}^{\mathconj}=\Psi_{12}$, $\Pi_{11}=1$ and
$\Pi_{21}=\Pi_{12}=0$, then for each frequency band response constraint:
\begin{align}
  \left[\begin{array}{cc}
          A & B \\
          I & 0 \end{array}\right]^{\mathconj}
  \left[\begin{array}{cc}
            P & \Psi_{12}Q \\
             \Psi_{12}^{\mathconj}Q & -P+\Psi_{22}Q \end{array}\right]
  \left[\begin{array}{cc}
          A & B \\
          I & 0 \end{array}\right]
  + \left[\begin{array}{cc}
          C & D \end{array}\right]^{\mathconj}
  \left[\begin{array}{cc}
    1 & 0 \\
    0 & \Pi_{22} \end{array}\right]
    \left[\begin{array}{cc}
          C & D \end{array}\right] &\preceq 0
\label{eqn:Iwasaki_Hara_KYP_SDP_constraints}
\end{align}
where $P$, $Q$ are Hermitian and $Q\succeq{}0$.
For an FIR filter, the unknown variables are $P$, $Q$, $C$ and
$D$. \emph{Pipeleers} and 
\emph{Vandeberghe}~\cite{Pipeleers_GeneralisedKYPRealData} show that if the  
$A$, $B$ and $\Theta$ matrixes are real valued then the $P$ and $Q$ matrixes can
be constrained to be real and symmetric.

\paragraph{Solving the  generalised KYP lemma with a rank-1 constraint}
Equation~\ref{eqn:Iwasaki_Hara_KYP_SDP_constraints} has the form
$\Gamma+X\preceq 0$ and the FIR filter coefficients are represented by the
rank-$1$ matrix $X=\left[\begin{array}{cc} C & D\end{array}\right]^{\top}
\left[\begin{array}{cc} C & D\end{array}\right]$.

The Octave script \emph{yalmip\_kyp\_lmirank\_lowpass\_test.m} calls the
YALMIP~\cite{Lofberg_YALMIP,Lofberg2004} 
\emph{lmirank}~\cite{Orsi_LMIRank,Orsi_NewtonLikeLMIRankConstrained}
solver to design a symmetric low-pass FIR filter with a rank-$1$ SDP constraint.
After running on my PC for $1276$ minutes the script had performed $694$
iterations and was still converging \emph{very} slowly.

Similarly, the Octave script \emph{yalmip\_kyp\_moment\_lowpass\_test.m}
calls the YALMIP \emph{moment} solver with a rank-$1$ constraint on the
minimum pass-band amplitude. This script requires an \emph{enormous} amount of
memory and CPU time to design a symmetric $6$-th order low-pass FIR filter.

\emph{Kheirandishfard et al.}~\cite{Kheirandishfard_ConvexificationBMI,
  Kheirandishfard_ConvexRelaxationBMI_PartI,
  Kheirandishfard_ConvexRelaxationBMI_PartII}
describe a successive approximation algorithm that relaxes rank-$1$ constraints
to LMIs. The Octave script \emph{yalmip\_parabolic\_convex\_bmi\_test.m} shows
some examples of this approach.
\subsubsection{Design of a symmetric low pass FIR filter}
The Octave script \emph{directFIRsymmetric\_kyp\_lowpass\_test.m}
designs a symmetric FIR low-pass filter with
YALMIP~\cite{Lofberg_YALMIP,Lofberg2004} and SeDuMi. The YALMIP objective is
empty. The YALMIP constraints for each frequency band are
Equation~\ref{eqn:Iwasaki_Hara_KYP_Lemma_8} with $Q\succeq{}0$. The $C$
matrix of the state variable description for the pass-band constraint is
modified to subtract a signal delayed by $M$ samples.

The filter specification is:
\begin{small}
\verbatiminput{directFIRsymmetric_kyp_lowpass_test_spec.m}
\end{small}
The value of $\varepsilon^{2}_{z}$ was found by trial-and-error. The actual
maximum squared-error in the pass-band compared with a pure delay is
$\varepsilon^{2}_{z}=$ 
\input{directFIRsymmetric_kyp_lowpass_test_max_passband_squared_error.tab} 
and the actual maximum stop-band squared-amplitude is $\varepsilon^{2}_{s}=$
\input{directFIRsymmetric_kyp_lowpass_test_max_stopband_squared_error.tab}.
The resulting FIR impulse response is: 
\begin{small}
\verbatiminput{directFIRsymmetric_kyp_lowpass_test_h_coef.m}
\end{small}
Figure~\ref{fig:Direct-FIR-symmetric-KYP-lowpass-response} shows the
amplitude response. The filter satisfies the constraints with
no numerical problems.
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_kyp_lowpass_test_response}}
\caption{Amplitude response of a symmetric FIR low pass filter designed with
the KYP lemma. See \emph{Iwasaki} and \emph{Hara}~\cite[Section
VII.B.2, pp. 53-55]{Iwasaki_GeneralizedKYPFrequencyDomainInequalities}.}
\label{fig:Direct-FIR-symmetric-KYP-lowpass-response}
\end{figure}

For comparison, Figure~\ref{fig:Direct-FIR-symmetric-mcclellan-lowpass-response}
shows a similar filter response designed by the \emph{mcclellanFIRsymmetric}
function described in Section~\ref{sec:Parks-McClellan-mini-max-FIR}. The filter
specification is: 
\begin{small}
\verbatiminput{directFIRsymmetric_kyp_lowpass_test_mcclellan_spec.m}
\end{small}
The distinct coefficients of the resulting FIR impulse response are: 
\begin{small}
\verbatiminput{directFIRsymmetric_kyp_lowpass_test_mcclellan_hM_coef.m}
\end{small}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_kyp_lowpass_test_mcclellan}}
\caption{Amplitude response of a symmetric FIR low pass filter designed with
the \emph{Parks-McClellan} algorithm.}
\label{fig:Direct-FIR-symmetric-mcclellan-lowpass-response}
\end{figure}
\clearpage
\subsubsection{\label{sec:Design-KYP-FIR-non-symmetric-low-pass}Design of a non-symmetric low pass FIR filter with given pass band delay}
As an example, \emph{Iwasaki} and \emph{Hara}~\cite[Section
VII.B.2, pp. 53-55]{Iwasaki_GeneralizedKYPFrequencyDomainInequalities} describe
the design of a low-pass FIR filter with order $N=30$ and a nominal pass-band
group delay of $d=10$ samples, $\omega_{p}=0.3\pi$ and $\omega_{s}=0.4\pi$,
$\varepsilon_{s}=0.01$. They optimised the zero-phase
pass-band sqared-error,
$\mathabs{H\left(\omega\right)-e^{-j\omega{}d}}^{2}<\varepsilon_{z}^{2}$ and found 
$\varepsilon^{2}_{z}=0.0569$\footnote{This is probably a typo and should read,
in my notation, $\varepsilon^{2}_{z}=0.00569$. I suspect that \emph{Iwasaki} and
\emph{Hara} made $\varepsilon^{2}_{z}$ a YALMIP SDP variable with the constraint 
$\varepsilon^{2}_{z}\le 0.00569$ and an empty objective.}.
The Octave script \emph{directFIRnonsymmetric\_kyp\_lowpass\_test.m}
designs a similar filter with YALMIP~\cite{Lofberg_YALMIP,Lofberg2004} and
SeDuMi. The YALMIP objective is empty. The YALMIP constraints for each
frequency band are Equation~\ref{eqn:Iwasaki_Hara_KYP_Lemma_8} with
$Q\succeq{}0$\footnote{The Octave script
\emph{directFIRnonsymmetric\_kyp\_lowpass\_alternate\_test.m} experiments with
constraints on $\varepsilon^{2}_{z}$ or $\varepsilon^{2}_{s}$, with an empty
objective or with the objective set to the sum of the pass-band squared-error.
It seems that it is best to optimise with an empty objective and with fixed
constraints on $\varepsilon_{z}$ and $\varepsilon_{s}$ found by
trial-and-error. \emph{Konopacki} and \emph{Mo\'{s}ci\'{n}ska}~\cite[Equation
5]{Konopacki_EstFilterOrdReducedDelay} show an estimate of the attenuation of a 
low-pass non-symmetric FIR filter when the pass and stop band errors are
equal. For the example of \emph{Iwasaki} and \emph{Hara} the estimated stop-band
attenuation is $42dB$. For comparison, the Octave script
\emph{directFIRnonsymmetric\_socp\_slb\_lowpass\_test.m}, described in
Section~\ref{app:Design-socp-slb-non-symmetric-FIR-low-pass-filter}, designs a 
similar filter using SOCP PCLS optimisation.}. The $C$ matrix of the state
variable description for the pass-band constraint is modified to subtract a
signal delayed by $d$ samples.

The filter specification is:
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_lowpass_test_spec.m}
\end{small}
The value of $\varepsilon^{2}_{z}$ was found by trial-and-error. The actual
maximum squared-error in the pass-band compared with a pure delay is
$\varepsilon^{2}_{z}=$ 
\input{directFIRnonsymmetric_kyp_lowpass_test_max_passband_squared_error.tab}
and the actual maximum stop-band squared-amplitude is $\varepsilon^{2}_{s}=$
\input{directFIRnonsymmetric_kyp_lowpass_test_max_stopband_squared_error.tab}.
The resulting FIR impulse response is: 
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_lowpass_test_h_coef.m}
\end{small}
Figure~\ref{fig:Direct-FIR-nonsymmetric-KYP-lowpass-response} shows the
amplitude and group delay response. The filter satisfies the constraints with
no numerical problems.
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRnonsymmetric_kyp_lowpass_test_response}}
\caption{Amplitude response of a non-symmetric FIR low pass filter designed with
the KYP lemma. See \emph{Iwasaki} and \emph{Hara}~\cite[Section
VII.B.2, pp. 53-55]{Iwasaki_GeneralizedKYPFrequencyDomainInequalities}.} 
\label{fig:Direct-FIR-nonsymmetric-KYP-lowpass-response}
\end{figure}

\subsubsection{Design of a non-symmetric FIR band pass filter with given pass
band delay} 
The Octave script \emph{directFIRnonsymmetric\_kyp\_bandpass\_test.m} uses
the  generalised KYP lemma of \emph{Iwasaki} and \emph{Hara} to design a band
pass FIR filter with YALMIP and SeDuMi. The YALMIP objective is
empty. The YALMIP constraints for each frequency band are
Equation~\ref{eqn:Iwasaki_Hara_KYP_Lemma_8} with $Q\succeq{}0$. The $C$ matrix of
the state variable description for the pass-band constraint is modified
to subtract a signal delayed by $d$ samples. The filter specification is:
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_bandpass_test_spec.m}
\end{small}
The value of $\varepsilon^{2}_{z}$ was found by trial-and-error. The actual
maximum squared-error in the pass-band compared with a pure delay is
$\varepsilon^{2}_{z}=$
\input{directFIRnonsymmetric_kyp_bandpass_test_max_passband_squared_error.tab}. 
The resulting FIR impulse response is:
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_bandpass_test_h_coef.m}
\end{small}
As shown in Section~\ref{app:Low-passband-sensitivity-FIR-digital-filters},
the complementary FIR lattice reflection coefficients are:
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_bandpass_test_k_coef.m}
\end{small}
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_bandpass_test_kc_coef.m}
\end{small}

Figure~\ref{fig:Direct-FIR-nonsymmetric-KYP-bandpass-response} shows the
amplitude, phase and group delay responses. The pass band phase error shown is
adjusted for the nominal delay.
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRnonsymmetric_kyp_bandpass_test_response}}
\caption{Amplitude, phase and group delay responses of a non-symmetric FIR band
  pass filter designed with the KYP lemma. The pass band phase error shown is
  adjusted for the nominal delay.}
\label{fig:Direct-FIR-nonsymmetric-KYP-bandpass-response}
\end{figure}
\subsubsection{Design of a non-symmetric FIR band pass Hilbert filter with given pass
band delay} 
The Octave script \emph{directFIRnonsymmetric\_kyp\_bandpass\_hilbert\_test.m}
uses the generalised KYP lemma of \emph{Iwasaki} and \emph{Hara} to design a band
pass FIR Hilbert filter with  with YALMIP and SeDuMi. The YALMIP objective
is empty. The YALMIP constraints for each frequency band are
Equation~\ref{eqn:Iwasaki_Hara_KYP_Lemma_8} with $Q\succeq{}0$. The $C$ matrix of
the state variable description for the pass-band constraint is modified
to subtract a signal delayed by $d$ samples. The filter specification is:
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_bandpass_hilbert_test_spec.m}
\end{small}
The value of $\varepsilon^{2}_{z}$ was found by trial-and-error. The actual
maximum squared-error in the pass-band compared with a pure delay is
$\varepsilon^{2}_{z}=$
\input{directFIRnonsymmetric_kyp_bandpass_hilbert_test_max_passband_squared_error.tab}.
The resulting FIR impulse response is:
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_bandpass_hilbert_test_h_coef.m}
\end{small}
Figure~\ref{fig:Direct-FIR-nonsymmetric-KYP-bandpass-hilbert-response} 
shows the amplitude, phase and group delay responses. The pass band phase
shown is adjusted for the nominal delay. 
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRnonsymmetric_kyp_bandpass_hilbert_test_response}}
\caption{Amplitude, phase and delay responses of a non-symmetric FIR band pass
  Hilbert filter designed with the KYP lemma. The pass band phase shown is
  adjusted for the nominal delay.}
\label{fig:Direct-FIR-nonsymmetric-KYP-bandpass-hilbert-response}
\end{figure}
\subsubsection{Design of a non-symmetric high pass FIR filter with given pass band delay}
The Octave script \emph{directFIRnonsymmetric\_kyp\_highpass\_test.m} designs a
high-pass filter with YALMIP and SeDuMi. The YALMIP objective is
empty. The YALMIP constraints for each frequency band are
Equation~\ref{eqn:Iwasaki_Hara_KYP_Lemma_8} with $Q\succeq{}0$. The $C$ matrix of
the state variable description for the pass-band constraint is modified
to subtract a signal delayed by $d$ samples. The filter specification is: 
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_highpass_test_spec.m}
\end{small}
The value of $\varepsilon^{2}_{z}$ was found by trial-and-error. The actual
maximum squared-error in the pass-band compared with a pure delay is
$\varepsilon^{2}_{z}=$
\input{directFIRnonsymmetric_kyp_highpass_test_max_passband_squared_error.tab}.
The resulting FIR impulse response is: 
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_highpass_test_h_coef.m}
\end{small}

Figure~\ref{fig:Direct-FIR-nonsymmetric-KYP-highpass-response} shows the
amplitude and delay responses.
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRnonsymmetric_kyp_highpass_test_response}}
\caption{Amplitude response of a non-symmetric FIR high pass filter designed with
the KYP lemma.} 
\label{fig:Direct-FIR-nonsymmetric-KYP-highpass-response}
\end{figure}
\clearpage
\subsection{\emph{Rantzer}'s transformation of the KYP lemma from discrete-time
  to continuous-time}
\emph{Rantzer}~\cite[Proof of Theorem 2]{Rantzer_KYP_PositiveSystems} shows an
alternative transformation of the KYP lemma from discrete-time to
continuous-time by parameterising the unit circle with
$\left(1+\imath\omega\right)/\left(1-\imath\omega\right)$ rather than
$e^{\imath\omega}$. Multiplying out:
\begin{align*}
  \left[\frac{1+\imath\omega}{1-\imath\omega}I - A\right]x&=Bu \\
  \left[\imath\omega\left(A+I\right)-\left(A-I\right)\right]x
                                   +\imath\omega B &=Bu\\
  \left[\imath\omega I-\left(A-I\right)\left(A+I\right)^{-1}\right]
  \left(A+I\right)x   +\imath\omega B &=Bu\\
  \left[\imath\omega I-\left(A-I\right)\left(A+I\right)^{-1}\right]
  \left(Ix+Ax+Bu\right)
     &=\left[I - \left(A-I\right)\left(A+I\right)^{-1}\right]Bu\\
  \left[\imath\omega I-\left(A-I\right)\left(A+I\right)^{-1}\right]
  \left(Ix+Ax+Bu\right)
     &=\left[\left(A+I\right) - \left(A-I\right)\right]\left(A+I\right)^{-1}Bu\\
  \left[\imath\omega I-\left(A-I\right)\left(A+I\right)^{-1}\right]
  \left(Ix+Ax+Bu\right) &=2\left(A+I\right)^{-1}Bu
\end{align*}

\emph{Rantzer} introduces:
\begin{align*}
  \hat{A}&=\left(A-I\right)\left(A+I\right)^{-1} \\
  \hat{B}&=2\left(A+I\right)^{-1}B \\
  \hat{x}&=Ix+Ax+Bu \\
  S&=\left[\begin{array}{cc}
             \left(A+I\right)^{-1} & -\left(A+I\right)^{-1}B \\
             0 & I \end{array}\right] \\
  \hat{\Theta}&=S^{\top}\Theta S \\
 \hat{P}&=P/2
\end{align*}
The corresponding frequency domain condition is:
\begin{align*}
  \left[\begin{array}{c}
          \left(\imath\omega I -\hat{A}\right)^{-1}\hat{B} \\
          I \end{array}\right]^{\mathconj}
  \hat{\Theta}
  \left[\begin{array}{c}
          \left(\imath\omega I -\hat{A}\right)^{-1}\hat{B} \\
          I \end{array}\right] \le 0
\end{align*}
which the continuous-time KYP lemma tells us is equivalent to:
\begin{align*}
  \left[\begin{array}{cc}
          \hat{A}^{\top}\hat{P}+\hat{P}\hat{A} & \hat{P}\hat{B} \\
          \hat{B}^{\top}\hat{P} & 0 \end{array}\right] + \hat{\Theta} \preceq 0
\end{align*}
for some symmetric real $\hat{P}$. Multiplying by $\left[\begin{array}{cc}
                        A+I & B \\
                        0 & I \end{array}\right]$  on the right and its
transpose on the left gives:
\begin{align*}
\begin{split}
 &  \left[\begin{array}{cc}
          A+I & B \\
          0 & I \end{array}\right]^{\top}\left[\begin{array}{cc}
          \hat{A}^{\top}\hat{P}+\hat{P}\hat{A} &\hat{P}\hat{B} \\
          \hat{B}^{\top}\hat{P} & 0\end{array}\right]\left[\begin{array}{cc}
          A+I & B \\
          0 & I \end{array}\right] +
    \left[\begin{array}{cc}
          A+I & B \\
          0 & I \end{array}\right]^{\top}S^{\top}\Theta S\left[\begin{array}{cc}
          A+I & B \\
          0 & I \end{array}\right] \preceq 0 \\
 & \left[\begin{array}{cc}
  \left(A+I\right)^{\top}\left(\hat{A}^{\top}\hat{P}+\hat{P}\hat{A}\right)
  &  \left(A+I\right)^{\top}\hat{P}\hat{B} \\
   B^{\top}\left(\hat{A}^{\top}\hat{P}+\hat{P}\hat{A}\right)+\hat{B}^{\top}\hat{P}
  &  B^{\top}\hat{P}\hat{B}
         \end{array}\right]\left[\begin{array}{cc}
          A+I & B \\
          0 & I \end{array}\right]  +  \cdots \\
  &    \left[\begin{array}{cc}
       A+I & B \\
       0 & I \end{array}\right]^{\top}\left[\begin{array}{cc}
       \left(A+I\right)^{-1} & -\left(A+I\right)^{-1}B \\
      0 & I \end{array}\right]^{\top}\Theta\left[\begin{array}{cc}
      \left(A+I\right)^{-1} & -\left(A+I\right)^{-1}B \\
      0 & I\end{array}\right]\left[\begin{array}{cc}
      A+I & B \\
      0 & I \end{array}\right]  \preceq 0 \\ 
 & \left[\begin{array}{cc}
           \left(A+I\right)^{\top}\left( \hat{A}^{\top}\hat{P}+
           \hat{P}\hat{A}\right)\left(A+I\right)
           &  \left(A+I\right)^{\top}\left( \hat{A}^{\top}\hat{P}+
             \hat{P}\hat{A}\right)B +\left(A+I\right)^{\top}\hat{P}\hat{B} \\
           B^{\top}\left( \hat{A}^{\top}\hat{P}+
           \hat{P}\hat{A}\right)\left(A+I\right)+
           \hat{B}^{\top}\hat{P}\left(A+I\right)
           &  B^{\top}\left( \hat{A}^{\top}\hat{P}+\hat{P}\hat{A}\right)B+
             \hat{B}^{\top}\hat{P}B+
             B^{\top}\hat{P}\hat{B}
   \end{array}\right]  +  \Theta \preceq 0 \\
& \left[\begin{array}{cc}
      \left(A-I\right)^{\top}\hat{P}\left(A+I\right) +
      \left(A+I\right)^{\top}\hat{P}\left(A-I\right)
    & \left(A-I\right)^{\top}\hat{P}B+
      \frac{1}{2}\left(A+I\right)^{\top}\hat{P}\left(A+I\right)\hat{B} \\
      \frac{1}{2}\hat{B}^{\top}\left(A+I\right)^{\top}\hat{P}\left(A+I\right)+
      B^{\top}\hat{P}\left(A-I\right)
    & \frac{1}{2}\hat{B}^{\top}\left(A+I\right)^{\top}\hat{P}B+
      \frac{1}{2}B^{\top}\hat{P}\left(A+1\right)\hat{B}
   \end{array}\right]  +  \Theta \preceq 0 \\
 & \left[\begin{array}{cc}
  2A^{\top}\hat{P}A-2\hat{P} & 2A^{\top}\hat{P}B\\
  2B^{\top}\hat{P}A & 2B^{\top}\hat{P}B\end{array}\right]+\Theta \preceq 0 \\
 & \left[\begin{array}{cc}
           A^{\top}PA -P & A^{\top}PB \\
           B^{\top}PA & B^{\top}PB \end{array}\right] + \Theta \preceq 0
\end{split}
\end{align*}
I experiment with this conversion in the Octave script
\emph{yalmip\_kyp\_rantzer\_test.m} and find that SeDuMi calculates
$P \approx -2\hat{P}$.
\clearpage
\subsection{\label{sec:Finslers-lemma-transformation-generalised-KYP}\emph{Finsler}'s lemma transformation of  the generalised KYP lemma}
\emph{Ren et al.}~\cite[Lemma 3]{Ren_SuccessiveConvexOptimizationBMI} write
\emph{Finsler}'s lemma in LMI form as:
\begin{framed}
  \emph{Lemma}: Let $P=P^{\top}$ and matrix $A$ with orthogonal complement,
  $A^{\bot}$, such that $A^{\bot}A=0$, then the
  following statements are equivalent:
  \begin{enumerate}
    \item $A^{\bot}P\left(A^{\bot}\right)^{\top}\prec 0$
    \item There exists a matrix $X$ satisfying $P+AX+X^{\top}A^{\top}\prec 0$
    \end{enumerate}
\end{framed}

\emph{Ren et al.}~\cite[Theorem 3]{Ren_SuccessiveConvexOptimizationBMI} apply
\emph{Finsler}'s Lemma to the generalised KYP lemma matrix inequality shown in
Equation~\ref{eqn:Iwasaki-Hara-Generalised-KYP-LMI}:
\begin{framed}
  \emph{Theorem}:
  Matrixes $P\in\mathbb{H}_{n}$, $Q\in\mathbb{H}_{n}$,
  $Q\succeq 0$ and $X\in\mathbb{C}^{n\times n}$, $Y\in\mathbb{C}^{n\times n}$,
  $Z\in\mathbb{C}^{m\times n}$ exist such that:
  \begin{align}
    \label{eqn:Iwasaki-Hara-Generalised-KYP-LMI-Finsler}
    \left[\begin{array}{ccc}
            L\left(P,Q\right) & 0 & 0\\
            0 & -\varepsilon^{2}I_{m} & 0 \\
            0 & 0 & I_{p} \end{array}\right] +
    UV+V^{\mathconj}U^{\mathconj} \preceq 0
  \end{align}
  where  we assume that
    $\Pi=\left[\begin{array}{cc}
                I_{p} & 0 \\
                0 & -\varepsilon^{2}I_{m}\end{array}\right]$ and define 
            $U=\left[\begin{array}{cccc}
              -I_{n} & A & B & 0 \\
              0 & C & D & -I_{m}\end{array}\right]^{\mathconj}$ ,
    $V=\left[\begin{array}{cc}
                        X & 0 \\
                        Y & 0 \\
                        Z & 0 \\
                        0 & I_{p} \end{array}\right]^{\mathconj}$.
\end{framed}
Recall that the state-variable system of equations has $n$ states,
$m$ inputs and $p$ outputs so that $A\in\mathbb{C}^{n\times n}$,
$B\in\mathbb{C}^{n\times m}$, $C\in\mathbb{C}^{p\times n}$,
$D\in\mathbb{C}^{p\times m}$, $P\in\mathbb{C}^{n\times n}$,
$Q\in\mathbb{C}^{n\times n}$, $L\left(P,Q\right)\in\mathbb{C}^{2n\times 2n}$,
$\Theta\in\mathbb{C}^{\left(n+m\right)\times\left(n+m\right)}$,
$\Pi\in\mathbb{C}^{\left(p+m\right)\times\left(p+m\right)}$,
$\Pi_{11}\in\mathbb{C}^{p\times p}$ and $\Pi_{22}\in\mathbb{C}^{m\times m}$.

\emph{Ren et al.} rewrite Equation~\ref{eqn:Iwasaki-Hara-Generalised-KYP-LMI} as:
  \begin{align*}
\left[\begin{array}{cc}
        A & B \\
        I_{n} & 0 \\
        0 & I_{m} \end{array}\right]^{\mathconj}\left\{
\left[\begin{array}{cc}
        L\left(P,Q\right) & 0 \\
        0 & 0_{m} \end{array}\right]+
\left[\begin{array}{cc}
        0_{n}& 0 \\
        0 & \Theta \end{array}\right]\right\}
\left[\begin{array}{cc}
        A & B \\
        I_{n} & 0 \\
        0 & I_{m} \end{array}\right]\preceq 0
\end{align*}
and define $\tilde{U}^{\bot}=\left[\begin{array}{cc}
        A & B \\
        I_{n} & 0 \\
        0 & I_{m} \end{array}\right]^{\mathconj}$ ,
    $\tilde{U}=\left[\begin{array}{ccc}
                        -I_{n} & A & B\end{array}\right]^{\mathconj}$ ,
 $\tilde{V}=\left[\begin{array}{ccc}
   X^{\mathconj} & Y^{\mathconj} & Z^{\mathconj}\end{array}\right]$.

Applying \emph{Finsler}'s lemma:
  \begin{align*}
\left[\begin{array}{cc}
        L\left(P,Q\right) & 0 \\
        0 & 0_{m} \end{array}\right]+
\left[\begin{array}{cc}
        0_{n}& 0 \\
        0 & \Theta \end{array}\right] +
    \tilde{U}\tilde{V}+
    \tilde{V}^{\mathconj}\tilde{U}^{\mathconj} \preceq 0
  \end{align*}
where:
  \begin{align*}
    \tilde{U}\tilde{V}
    &=\left[\begin{array}{c}
              -I_{n}\\
              A^{\mathconj}\\
              B^{\mathconj} \end{array}\right]
      \left[\begin{array}{ccc}
              X^{\mathconj} & Y^{\mathconj} & Z^{\mathconj} \end{array}\right] 
    =\left[\begin{array}{ccc}
 -X^{\mathconj} & -Y^{\mathconj} & -Z^{\mathconj}\\
  A^{\mathconj}X^{\mathconj} & A^{\mathconj}Y^{\mathconj} & A^{\mathconj}Z^{\mathconj}\\
  B^{\mathconj}X^{\mathconj} & B^{\mathconj}Y^{\mathconj} & B^{\mathconj}Z^{\mathconj}
            \end{array}\right]
  \end{align*}
Also:
\begin{align*}
\left[\begin{array}{cc}
        0_{n}& 0 \\
        0 & \Theta \end{array}\right]
  &= \left[\begin{array}{cc}
             0_{n}& 0 \\
             0 & \left[\begin{array}{cc}
                         C & D \end{array}\right]^{\mathconj}
                 I_{p}\left[\begin{array}{cc}
                         C & D \end{array}\right]
           \end{array}\right]+
  \left[\begin{array}{cc}
          0_{2n}& 0 \\
          0 & -\varepsilon^{2}I_{m}\end{array}\right]
\end{align*}
Apply the Schur complement to:
\begin{align*}
  \left[\begin{array}{cc}
\tilde{U}\tilde{V}+
          \tilde{V}^{\mathconj}\tilde{U}^{\mathconj} & 0 \\
          0 & 0_{p}\end{array}\right]+
  \left[\begin{array}{cc}
             0_{n}& 0 \\
             0 & \left[\begin{array}{cc}
                         C & D \end{array}\right]^{\mathconj}
                 I_{p}\left[\begin{array}{cc}
                         C & D \end{array}\right]
           \end{array}\right]
\end{align*}
so that:
\begin{align*}
\left[\begin{array}{cccc}
-X^{\mathconj}&-Y^{\mathconj}&-Z^{\mathconj}&0\\
A^{\mathconj}X^{\mathconj}&A^{\mathconj}Y^{\mathconj}&A^{\mathconj}Z^{\mathconj}&C^{\mathconj}\\
B^{\mathconj}X^{\mathconj}&B^{\mathconj}Y^{\mathconj}&B^{\mathconj}Z^{\mathconj}&D^{\mathconj}\\
        0 & 0 & 0 & -I_{p} \end{array}\right]+
\left[\begin{array}{cccc}
-X & XA & XB & 0 \\
-Y & YA & YB & 0 \\
-Z & ZA & ZB & 0 \\
 0 & C & D & -I_{p} \end{array}\right]+
\left[\begin{array}{cc}
        0_{2n+m} & 0 \\
        0 & I_{p} \\
      \end{array}\right]  
  &= UV+V^{\mathconj}U^{\mathconj}+
    \left[\begin{array}{cc}
            0_{2n+m} & 0 \\
            0 & I_{p} \\
          \end{array}\right]  
\end{align*}

The Octave script \emph{yalmip\_kyp\_finsler\_test.m} checks
Equation~\ref{eqn:Iwasaki-Hara-Generalised-KYP-LMI-Finsler}.

The Octave script \emph{directFIRnonsymmetric\_kyp\_finsler\_lowpass\_test.m}
repeats the filter design of
Section~\ref{sec:Design-KYP-FIR-non-symmetric-low-pass} with the Finsler
transformation of the generalised KYP lemma.

\subsection{The dual of the KYP lemma}
\emph{Wallin}, \emph{Vandeberghe} and others note that solution of the KYP lemma
by Equation~\ref{eqn:KYPlemmaLMI_expanded} is an $\mathcal{O}\left(n^{6}\right)$
complexity problem, that solving the \emph{dual} problem reduces this to
$\mathcal{O}\left(n^{4}\right)$ and that exploiting the structure of the dual
problem can reduce the complexity further to
$\mathcal{O}\left(n^{3}\right)$~
\cite{Balakrishnan_SDPDualityLinearTimeInvariantSystems,
  VandenbergheBalakrishnan_ImplementationInteriorPointKYPlemma,
  WallinHanssonVandenberge_SemiDefiniteKYPlemmaStandardSolvers,
  WallinHanssonVandenberge_ComparisonStructureExploitingIntegralQuadratic,
  ChengYiping_ProofDiscreteTimeKYPusingSDPduality}.
\subsubsection{The \emph{adjoint} of the discrete-time KYP linear mapping}
\emph{Cheng}~\cite{ChengYiping_ProofDiscreteTimeKYPusingSDPduality} shows
proofs of the continuous-time and discrete-time KYP lemmas by duality.
He begins by reviewing the definition of the \emph{adjoint} of the linear
mapping of a hermitian matrix. The inner product defined on the Hilbert space of
$n\times n$ Hermitian matrixes, $\mathbb{H}^{n}$, is\footnote{See
  Section~\ref{app:Linear-algebra-trace-of-matrix}}:
\begin{align*}
  \langle A,B\rangle = \mathtrace\left(A^{\mathconj}B\right) =
    \mathtrace\left(AB\right)
\end{align*}
Also:
\begin{quotation}
  ... given two Hilbert spaces $V$ and $W$ and a linear mapping
  $\mathcal{A}:V\rightarrow W$, the adjoint mapping of $\mathcal{A}$,
  denoted $\mathcal{A}^{adj}$, is a linear mapping from $W$ to $V$ such that
  \begin{align*}
    \forall x\in V, y\in W, \langle\mathcal{A}\left(x\right),y\rangle_{W} =
    \langle x,\mathcal{A}^{adj}\left(y\right)\rangle_{V}
  \end{align*}
\end{quotation}

The linear mapping associated with the discrete-time KYP lemma is
$\mathcal{D}:\mathbb{H}^{n}\rightarrow\mathbb{H}^{n+m}$:
\begin{align}
  \mathcal{D}\left(P\right) &= \left[\begin{array}{cc}
         A^{\mathconj}PA-P & A^{\mathconj}PB \\
         B^{\mathconj}PA   & B^{\mathconj}PB\end{array}\right]
  \label{eqn:Discrete-time-KYP-lemma-linear-mapping}
\end{align}
The adjoint mapping, $\mathcal{D}^{adj}:\mathbb{H}^{n+m}\rightarrow\mathbb{H}^{n}$,
is:
\begin{align*}
  \mathcal{D}^{adj}\left(Z\right)
  &= AZ_{11}A^{\mathconj}-Z_{11} + BZ_{12}^{\mathconj}A^{\mathconj}
    + AZ_{12}B^{\mathconj} + BZ_{22}B^{\mathconj}
\end{align*}
where
\begin{align*}
  Z&=\left[\begin{array}{cc}
             Z_{11} & Z_{12} \\
             Z_{12}^{\mathconj} & Z_{22}\end{array}\right]
\end{align*}
This follows from the definition of the inner product:
\begin{align*}
  \langle\mathcal{D}\left(P\right),Z\rangle &=
  \mathtrace\left(\mathcal{D}\left(P\right)Z\right)  \\
  &= \mathtrace\left(\left[\begin{array}{cc}
         A^{\mathconj}PA-P & A^{\mathconj}PB \\
         B^{\mathconj}PA   & B^{\mathconj}PB\end{array}\right]
    \left[\begin{array}{cc}
             Z_{11} & Z_{12} \\
            Z_{12}^{\mathconj} & Z_{22}\end{array}\right]\right) \\
  &= \mathtrace\left(\left[\begin{array}{cc}
    A^{\mathconj}PAZ_{11}-PZ_{11} +A^{\mathconj}PBZ_{12}^{\mathconj} & \cdots \\
    \cdots & B^{\mathconj}PAZ_{12}+B^{\mathconj}PBZ_{22}\end{array}\right]\right) \\
  &= \mathtrace\left( PAZ_{11}A^{\mathconj}-PZ_{11} +PBZ_{12}^{\mathconj}A^{\mathconj}
    +PAZ_{12}B^{\mathconj}+PBZ_{22}B^{\mathconj}\right) \\
  &= \langle P,\mathcal{D}^{adj}\left(Z\right)\rangle 
\end{align*}
and the following properties of $\mathtrace$:
\begin{align*}
  \mathtrace\left(A+B\right) &=
      \mathtrace\left(A\right) + \mathtrace\left(B\right) \\
  \mathtrace\left(AB\right) &=
      \mathtrace\left(A^{\top}B\right) = \mathtrace\left(AB^{\top}\right)
        =\mathtrace\left(B^{\top}A\right) = \mathtrace\left(BA^{\top}\right) \\
  \mathtrace\left(ABCD\right) &= \mathtrace\left(BCDA\right) =
                                \mathtrace\left(CDAB\right) =
                                \mathtrace\left(DABC\right) \\
  \mathtrace\left(ABC\right) &= \mathtrace\left(\left(ABC\right)^{\top}\right)=
                                \mathtrace\left(CBA\right) 
\end{align*}

\subsubsection{The dual of the discrete-time KYP lemma}
\emph{Cheng}
proves the following dual of the discrete-time KYP lemma with the linear
mapping shown in Equation~\ref{eqn:Discrete-time-KYP-lemma-linear-mapping}:
\begin{framed}
  \emph{Proposition 2}~\cite[Section
  3.5]{ChengYiping_ProofDiscreteTimeKYPusingSDPduality}: There exists
  $Z\in\mathbb{H}^{n+m}$ such that:
  \begin{align*}
    Z = \left[\begin{array}{cc}
             Z_{11} & Z_{12} \\
             Z_{12}^{\mathconj} & Z_{22}\end{array}\right] &\prec 0 \\
    AZ_{11}A^{\mathconj} - Z_{11} + BZ_{12}^{\mathconj}A^{\mathconj}
    + AZ_{12}B^{\mathconj} + BZ_{22}B^{\mathconj} &= 0\\
    \mathtrace\left(\Theta Z\right) &\le 0
  \end{align*}
\end{framed}
Here $\Theta$ is as in Equation~\ref{eqn:Discrete-time-KYP-Theta}.
The Octave script \emph{yalmip\_kyp\_dual\_test.m} calls YALMIP to check the
dual of the KYP lemma for the maximum amplitude of a low-pass FIR filter
designed with the Octave \emph{remez} function. Unfortunately, in this script,
SeDuMi fails for the KYP lemma linear mapping of
Equation~\ref{eqn:Discrete-time-KYP-lemma-linear-mapping} but the SDPT3 solver
succeeds. However, SeDuMi does solve the dual mapping and solves the
primal problem when the YALMIP \emph{'dualize'} option is set.

\subsubsection{The dual of the generalised discrete-time KYP lemma}
\emph{Seungil} and
\emph{Doyle}~\cite{SeungilDoyle_LagrangianDualApproachGeneralizedKYP} prove
the generalised discrete-time KYP lemma by the dual of the Lagrangian of
Equation~\ref{eqn:Iwasaki-Hara-Generalised-KYP-LMI}.
\clearpage
\section{Generalisation of the KYP lemma to the union of disjoint  frequency intervals}
\emph{Pipeleers}, \emph{Iwasaki}
and \emph{Hara}~\cite{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals}
describe the generalisation of the KYP lemma to the union of disjoint frequency
intervals. 
\subsection{\label{sec:Union-of-frequency-intervals}Union of frequency intervals}
\emph{Pipeleers}, \emph{Iwasaki} and \emph{Hara} generalise
$\boldsymbol{\Lambda}\left(\Phi,\Psi\right)$, to a union of $l\in\mathbb{N}$
curves with Hermitian matrixes $\Phi,\Psi\in\mathbb{H}^{l+1}$ and a mapping 
$L_{l}\left(\lambda\right)\;:\;\mathbb{C}\rightarrow\mathbb{C}^{l+1}$
defined as:
\begin{align*}
L_{0}\left(\lambda\right)&=1 \\
L_{l}\left(\lambda\right) &=
\left[\lambda^{l},\;\lambda^{l-1},\;\cdots,\;\lambda,\;1\right]^{\top}
\end{align*}
so that:
\begin{align*}
\boldsymbol{\Lambda}\left(\Phi,\Psi\right)&=\left\{\lambda\in\mathbb{C} :
L_{l}\left(\lambda\right)^{\mathconj}\Phi L_{l}\left(\lambda\right) = 0,
L_{l}\left(\lambda\right)^{\mathconj}\Psi L_{l}\left(\lambda\right) \ge 0\right\}
\end{align*}
If $\boldsymbol{\Lambda}\left(\Phi,\Psi\right)$ is unbounded then it is extended
with
\begin{align*}
L_{l}\left(\infty\right)&=\left[1\; 0_{1,l}\right]^{\top}
\end{align*}
In addition, \emph{Pipeleers et al.} define
\begin{align*}
L_{l}\left(\lambda\right)^{\mathreverse} &=
\left[1,\;\lambda^{1},\;\cdots,\;\lambda^{l}\right]^{\top}
\end{align*}

\emph{Pipeleers et al.} make the following two assumptions about the matrixes
$\Phi$ and $\Psi$.

\begin{framed}
\emph{Assumption 1}: The matrixes $\Phi$ and $\Psi$ can be decomposed as
\begin{align}
\label{eqn:GenKYPFreqIneq_Phi_T_Psi_T}
\Phi=T^{\mathconj}\Phi_{o}T, \quad \Psi=T^{\mathconj}\Psi_{o}T
\end{align}
where
\begin{align}
\label{eqn:GenKYPFreqIneq_Phi_o_Psi_o}
  \Phi_{o} = \left[\begin{array}{cc}
                      0 & 1 \\
                      1 & 0 \\
                    \end{array}\right],\quad
  \Psi_{o} = \left[\begin{array}{cc}
                     \alpha & \beta \\
                     \beta & \gamma \\
                   \end{array}\right]
 \text{ where }\alpha < 0 < \gamma\text{ or } 0\le\alpha\le\gamma
\end{align}
for some matrix $T\in\mathbb{C}^{2\times\left(l+1\right)}$ with full row rank
and some $\alpha{}, \beta{},\gamma\in\mathbb{R}$.

For each $s\in\boldsymbol{\Lambda}\left(\Phi_{o},\Psi_{o}\right)$, the $l$-th
degree polynomial in $\lambda$
\begin{align}
\label{eqn:Pipeleers_GenKYPMulFreqInt_2_4}
\begin{split}
\left[1\; -s\right]\;T\;L_{l}\left(\lambda\right)&=0,
\quad\text{for }s\ne\infty\\
\left[0\;\phantom{-}1\right]\;T\;L_{l}\left(\lambda\right)&=0,
\quad\text{for }s=\infty
\end{split}
\end{align}
has $l$ distinct roots grouped in the set $\mathcal{R}_{T}\left(s\right)$.
\end{framed}
\begin{framed}
\emph{Assumption 2}: When $l\ge 2$ we assume that there exists a Hermitian
matrix $R\in\mathbb{H}^{l}$ such that:
\begin{align*}
L_{l-1}\left(\lambda\right)^{\mathconj}R\;L_{l-1}\left(\lambda\right)&>0
\quad\text{for all }\lambda\in\boldsymbol{\Lambda}\left(\Phi,\Psi\right)\\
L_{l-1}\left(\lambda_{p}\right)^{\mathconj}R\;L_{l-1}\left(\lambda_{q}\right)&=0
\quad\text{for all }\lambda_{p},\lambda_{q}\in\mathcal{R}_{T}\left(s\right),
\;p\ne q,\;\text{for all }s\in\boldsymbol{\Lambda}\left(\Phi_{o},\Psi_{o}\right) 
\end{align*}
\end{framed}

Assumption $2$ implies that $R\succ 0$. Assumption $1$ allows a large variety of
curves in $\mathbb{C}$ but only the union of segments of a circle or straight
line has been found to also comply with Assumption $2$. The similarity
transformation, $T$, defines a mapping between the curves
$\boldsymbol{\Lambda}\left(\Phi,\Psi\right)$ and a segment of the imaginary axis
corresponding to $\boldsymbol{\Lambda}\left(\Phi_{o},\Psi_{o}\right)$. Each
$s\in\boldsymbol{\Lambda}\left(\Phi_{o},\Psi_{o}\right)$ is mapped onto the
$l$ roots grouped in
$\mathcal{R}_{T}\left(s\right)\subset\boldsymbol{\Lambda}\left(\Phi,\Psi\right)$,
while all $\lambda\in\mathcal{R}_{T}\left(s\right)$ are mapped into the same $s$:
\begin{align*}
s&=\begin{cases}\frac{\left[1\;0\right]\;TL_{l}\left(\lambda\right)}
{\left[0\;1\right]\;TL_{l}\left(\lambda\right)}=
\frac{t_{1}\left(\lambda\right)}{t_{2}\left(\lambda\right)} & \text{if }
t_{2}\left(\lambda\right)\ne 0 \\
\infty & \text{otherwise}
\end{cases}
\end{align*}
The similarity transformation can be reformulated as:
\begin{align*}
1-s\frac{t_{2}\left(\lambda\right)}{t_{1}\left(\lambda\right)}&=0
\end{align*}
The curve $\boldsymbol{\Lambda}\left(\Phi,\Psi\right)$ corresponds to the set of
complex numbers $\lambda$ that solve this root locus equation for some
$s\in\boldsymbol{\Lambda}\left(\Phi_{o},\Psi_{o}\right)$. As for every such $s$
the roots in $\mathcal{R}_{T}\left(s\right)$ must be distinct, only root locuses
without branching points are allowed.

For $l=1$ the curves, $\boldsymbol{\Lambda}\left(\phi,\psi\right)$, correspond
to the single non-empty and non-singular segments of a circle or line
considered in the generalised KYP lemma of \emph{Iwasaki} and
\emph{Hara}~\cite{Iwasaki_GeneralizedKYPFrequencyDomainInequalities} described in
Section~\ref{sec:Generalised_discrete_time_KYP_theorem}. If, in addition,
$\Phi=0$, then the curve corresponds to the entire circle or line
and the original KYP lemma.

\subsubsection{Union of frequency intervals on the real axis}
\emph{Pipeleers}, \emph{Iwasaki} and \emph{Hara}~\cite[Section
3]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals} describe the
construction of the matrixes $\Phi,\Psi$ and $R$ over a union of segments of the
real axis. Subsequently, the extension of this mapping to the unit circle in the
complex plane is obtained by a M\"{o}bius transformation.

Here $T_{r}$ defines a bijective mapping between
$s\in\boldsymbol{\Lambda}\left(\Phi_{0},\Psi_{0}\right)$ and
$\kappa\in\boldsymbol{\Lambda}\left(\Phi_{r},\Psi_{r}\right)$ and $\tilde{T}$
maps each $\kappa$ into $l$ roots
$\lambda_{k}\in\left[\alpha_{k},\beta_{k}\right]$.

Firstly, on the real axis $\Phi_{r}$ and $\Psi_{r}$ are defined by:
\begin{align*}
  \boldsymbol{\Lambda}\left(\Phi_{r},\Psi_{r}\right)
&=\left\{\lambda\in\mathbb{R} \; :\;
L_{1}^{\mathconj}\left(\lambda\right)\Phi_{r}L_{1}\left(\lambda\right)=0\;,\;
L_{1}^{\mathconj}\left(\lambda\right)\Psi_{r}L_{1}\left(\lambda\right)\ge 0\right\}
=\mathbb{R}_{+}\cup\left\{\infty\right\}
\end{align*}
In this case \emph{Pipeleers et al.} use:
\begin{align*}
\Phi_{r} = \left[\begin{array}{cc}
\phantom{-}0 & \imath\\
-\imath & 0\end{array}\right], \quad
\Psi_{r} = \left[\begin{array}{cc}
0 & 1\\
1 & 0\end{array}\right]
\end{align*}
so that:
\begin{align*}
  L_{1}^{\mathconj}\left(\lambda\right)\Phi_{r}L_{1}\left(\lambda\right)
  &= \left[\begin{array}{cc}
             \lambda & 1\end{array}\right]
             \left[\begin{array}{cc}
\phantom{-}0 & \imath\\
     -\imath & 0\end{array}\right]
             \left[\begin{array}{c}
             \lambda\\
                     1\end{array}\right] = 0
\end{align*}
and:
\begin{align*}
  L_{1}^{\mathconj}\left(\lambda\right)\Psi_{r}L_{1}\left(\lambda\right)
  &= \left[\begin{array}{cc}
             \lambda & 1\end{array}\right]
             \left[\begin{array}{cc}
   0 & 1\\
   1 & 0\end{array}\right]
             \left[\begin{array}{c}
             \lambda\\
                     1\end{array}\right]= 2\lambda > 0
\end{align*}

For $l\in\mathbb{N}$, the matrix
$J_{l}\in\mathbb{R}^{2l\times\left(l+1\right)}$ is defined as:
\begin{align*}
J_{l}&=\left[\begin{array}{cc}
I_{l} & 0_{l,1} \\
0_{l,1} & I_{l}\end{array}\right]
\end{align*}

\begin{framed}
\label{thm:Pipeleers_3_1}\emph{Lemma}~\cite[Lemma
3.1]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals}
: Let $2l$ scalars
$\alpha_{k},\beta_{k}\in\mathbb{R}\cup\left\{\infty\right\}$,
$k\in\mathbb{N}_{l}$, be given that satisfy
\begin{align*}
\alpha_{1}<\beta_{1}<\alpha_{2}<\cdots <\beta_{l-1}<\alpha_{l}<\beta_{l}
\end{align*}
Let the vectors $a,b\in\mathbb{R}^{l+1}$ be defined by:
\begin{align*}
\prod^{l}_{k=1}\left(\lambda-\alpha_{k}\right)&=a^{\top}L_{l}\left(\lambda\right) \\
\prod^{l}_{k=1}\left(\lambda-\beta_{k}\right)&=b^{\top}L_{l}\left(\lambda\right)
\end{align*}
where $\left(\lambda-\alpha_{1}\right)=1$ for $\alpha_{1}=-\infty$ and
$\left(\lambda-\beta_{l}\right)=-1$ for $\beta_{l}=\infty$ and set
$\tilde{T}=\left[-a\;b\right]^{\top}$. Then the matrixes
$\Phi,\Psi\in\mathbb{H}^{l+1}$:
\begin{align*}
\Phi&=\tilde{T}^{\mathconj}\Phi_{r}\tilde{T}\\
\Psi&=\tilde{T}^{\mathconj}\Psi_{r}\tilde{T}
\end{align*}
satisfy Assumptions $1$ and $2$, and
\begin{align*}
\boldsymbol{\Lambda}\left(\Phi,\Psi\right)&=
\bigcup^{l}_{k=1}\left[\alpha_{k},\beta_{k}\right]
\end{align*}
In particular, a matrix $R\in\mathbb{S}^{l}$ satisfying Assumption $2$ is
given by the unique solution of:
\begin{align*}
&\Phi=J^{\mathconj}_{l}\left(\Phi_{r}\otimes R\right)J_{l}\\
&L_{l-1}\left(\lambda\right)^{\mathconj}RL_{l-1}\left(\lambda\right)>0,\quad
\forall\lambda\in\mathbb{R}
\end{align*}
\end{framed}

\emph{Pipeleers et al.} prove this lemma by defining a mapping between
$\kappa\in\boldsymbol{\Lambda}\left(\Phi_{r},\Psi_{r}\right)=
\mathbb{R}_{+}\cup\left\{\infty\right\}$ and
$\lambda\in\boldsymbol{\Lambda}\left(\Phi,\Psi\right)$ where every $\kappa$ is
mapped onto the $l$ roots of:
\begin{align*}
  \left[\begin{array}{cc}
  1 & -\kappa\end{array}\right]\tilde{T}L_{l}\left(\lambda\right)
  &= -a^{\top}L_{l}\left(\lambda\right)-\kappa b^{\top}L_{l}\left(\lambda\right)=0
\end{align*}
For $\kappa=\infty$ this reads as $b^{\top}L_{l}\left(\lambda\right)=0$. Hence,
$\boldsymbol{\Lambda}\left(\Phi,\Psi\right)$ corresponds to the
root-locus plot\footnote{If the closed-loop transfer function of a feedback
  control system is:
  \begin{align*}
    \frac{G\left(s\right)}{1+G\left(s\right)H\left(s\right)}\;  , \quad
      G\left(s\right)H\left(s\right)
      =K\frac{\left(s-z_{1}\right)\hdots\left(s-z_{m}\right)}
        {\left(s-p_{1}\right)\hdots\left(s-p_{n}\right)}
\end{align*}
then the root-locus plot consists of the roots of the characteristic equation
$1+G\left(s\right)H\left(s\right)=0$ for any value of $K$.} of:
\begin{align*}
  \frac{b^{\top}L_{l}\left(\lambda\right)}{a^{\top}L_{l}\left(\lambda\right)}
\end{align*}
\emph{Pipeleers et al.}~\cite[Figure
2]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals} illustrate this lemma
as a transformation
\begin{align*}
    1-s \frac{\imath\kappa+\imath}{\kappa-1}=0
\end{align*}
from $s\in\left[-\imath,\imath\right]$ to
$\kappa\in\mathbb{R}_{+}\cup\left\{\infty\right\}$ followed by a transformation
\begin{align*}
  1+\kappa\frac{\prod^{l}_{k=1}\left(\lambda-\beta_{k}\right)}
  {\prod^{l}_{k=1}\left(\lambda-\alpha_{k}\right)}=0
\end{align*}
from $\kappa$ to the $l$ distinct roots
$\lambda_{k}\in\left[\alpha_{k},\beta_{k}\right]$.

\emph{Pipeleers et al.} state that the following similarity transformation
shows that \emph{Assumption 1} is satisfied:
\begin{align}
\label{eqn:GeneralisedKYPUnionFreqIntervals_Phi_r_Psi_r}
  \Phi_{r}=T_{r}^{\mathconj}\Phi_{o}T_{r},\quad \Psi_{r}=T_{r}^{\mathconj}\Psi_{o}T_{r}
\end{align}
with:
\begin{align}
\label{eqn:GeneralisedKYPUnionFreqIntervals_Psi_o_T_r}
  T_{r}=\frac{1}{\sqrt{2}}\left[\begin{array}{cc}
         1 & -1 \\
    \imath & \phantom{-}\imath\end{array}\right], \quad
  \Psi_{o}=\left[\begin{array}{cc}
           -1 & 0 \\
 \phantom{-}0 & 1 \end{array}\right]
\end{align}
and $T=T_{r}\tilde{T}$. Here $T_{r}$ defines a bijective mapping between
$s\in\boldsymbol{\Lambda}\left(\Phi_{0},\Psi_{0}\right)$ and
$\kappa\in\boldsymbol{\Lambda}\left(\Phi_{r},\Psi_{r}\right)$ and $\tilde{T}$
maps each $\kappa$ into $l$ roots
$\lambda_{k}\in\left[\alpha_{k},\beta_{k}\right]$.

The first part of the Octave script \emph{kyp\_complex\_curve\_union\_test.m}
shows the mapping of the segment of the imaginary axis,
$s\in\left[-\imath,\imath\right]$, to a union of segments of the real axis 
$\lambda\in\left[\alpha_{k},\beta_{k}\right]$. The real parts of the roots of
\begin{align*}
  \left[\begin{array}{cc}
          1 & 0\end{array}\right]T -s\left[\begin{array}{cc}
          0 & 1\end{array}\right]T &=0
\end{align*}
are plotted against $\Im s$. In each case the imaginary
part of the roots is $0$.
Figure~\ref{fig:KYP-complex-curve-union-test-1-root-locus}
shows the plot of the root locus when the intervals are represented by:
\begin{small}
\verbatiminput{kyp_complex_curve_union_test_1_alpha_m1_coef.m}
\verbatiminput{kyp_complex_curve_union_test_1_beta_m1_coef.m}
\end{small}

\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{kyp_complex_curve_union_test_1_root_locus_m1}}
\caption{Test of Assumption 1 for an interval on the imaginary $s$ axis mapped to
  a union of intervals on the real axis.}
\label{fig:KYP-complex-curve-union-test-1-root-locus}
\end{figure}

Figure~\ref{fig:KYP-complex-curve-union-test-1-root-locus-infty} shows the plot
of the root locus when the intervals are represented by:
\begin{small}
\verbatiminput{kyp_complex_curve_union_test_1_alpha_m2_coef.m}
\verbatiminput{kyp_complex_curve_union_test_1_beta_m2_coef.m}
\end{small}

\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{kyp_complex_curve_union_test_1_root_locus_m2}}
\caption{Test of Assumption 1 for an interval on the imaginary $s$ axis mapped to
  a union of intervals on the real axis with $\pm\infty$ endpoints.}
\label{fig:KYP-complex-curve-union-test-1-root-locus-infty}
\end{figure}
\clearpage
\subsubsection{Union of frequency intervals on a circle or line}
\emph{Pipeleers et
  al.}~\cite[pp. 3627-3629]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals}
~\cite[p. 3915]{Pipeleers_GeneralizingKYPUnionFrequencyIntervals} 
consider the union of $l$ non-empty, non-singleton, non-intersecting segments
$\boldsymbol{\Lambda}\left(\Phi,\Psi_{k}\right)$, $k\in\mathbb{N}_{l}$ on an
arbitrary circle or line $\boldsymbol{\Lambda}\left(\Phi,0\right)$. They use a
M\"{o}bius transformation that maps $\boldsymbol{\Lambda}\left(\Phi,0\right)$ to
the real axis, $\boldsymbol{\Lambda}\left(\Phi_{r},0\right)$, and every segment
$\boldsymbol{\Lambda}\left(\Phi,\Psi_{k}\right)$ into an interval
$\left[\alpha_{k},\beta_{k}\right]$ with $\alpha_{k}<\beta_{k}$. For distinct
points $z_{1},z_{2},z_{3}\in\mathbb{C}\cup\left\{\infty\right\}$, the M\"{o}bius
transform
\begin{align}
\label{eqn:Moebius-transform}
\mu\left(\lambda\right)&=\frac{\left(\lambda-z_{1}\right)\left(z_{2}-z_{3}\right)}
                         {\left(\lambda-z_{3}\right)\left(z_{2}-z_{1}\right)}
\end{align}
maps $\left\{z_{1},z_{2},z_{3}\right\}$ onto $\left\{0,1,\infty\right\}$ and
the circle or line through $z_{1},z_{2},z_{3}$ onto the real axis. With any
distinct set of points
$z_{1},z_{2},z_{3}\subset\boldsymbol{\Lambda}\left(\Phi,0\right)$ ,
$z_{3}\notin\bigcup_{k=1}^{l}\boldsymbol{\Lambda}\left(\Phi,\Psi_{k}\right)$,
this transformation satisfies the requirements. Let
$\hat{\Phi},\hat{\Psi}\in\mathbb{H}^{l+1}$  and $\hat{R}\in\mathbb{H}^{l}$ be
the result of applying the Lemma~\cite[Lemma
3.1]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals} to the image of
$\bigcup_{k=1}^{l}\boldsymbol{\Lambda}\left(\Phi,\Psi_{k}\right)$ under the
M\"{o}bius transformation. In addition, set
\begin{align*}
  M&=\left[\begin{array}{cc}
             z_{2}-z_{3} & -z_{1}\left(z_{2}-z_{3}\right) \\
             z_{2}-z_{1} & -z_{3}\left(z_{2}-z_{1}\right)\end{array}\right]
                           =\left[\begin{array}{c}
             M_{1} \\
             M_{2}\end{array}\right]
\end{align*}
and for $k\in\mathbb{N}$ define the matrix
$\boldsymbol{M}_{k}\in\mathbb{R}^{\left(k+1\right)\times\left(k+1\right)}$ as:
\begin{align*}
  \boldsymbol{M}_{k}&=\left[\begin{array}{c}
           \mathconv^{k}\left(M_{1}\right) \\
           \mathconv\left(\mathconv^{k-1}\left(M_{1}\right),M_{2}\right) \\
           \vdots \\
           \mathconv^{k}\left(M_{2}\right) \end{array}\right]
\end{align*}
Then $\Phi,\Psi\in\mathbb{H}^{l+1}$ and $R\in\mathbb{H}^{l}$ defined by
\begin{align*}
  \Phi&=\boldsymbol{M}_{l}^{\mathconj}\hat{\Phi}\boldsymbol{M}_{l} \\
  \Psi&=\boldsymbol{M}_{l}^{\mathconj}\hat{\Psi}\boldsymbol{M}_{l} \\
  R&=\boldsymbol{M}_{l-1}^{\mathconj}\hat{R}\boldsymbol{M}_{l-1} 
\end{align*}
satisfy
$\boldsymbol{\Lambda}\left(\Phi,\Psi\right)=
\bigcup_{k=1}^{l}\boldsymbol{\Lambda}\left(\Phi,\Psi_{k}\right)$
and $\Phi=J^{\mathconj}_{l}\left(\left(M^{\mathconj}\Phi_{r}M\right)\otimes
R\right)J_{l}$.

\paragraph{\emph{Pipeleers et al.} Example 1 : Union of two continuous time
  frequency intervals}
\emph{Pipeleers}, \emph{Iwasaki} and \emph{Hara}~\cite[Example
1]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals} show an example of the
union of two continuous time frequency intervals on the imaginary axis:
\begin{align*}
  \boldsymbol{\Lambda}\left(\Phi,\Psi\right)
  &=\left\{\lambda =\imath\omega\;:\;
    \omega\in\left[\alpha_{1},\beta_{1}\right]\cup
    \left[\alpha_{2},\beta_{2}\right]\right\}
\end{align*}
with $-\infty < \alpha_{1} < \beta_{1} < \alpha_{2} < \beta_{2} < \infty$. A
M\"{o}bius transformation $\mu\left(\lambda\right)$ that maps the imaginary axis
to the real axis is given by:
\begin{align*}
  \mu\left(\lambda\right)&=-\imath\lambda
  \quad \rightarrow \quad M=\left[\begin{array}{cc}
                        -\imath & 0 \\
                        \phantom{-}0 & 1\end{array}\right]
\end{align*}
which is a M\"{o}bius transformation with
$z_{1}=0,z_{2}=\imath,z_{3}=\infty$. As stated above:
\begin{align*}
  \tilde{T}&=\left[\begin{array}{ccc}
-1 & \phantom{-}\imath\alpha_{1}+\imath\alpha_{2}&\phantom{-}\alpha_{1}\alpha_{2}\\
 \phantom{-}1 & -\imath\beta_{1}-\imath\beta_{2}& -\beta_{1}\beta_{2}
                   \end{array}\right]\\
  \Phi&=\tilde{T}^{\mathconj}\Phi_{r}\tilde{T} \\
  \Psi&=\tilde{T}^{\mathconj}\Psi_{r}\tilde{T} \\
  \hat{R}&=\left[\begin{array}{cc}
  \beta_{1}+\beta_{2}-\alpha_{1}-\alpha_{2}&\alpha_{1}\alpha_{2}-\beta_{1}\beta_{2}\\
                        \alpha_{1}\alpha_{2}-\beta_{1}\beta_{2}&
                        \beta_{1}\beta_{2}\left(\alpha_{1}+\alpha_{2}\right)-
                        \alpha_{1}\alpha_{2}\left(\beta_{1}+\beta_{2}\right)
  \end{array}\right]\\
  R&=M^{\mathconj}\hat{R}M
\end{align*}
\paragraph{\emph{Pipeleers et al.} Example 2 : Union of two discrete time
  frequency intervals}
\emph{Pipeleers}, \emph{Iwasaki} and \emph{Hara}~\cite[Example
2]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals} show an example of the
union of two discrete time frequency intervals on the unit circle (see
Equation~\ref{eqn:Lambda-sigma-unit-circle}):
\begin{align*}
\boldsymbol{\Lambda}\left(\Phi,\Psi\right)&=\left\{\lambda =e^{\imath\theta}\;
:\; \theta\in\left[\eta_{1},\zeta_{1}\right]\cup
\left[\eta_{2},\zeta_{2}\right]\right\}
\end{align*}
with $-\pi < \eta_{1} < \zeta_{1}< \eta_{2} < \zeta_{2} < \pi$. 
A M\"{o}bius
transform that maps the unit circle to the real axis is:
\begin{align*}
\mu\left(\lambda\right)&=-\imath\frac{\lambda-1}{\lambda+1}
\quad \rightarrow \quad M=\left[\begin{array}{cc}
-\imath & \imath \\
\phantom{-}1 & 1 \end{array}\right]
\end{align*}
with $z_{1}=1,z_{2}=\imath,z_{3}=-1$ and where
the two discrete time frequency intervals are mapped into the real axis
intervals $\left[\alpha_{k}=\mu\left(e^{\imath\eta_{k}}\right),
 \beta_{k}=\mu\left(e^{\imath\zeta_{k}}\right)\right]$.
The corresponding $\Phi$ and $\Psi$ matrixes are:
\begin{align*}
\Phi&=\tilde{T}^{\mathconj}\left[\begin{array}{cc}
\phantom{-}0 & \imath c \\
-\imath \bar{c} & 0\end{array}\right]\tilde{T} \\
\Psi&=\tilde{T}^{\mathconj}\left[\begin{array}{cc}
0 & c \\
\bar{c} & 0\end{array}\right]\tilde{T}
\end{align*}
where:
\begin{align*}
 c&=\left(1+\imath\alpha_{1}\right)\left(1+\imath\alpha_{2}\right)
\left(1-\imath\beta_{1}\right)\left(1-\imath\beta_{2}\right) \\
\tilde{T}&=\left[\begin{array}{ccc}
-1&\phantom{-}e^{\imath\eta_{1}}+e^{\imath\eta_{2}}&-e^{\imath\eta_{1}}e^{\imath\eta_{2}}\\
\phantom{-}1&-e^{\imath\zeta_{1}}-e^{\imath\zeta_{2}} &
\phantom{-}e^{\imath\zeta_{1}}e^{\imath\zeta_{2}}\end{array}\right]
\end{align*}

The third part of the Octave script \emph{kyp\_complex\_curve\_union\_test.m}
shows the mapping of a union of segments of the unit circle to a union of
segments of the real axis $\lambda\in\left[\alpha_{k},\beta_{k}\right]$. The
angles of the roots of
\begin{align*}
  \left[\begin{array}{cc}
          1 & 0\end{array}\right]T -s\left[\begin{array}{cc}
          0 & 1\end{array}\right]T &=0
\end{align*}
are plotted against $\Im s$. Recall that we are first mapping the
imaginary axis to the real axis so that $T=T_{r}\tilde{T}$.
In each case the magnitude of the roots is $1$.
Figure~\ref{fig:KYP-complex-curve-union-test-3-root-locus}
shows the plot of the root locus when the intervals are represented by:
\begin{small}
\verbatiminput{kyp_complex_curve_union_test_3_eta_coef.m}
\verbatiminput{kyp_complex_curve_union_test_3_zeta_coef.m}
\end{small}

\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{kyp_complex_curve_union_test_3_root_locus}}
\caption{Test of Assumption 1 for an interval on the unit circle mapped to
  a union of intervals on the real axis.}
\label{fig:KYP-complex-curve-union-test-3-root-locus}
\end{figure}

The fourth part of the Octave script \emph{kyp\_complex\_curve\_union\_test.m}
shows the mapping of a union of segments of the unit circle to a union of
segments of the real axis $\lambda\in\left[\alpha_{k},\beta_{k}\right]$ when
the upper limit of one segment on the real axis is $\beta_{l}=\infty$. In this
case I use $\hat{\Phi}$, $\hat{\Psi}$ and $\hat{R}$. The angles
of the roots of
\begin{align*}
  \left[\begin{array}{cc}
          1 & 0\end{array}\right]T -s\left[\begin{array}{cc}
          0 & 1\end{array}\right]T &=0
\end{align*}
are plotted against $\Im s$. In each case the magnitude of the roots is $1$.
Figure~\ref{fig:KYP-complex-curve-union-test-4-root-locus}
shows the plot of the root locus when the intervals are represented by:
\begin{small}
\verbatiminput{kyp_complex_curve_union_test_4_eta_coef.m}
\verbatiminput{kyp_complex_curve_union_test_4_zeta_coef.m}
\end{small}

\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{kyp_complex_curve_union_test_4_root_locus}}
\caption{Test of Assumption 1 for an interval on the unit circle mapped to
  a union of intervals on the real axis when $\beta_{l}=\infty$.}
\label{fig:KYP-complex-curve-union-test-4-root-locus}
\end{figure}

\subsection{Generalised KYP lemma over a union of frequency intervals}
\emph{Pipeleers}, \emph{Iwasaki}
and \emph{Hara}~\cite{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals}
show the following preliminary definitions.
For $A\in\mathbb{C}^{n\times n}$, $B\in\mathbb{C}^{n\times m}$ and
$l\in\mathbb{N}$, define
$F_{l}\left(A,B\right)\in\mathbb{C}^{\left(l+1\right)n\times\left(n+ml\right)}$:
\begin{align*}
F_{l}\left(A,B\right)&=\left[\begin{array}{ccccc}
A^{l} & A^{l-1}B & A^{l-2}B & \cdots & B \\
A^{l-1} & A^{l-2}B & \cdots & B & 0 \\
\hdots & \hdots & \hdots & \hdots & \hdots \\
A & B & 0 & \hdots & 0 \\
I & 0 & \hdots & \hdots & 0\\
\end{array}\right]
\end{align*}
Similarly, define $G_{l}\left(A,B\right)
\in\mathbb{C}^{\left(n+m\right)\times\left(n+ml\right)}$\footnote{\emph{Pipeleers
et al.}~\cite[Equation 2.8]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals}
show the last term as $F_{l}\left(0_{m,m},I_{m}\right)$.}: 
\begin{align*}
G_{l}\left(A,B\right)&=\left(I_{l}\otimes\left[\begin{array}{c}
I_{n}\\
0_{m,n}\end{array}\right]\right)\left[\begin{array}{cc}
F_{l-1}\left(A,B\right) & 0_{nl,m}\end{array}\right]
+\left(I_{l}\otimes\left[\begin{array}{c}
0_{n,m}\\
I_{m}\end{array}\right]\right)\left[\begin{array}{cc}
0_{ml,n} & F_{l-1}\left(0_{m,m},I_{m}\right)\end{array}\right]
\end{align*}
For example:
\begin{align*}
G_{2}\left(A,B\right)&=\left[\begin{array}{ccc}
A & B & 0_{n,m} \\
0_{m,n} & 0_{m,m} & I_{m} \\
I_{n} & 0_{n,m} & 0_{n,m} \\
0_{m,n} & I_{m} & 0_{m,m}\end{array}\right]
\end{align*}

In addition, for $\lambda\in\mathbb{C}$, define the set
$\mathcal{N}_{A,B}\left(\lambda\right)$ as:
\begin{align*}
\mathcal{N}_{A,B}\left(\lambda\right)&=\begin{cases}
\left(x,u\right)\in \mathbb{C}^{n}\times\mathbb{C}^{m}\; :\; \left(\lambda
I-A\right)x=Bu & \text{for }\lambda\ne\infty \\
\left\{0\right\}\times\mathbb{C}^{m} & \text{for }\lambda = \infty
\end{cases}
\end{align*}
Note that if $\det\left(\lambda I-A\right)\ne 0$, every element of
$\mathcal{N}_{A,B}\left(\lambda\right)$ is of the form:
\begin{align*}
\left[\begin{array}{c}
\left(\lambda I-A\right)^{-1}B \\
I\end{array}\right] u
\end{align*}
for some $u\in\mathbb{C}^{m}$.

Firstly, \emph{Pipeleers et al.} prove the following two Lemmas:
\begin{framed}
\emph{Lemma 2.3}~\cite[Lemma 2.3 and Appendix
A]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals}: Let matrixes
$A\in\mathbb{C}^{n\times n}$, $B\in\mathbb{C}^{n\times m}$ and
$T\in\mathbb{C}^{2\times \left(l+1\right)}$, be given, and assume $B$ has full
column rank and $T$ full row rank. In addition, let
$s\in\mathbb{C}\cup\left\{\infty\right\}$ be given and assume that the $l$ roots
$\lambda_{k}$, $k\in\mathbb{N}_{l}$, in $\mathcal{R}_{T}\left(s\right)$ are
all distinct. Then a vector $z\in\mathbb{C}^{n+ml}$ satisfies
\begin{align}
\label{eqn:Pipeleers_GenKYPMulFreqInt_A_1}
\begin{split}
\left(\left[1\; -s\right]\otimes{}I_{n}\right)
\left(T\otimes{}I_{n}\right)F_{l}z &=0 \quad\text{for }s\ne\infty \\
\left(\left[0\; \phantom{-}1\right]\otimes{}I_{n}\right)
\left(T\otimes{}I_{n}\right)F_{l}z &=0 \quad\text{for }s=\infty
\end{split}
\end{align}
if-and-only-if it can be decomposed as
\begin{align*}
z=\sum^{l}_{k=1}\left[\begin{array}{c}
x_{k} \\
L_{l-1}\left(\lambda_{k}\right)^{\mathreverse}\otimes{}u_{k}
\end{array}
\right]
\end{align*}
with $\left(x_{k},u_{k}\right)\in\mathcal{N}_{A,B}\left(\lambda_{k}\right)$ for
all $k\in\mathbb{N}_{l}$.
\end{framed}
The proof of Lemma 2.3 proceeds by elaborating each $F_{l}z_{k}$ recursively
from the bottom row to the top row and recalling the definition of
$L_{l}\left(\infty\right)$:
\begin{align*}
F_{l}\left[\begin{array}{c}
x_{k} \\
L_{l-1}\left(\lambda_{k}\right)\otimes{}u_{k}\end{array}\right]
=L_{l}\left(\lambda_{k}\right)\otimes\chi\left(x_{k},u_{k}\right) 
\end{align*}
where
\begin{align*}
\chi\left(x_{k},u_{k}\right)=\begin{cases}
x_{k}  & \text{if } \lambda\ne\infty \\
Bu_{k} & \text{if } \lambda{}=\infty
\end{cases}
\end{align*}
As $\lambda_{k}$ are the $l$ roots of
Equation~\ref{eqn:Pipeleers_GenKYPMulFreqInt_2_4}, each $z_{k}$ satisfies
Equation~\ref{eqn:Pipeleers_GenKYPMulFreqInt_A_1} and so does
$z=\sum^{l}_{k=1}z_{k}$. 
\begin{framed}
\emph{Lemma 2.4}~\cite[Lemma 2.4 and Appendix
B]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals}: Let
$\Phi_{o},\Psi_{o}\in\mathbb{H}^{2}$  of the form shown in
Equation~\ref{eqn:GenKYPFreqIneq_Phi_o_Psi_o} be given, as well as
$X,Y\in\mathbb{C}^{n\times m}$. Then
\begin{align}
\label{eqn:Pipeleers_GenKYPMulFreqInt_2_15}
\begin{split}
\left[\begin{array}{cc}
X & Y
\end{array}\right]\left(\Phi_{o}\otimes{}I_{m}\right)\left[\begin{array}{c}
X^{\mathconj}\\
Y^{\mathconj}
\end{array}\right] = 0 \\
\left[\begin{array}{cc}
X & Y
\end{array}\right]\left(\Psi_{o}\otimes{}I_{m}\right)\left[\begin{array}{c}
X^{\mathconj}\\
Y^{\mathconj}
\end{array}\right] \succeq 0
\end{split}
\end{align}
hold if-and-only-if $X$ and $Y$ can be factored as
\begin{align}
\label{eqn:Pipeleers_GenKYPMulFreqInt_2_16}
\begin{split}
X&=W\mathdiag\left(s_{1},\ldots,s_{m}\right)V^{\mathconj} \\
Y&=WV^{\mathconj}
\end{split}
\end{align}
with some $W\in\mathbb{C}^{n\times{}m}$, unitary $V\in\mathbb{C}^{m\times{}m}$
and $s_{k}\in\Lambda\left(\Phi_{o},\Psi_{o}\right)$ for all $k\in\mathbb{N}_{m}$.
\end{framed}

\emph{Pipeleers et al.}~\cite[Appendix
B]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals} show a construction for
$W$ and $V$. The  equality is equivalent to
\begin{align*}
XY^{\mathconj}+YX^{\mathconj}&= -XY^{\mathconj} - YX^{\mathconj} \\
\left(X+Y\right)\left(X+Y\right)^{\mathconj}&=
\left(X-Y\right)\left(X-Y\right)^{\mathconj}
\end{align*}
so that $X+Y$ and $X-Y$ have the same left singular vectors and singular values
\begin{align*}
X+Y &= P\Sigma{}Q^{\mathconj}_{1} \\
X-Y &= P\Sigma{}Q^{\mathconj}_{2}
\end{align*}
where $P\in\mathbb{C}^{n\times{}n}$ is unitary,
$Q_{1},Q_{2}\in\mathbb{C}^{m\times{}m}$ are unitary and
$\Sigma\in\mathbb{R}^{n\times{}m}$ is diagonal. The matrix
$Q_{1}^{\mathconj}Q_{2}$ is unitary and can be factorised as 
$V\mathdiag\left(\sigma_{k}\right)V^{\mathconj}$ with $\mathabs{\sigma_{k}}=1$
for $k=1,\ldots,m$. Define $W=YV$ and
$s_{k}=\left(1+\sigma_{k}\right)/\left(1-\sigma_{k}\right)$. If
$\sigma_{k}=e^{\imath\omega_{k}}$ then the $s_{k}=\imath\cotan\frac{\omega_{k}}{2}$
result from a mapping of the unit circle to the imaginary axis in the complex
plane. Expanding Equation~\ref{eqn:Pipeleers_GenKYPMulFreqInt_2_15} and
substituting Equation~\ref{eqn:Pipeleers_GenKYPMulFreqInt_2_16}\footnote{For
$s_{k}\in\Lambda\left(\Phi_{o},\Phi_{o}\right)$ defined in
Equation~\ref{eqn:IwasakiHaraDiscreteTimeKYPLambda} and $\Phi_{o}$
and $\Psi_{o}$ defined in Equation~\ref{eqn:GenKYPFreqIneq_Phi_o_Psi_o}
\begin{align*}
\left[\begin{array}{cc}
s_{k}^{\mathconj} & 1\end{array}\right]\Phi_{o}\left[\begin{array}{c}
s_{k} \\
1\end{array}\right] &= s_{k}^{\mathconj}+s_{k} =0 \\
\left[\begin{array}{cc}
s_{k}^{\mathconj} & 1\end{array}\right]\Psi_{o}\left[\begin{array}{c}
s_{k} \\
1\end{array}\right] &=
\alpha{} s_{k}s_{k}^{\mathconj}+\beta{}s_{k}+\beta{}s_{k}^{\mathconj}+\gamma
=\alpha\mathabs{s_{k}}^{2}+\gamma \ge 0
\end{align*}}
\begin{align*}
XY^{\mathconj}+YX^{\mathconj}&= W\mathdiag\left(s_{k}\right)V^{\mathconj}VW^{\mathconj}+
WV^{\mathconj}V\mathdiag\left(s_{k}\right)^{\mathconj}V^{\mathconj}W^{\mathconj} =
\mathdiag\left(s_{k}+s_{k}^{\mathconj}\right) = 0 \\
\alpha XX^{\mathconj}+\gamma YY^{\mathconj}&=
\alpha{}W\mathdiag\left(s_{k}\right)V^{\mathconj}
V\mathdiag\left(s_{k}\right)^{\mathconj}W^{\mathconj} +
\gamma{}WV^{\mathconj}VW^{\mathconj} =
\alpha\mathdiag\left(\mathabs{s_{k}}^{2}\right)+\gamma \succeq 0
\end{align*}

\emph{Pipeleers et al.} now prove the following generalised KYP lemma for
non-strict inequalities\footnote{The Octave script
  \emph{yalmip\_kyp\_check\_iir\_bandpass\_test.m} uses
  the generalised KYP lemma to check the response of a parallel all-pass
  one-multiplier Schur lattice filter designed by the Octave script
  \emph{schurOneMPAlattice\_socp\_slb\_bandpass\_delay\_test.m}. The filter is
  intended to have a pass-band phase that is an integer multiple of $\pi$ plus
  the nominal pass-band phase shift so that the pass-band response may be
  compared to a delay of an integral number of samples.}:
\begin{framed}
\emph{Theorem}~\cite[Theorem
2.2, Appendix C]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals}: Let
Hermitian matrixes $\Phi,\;\Psi\in\mathbb{H}^{l+1}$ and
$\Theta\in\mathbb{H}^{m+n}$, and matrixes $A\in\mathbb{C}^{n\times n}$ and
$B\in\mathbb{C}^{n\times m}$, be given, with $B$ of full column rank and
$\left(A,B\right)$ controllable. Suppose $\Phi$ and $\Psi$ satisfy Assumptions 1
and 2, and let $R\in\mathbb{H}^{l}$ be a matrix satisfying Assumption 2. Then
the following statements are equivalent:
\begin{enumerate}
\item The inequality:
\begin{align*}
\left[\begin{array}{c}
x \\
u
\end{array}\right]^{\mathconj}\Theta\left[\begin{array}{c}
x \\
u
\end{array}\right]\le 0
\end{align*}
holds for all $\left(x,u\right)\in\mathcal{N}_{A,B}\left(\lambda\right)$
\item There exist $P,Q\in\mathbb{H}^{n}$ that satisfy $Q\succeq 0$ and
\begin{align*}
F_{l}\left(A,B\right)^{\mathconj}\left(\Phi\otimes P+\Psi\otimes Q\right)
F_{l}\left(A,B\right) +
G_{l}\left(A,B\right)^{\mathconj}\left(R\otimes\Theta\right)
G_{l}\left(A,B\right)\preceq 0
\end{align*}
\end{enumerate}
\end{framed}

The terms in $\left[\begin{array}{cc}C & D\end{array}\right]$ are
linearised by applying the Schur complement to $R\otimes\Theta$:
\begin{align*}
R\otimes\Theta &= R\otimes\left(\left[\begin{array}{cc}
C & D\\
0 & I\end{array}\right]^{\mathconj}\left[\begin{array}{cc}
\Pi_{11} & \Pi_{12} \\
\Pi_{12}^{\mathconj} & \Pi_{22}\end{array}\right]\left[\begin{array}{cc}
C & D \\
0 & I\end{array}\right]\right)\\
&=R\otimes\left[\begin{array}{cc}
0 & C^{\mathconj}\Pi_{12} \\
\Pi_{12}^{\mathconj}C &
D^{\mathconj}\Pi_{12}+\Pi_{12}^{\mathconj}D+\Pi_{22}\end{array}\right]
+ R\otimes\left(\left[\begin{array}{cc}
C & D\end{array}\right]^{\mathconj}\Pi_{11}\left[\begin{array}{cc}
C & D \end{array}\right]\right)\\
&=R\otimes\left[\begin{array}{cc}
0 & C^{\mathconj}\Pi_{12} \\
\Pi_{12}^{\mathconj}C &
D^{\mathconj}\Pi_{12}+\Pi_{12}^{\mathconj}D+\Pi_{22}\end{array}\right]
+ \left(I_{2}\otimes\left[\begin{array}{cc}
C & D\end{array}\right]\right)^{\mathconj}\left(R\otimes\Pi_{11}\right)
\left(I_{2}\otimes\left[\begin{array}{cc}
C & D \end{array}\right]\right)
\end{align*}
where I have made repeated use of the mixed product rule,
$\left(A\otimes B\right)\left(C\otimes D\right)=
\left(AC\right)\otimes\left(BD\right)$. If $R\otimes\Pi_{11}\succeq{}0$ then
the Schur complement includes $-\left(R\otimes\Pi_{11}\right)^{-1}$.

\subsection{Examples of FIR filter design with the generalised KYP lemma extended to the  union of disjoint frequency bands}
\subsubsection{Design of a symmetric band pass FIR filter with the union of the upper and lower stop bands}
The Octave script \emph{directFIRsymmetric\_kyp\_union\_bandpass\_test.m} uses
\emph{Pipeleer et al.}'s generalised KYP lemma to design a band pass FIR filter
with a specification similar to that of their example~\cite[Figure
4]{Pipeleers_GeneralizingKYPMultipleFrequencyIntervals}. The stop band LMI
is expressed as the union of the upper and lower stop band frequency intervals:
\begin{align*}
\left[\eta_{1},\zeta_{1}\right]\cup\left[\eta_{2},\zeta_{2}\right]&=
2\pi\left[-f_{asl}, f_{asl}\right]\cup 2\pi\left[ f_{asu}, 1-f_{asu}\right]
\end{align*}
The M\"{o}bius transformation from the unit circle to the real axis is chosen as
$z_{1}=1,z_{2}=\imath,z_{3}=-\imath$. In the pass band the filter
response is compared to a nominal delay. In the stop band
$\mathabs{H\left(\omega\right)}^{2}\le\varepsilon_{s}^{2}$. 

The filter specification is:
\begin{small}
\verbatiminput{directFIRsymmetric_kyp_union_bandpass_test_spec.m}
\end{small}
The value of $\varepsilon^{2}_{z}$ was found by trial-and-error. The actual
maximum squared-error in the pass-band compared with a pure delay is
$\varepsilon^{2}_{z}=$
\input{directFIRsymmetric_kyp_union_bandpass_test_max_passband_squared_error.tab}.
I did not achieve the pass-band error of $\varepsilon_{z}=\;$2.5e-4 specified by
\emph{Pipeleers et al.}. The resulting FIR impulse response is:
\begin{small}
\verbatiminput{directFIRsymmetric_kyp_union_bandpass_test_h_coef.m}
\end{small}
Figure~\ref{fig:Direct-FIR-symmetric-KYP-union-bandpass-response} shows the
stop band and pass band amplitude responses.

\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRsymmetric_kyp_union_bandpass_test_response}}
\caption{Stop band and pass band amplitude responses of a symmetric FIR band
pass filter designed with the generalised KYP lemma over a union of stop band
regions.}
\label{fig:Direct-FIR-symmetric-KYP-union-bandpass-response}
\end{figure}

\subsubsection{Design of a non-symmetric band pass FIR filter with the union of the upper and lower stop bands}
The Octave script \emph{directFIRnonsymmetric\_kyp\_union\_bandpass\_test.m}
uses \emph{Pipeleer et al.}'s generalised KYP lemma to design a non-symmetric
band pass FIR filter. The M\"{o}bius transformation from the unit circle to the
real axis is chosen as $z_{1}=1,z_{2}=\imath,z_{3}=-\imath$~(see
Equation~\ref{eqn:Moebius-transform}). In the pass band the filter response is
compared to a nominal delay. In the stop band
$\mathabs{H\left(\omega\right)}^{2}\le\varepsilon_{s}^{2}$. The filter
specification is:
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_union_bandpass_test_spec.m}
\end{small}
The resulting FIR impulse response is:
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_union_bandpass_test_h_coef.m}
\end{small}
The value of $\varepsilon^{2}_{z}$ was found by trial-and-error. The actual
maximum squared-error in the pass-band compared with a pure delay is
$\varepsilon^{2}_{z}=$
\input{directFIRnonsymmetric_kyp_union_bandpass_test_max_passband_squared_error.tab}.

Figure~\ref{fig:Direct-FIR-nonsymmetric-KYP-union-bandpass-response} shows the
amplitude, phase and delay responses. The pass band phase error is adjusted for
the nominal delay. 
Figure~\ref{fig:Direct-FIR-nonsymmetric-KYP-union-bandpass-zeros} shows the
zeros of the transfer function.
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRnonsymmetric_kyp_union_bandpass_test_response}}
\caption{Amplitude, phase error and delay responses of a non-symmetric
FIR band pass filter designed with the generalised KYP lemma over a union of
stop band regions. The pass band phase error is adjusted for the nominal delay.} 
\label{fig:Direct-FIR-nonsymmetric-KYP-union-bandpass-response}
\end{figure}
\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRnonsymmetric_kyp_union_bandpass_test_zeros}}
\caption{Zeros of a non-symmetric FIR band pass filter designed with the
  generalised KYP lemma over a union of stop band regions.} 
\label{fig:Direct-FIR-nonsymmetric-KYP-union-bandpass-zeros}
\end{figure}
\subsubsection{Design of a non-symmetric band pass FIR filter with the union of
  multiple pass bands and stop bands}
The Octave script
\emph{directFIRnonsymmetric\_kyp\_union\_double\_bandpass\_test.m}
uses \emph{Pipeleer et al.}'s generalised KYP lemma to design a non-symmetric
band pass FIR filter with the union of two pass bands and the union of three
stop bands. The filter amplitude response is similar to that of the symmetric
FIR filter shown in
Figure~\ref{fig:mcclellanFIRsymmetric-multiband-test-response}.

In the pass band the filter response is compared to a nominal delay. In the
stop band $\mathabs{H\left(\omega\right)}^{2}\le\varepsilon_{s}^{2}$. The filter
specification is:
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_union_double_bandpass_test_spec.m}
\end{small}

In the pass bands, the M\"{o}bius transformation from the unit circle to the
real axis is chosen as $z_{1}=1,z_{2}=\imath,z_{3}=-\imath$. In the stop bands
each of these $z$s is rotated by $\pi\left(f_{sl2}-f_{pu1}\right)$ radians
so that $z_{3}$ is not in a stop band. The resulting FIR impulse response is:
\begin{small}
\verbatiminput{directFIRnonsymmetric_kyp_union_double_bandpass_test_h_coef.m}
\end{small}

Figure~\ref{fig:Direct-FIR-nonsymmetric-KYP-union-double-bandpass-response}
shows the amplitude, phase and group delay responses. The pass band
phase error is adjusted for the nominal delay. 
The actual maximum squared-error in the pass-band compared with a pure delay is
$\varepsilon^{2}_{z}=$
\input{directFIRnonsymmetric_kyp_union_double_bandpass_test_max_passband_squared_error.tab}.

\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{directFIRnonsymmetric_kyp_union_double_bandpass_test_response}}
\caption{Amplitude, phase and group delay responses of a non-symmetric FIR band
  pass filter designed with the generalised KYP lemma with multiple pass and
  stop bands.}
\label{fig:Direct-FIR-nonsymmetric-KYP-union-double-bandpass-response}
\end{figure}

SeDuMi fails with a ``\emph{Run into numerical problems}'' warning with the
default \emph{eps=1e-9} so it is increased in the YALMIP options. YALMIP still
warns about numerical problems. This warning is removed by setting the YALMIP
constraints as :
\begin{small}
\begin{verbatim}
Constraints=[F_plu<=-sedumi_eps,Q_plu>=0,F_slmu<=-sedumi_eps,Q_slmu>=0];
\end{verbatim}
\end{small}
The resulting filter frequency response is acceptable. These numerical problems
occurred for all combinations of $N$ and $d$ that I tried.
\clearpage
\section{Design of one-multiplier Schur lattice  filters with the KYP lemma}
This section considers the use of the KYP lemma to design IIR filters
implemented as the parallel combination of two all-pass one-multiplier Schur
lattice filters. The matrix inequality part of the KYP lemma shown in
Equation~\ref{eqn:Iwasaki-Hara-Generalised-KYP-LMI} is not linear in the state
transition matrix, $A$, coefficients and the design problem requires the
solution of bilinear matrix inequality (BMI) constraints. The design of robust
feedback control systems has motivated much research into the solution of BMI
constraints derived from the KYP lemma. See, for example, \emph{Van Antwerp} and
\emph{Braatz}~\cite{VanAntwerpBraatz_LinearBilinearMatrixInequalities} or
\emph{Dinh et
 al.}~\cite[Section 1]{Dinh_ConvexConcaveDecompositionLinearizationBMI}.
\begin{comment}
  \emph{Dinh et al.} consider the following state variable description of a
  feedback control system:
 \begin{align*}
    \left[\begin{array}{c}
            x^{\prime} \\
            z \\
            y \end{array}\right]
    &= \left[\begin{array}{ccc}
               A & B_{w} & B_{u} \\
               C_{z} & D_{zw} & D_{zu} \\
               C_{y} & D_{yw} & 0 \end{array}\right]
      \left[\begin{array}{c}
              x \\
              w \\
              u \end{array}\right]
 \end{align*}
  where $x$ is the state vector, $w$ is the control input, $u$ is an input
  disturbance, $y$ is the output to be controlled and $z$ is the output
  measurement. The state variable coefficients are known. The design
  objective is to find a feedback gain, $K$, such that $u=Ky$ and the following
  closed loop system is stable:
  \begin{align*}
    \left[\begin{array}{c}
            x^{\prime} \\
            z \end{array}\right]
    &= \left[\begin{array}{cc}
               A + B_{u}K C_{y} & B_{w}+B_{u}K D_{yw} \\
               C_{z} + D_{zu}K C_{y}& D_{zw} + D_{zu}K D_{yw}\end{array}\right]
      \left[\begin{array}{c}
              x \\
              w \end{array}\right]
  \end{align*}
\end{comment}
The solution of an optimisation problem with BMI constraints can be obtained
as the limit of a sequence of upper bounding convex (or LMI) problems.
\emph{Duffin} and \emph{Peterson}~\cite[p.533]{Duffin_ReversedGeometricPrograms}
describe the solution of a ``geometric program'' by a sequence of ``upper-bound
inequality posynomial'' constraints.
\emph{Marks} and \emph{Wright}~\cite{Marks_InnerApproximationNonconvexPrograms}
demonstrated the convergence of a ``sequence of approximating convex programs''.
\emph{Dinh et al.}~\cite{Dinh_ConvexConcaveDecompositionLinearizationBMI,
Dinh_InnerConvexApproximationBMI} ``decompose the bilinear mapping as a
difference between two positive semidefinite convex mappings. At each iteration
of the algorithm the concave part is linearized, leading to a convex
subproblem''. \emph{Lee} and \emph{Hu}~\cite{Lee_SequentialConvexApproxBMI},
\emph{Warner} and
\emph{Scruggs}~\cite{WarnerScruggs_IterativeConvexOverboundingBMI},
\emph{Sebe}~\cite{Sebe_SequentialConvexOverboundingBMI}
and \emph{Ren et al.}~\cite{Ren_SuccessiveConvexOptimizationBMI} each show an
alternative method of convex upper approximation to the BMI constraint.

\subsection{Preliminaries}
\subsubsection{Positive-semi-definite convex mappings}
Suppose the mapping $\mathcal{A}\colon\mathbb{R}^{n}\rightarrow\mathbb{S}^{p}$
is represented by $A\left(x\right)\in\mathbb{S}^{p}$, the set of symmetric
$p\times p$ matrixes. $A\left(x\right)$ is said to be \emph{psd-convex} on a
convex set, $\mathcal{C}\subseteq\mathbb{R}^{n}$, if, for $t\in\left[0,1\right]$
and $x,y\in\mathcal{C}$:
\begin{align*}
A\left(tx+\left[1-t\right]y\right) & \preceq
tA\left(x\right)+\left[1-t\right]A\left(y\right)
\end{align*}
Similarly, $-A\left(x\right)$ is \emph{psd-concave}.
The first-order linearised approximation at $x=x_{i}+\Delta_{x}$ of a psd-convex
mapping $\mathcal{A}$ represented by $A\left(x\right)$
satisfies~\cite[Section 3.1.3]{BoydVandenberghe_ConvexOptimization}:
\begin{align*}
  A\left(x_{i}\right) + \nabla A\left(x_{i}\right)\Delta_{x}
  \preceq A\left(x\right), \text{ for all } x\in\mathcal{C}
\end{align*}

\subsubsection{Schur complement of a psd-convex mapping}
\emph{Dinh et al.}~\cite[Section
3.1]{Dinh_ConvexConcaveDecompositionLinearizationBMI}
define a \emph{Schur psd-convex} mapping as
$\mathcal{F}\colon \mathbb{R}^{p\times q}\times\mathbb{S}^{p}
\rightarrow\mathbb{S}^{p}$
given by $F\left(X,Y\right)=XQ^{-1}X^{\top}-Y$, where $Q\in\mathbb{S}^{p}_{++}$,
the set of symmetric, positive definite, $p\times p$ matrixes. They show the
following lemma, used to transform a Schur psd-convex constraint into an LMI
constraint~\cite[Lemma 3.2]{Dinh_ConvexConcaveDecompositionLinearizationBMI}:
\begin{framed}
  \emph{Lemma 3.2}~\cite{Dinh_ConvexConcaveDecompositionLinearizationBMI}:
  \begin{enumerate}
  \item Suppose that $A\in\mathcal{S}^{n}$. Then:
    \begin{align}
      \label{eqn:Dinh-convex-Schur-complement}
      BB^{\top}-A\preceq 0
      \quad & \Longleftrightarrow\quad
      \left[\begin{array}{cc}
              A & B \\
              B^{\top}& I\end{array}\right] \succeq 0 
    \end{align}
  \item Suppose that $A\in\mathbb{S}^{n}$ and $D\succeq 0$ then:
    \begin{align}
      \label{eqn:Dinh-convex-concave-Schur-complement}
      \left[\begin{array}{cc}
              A-BB^{\top} & C \\
              C^{\top}& D\end{array}\right] \succeq 0
      \quad & \Longleftrightarrow\quad
      \left[\begin{array}{ccc}
              A & B & C \\
              B^{\top}& I & 0 \\
              C^{\top}& 0 & D\end{array}\right] \succeq 0          
    \end{align}
  \end{enumerate}
\end{framed}
\subsubsection{Problem statement}
This section considers the following optimisation problem with bilinear matrix
inequality constraints~\cite[Equation 1]{Lee_SequentialConvexApproxBMI}:
\begin{samepage}
  \begin{align*}
    \textbf{minimise}\quad &f\left(z\right) \\
    \textbf{subject to}\quad
                           & z\in\mathcal{C} \\
                           & F\left(z\right)=C+D\left(z\right) +
                             \mathhe\left(A\left(x\right)B\left(y\right)\right)
                             \preceq 0
  \end{align*}
\end{samepage}
where $z^{\top}=\left[x^{\top},y^{\top}\right]\in\mathbb{R}^{n}$, 
$\mathhe\left(X\right)=X+X^{\top}$, $f\colon\mathbb{R}^{n}\rightarrow\mathbb{R}$
is convex, $\mathcal{C}\subset\mathbb{R}^{n}$ is convex and closed, a feasible
initial point, $x_{0}\in\mathcal{C}$, is known, $C$ is a constant matrix
and $D$, $A$ and $B$ are matrixes\footnote{Here $A$, $B$, $C$ and $D$ are
  \textbf{not} filter state-variable matrixes.} that are linear in the
coefficients, $x$, $y$ and $z$ and $F\left(z\right)$ represents
Equation~\ref{eqn:Iwasaki-Hara-Generalised-KYP-LMI-Finsler}.

At the $m$'th iteration, \emph{Lee} and
\emph{Hu}~\cite[Equation 4]{Lee_SequentialConvexApproxBMI} partially linearise
$F\left(z\right)$ at $z=z_{m}+\Delta_{z}$ where
$z_{m}^{\top}=\left[x_{m}^{\top},y_{m}^{\top}\right]$ as follows:
\begin{align}
  F\left(z\right)
  &\approx F\left(z_{m}\right) + \nabla F\left(z_{m}\right)\Delta_{z}+
    \mathhe\left(\Delta_{A} \Delta_{B}\right) \preceq 0
    \label{eqn:Lee-Hu-partially-linearised-bilinear-mapping}
\end{align}
where, for convenience, $\Delta_{A}=\nabla A\left(x_{m}\right)\Delta_{x}$.
Equation~\ref{eqn:Lee-Hu-partially-linearised-bilinear-mapping} retains
the bilinear terms in $\Delta_{z}$. The linear part of
Equation~\ref{eqn:Lee-Hu-partially-linearised-bilinear-mapping} is:
\begin{align*}
  \nabla F\left(z_{m}\right)\Delta_{z}
  &\approx  \Delta_{D} +
    \mathhe\left(A\left(x_{m}\right)\Delta_{B}\right)+
     \mathhe\left(\Delta_{A}B\left(y_{m}\right)\right)
\end{align*}
\subsection{Sequential approximation of BMI constraints}
This section describes methods of finding a sequence of convex upper
approximations to the bilinear terms at the $z_{m}$ of each iteration of
Equation~\ref{eqn:Lee-Hu-partially-linearised-bilinear-mapping}. 

\subsubsection{\emph{Dinh et al.} psd-convex-concave optimisation with BMI constraints}
\emph{Dinh et al.}~\cite[Lemma
3.1]{Dinh_ConvexConcaveDecompositionLinearizationBMI} decompose the bilinear
form $X^{\top}Y+Y^{\top}X$ into a difference of convex and concave
mappings\cite{Hartman_DifferenceConvexFunctions}:
\begin{framed}
  \emph{Lemma 3.1}~\cite{Dinh_ConvexConcaveDecompositionLinearizationBMI}:
  \begin{enumerate}
  \item The mappings $f\left(X\right)\coloneq X^{\top}X$ and
    $g\left(X\right)\coloneq X X^{\top}$ are psd-convex on $\mathbb{R}^{m\times n}$.
    The mapping $f\left(X\right)\coloneq X^{-1}$ is psd-convex on
    $\mathbb{S}_{++}^{p}$.
  \item The bilinear matrix form $X^{\top}Y+Y^{\top}X$ can be represented as a
    psd-convex-concave mapping in at least three forms:
    \begin{subequations}
    \begin{align}
       X^{\top}Y+Y^{\top}X &= \left(X+Y\right)^{\top}\left(X+Y\right) -
                            \left(X^{\top}X+Y^{\top}Y\right)
      \label{eqn:Dinh-bilinear-convex-concave-a} \\
      &= \left(X^{\top}X+Y^{\top}Y\right) - \left(X-Y\right)^{\top}\left(X-Y\right)
      \label{eqn:Dinh-bilinear-convex-concave-b} \\
      &= \frac{1}{2}\left[\left(X+Y\right)^{\top}\left(X+Y\right) -
      \left(X-Y\right)^{\top}\left(X-Y\right)\right]
      \label{eqn:Dinh-bilinear-convex-concave-c}
    \end{align}
    \end{subequations}
  \end{enumerate}
\end{framed}

\emph{Dinh et al.}~\cite[Sections 3.2 and
4]{Dinh_ConvexConcaveDecompositionLinearizationBMI} consider the following
convex optimisation problem:
\begin{align*}
\textbf{minimise}\quad &f\left(x\right) \\
  \textbf{subject to}\quad
   & x\in\mathcal{C} \\
   & G\left(x\right)- H\left(x\right)\preceq 0 
\end{align*}
where $f\colon\mathbb{R}^{n}\rightarrow\mathbb{R}$ is convex,
$\mathcal{C}\subseteq\mathbb{R}^{n}$ is a non-empty, closed, convex set and
$G\left(x\right)$ and $ H\left(x\right)$ are psd-convex.

\begin{comment}
  The Lagrangian function of this problem is:
\begin{align*}
  L\left(x,\Lambda\right)
  &\coloneq
    f\left(x\right)+
    \sum\langle\Lambda_{l},\left[G_{l}\left(x\right)-
    H_{l}\left(x\right)\right]\rangle
\end{align*}
where $\Lambda_{l}\in\mathbb{S}^{p}$ are the Lagrange multipliers and
$\langle X,Y\rangle\coloneq\mathtrace\left(X^{\top}Y\right)$ is the matrix inner
product. The KKT conditions\footnote{See
  Section~\ref{sub:Karush-Kuhn-Tucker-Conditions}}
  are~\cite[Equation 3.6]{Dinh_ConvexConcaveDecompositionLinearizationBMI}:
\begin{align*}
0\in\nabla f\left(x\right)+
  \sum \langle\Lambda_{l},
  \nabla\left[G_{l}\left(x\right)- H_{l}\left(x\right)\right]\rangle+
  N_{\mathcal{C}}\left(x\right) \\
  G_{l}\left(x\right)- H_{l}\left(x\right)\preceq 0 \\
  \Lambda_{l}\succeq 0 \\
\langle\Lambda_{l},\left[G_{l}\left(x\right)- H_{l}\left(x\right)\right]\rangle=0
\end{align*}
where $N_{\mathcal{C}}\left(x\right)$ is the normal cone of $\mathcal{C}$:
\begin{align*}
  N_{\mathcal{C}}\left(x\right)\coloneq
  \begin{cases}
    \left\{w\in\mathbb{R}^{n}\colon w\left(y-x\right)\ge 0
    \text{, for all }y\in\mathcal{C}\right\} & \text{ if } x\in\mathcal{C}\\
    \emptyset & \text{otherwise}
  \end{cases}
\end{align*}
\end{comment}

\emph{Dinh et al.} linearise the optimisation problem as follows:
\begin{align}
  \begin{split}
  \textbf{minimise}\quad &f_{m}\left(x\right)\coloneq f\left(x\right) +
  \rho_{m}\mathnorm{Q_{m}\Delta_{x}}_{2}^{2}\\
  \textbf{subject to}\quad
   & x\in\mathcal{C} \\
   & G\left(x\right)- H\left(x_{m}\right) -
     \nabla H\left(x_{m}\right)\Delta_{x} \preceq 0
  \end{split}
  \label{eqn:Linearised-BMI-optimisation}
\end{align}
where the linearised concave part is an upper approximation:
\begin{align*}
  -H\left(x\right)\preceq -H\left(x_{m}\right) -
  \nabla H\left(x_{m}\right)\Delta_{x},
  \text{ for all } x\in\mathcal{C}
\end{align*}
and the convex part is linearised by applying
Equation~\ref{eqn:Dinh-convex-Schur-complement}.

Given a feasible initial point, $x_{0}$, and initial $\rho_{0}>0$ and
$Q_{0}\in\mathbb{S}^{n}_{+}$, \emph{Dinh et al.}~\cite[Algorithm
1]{Dinh_ConvexConcaveDecompositionLinearizationBMI} suggest repeatedly solving
Equation~\ref{eqn:Linearised-BMI-optimisation} for $x_{i+1}$ until a termination
condition is met. If necessary, $\rho_{m}$ and $Q_{m}$ are updated at each step.
\emph{Dinh et al.}~\cite[Section
5]{Dinh_ConvexConcaveDecompositionLinearizationBMI} show examples in which they
apply the Schur complement to the psd-convex-linearised-concave decomposition of
Equation~\ref{eqn:Dinh-bilinear-convex-concave-c}.

\subsubsection{\emph{Lee and Hu} sequential convex upper-approximation with BMI constraints}
\emph{Lee} and \emph{Hu}~\cite[Lemma 2]{Lee_SequentialConvexApproxBMI} prove
the following lemma\footnote{See~\cite[Section
  3.6]{BoydVandenberghe_ConvexOptimization}.}:
\begin{framed}
  \emph{Lemma 2}~\cite{Lee_SequentialConvexApproxBMI}: Let $D$ and $E$ be real
  matrixes of appropriate dimensions. Then, for any $S\in\mathbb{S}_{++}^{n}$:
  \begin{align}
    DE+E^{\top}D^{\top} \preceq DSD^{\top}+E^{\top}S^{-1}E
    \label{eqn:Lee-Hu-lemma-2}
  \end{align}
  \emph{Proof:}~ Expand
  $\left(D^{\top}-S^{-1}E\right)^{\top}S\left(D^{\top}-S^{-1}E\right) \succeq 0$.
\end{framed}
\emph{Lee} and \emph{Hu}~\cite[Equation 5]{Lee_SequentialConvexApproxBMI} apply
this lemma to the partially linearised bilinear mapping of
Equation~\ref{eqn:Lee-Hu-partially-linearised-bilinear-mapping}\footnote{This
  is similar to overbounding the constraint by ignoring the second term in
  Equation~\ref{eqn:Dinh-bilinear-convex-concave-b}.}:
\begin{align*}
  F\left(z\right)
  & \preceq F\left(z_{m}\right)+
    \nabla F\left(z_{m}\right)\Delta_{z}+
    \Delta_{A}\left(\Delta_{x}\right)S\Delta_{A}\left(\Delta_{x}\right)^{\top}+
    \Delta_{B}\left(\Delta_{y}\right)^{\top}S^{-1}\Delta_{B}\left(\Delta_{y}\right)
    \preceq 0
\end{align*}
and, applying the Schur complement as shown in
Equation~\ref {eqn:Dinh-convex-concave-Schur-complement}, obtain the following
symmetric linear matrix inequality:
\begin{align*}
  \left[\begin{array}{ccc}
          F\left(z_{m}\right)+
          \nabla F\left(z_{m}\right)\Delta_{z} & \ast & \ast \\
          \Delta_{A}\left(\Delta_{z}\right)^{\top} & -S^{-1} & \ast \\
          \Delta_{B}\left(\Delta_{z}\right) & 0 & -S \end{array}\right]\preceq 0
\end{align*}
where I omit the symmetric components. Further, \emph{Dinh et
  al.}~\cite[Lemma 3.1]{Dinh_ConvexConcaveDecompositionLinearizationBMI} show
that $S^{-1}$ is psd-convex and, consequently, \emph{Lee} and
\emph{Hu}~\cite[Lemma 3]{Lee_SequentialConvexApproxBMI} prove the following
lemma:
\begin{framed}
  \emph{Lemma 3}~\cite{Lee_SequentialConvexApproxBMI}: Suppose that
  $\mathbb{S}\colon\mathbb{R}^{n}\rightarrow\mathbb{S}^{p}$ is a linear mapping
  defined as $S\left(x\right)=\sum_{l=1}^{n}x_{l}S_{l}$,
  where $S_{l}\in\mathbb{S}^{p}$ is symmetric and real. If
  $S\left(x\right)\succ 0$ and $S\left(y\right)\succ 0$,
  then $-S\left(y\right)^{-1} \preceq -2S\left(x\right)^{-1}+
  S\left(x\right)^{-1}S\left(y\right)S\left(x\right)^{-1}$.
  
  \emph{Proof:}~ Linearise $-S\left(y\right)^{-1}$ around $x$ and apply the
  matrix identities $SS^{-1}=I$ and
  $\frac{dS}{dx}S^{-1}+S\frac{dS^{-1}}{dx}=0$.
\end{framed}
After replacing the psd-concave mapping, $-S^{-1}$, with its upper approximation
linearised around $S_{m}$ and scaling by the congruence transformation
$\mathdiag \left[I,S_{m},I\right]$, the upper approximation to
$F\left(z\right)$ near $z=z_{m}$ is the LMI
constraint~\cite[Equation 8]{Lee_SequentialConvexApproxBMI}:
\begin{align}
  \label{eqn:Lee-Hu-linearised-bilinear-mapping} 
  \left[\begin{array}{ccc}
  F\left(z_{m}\right)+
  \nabla F\left(z_{m}\right)\Delta_{z} & \ast & \ast \\
   S_{m}\Delta_{A}\left(\Delta_{z}\right)^{\top} & -2S_{m}+S & \ast \\
   \Delta_{B}\left(\Delta_{z}\right) & 0 & -S \end{array}\right] & \preceq 0
\end{align}

\emph{Lee} and \emph{Hu}~\cite[Algorithm 1]{Lee_SequentialConvexApproxBMI}
propose a sequential approximation algorithm with the ``regularised'' objective
function $f\left(z\right)+\frac{\rho}{2}\mathnorm{\Delta_{z}}^{2}$ and the LMI
constraint of Equation~\ref{eqn:Lee-Hu-linearised-bilinear-mapping} and
$S_{0}=I_{n}$, $c_{1}I\preceq S\preceq c_{2}I$, $-2S_{m}+S\preceq -c_{3}I$ with
$\rho>0$, $c_{2}>c_{1}>0$, $c_{3}>0$. \emph{Lee} and
\emph{Hu}~\cite[Section 5]{Lee_SequentialConvexApproxBMI} provide an example
with values for $\rho$, $c_{1}$, $c_{2}$ and $c_{3}$.

\emph{Lee} and \emph{Hu}~\cite[Remark 2]{Lee_SequentialConvexApproxBMI}
compare their method to the difference of convex functions (DC) method of
\emph{Dinh et al.}:
\begin{quotation}
  In fact, a more general psd-convex-concave mapping can be derived by
  introducing the auxiliary matrix, $S$, as follows:
  $X^{\top}Y+Y^{\top}X=X^{\top}SX+Y^{\top}S^{-1}Y-\left(X-S^{-1}Y\right)^{\top}S
  \left(X-S^{-1}Y\right)$. Note that the last term $-\left(X-S^{-1}Y\right)^{\top}S
  \left(X-S^{-1}Y\right)$ is concave in $X$ and $Y$. If we set $S$ to be a
  constant, i.e. $S=I$, and linearize the last term
  $\left(X-S^{-1}Y\right)^{\top}S\left(X-S^{-1}Y\right)$ with respect to
  $\left(X,Y\right)$ at the point $\left(X,Y\right)=\left(X_{m},Y_{m}\right)$,
  then the over approximation of the DC programming method is obtained. Instead,
  if we drop the last term and linearize $S^{-1}$ at $S=S_{m}$, then the over
  approximation of the proposed Algorithm 1 is obtained. From the interpretation
  it is not easy to claim which approximation is better than the other. Since
  the last term is entirely dropped in Algorithm 1, it can be seen as a less
  accurate one in general. However, the auxiliary matrix $S$ can be adjusted as
  a decision variable of the convex subproblem, the over approximation can be
  tightened at each iteration.
\end{quotation}

\subsubsection{\emph{Warner and Scruggs} iterative convex over-bounding optimisation with BMI constraints}
\emph{Warner} and
\emph{Scruggs}~\cite{WarnerScruggs_IterativeConvexOverboundingBMI}
describe iterative convex over-bounding techniques for BMI problems like:
\begin{align*}
  Q+\mathhe\left(BRDSC\right) \prec 0
\end{align*}
where $Q$, $B$, $C$ and $D$ are constants and $R$ and $S$ are the design
variables with known feasible intial values $R_{0}$ and $S_{0}$. At the $m$'th iteration, with perturbed values $R=R_{m}+\Delta_{R}$ and $S=S_{m}+\Delta_{S}$:
\begin{align*}
  Q+\mathhe\left(\phi\left(R,S\right)+B\Delta_{R}D\Delta_{S}C\right) \prec 0
\end{align*}
where:
\begin{align*}
  \phi\left(R,S\right)&=B\left[RDS_{m}+R_{m}DS-R_{m}DS_{m}\right]C
\end{align*}
\emph{Warner} and \emph{Scruggs} now set $D=UV$ where $U$ and $V^{\top}$ have full
column rank and for an arbitrary invertible matrix $L_{1}$:
\begin{align*}
  Q+\mathhe\left(\phi\left(R,S\right)\right)+
  B\Delta_{R}UL_{1}L_{1}^{\top}U^{\top}\Delta_{R}^{\top}B^{\top} +
  C^{\top}\Delta_{S}^{\top}V^{\top}L_{1}^{-\top}L_{1}^{-1}V\Delta_{S} C \prec\eta\eta^{\top}
\end{align*}
where:
\begin{align*}
  \eta = B\Delta_{R} U L_{1} - C^{\top}\Delta_{S}^{\top}V^{\top}L_{1}^{-\top}
\end{align*}
Since $\eta\eta^{\top}\ge 0$ an over-approximation is:
\begin{align*}
  Q+\mathhe\left(\phi\left(R,S\right)\right)+
  B\Delta_{R}UL_{1}L_{1}^{\top}U^{\top}\Delta_{R}^{\top}B^{\top} +
  C^{\top}\Delta_{S}^{\top}V^{\top}L_{1}^{-\top}L_{1}^{-1}V\Delta_{S} C \prec 0
\end{align*}
Defining $W_{1}=L_{1}L_{1}^{\top}$ and applying the Schur complement:
\begin{align*}
  \left[\begin{array}{ccc}
          Q+\mathhe\left(\phi\left(R,S\right)\right) & \ast & \ast \\
          U^{\top}\left(\Delta_{R}\right)^{\top}B^{\top} & -W_{1}^{-1} & \ast \\
          V\left(\Delta_{S}\right)C & 0 & -W_{1}\end{array}\right] \prec 0
\end{align*}
Alternatively:
\begin{align*}
  \mathhe\left(\phi\left(R,S\right)\right)+\alpha\alpha^{\top} \prec
  B\Delta_{R}UL_{2}L_{2}^{\top}U^{\top}\Delta_{R}^{\top}B^{\top} +
  C^{\top}\Delta_{S}^{\top}V^{\top}L_{2}^{-\top}L_{2}^{-1}V\Delta_{S} C
\end{align*}
where $L_{2}$ is an arbitrary invertible matrix and:
\begin{align*}
  \alpha = B\Delta_{R} U L_{2} + \Delta_{S} C V L_{2}^{-1}
\end{align*}
Define $W_{2}=L_{2}L_{2}^{\top}$ and choose $L_{2}$ so that  $W_{2}\succ 0$. Then:
\begin{align*}
  \mathhe\left(\phi\left(R,S\right)\right)+\beta W_{2}^{-1}\beta^{\top} \prec
  B\Delta_{R}UW_{2}U^{\top}\Delta_{R}^{\top}B^{\top} +
  C^{\top}\Delta_{S}^{\top}V^{\top}W_{2}^{-1}V\Delta_{S} C
\end{align*}
where:
\begin{align*}
  \beta = B\Delta_{R} U W_{2} + C^{\top}\Delta_{S} V^{\top}
\end{align*}
Since $W_{2}$ is positive definite, after applying the Schur complement an
upper-approximation is:
\begin{align*}
  \left[\begin{array}{cc}
 \mathhe\left(\phi\left(R,S\right)\right) & \ast \\
 B\left(\Delta_{R}\right)UW_{2}+C^{\top}\left(\Delta_{S}\right)^{\top}V^{\top} & -W_{2}
        \end{array}\right] \prec 0
\end{align*}

Finally, \emph{Warner} and \emph{Scruggs} propose using a linear combination
of these two LMI constraints:
\begin{align*}
  Q+\mathhe\left(BRU\Lambda VSC\right) +
  \mathhe\left(BRU\left(I-\Lambda\right)VSC\right) \prec 0
\end{align*}
where $\Lambda$ is symmetric interpolation matrix and $0\prec\Lambda\prec I$.
The over-all convex upper-approximation constraint is:
\begin{align*}
 \left[\begin{array}{cccc}
 Q+\mathhe\left(\phi\left(R,S\right)\right) & \ast & \ast & \ast \\
 U^{\top}\left(\Delta_{R}\right)^{\top}B^{\top} &-\hat{W}_{1}^{-1} & \ast & \ast\\
 V\left(\Delta_{S}\right)C & 0 & -\hat{W}_{1} & \ast \\
 \left[\begin{array}{c}
 W_{2}B\left(\Delta_{R}\right)U+ \\
  C^{\top}\left(\Delta_{S}\right)^{\top}C^{\top}\end{array}\right]& 0 & 0 &-\hat{W}_{2}
       \end{array}\right] \prec 0
\end{align*}
where $\hat{W}_{1}=L_{1}\Lambda^{-1} L_{1}^{\top}$ and
$\hat{W}_{2}=L_{2}\left(1-\Lambda\right)^{-1} L_{2}^{\top}$.

\emph{Warner} and \emph{Scruggs} suggest:
\begin{enumerate}
\item using a ``regularised'' objective function and
  LMI constraint similar to that described by \emph{Lee} and \emph{Hu}.
\item updating the weights $L_{1}$, $L_{2}$ and $\Lambda$
  in separate sub-steps during each iteration of the optimisation.
\end{enumerate}

\subsubsection{\emph{Sebe} sequential convex over-bounding optimisation with BMI constraints}
\emph{Sebe}~\cite[Section 2.1]{Sebe_SequentialConvexOverboundingBMI} argues that
the preferred decomposition of $\mathhe\left(XY\right)$\footnote{\emph{Dinh et
    al.} write $\mathhe\left(X^{\top}Y\right)$.} is
Equation~\ref{eqn:Dinh-bilinear-convex-concave-c}. \emph{Sebe}~\cite[Section
2.2]{Sebe_SequentialConvexOverboundingBMI} then considers the psd-convex-concave
decomposition of bilinear constraints in the form
$\mathhe\left(XNY\right)\prec -\mathhe\left(Q\right)$ where $N$ is a constant
matrix and $\mathhe\left(Q\right)$ is ``the other part of the matrix
inequality''\footnote{The linear part?}.
After pointing out that:
\begin{align*}
  \mathhe\left(XNY\right)
  &=\left[\begin{array}{cc}
            X & Y^{\top}\end{array}\right]
    \left[\begin{array}{cc}
            0 & N \\
            N^{\top} & 0\end{array}\right]
    \left[\begin{array}{c}
            X^{\top} \\
            Y \end{array}\right]
\end{align*}
\emph{Sebe}~\cite[Proposition 3]{Sebe_SequentialConvexOverboundingBMI} shows
that:
\begin{align*}
    \left[\begin{array}{cc}
            0 & N \\
            N^{\top} & 0\end{array}\right]
  &=\left[\begin{array}{cc}
            N & N \\
            G^{\top} & -G\end{array}\right]
    \left[\begin{array}{cc}
            \left(G+G^{\top}\right)^{-1} & 0 \\
            0 & -\left(G+G^{\top}\right)^{-1} \end{array}\right]
    \left[\begin{array}{cc}
            N & N \\
            G^{\top} & -G\end{array}\right]^{\top}
\end{align*}
where $G\in\mathbb{R}^{n\times n}$ satisfies $G+G^{\top}\succ 0$. With this result,
the constraint $\mathhe\left(Q+XNY\right)\prec 0$ has the upper approximation:
\begin{align*}
  \mathhe\left(Q\right) + \left(XN+Y^{\top}G^{\top}\right)
  \left(G+G^{\top}\right)^{-1}\left(XN+Y^{\top}G^{\top}\right)^{\top} \prec 0
\end{align*}
Applying the Schur complement:
\begin{align*}
    \left[\begin{array}{cc}
            \mathhe\left(Q\right) & XN+Y^{\top}G^{\top} \\
            \left(XN+Y^{\top}G^{\top}\right)^{\top} & -\left(G+G^{\top}\right)
          \end{array}\right] \prec 0
\end{align*}
or, simply:
\begin{align*}
  \mathhe\left(\left[\begin{array}{cc}
            Q & XN \\
            GY & -G \end{array}\right]\right) \prec 0
\end{align*}

\subsection{Design of Schur lattice filters with  BMI constraints derived from the KYP lemma}
In this Section I apply the successive convex optimisation
to the design of filters implemented as the parallel combination of the doubly
pipelined all-pass one-multiplier Schur lattice filters described in
Section~\ref{sec:State-variable-all-pass-doubly-pipelined-One-multiplier-Schur-lattice-filter}\footnote{This design procedure can also be applied to the tapped
  doubly pipelined one-multiplier Schur lattice filters described in
Section~\ref{sec:State-variable-doubly-pipelined-One-multiplier-Schur-lattice-filter}
with the added complication that the tap coefficients, $c_{n}$, depend on the
$\epsilon_{n}\in\left\{-1,1\right\}$.}. The filters are assumed to have a single
input and a single output. For such filters, the state transition matrix, $A$,
is:
\begin{align*}
  A\left(\boldsymbol{k}\right) = A_{0}+\sum_{l=1}^{N} k_{l}A_{l}
\end{align*}
where
$\boldsymbol{k}=\left[\begin{array}{ccc}k_{1} & \hdots & k_{N}\end{array}\right]$
are the Schur lattice filter reflection coefficients, $A\in\mathbb{R}^{n\times n}$
and the $A_{0},\hdots,A_{N}$ matrixes and the state-variable $B$, $C$ and $D$
matrixes are constant. After applying Finsler's transformation to the KYP lemma
matrix inequality of Equation~\ref{eqn:Iwasaki-Hara-Generalised-KYP-LMI}, as
shown in Section~\ref{sec:Finslers-lemma-transformation-generalised-KYP}, the
optimisation problem is:
\begin{align*}
  \textbf{minimise}\quad
  & \mathcal{E}^{2}\left(\boldsymbol{k}\right) \\
  \textbf{subject to}\quad
  &-1 < \boldsymbol{k} < 1 \\
  & P,Q\in\mathbb{S}^{n}\text{ and } Q\succeq 0 \\
  & \text{Equation~\ref{eqn:Iwasaki-Hara-Generalised-KYP-LMI-Finsler}}
\end{align*}
where $\mathcal{E}^{2}\left(\boldsymbol{k}\right)$ is the filter squared error at
$\boldsymbol{k}=\boldsymbol{k}_{m}+\Delta_{\boldsymbol{k}}$:
\begin{align*}
  \mathcal{E}^{2}\left(\boldsymbol{k}_{m}+\Delta_{\boldsymbol{k}}\right)
  &\approx \mathcal{E}^{2}\left(\boldsymbol{k}_{m}\right)
+\nabla_{\mathcal{E}^{2}}\left(\boldsymbol{k}_{m}\right)^{\top}\Delta_{\boldsymbol{k}}
    +\frac{1}{2}\Delta_{\boldsymbol{k}}^{\top}\nabla^{2}_{\mathcal{E}^{2}}
    \left(\boldsymbol{k}_{m}\right)\Delta_{\boldsymbol{k}}
\end{align*}
Assume that $\boldsymbol{k}_{0}$ is a known feasible initial point. Set
$\Delta_{z}=\mathvec\left(\Delta_{\boldsymbol{k}},\Delta_{\varepsilon^{2}},\Delta_{P},
  \Delta_{Q},\Delta_{X},\Delta_{Y},\Delta_{Z}\right)$ and, after the $m$'th
iteration,  $z_{m}=\mathvec\left(\boldsymbol{k}_{m},\varepsilon_{m}^{2},P_{m},Q_{m},
  X_{m},Y_{m},Z_{m}\right)$.

\subsubsection{Successive convex optimisation with the algorithm of \emph{Dinh et al.}~\cite[Algorithm 1]{Dinh_ConvexConcaveDecompositionLinearizationBMI}\label{sec:Successive-convex optimisation-Dinh}}
Apply Equation~\ref{eqn:Dinh-bilinear-convex-concave-c} to
Equation~\ref{eqn:Iwasaki-Hara-Generalised-KYP-LMI-Finsler}:
\begin{align*}
  \begin{split}
   & \left[\begin{array}{ccc}
      L\left(P,Q\right) & 0 & 0\\
      0 & -\varepsilon^{2}I & 0 \\
      0 & 0 & I \end{array}\right] + \hdots \\
   & \frac{1}{2}\left\{
      \left(\left[\begin{array}{cccc}
        -I & A & B & 0 \\
         0 & C & D & -I \end{array}\right]+
      \left[\begin{array}{cccc}
        X & 0 \\
        Y & 0 \\
        Z & 0 \\
        0 & I\end{array}\right]^{\mathconj}
      \right)^{\mathconj}
      \left(\left[\begin{array}{cccc}
        -I & A & B & 0 \\
         0 & C & D & -I \end{array}\right]+
      \left[\begin{array}{cccc}
        X & 0 \\
        Y & 0 \\
        Z & 0 \\
        0 & I\end{array}\right]^{\mathconj}
      \right)\right\} - \hdots \\
    & \frac{1}{2}\left\{
      \left(\left[\begin{array}{cccc}
        -I & A & B & 0 \\
         0 & C & D & -I \end{array}\right]-
      \left[\begin{array}{cccc}
        X & 0 \\
        Y & 0 \\
        Z & 0 \\
        0 & I\end{array}\right]^{\mathconj}
      \right)^{\mathconj}
      \left(\left[\begin{array}{cccc}
        -I & A & B & 0 \\
         0 & C & D & -I \end{array}\right]-
      \left[\begin{array}{cccc}
        X & 0 \\
        Y & 0 \\
        Z & 0 \\
        0 & I\end{array}\right]^{\mathconj}
      \right)\right\} \preceq 0
  \end{split}
\end{align*}
Applying the Schur complement to the first and second terms:
\begin{align*}
  \left[\begin{array}{cc}
    \left[\begin{array}{ccc}
      L\left(P,Q\right) & 0 & 0 \\
      0 & -\varepsilon^{2}I & 0 \\
      0 &                 0 & I \end{array}\right] & \ast \\
    \frac{1}{\sqrt{2}}\left[\begin{array}{cccc}
      -I+X^{\mathconj}  & A+Y^{\mathconj} & B+Z^{\mathconj} & 0 \\
      0 &  C  &  D  & 0 \end{array}\right] & -I \end{array}\right]
  -\frac{1}{2}\left[\begin{array}{cc}
    R^{\mathconj}R & 0 \\
    0 & 0  \end{array}\right] \preceq 0
\end{align*}
where:
\begin{align*}
  R &=\left[\begin{array}{cccc}
      -I-X^{\mathconj} & A-Y^{\mathconj} & B-Z^{\mathconj} & 0 \\
                   0 &             C &             D & -2I\end{array}\right]
\end{align*}
After the $m$'the iteration, at $z=z_{m}+\Delta_{z}$,
$A\left(\boldsymbol{k}\right)\approx
A\left(\boldsymbol{k}_{m}\right)+\sum_{l=1}^{N}\Delta_{k_{l}}A_{l}$,
$X\left(z\right)\approx X\left(z_{m}\right)+\Delta_{X}$, etc.
The linear approximation to the bilinear term,
$R\left(z\right)^{\mathconj}R\left(z\right)$, is:
\begin{align*}
  R\left(z\right)^{\mathconj}R\left(z\right)
  & \approx R\left(z_{m}\right)^{\mathconj}R\left(z_{m}\right)
    +R\left(z_{m}\right)^{\mathconj}\Delta_{R}
    +\Delta_{R}^{\mathconj}R\left(z_{m}\right)
\end{align*}
At each iteration, the SDP decision variables are $\Delta_{z}$.

The Octave script
\emph{schurOneMPAlatticeDoublyPipelinedDelay\_kyp\_Dinh\_lowpass\_test.m}
implements the successive convex approximation algorithm of
\emph{Dinh et al.} with YALMIP in order to design a filter consisting of
the parallel combination of a delay and a Schur one-multiplier all-pass lattice
filter. The initial filter is designed with the \emph{WISE} method shown in
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}. The objective
function is an approximation to the summed squared error of the amplitude
response. The script finds initial values for the symmetric and real SDP
decision variables $P$, $Q$, $X$ etc. with \emph{SeDuMi} and then uses the
\emph{SDPT3} solver for successive convex approximation. The filter
specification is:
\begin{small}
\verbatiminput{schurOneMPAlatticeDoublyPipelinedDelay_kyp_Dinh_lowpass_test_spec.m}
\end{small}
The initial reflection coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlatticeDoublyPipelinedDelay_kyp_Dinh_lowpass_test_k0_coef.m}
\end{small}
Figure~\ref{fig:schurOneMPA-DoublyPipelinedDelay-kyp-Dinh-lowpass-initial}
shows the initial filter amplitude response.
The optimised reflection coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlatticeDoublyPipelinedDelay_kyp_Dinh_lowpass_test_k_coef.m}
\end{small}
Figure~\ref{fig:schurOneMPA-DoublyPipelinedDelay-kyp-Dinh-lowpass-response}
shows the filter amplitude and delay responses.
Figure~\ref{fig:schurOneMPA-DoublyPipelinedDelay-kyp-Dinh-lowpass-pz}
shows the filter pole-zero plot.
Figure~\ref{fig:schurOneMPADoublyPipelinedDelay-Dinh-lowpass-convergence-Esq}
shows the convergence of the squared-error and $\Delta_{k}$ of the filter design.
Figure~\ref{fig:schurOneMPADoublyPipelinedDelay-Dinh-lowpass-convergence-Asq}
shows the convergence of the minimum pass-band amplitude and maximum stop-band
amplitude of the filter design.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDoublyPipelinedDelay_kyp_Dinh_lowpass_test_initial_response}}
\caption{Initial amplitude response of a lowpass filter comprised
  of a Schur one-multiplier lattice all-pass filter in parallel with a delay.}
\label{fig:schurOneMPA-DoublyPipelinedDelay-kyp-Dinh-lowpass-initial}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDoublyPipelinedDelay_kyp_Dinh_lowpass_test_response}}
\caption{Amplitude and delay responses of a lowpass filter comprised of a
  Schur one-multiplier lattice all-pass filter in parallel with a delay
  designed with the generalised KYP lemma amd the algorithm of \emph{Dinh et
    al.}~\cite[Algorithm 1]{Dinh_ConvexConcaveDecompositionLinearizationBMI}.}
\label{fig:schurOneMPA-DoublyPipelinedDelay-kyp-Dinh-lowpass-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDoublyPipelinedDelay_kyp_Dinh_lowpass_test_pz}}
\caption{Pole-zero plot of a lowpass filter comprised of a
  Schur one-multiplier lattice all-pass filter in parallel with a delay
  designed with the generalised KYP lemma amd the algorithm of \emph{Dinh et
    al.}~\cite[Algorithm 1]{Dinh_ConvexConcaveDecompositionLinearizationBMI}.}
\label{fig:schurOneMPA-DoublyPipelinedDelay-kyp-Dinh-lowpass-pz}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDoublyPipelinedDelay_kyp_Dinh_lowpass_test_convergence}}
\caption{Convergence of the mean-squared-error of the amplitude response and the
  $\mathnorm{\Delta_{\boldsymbol{k}}}$ of a lowpass filter comprised of a Schur
  one-multiplier lattice all-pass filter in parallel with a delay designed with
  the generalised KYP lemma and the algorithm of \emph{Dinh et
    al.}~\cite[Algorithm 1]{Dinh_ConvexConcaveDecompositionLinearizationBMI}.}
\label{fig:schurOneMPADoublyPipelinedDelay-Dinh-lowpass-convergence-Esq}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDoublyPipelinedDelay_kyp_Dinh_lowpass_test_Asq_min_max}}
\caption{Convergence of the minimum pass-band and maximum stop-band
  amplitudes of a lowpass filter comprised of a Schur
  one-multiplier lattice all-pass filter in parallel with a delay designed with
  the generalised KYP lemma and the algorithm of \emph{Dinh et
    al.}~\cite[Algorithm 1]{Dinh_ConvexConcaveDecompositionLinearizationBMI}.}
\label{fig:schurOneMPADoublyPipelinedDelay-Dinh-lowpass-convergence-Asq}
\end{figure}

\subsubsection{Successive convex optimisation with the algorithm of
  \emph{Lee} and \emph{Hu}~\cite[Algorithm 1]{Lee_SequentialConvexApproxBMI}}
Alternatively, apply the algorithm of \emph{Lee} and \emph{Hu} to
Equation~\ref{eqn:Lee-Hu-partially-linearised-bilinear-mapping}.
After the $m$'the iteration, at  $z=z_{m}+\Delta_{z}$, the linear part is:

\begin{align*}
  \begin{split}
   \nabla  F\left(z_{m}\right)\Delta_{z}
  \approx & \left[\begin{array}{ccc}
      L\left(\Delta_{P},\Delta_{Q}\right) & 0 & 0\\
      0 & -\Delta_{\varepsilon^{2}} & 0 \\
      0 & 0 & 0 \end{array}\right] + \hdots \\
    & \mathhe{ \left( \left[ \begin{array}{cc}
      X_{m} & 0 \\
      Y_{m} & 0 \\
      Z_{m} & 0 \\
      0 & 1 \end{array} \right]
      \left[\begin{array}{cccc}
        0 & \Delta_{A} & 0 & 0 \\
        0 & 0 & 0 & 0 \end{array}\right]\right) } + 
      \mathhe{ \left( \left[ \begin{array}{cc}
        \Delta_{X} & 0 \\
        \Delta_{Y} & 0 \\
        \Delta_{Z} & 0 \\
        0 & 0\end{array} \right]
      \left[\begin{array}{cccc}
        -I & A\left(\boldsymbol{k}_{m}\right) & B & 0 \\
        0 & C & D & -1 \end{array}\right]\right) }
  \end{split}
\end{align*}

The overall bilinear matrix inequality is:
\begin{align}
  \label{eqn:One-multiplier-Schur-lattice-bilinear-matrix-inequality}
  F\left(z_{m}+\Delta_{z}\right)
  \approx & F\left(z_{m}\right) + \nabla  F\left(z_{m}\right)\Delta_{z} +
    \mathhe{ \left( \left[ \begin{array}{cc}
      \Delta_{X} & 0 \\
      \Delta_{Y} & 0 \\
      \Delta_{Z} & 0 \\
      0 & 0 \end{array} \right]
    \left[ \begin{array}{cccc}
      0 & \Delta_{A} & 0 & 0 \\
    0 & 0 & 0 & 0 \end{array} \right] \right) }
    \preceq 0
\end{align}
With the convex upper-approximation of \emph{Lee} and
\emph{Hu}~\cite[Lemma 2]{Lee_SequentialConvexApproxBMI}, shown in
Equation~\ref{eqn:Lee-Hu-lemma-2} the bilinear part of
Equation~\ref{eqn:One-multiplier-Schur-lattice-bilinear-matrix-inequality} is:
\begin{align*}
  \begin{split}
    \mathhe{ \left( \left[ \begin{array}{cc}
      \Delta_{X}& 0 \\
      \Delta_{Y}& 0 \\
      \Delta_{Z}& 0 \\
      0 & 0 \end{array} \right]
    \left[ \begin{array}{cccc}
      0 & \Delta_{A} & 0 & 0 \\
      0 & 0 & 0 & 0\end{array} \right] \right) } \preceq
    & \left[ \begin{array}{cc}
      \Delta_{X} & 0 \\
      \Delta_{Y} & 0 \\
      \Delta_{Z} & 0 \\
      0 & 0 \end{array} \right] S \left[ \begin{array}{cc}
        \Delta_{X} & 0 \\
        \Delta_{Y} & 0 \\
        \Delta_{Z} & 0 \\
        0 & 0 \end{array} \right]^{\top}+ \hdots \\
    & \left[ \begin{array}{cccc}
      0 & \Delta_{A} & 0 & 0 \\
      0 & 0 & 0 & 0\end{array}\right]^{\top}S^{-1}
      \left[ \begin{array}{cccc}
        0 & \Delta_{A} & 0 & 0 \\
        0 & 0 & 0 & 0 \end{array}\right]\preceq 0
  \end{split}
\end{align*}
where $S\in\mathbb{S}_{++}^{n+1}$ is a positive definite, symmetric matrix.
After linearising $S^{-1}$ and applying the Schur complement, as shown in
Equation~\ref{eqn:Lee-Hu-linearised-bilinear-mapping}, at the $m$'th iteration
the convex upper-approximation at $z=z_{m}+\Delta_{z}$ satisfies:
\begin{align}
  \label{eqn:Lee-Hu-linearised-pipelined-all-pass-Schur-lattice}
  \left[\begin{array}{ccc}
  F\left(z_{m}\right)+ \nabla F\left(z_{m}\right)\Delta_{z} & \ast & \ast \\
    S_{m}\left[ \begin{array}{cc}
      \Delta_{X} & 0 \\
      \Delta_{Y} & 0 \\
      \Delta_{Z} & 0 \\
      0 & 0 \end{array} \right]^{\top} & -2S_{m}+S & \ast \\
   \left[ \begin{array}{cccc}
     0 & \Delta_{A} & 0 & 0 \\
     0 & 0 & 0 & 0 \end{array} \right] & 0 & -S \end{array}\right] & \preceq 0
\end{align}
The SDP decision variables are $\Delta_{z}$ and $S$.

The Octave script
\emph{schurOneMPAlatticeDoublyPipelinedDelay\_kyp\_LeeHu\_lowpass\_test.m}
implements the successive convex approximation algorithm of
\emph{Lee} and \emph{Hu} with YALMIP in order to design a filter consisting of
the parallel combination of a delay and a Schur one-multiplier all-pass lattice
filter. The initial filter is designed with the \emph{WISE} method shown in
Section~\ref{Tarczynski-unconstrained-minimisation-with-barrier}. The objective
function is an approximation to the summed squared error of the amplitude response. The script finds initial values for the SDP decision variables $P$, $Q$ etc. with \emph{SeDuMi} and then uses the \emph{SDPT3} solver for successive convex approximation. The filter specification and the initial filter are those
of Section~\ref{sec:Successive-convex optimisation-Dinh}. The optimised
reflection coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlatticeDoublyPipelinedDelay_kyp_LeeHu_lowpass_test_k_coef.m}
\end{small}
Figure~\ref{fig:schurOneMPA-DoublyPipelinedDelay-kyp-LeeHu-lowpass-response}
shows the filter amplitude and delay responses.
Figure~\ref{fig:schurOneMPA-DoublyPipelinedDelay-kyp-LeeHu-lowpass-pz}
shows the filter pole-zero plot.
Figure~\ref{fig:schurOneMPADoublyPipelinedDelay-LeeHu-lowpass-convergence-Esq}
shows the convergence of the squared-error and $\Delta_{z}$ of the filter design.
Figure~\ref{fig:schurOneMPADoublyPipelinedDelay-LeeHu-lowpass-convergence-Asq}
shows the convergence of the minimum pass-band amplitude and maximum stop-band
amplitude of the filter design.
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDoublyPipelinedDelay_kyp_LeeHu_lowpass_test_response}}
\caption{Amplitude and delay responses of a lowpass filter comprised of a
  Schur one-multiplier lattice all-pass filter in parallel with a delay
  designed with the generalised KYP lemma and the bilinear algorithm of
  \emph{Lee} and \emph{Hu}~\cite[Algorithm 1]{Lee_SequentialConvexApproxBMI}.}
\label{fig:schurOneMPA-DoublyPipelinedDelay-kyp-LeeHu-lowpass-response}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDoublyPipelinedDelay_kyp_LeeHu_lowpass_test_pz}}
\caption{Pole-zero plot of a lowpass filter comprised of a
  Schur one-multiplier lattice all-pass filter in parallel with a delay
  designed with the generalised KYP lemma amd the algorithm of \emph{Lee, Hu
et al.}~\cite[Algorithm 1]{Lee_SequentialConvexApproxBMI}.}
\label{fig:schurOneMPA-DoublyPipelinedDelay-kyp-LeeHu-lowpass-pz}
\end{figure}

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDoublyPipelinedDelay_kyp_LeeHu_lowpass_test_convergence}}
\caption{Convergence of the mean-squared-error of the amplitude response and the
  $\mathnorm{\Delta_{\boldsymbol{k}}}$ of a lowpass filter comprised of a Schur
  one-multiplier lattice all-pass filter in parallel with a delay designed with
  the generalised KYP lemma and the algorithm of \emph{Lee} and
  \emph{Hu}~\cite[Algorithm 1]{Lee_SequentialConvexApproxBMI}.}
\label{fig:schurOneMPADoublyPipelinedDelay-LeeHu-lowpass-convergence-Esq}
\end{figure}

\begin{figure}[!ht]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDoublyPipelinedDelay_kyp_LeeHu_lowpass_test_Asq_min_max}}
\caption{Convergence of the minimum pass-band amplitude and maximum stop-band
  amplitudes of a lowpass filter comprised of a Schur
  one-multiplier lattice all-pass filter in parallel with a delay designed with
  the generalised KYP lemma and the algorithm of \emph{Lee} and
  \emph{Hu}~\cite[Algorithm 1]{Lee_SequentialConvexApproxBMI}.}
\label{fig:schurOneMPADoublyPipelinedDelay-LeeHu-lowpass-convergence-Asq}
\end{figure}
\vspace{3cm}
\subsubsection{Comparison with SOCP PCLS design}
For comparison, the Octave script
\emph{schurOneMPAlatticeDelay\_socp\_slb\_lowpass\_test.m} uses the
PCLS algorithm and SOCP optimisation to design a lowpass filter comprised of a
Schur one-multiplier lattice all-pass filter in parallel with a delay.
The filter specification is similar to that of
Section~\ref{sec:Successive-convex optimisation-Dinh}. The initial filter is
designed with the \emph{WISE} method and the initial reflection coefficients
are those found in Section~\ref{sec:Successive-convex optimisation-Dinh}.

The optimised reflection coefficients are:
\begin{small}
\verbatiminput{schurOneMPAlatticeDelay_socp_slb_lowpass_test_m_5_A1k_coef.m}
\end{small}
Figure~\ref{fig:schurOneMPA-delay-m-5-lowpass-response}
shows the filter amplitude response.
Figure~\ref{fig:schurOneMPA-delay-m-5-lowpass-pz} shows the filter pole-zero
plot.

\begin{figure}[!hb]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDelay_socp_slb_lowpass_test_m_5_response}}
\caption{Amplitude response of a lowpass filter comprised of a
  Schur one-multiplier lattice all-pass filter in parallel with a delay
  designed with the PCLS algorithm and SOCP optimisation.}
\label{fig:schurOneMPA-delay-m-5-lowpass-response}
\end{figure}

\begin{figure}[!hb]
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{schurOneMPAlatticeDelay_socp_slb_lowpass_test_m_5_pz}}
\caption{Pole-zero plot of a lowpass filter comprised of a
  Schur one-multiplier lattice all-pass filter in parallel with a delay
  designed with the PCLS algorithm and SOCP optimisation.}
\label{fig:schurOneMPA-delay-m-5-lowpass-pz}
\end{figure}

Table~\ref{tab:SOCP-KYP-Dinh-KYP-LeeHu-low-pass-filter-comparison} compares the
mean-squared-error, the maximum in the stop-band and the minimum in the
pass-band of the amplitude responses of the SOCP(PCLSa), KYP(Dinh) and KYP(Lee
and Hu) designs of a low-pass Schur one-multiplier all-pass lattice filter in
parallel with a delay. The SOCP(PCLS) design procedure is much faster than the
KYP design procedure.
\begin{table}[htbp]
\centering
\begin{threeparttable}
\begin{tabular}{lrrr} \\ \toprule
 & $\mathcal{E}^2$ & $A_{max}$(dB) & $A_{min}$(dB)\\ \midrule
\input{schurOneMPAlatticeDelay_lowpass_Esq_comparison_test.tab} \\ \bottomrule
\end{tabular}
\end{threeparttable}
\caption{Mean-squared-error of the amplitude response, maximum stop-band
  amplitude and minimum pass-band amplitude of the SOCP(PCLS), KYP(Dinh) and
  KYP(Lee and Hu) designs of a low-pass Schur one-multiplier all-pass lattice
  filter in parallel with a delay.}
\label{tab:SOCP-KYP-Dinh-KYP-LeeHu-low-pass-filter-comparison}
\end{table}

\cleardoublepage
\chapter*{\hypertarget{sec:Colophon}{Colophon}}
\addcontentsline{toc}{part}{Colophon}
\pdfbookmark[0]{Requirements}{requirements}
\setcounter{footnote}{0}
\section*{Software requirements}
I currently use the Fedora 41 distribution of Linux~\cite{Fedora_website} with:
\begin{itemize}
\item \texttt{uname -r} is \emph{6.13.5-200.fc41.x86\_64}
\item \emph{gcc} version \emph{14.2.1 20250110 (Red Hat 14.2.1-7)}
\item a local build of \emph{octave-9.4.0} with the \emph{struct}, \emph{io},
  \emph{statistics}, \emph{optim}, \emph{control}, \emph{signal},
  \emph{symbolic}\footnote{The \emph{symbolic} Octave-Forge package assumes that
  the \emph{python3-sympy} Fedora package is installed.} and \emph{parallel}
  Octave-Forge packages
\item the Octave scripts use the \emph{qt} graphics toolkit with
  \emph{qt6-qtbase-6.8.20-3} and a local build of \emph{GraphicsMagick}
\item \emph{texlive-2023-73} and various packages are installed
\item \emph{dia-0.97.3-28} is used for line drawings
\end{itemize}

The local build of \emph{octave-9.4.0} and Octave-Forge packages assumes that
the following packages are installed in addition to the base Fedora distribution:
\begin{small}
\begin{verbatim}
dnf install wget readline-devel lzip sharutils gcc gcc-c++ \
gcc-gfortran gmp-devel mpfr-devel make cmake gnuplot-latex m4 gperf \
bison flex openblas-devel patch texinfo texinfo-tex librsvg2 librsvg2-devel \
librsvg2-tools icoutils autoconf automake libtool pcre pcre-devel freetype \
freetype-devel gnupg2 texlive-dvisvgm gl2ps gl2ps-devel hdf5 hdf5-devel \
qhull qhull-devel portaudio portaudio-devel libsndfile libsndfile-devel \
libcurl libcurl-devel gl2ps gl2ps-devel fontconfig-devel mesa-libGLU \
mesa-libGLU-devel qt qt6-qtbase qt6-qtbase-common qt6-qtbase-devel \
qt6-qtbase-gui qt6-qt5compat qt6-qt5compat-devel qt6-qttools \
qt6-qttools-common qt6-qttools-devel rapidjson-devel python3-sympywget \
rapidjson-devel python3-sympy java-17-openjdk-devel xerces-j2
\end{verbatim}
\end{small}

The oct-file \emph{src/minphase.cc} assumes the \emph{eigen3-devel} package is
installed. The \emph{maxima} package is required to run the \emph{.max} scripts.

The following packages are required to build this document:
\begin{small}
\begin{verbatim}
dnf install dia epstool texlive \
texlive-algorithmicx texlive-appendix texlive-boondox \
texlive-calculator texlive-chngcntr texlive-dvipng texlive-dvisvgm \
texlive-environ texlive-epstopdf texlive-esint texlive-esint-type1 \
texlive-fontaxes texlive-fouriernc texlive-fourier texlive-framed \
texlive-gsftopk texlive-kpfonts texlive-latex-base-dev texlive-latex-bin-dev \
texlive-latex-graphics-dev texlive-ly1 texlive-mathdesign \
texlive-multirow texlive-nag texlive-needspace texlive-newpx \
texlive-newtx texlive-pdfcrop texlive-powerdot \
texlive-pst-blur texlive-pst-pdf texlive-pst-slpe texlive-rotfloat \
texlive-scheme-basic texlive-threeparttable texlive-tocbibind \
texlive-trimspaces texlive-type1cm texlive-upquote texlive-wrapfig \
texlive-dvisvgm
\end{verbatim}
\end{small}
  
\pdfbookmark[0]{Makefile}{makefile}
\section*{\emph{Makefile}}
This document is built with \emph{GNU make-4.4.1}. The \emph{Makefile} in the
project archive builds the PDF version of this document from the \LaTeX source
in \emph{DesignOfIIRFilters.tex}. The project archive contains the files
required to generate the figures shown in this document. The line diagrams are
in \emph{dia} format~\cite{Dia_DiagramEditor} in directory \emph{fig}.  The
source code is in directory \emph{src}.  The source code languages are C++,
Maxima and Octave. The \emph{Makefile} includes a \emph{.mk} file for each of
the Octave test script dependencies listed in the variable
\emph{OCTAVE\_SCRIPTS}. For example, the Octave script
\emph{butt3NS\_test.m}, referred to in
Section~\ref{sec:Round-off-normalised-scaled-lattice}, has the corresponding
\emph{Makefile} fragment, \emph{butt3NS\_test.mk}\footnote{\emph{github.com}
  enforces a limit of $1000$ files per directory in a repository. To conform
  to this limit the \emph{*\_test.m} Octave scripts were moved to \emph{src/test}
  and the \emph{*\_test.mk} Makefile fragments were moved to \emph{src/mk}.}: 
\begin{small}
\verbatiminput{src/mk/butt3NS_test.mk}
\end{small}

\pdfbookmark[0]{Octave}{octave}
\section*{Octave}
The \emph{build-octave.sh} script builds a patched, local, command-line only,
version of \emph{octave-9.4.0} avoiding the vagaries of the Fedora
packagers.

The \emph{build-octave.sh} script builds Octave and the associated numerical
libraries with the \emph{g++} option \texttt{-march=nehalem}. The patch file,
\emph{octave-9.4.0.patch}, is a shell \emph{here} document
within \emph{build-octave.sh}. 

The \emph{build-octave.sh} script assumes the default sizes of FORTRAN
data types. For example, \texttt{real} and \texttt{integer} are $4$ bytes. The
script must be modified to use $8$ byte integer array indexes in \emph{blas},
\emph{lapack}, \emph{SuiteSparse}, \emph{octave} etc.

The local build of Octave links to locally built versions of the following
libraries: 
\emph{arpack-ng-3.9.1}~\cite{ARPACKNG_website},
\emph{fftw-3.3.10}~\cite{FFTW_website},
\emph{glpk-5.0}~\cite{GNU_GLPK},
\emph{lapack-3.12.1}~\cite{LAPACK_website}\footnote{The $16$-byte
  DOUBLE LAPACK static libraries, \emph{libqblas.a} and \emph{libqlapack.a},
  are compiled with the \texttt{-freal-8-real-16} flag.},
\emph{qrupdate-1.1.2}~\cite{QRUPDATE_website},
\emph{SuiteSparse-7.10.0}~\cite{SUITESPARSE_website},
\emph{sundials-7.2.1}~\cite{SUNDIALS_website} and
\emph{GraphicsMagick-1.3.45}~\cite{GraphicsMagick_website}.
The local build of the \emph{LAPACK} library includes the deprecated routines.

Display the Octave internal build configuration with:
\begin{small}
\begin{verbatim}
$ octave --eval "__octave_config_info__"
\end{verbatim}
\end{small}

This project includes a number of Octave \emph{oct-file} extensions written in
C++. The Octave on-line FAQ states:
\begin{quote}
  Code written using Octave's native plug-in interface (also known as a
  \emph{.oct} file) necessarily links with Octave internals and is considered
  a derivative work of Octave and therefore must be released under terms that
  are compatible with the GPL.
\end{quote}

The \emph{build-octave.sh} script builds Octave with the \emph{java} interface.
Initialise the \emph{java} interface similarly to:
\begin{small}
\begin{verbatim}
usejava ("jvm")
javaaddpath(strcat(OCTAVE_HOME,"/share/octave/",OCTAVE_VERSION,"/m/java"));
javaclasspath
\end{verbatim}
\end{small}

The section \emph{Summary of important user-visible changes for version 4.0} in 
the \emph{NEWS} file of the Octave source distribution includes the following
comment: 
\begin{quote}
  Octave now automatically truncates intermediate calculations done with
  floating point values to 64 bits.  Some hardware math co-processors, such
  as the x87, maintain extra precision, but this leads to disagreements in
  calculations when compared to reference implementations in software using
  the IEEE standard for double precision.  There was no measurable
  performance impact to this change, but it may be disabled with the
  configure option --disable-float-truncate.  MinGW and Cygwin platforms,
  as well as GCC compilers >= 5.0 require this feature.  Non-x87 hardware,
  or hardware using SSE options exclusively, can disable float truncation
  if desired.
\end{quote}

The \emph{fftw-3.3.8} release notes (May 28th, 2018-2019-2020)
state\footnote{Also see \url{https://kristerw.github.io/2021/10/19/fast-math/}.}:
\begin{quote}
    Fixed AVX, AVX2 for gcc-8.
      By default, FFTW 3.3.7 was broken with gcc-8. AVX and AVX2 code
      assumed that the compiler honors the distinction between +0 and -0,
      but gcc-8 -ffast-math does not. The default CFLAGS included
      -ffast-math . This release ensures that FFTW works with gcc-8
      -ffast-math , and removes -ffast-math from the default CFLAGS for
      good measure.
\end{quote}

\subsubsection*{Problems with Octave}
The \emph{octave-9.4.0.patch} \texttt{here} document within
\emph{build-octave.sh} patches files to:
\begin{itemize}
\item prevent a \emph{valgrind} warning from \emph{load-save.cc}
\item copies the \emph{unique.m} script from the development version of Octave
      to add stable sorting
\end{itemize}

I have found that the best way to include plots in this document is to
print from Octave with the \emph{-dpdflatex} device. Unfortunately, producing
plots this way is very slow. Here is an example for \emph{octave-9.2.0}:
\begin{small}
\begin{verbatim}
$ time octave -q --no-gui src/test/print_latex_test.m

ans = 9.2.0-robj
Elapsed time is 17.3568 seconds.
   #      Function Attr     Time (s)   Time (%)        Calls
------------------------------------------------------------
  36           set    R       12.180      68.80           61
  20           get             5.013      28.32          269
  33 __go_uimenu__             0.196       1.11           24
 182 __go_delete__             0.112       0.63            1
 172       drawnow             0.078       0.44            3

real    0m18.142s
user    0m8.938s
sys     0m9.143s
\end{verbatim}
\end{small}

I ran \emph{octave} under \emph{callgrind} and viewed the results with
\emph{qcachegrind}. \emph{run\_command\_and\_return\_output()} was called
$123$ times. Next I used \emph{gdb} to look at the \emph{cmd\_str} passed to
that function. It seems that for each tick-mark label in the \TeX file, the
\LaTeX, \emph{dvisvgm} and \emph{dvipng} renderers are run in a sub-process $41$
times each. The aim appears to be to find the bounding box of the label for
typesetting. \LaTeX provides macros to do this.

\subsubsection*{Using the Octave external code interface}
From the Octave \emph{info} documentation:
\begin{quotation}Octave offers a versatile interface for including
  chunks of compiled code as dynamically linked extensions.\end{quotation}
I use the Octave external code interface for the following reasons:
\paragraph{Improved execution time}
For example, the \emph{schurdecomp.m} and \emph{zhong\_inverse.m} functions use
recurrence relations to calculate intermediate results. Recurrence relations
cannot be vectorised in Octave code.
\paragraph{Access to LAPACK functions}
For example, the \emph{complex\_zhong\_inverse} Oct-file pre-processes
a Hessenberg matrix to produce a triangular matrix and then calls the LAPACK
ZTRTRI function to calculate the inverse of that matrix. Similarly, the
\emph{complex\_lower\_hessenberg\_inverse} Oct-file calls the LAPACK ZGBSV
function to calculate the inverse of a lower Hessenberg, banded, matrix.
\paragraph{Improved accuracy}
For example, the \emph{schurdecomp} Oct-file uses
the MPFR~\cite{Fousse:2007:MMB:1236463.1236468} multi-precision library to
obtain improved accuracy in the Schur decomposition of a polynomial. As
mentioned in the \hyperlink{sec:Introduction}{Introduction}, polynomial
root-finding is notoriously difficult. The \emph{qzsolve} Oct-file adapts
the GNU Scientific Library~\cite{GNU_GSL} \emph{gsl\_poly\_complex\_solve()}
function, in the GSL file \emph{poly/zsolve.c}, from \texttt{double} to IEEE
\texttt{\_\_float128} variables. Similarly, the \emph{mzsolve} Oct-file
adapts that GSL function from \texttt{double} to an \texttt{mpfr\_t} data type
defined by the \emph{Boost.Multiprecision} C++ template
library~\cite{Boost_Multiprecision_website}. I tried running the existing test
scripts with \emph{mzsolve} called by \emph{qroots.m}. A single test fails
because of the differences in an approximately zero value. Finally, the
\emph{lzsolve} Oct-file calls a $16$-byte \texttt{DOUBLE}, or IEEE
\texttt{\_\_float128}, version of the LAPACK DGEEV function\footnote{The
  \emph{src/mk/lzsolve\_test.mk} Makefile fragment adds the \emph{libqblas.a} and
  \emph{libqlapack.a} static libraries to \emph{lzsolve.oct}.}. Unsurprisingly,
the accuracy obtained with \emph{lzsolve} is similar to that obtained with
\emph{qzsolve}. 

\subsubsection*{Octave packages and solvers}
The \emph{build-octave.sh} script installs the following Octave Forge packages:
\begin{small}
\verbatiminput{octave_info_test.diary}
\end{small}
The \emph{build-octave.sh} script installs the \emph{SeDuMi}, \emph{SDPT3},
\emph{SCS} and \emph{YALMIP} from their respective software repositories,
and forked versions of the \emph{SparsePOP} and \emph{gloptipoly3} solvers from
\url{https://github.com/robertgj}.

\subsubsection*{Problems with Octave-Forge packages}
The following packages are patched with shell \emph{here} documents
within \emph{build-octave.sh}:
\begin{itemize}
\item the \emph{signal-1.4.6} package \texttt{zplane} function is patched to
  avoid a \LaTeX~error.
\item the \emph{signal-1.4.6} package \texttt{grpdelay} function is replaced
  with a local version called \texttt{delayz}.
\end{itemize}

\pdfbookmark[1]{Building Octave}{building-octave}
\subsection*{Building Octave}
\subsubsection*{Building Octave with LTO and PGO}
The following commands build Octave linked with the system \emph{lapack} and
\emph{blas} shared libraries with link-time-optimisation (LTO) and
profile-guided-optimisation (PGO):
\begin{small}
  \verbatiminput{benchmark/build-shared-lto-pgo.sh}
\end{small}
The PGO profile information is generated by running the Octave test suite.
\subsubsection*{Building Octave for debugging}
To build a debugging version of Octave:
\begin{small}
  \verbatiminput{benchmark/build-dbg.sh}
\end{small}

\subsubsection*{Building Octave oct-files for debugging}
To debug an oct-file with \emph{valgrind} and \emph{gdb}:
\begin{small}
\begin{verbatim}
valgrind --vgdb=yes --vgdb-error=0 octave-cli -p src src/test/scriptname
\end{verbatim}
\end{small}
In a separate shell run:
\begin{small}
\begin{verbatim}
   gdb octave-cli
\end{verbatim}
\end{small}
and issue the following gdb commands:
\begin{small}
\begin{verbatim}
   target remote | vgdb
   continue
\end{verbatim}
\end{small}

To test an oct-file with \emph{address-sanitizer} add these flags:
\begin{small}
\begin{verbatim}
-g -fsanitize=address -fsanitize=undefined -fno-sanitize=vptr -fno-omit-frame-pointer
\end{verbatim}
\end{small}
and ``pre-load'' the \emph{address-sanitizer} library:
\begin{small}
\begin{verbatim}
LD_PRELOAD=/usr/lib64/libasan.so.8 octave-cli --eval oct_file_test_script
\end{verbatim}
\end{small}

\subsubsection*{Installing Octave-Forge packages}
To install Octave packages from a remote Octave-Forge file-server:
\begin{small}
\begin{verbatim}
octave-cli --eval 'pkg install -forge struct io statistics optim control signal'
\end{verbatim}
\end{small}

If \emph{octave} was configured with \emph{--disable-docs} then packages can 
be installed with this work-around:
\begin{small}
\begin{verbatim}
/usr/local/octave-dbg/bin/octave-cli \
--eval 'texi_macros_file("/dev/null");pkg install package_file_name'
\end{verbatim}
\end{small}
\pdfbookmark[1]{Benchmarking Octave}{benchmarking-octave}
\subsection*{Benchmarking Octave}
This section shows the results of benchmarking various builds of Octave
and benchmarking \emph{blas} and \emph{lapack} libraries with a shared library
\emph{LTO} and \emph{PGO} build of Octave.
The CPU is an Intel i7-7700K with $4$ CPU cores ($8$ hyper-threaded).
During the benchmark the CPU frequency was fixed
at $4.5GHz$.  To do this, as the \emph{root} user:
\begin{small}
\begin{verbatim}
for c in `seq 0 7`;do 
  echo "4500000" > /sys/devices/system/cpu/cpu$c/cpufreq/scaling_min_freq; 
  echo "performance" > /sys/devices/system/cpu/cpu$c/cpufreq/scaling_governor;
done
cpupower -c all frequency-info
\end{verbatim}
\end{small}

\subsubsection*{Benchmarking Octave builds}
The shell script \emph{benchmark/build-benchmark.sh} generates the Octave
builds shown in Table~\ref{tab:benchmark-octave-builds}. It is assumed to run
in the \emph{benchmark} sub-directory. The Octave build benchmark test loops
$100$ times finding the amplitude, group delay and phase response of a
filter. Numerical differences between the \emph{blas} and  \emph{lapack}
implementations make it impossible to usefully benchmark with a filter design
script like \emph{iir\_sqp\_slb\_bandpass\_test.m} or
\emph{decimator\_R2\_test.m}. The times given are the average of $10$ runs. For
the \emph{debug} build the optimisation level is \emph{-O0} and for the other
builds it is \emph{-O2 -m64 -mtune=generic}. The Octave build is
\emph{configure}d for command-line only and local libraries with the folowing
options:
\begin{small}
\begin{verbatim}
export OCTAVE_CONFIG_OPTIONS=" \
       --disable-docs \
       --disable-java \
       --disable-atomic-refcount \
       --without-fltk \
       --without-qt \
       --without-sndfile \
       --without-portaudio \
       --without-qhull \
       --without-magick \
       --without-glpk \
       --without-hdf5 \
       --with-arpack-includedir=$LOCAL_PREFIX/include \
       --with-arpack-libdir=$LOCAL_PREFIX/lib \
       --with-qrupdate-includedir=$LOCAL_PREFIX/include \
       --with-qrupdate-libdir=$LOCAL_PREFIX/lib \
       --with-amd-includedir=$LOCAL_PREFIX/include \
       --with-amd-libdir=$LOCAL_PREFIX/lib \
       --with-camd-includedir=$LOCAL_PREFIX/include \
       --with-camd-libdir=$LOCAL_PREFIX/lib \
       --with-colamd-includedir=$LOCAL_PREFIX/include \
       --with-colamd-libdir=$LOCAL_PREFIX/lib \
       --with-ccolamd-includedir=$LOCAL_PREFIX/include \
       --with-ccolamd-libdir=$LOCAL_PREFIX/lib \
       --with-cholmod-includedir=$LOCAL_PREFIX/include \
       --with-cholmod-libdir=$LOCAL_PREFIX/lib \
       --with-cxsparse-includedir=$LOCAL_PREFIX/include \
       --with-cxsparse-libdir=$LOCAL_PREFIX/lib \
       --with-umfpack-includedir=$LOCAL_PREFIX/include \
       --with-umfpack-libdir=$LOCAL_PREFIX/lib \
       --with-fftw3-includedir=$LOCAL_PREFIX/include \
       --with-fftw3-libdir=$LOCAL_PREFIX/lib \
       --with-fftw3f-includedir=$LOCAL_PREFIX/include \
       --with-fftw3f-libdir=$LOCAL_PREFIX/lib"
\end{verbatim}
\end{small}

\begin{table}[H]
\centering
\begin{threeparttable}
\bgroup{}
\begin{tabular}{lr} \toprule
Octave build & IIR benchmark execution time (seconds) \\
\midrule
Debug, shared reference lapack and blas              & 204.6 \\
Generic, shared reference lapack and blas            &  51.3 \\
Generic, shared reference lapack and blas, LTO       &  51.2 \\
Generic, shared reference lapack and blas, PGO       &  52.1 \\
Generic, shared reference lapack and blas, LTO, PGO  &  50.0 \\
\bottomrule
\end{tabular}
\egroup
\end{threeparttable}
\caption[Benchmark results for Octave builds]{Average execution time 
  for 10 runs of the IIR benchmark script with various \emph{Octave} builds.}
\label{tab:benchmark-octave-builds}
\end{table}

\subsubsection*{Benchmarking \emph{blas} and \emph{lapack} libraries}
The shell script \emph{library-benchmark.sh} benchmarks the shared library
\emph{LTO} and \emph{PGO} version of Octave with the
\emph{linpack.m}~\cite{Rutter_LinpackBenchmark} script, the previous IIR
benchmark script and a script that solves a KYP problem by calling YALMIP and
SeDuMi. The \emph{linpack.m} script was modified to produce
repeatable residuals. The alternative \emph{blas} and \emph{lapack} library
versions used are local builds of \emph{blas-3.12.1} and \emph{lapack-3.12.1} and
the Fedora 40 \emph{lapack}, \emph{blas}, \emph{atlas}~\cite{ATLAS_website},
\emph{gsl}~\cite{GNU_GSL} and \emph{openblas}~\cite{OpenBLAS_website}
packages\footnote{The test script \emph{test/02/t0294a.sh} compares the output
  of \emph{DGESVD} for a problematic matrix and the \emph{libtatlas}, system
  \emph{libblas} and ``local'' \emph{libblas} libraries:\\
\begin{texttt}
  > ./dgesvd\_test\_atlas\\
  0.14709002182058989\\
  > ./dgesvd\_test\_sysblas \\
  0.14709002182060871\\
  > LD\_LIBRARY\_PATH=/usr/local/octave-9.1.0/lib ./dgesvd\_test\_sysblas\\
  0.14709002182060871
\end{texttt} \\
Previous versions of \emph{atlas} produced slightly different results on each
run.}:

\begin{small}
\begin{verbatim}
atlas.x86_64            3.10.3-24.fc39
blas.x86_64             3.12.0-7.fc41
lapack.x86_64           3.12.0-7.fc41
gsl.x86_64              2.7.1-11.fc41
gsl-devel.x86_64        2.7.1-11.fc41
openblas.x86_64         0.3.26-5.fc41
openblas-threads.x86_64 0.3.26-5.fc41
\end{verbatim}
\end{small}

The library to be used is specified by the \emph{LD\_PRELOAD} environment 
variable. For example:
\begin{small}
\begin{verbatim}
LD_PRELOAD=/usr/lib64/libgslcblas.so.0 octave-cli -q linpack.m
\end{verbatim}
\end{small}

The number of threads used by \emph{libtatlas} was set at compile-time by the
package builder. For \emph{libopenblasp}, the number of threads is set to, for 
example $2$, by:
\begin{small}
\begin{verbatim}
export OPENBLAS_NUM_THREADS=2
\end{verbatim}
\end{small}

Table~\ref{tab:benchmark-octave-blas-libraries} shows the average MFLOPS or
execution time for $10$\footnote{Probably not enough!} runs of each test
using the shared library \emph{PGO} and \emph{LTO} build of Octave. The
normalised residuals for the two ATLAS libraries varied between two values.
The largest is shown.

\begin{table}
\centering
\begin{threeparttable}
\bgroup{}
%\newcommand\arraystretch{2}
\begin{tabular}{lrrrr} \toprule
\multirow{3}{*}
{\emph{blas} library}      &\multicolumn{2}{c}{linpack.m} &IIR benchmark script&KYP benchmark script\\
\cmidrule{2-5}             & MFLOPS & Normalised  & Execution time & Execution time \\
                           &        & residual    & (seconds)      & (seconds) \\
\midrule                                                              
Generic libblas/liblapack  &  3924  & 21.3        &  49.9          &  62.4 \\
Intel libblas/liblapack    &  3900  & 21.3        &  49.9          &  62.9 \\
Haswell libblas/liblapack  &  4822  & 18.5        &  49.6          &  56.9 \\
Nehalem libblas/liblapack  &  3926  & 21.3        &  49.9          &  62.5 \\
Skylake libblas/liblapack  &  4807  & 18.5        &  49.5          &  56.9 \\
Fedora 41 libblas/liblapack&  3914  & 21.3        &  49.9          &  62.4 \\
libgslcblas                &  3917  & 21.3        &  49.9          &  62.5 \\
libsatlas                  & 13233  & 13.1        &  49.6          &  66.8 \\
libtatlas                  & 19900  & 14.3        &  49.8          &  66.8 \\
libopenblas                & 32599  &  9.9        &  48.3          &  56.9 \\
libopenblasp (1 thread)    & 32650  &  9.9        &  48.3          &  57.5 \\
libopenblasp (2 threads)   & 45858  & 12.1        &  48.6          &  57.5 \\
libopenblasp (4 threads)   & 57407  & 10.8        &  48.6          &  57.6 \\
\bottomrule
\end{tabular}
\egroup{}
\end{threeparttable}
\caption[Benchmark results for \emph{blas} implementations]{Benchmark results
  for \emph{linpack.m} and the IIR and KYP benchmark scripts with various
  \emph{blas} and \emph{lapack} implementations.}
\label{tab:benchmark-octave-blas-libraries}
\end{table}

\subsubsection*{Benchmarking \emph{freqz}, \emph{iirA}  and \emph{schurOneMPAlatticeAsq}}
The Octave script \emph{benchmark\_iirA\_freqz.sh} compares the average execution
time of the Octave \emph{signal} package function \emph{freqz} (calculated at
equal frequency intervals with an FFT) and the \emph{iirA} and
\emph{schurOneMPAlatticeAsq} functions (calculated at arbitrary frequencies with
matrix multiplication).
Figure~\ref{fig:benchmark-iirA-freqz-test-10000} shows the mean execution times
for frequency vectors with a length that is a multiple of $200$.
Figure~\ref{fig:benchmark-iirA-freqz-test-65536} shows the mean execution times
for frequency vectors with a length that is a power of $2$.

\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{benchmark_iirA_freqz_test_n_10000}}
\caption{Mean execution times of \emph{freqz}, \emph{iirA} and
\emph{schurOneMPAlatticeAsq} for frequency vectors with a length that is a
multiple of $200$.}  
\label{fig:benchmark-iirA-freqz-test-10000}
\end{figure}
\begin{figure}
\centering
\scalebox{\DesignOfIIRFiltersPdfScale}{\input{benchmark_iirA_freqz_test_n_65536}}
\caption{Mean execution times of \emph{freqz}, \emph{iirA} and
\emph{schurOneMPAlatticeAsq} for frequency vectors with a length that is a
power of $2$.}
\label{fig:benchmark-iirA-freqz-test-65536}
\end{figure}

\pdfbookmark[0]{Profiling Octave}{profiling-octave}
\section*{Profiling Octave}
\subsection*{Profiling Octave scripts with the internal profiler}
Here is an example of the use of the internal Octave profiler in the Octave
script \emph{yalmip\_kyp\_moment\_lowpass\_test.m}:
\begin{small}
\begin{verbatim}
Constraints=[F_max<=-sedumi_eps, Q_max>=0, F_pl<=0, Q_pl>=0, F_s<=0, Q_s>=0];
Objective=(hsdp*G*hsdp')+(2*hsdp*g')+(2*fap);
Options=sdpsettings("solver","moment","sedumi.eps",sedumi_eps);
profile("on");
try
  sol=optimize(Constraints,Objective,Options);
catch
  fprintf(stderr,lasterror().message);
end_try_catch
profile("off");
T=profile("info");
profshow(T);
\end{verbatim}
\end{small}
with Octave profiler output:
\begin{small}
\begin{verbatim}
   #              Function Attr     Time (s)   Time (%)        Calls
--------------------------------------------------------------------
 415               blkchol          1693.754      93.10           14
 414               getada3            50.494       2.78           14
 412               getada2            27.194       1.49           14
 411               getada1            23.795       1.31           14
 377                sedumi             4.569       0.25            1
 427              bwblkslv             3.000       0.16           60
 423              fwblkslv             1.879       0.10           60
 393            getsymbada             1.604       0.09            1
 313        findhashsorted             1.264       0.07        16900
   8              binary +    R        1.194       0.07       274728
 179                system             0.949       0.05            5
 311                   abs             0.767       0.04          301
 400             symbfwblk             0.704       0.04            4
  73              binary *             0.667       0.04         6194
 272                sparse             0.628       0.03          100
 288             monpowers             0.623       0.03            2
 419              psdscale             0.609       0.03          205
 294 @sdpvar/recovermonoms             0.544       0.03            2
 396                  tril             0.413       0.02          869
 300        @sdpvar/mtimes             0.388       0.02            1
\end{verbatim}
\end{small}

\subsection*{Profiling the Octave binary}
I have not succeeded in profiling the \emph{octave} binary with
\emph{gprof}\footnote{I configured \emph{octave} with \texttt{--disable-docs}
  and compiled with \texttt{-ggdb3 -O0 -pg}. Unfortunately, running
  \emph{octave} fails with the message "Profiling timer expired".} or
\texttt{.oct} shared object files with either \emph{sprof} or \emph{gprofng}.

To ``sort-of'' profile \emph{octave} with \emph{callgrind}:
\begin{small}
\begin{verbatim}
valgrind --tool=callgrind --enable-debuginfod=no --instr-atstart=no \
 --dump-instr=yes --collect-jumps=yes --log-file=valgrind.%p.log \
 --trace-children=yes /usr/local/octave-10.0.0/bin/octave-10.0.0 --no-gui
\end{verbatim}
\end{small}
When the \emph{octave} prompt appears, run \texttt{callgrind\_control
  --instr=on} in another terminal to start sampling.

\pdfbookmark[0]{Solvers}{solvers}
\section*{Solvers}
\pdfbookmark[1]{SeDuMi}{sedumi}
\subsection*{SeDuMi}
The \emph{SeDuMi} source is available from \emph{LeHigh University} as
\emph{SeDuMi\_1\_3.zip}~\cite{Sturm_SeDuMi_1_3}. Unfortunately, this version
does not seem to be actively maintained. An ``unofficial''
\emph{GitHub}~\cite{Sturm_SeDuMi_GitHub} fork is compatible with Octave.
The \emph{1.3.8} tag runs without modification under Octave\footnote{The
\emph{SeDuMi-1.3} source file \emph{vec.m} shadows a built-in Octave function.}.

The \emph{SeDuMi} source depends on the \emph{OpenBLAS} \emph{f77blas.h} and
\emph{openblas\_config.h} headers. \emph{install\_sedumi.m} assumes they are
present in \emph{/usr/include/openblas}. A 64-bit version of \emph{SeDuMi}
requires \emph{-DOPENBLAS\_USE64BITINT}. The \emph{install\_sedumi.m} script can
be called with a \emph{mex} template. For example, to enable the \emph{mxAssert}
checks: 
\begin{small}
\begin{verbatim}
octave:1> mexcmd = ['mex -O2 -DMEX_DEBUG -DOCTAVE -I/usr/include/openblas %s '];
octave:2> install_sedumi ('-rebuild', mexcmd);
\end{verbatim}
\end{small}

\subsubsection*{Problems with SeDuMi}
The \emph{SeDuMi} User Guide~\cite[Section 4]{Sturm_SeDuMiUserGuide_GitHub} shows
an example of optimising a complex valued Toeplitz matrix. The Octave script
\emph{sedumi\_toepest\_test.m} runs this example. Unfortunately, the $Z$ matrix
found by this script is different to that shown in the \emph{SeDuMi} User Guide.
The Octave script \emph{sedumi\_real\_toepest\_test.m} expresses the $Z$ and $P$
matrixes in terms of the real and imaginary parts of the matrix elements (see
Appendix~\ref{app:Linear-algebra-positive-definite-matrixes}). The $Z$ matrix
found by that script agrees with that shown in the \emph{SeDuMi} User Guide.
\emph{L\"{o}fberg}~\cite{Lofberg_YALMIP_complex_example} shows five different
\emph{YALMIP} solutions for this problem, reproduced in the Octave script
\emph{yalmip\_complex\_test.m}. The $Z$ matrixes found by that script agree with
the $Z$ matrix shown in the \emph{SeDuMi} User Guide. \emph{YALMIP} supports
complex-valued constraints for all solvers by automatically converting
complex-valued problems to real-valued problems.

The Octave script \emph{sedumi\_profiler\_test.m} profiles the
\emph{SeDuMi/examples/test\_sedumi.m} script:
\begin{small}
\verbatiminput{sedumi_profiler_test.info}
\end{small}
The \emph{SeDuMi} m-file \emph{SeDuMi/psdscale.m} is complex and has no comments.

\pdfbookmark[1]{SparsePOP}{sparsepop}
\subsection*{SparsePOP}
\emph{SparsePOP}~\cite{SparsePOP} is ``a semidefinite relaxations package for
polynomial programming''. \emph{SparsePOP303} runs under Octave with the
modifications shown in \emph{SparsePOP303.patch}.

The \emph{readGMS.m} and \emph{convert2.m} functions are altered to support the
Octave-Forge \emph{symbolic} package~\cite{OctaveForge_SymbolicPackage}. The
latter is based on \emph{SymPy}~\cite{SymPy}, a Python library for symbolic
mathematics. The Octave \emph{sparsePOP\_test.m} script shows an example of
\emph{sparsePOP} reading the \emph{Bex5\_2\_5.gms} GAMS format example with the
Octave-Forge \emph{symbolic} package.

\subsubsection*{Problems with SparsePOP}
The \emph{sparsePOP\_solveExample\_test.m} script runs the SparsePOP
\emph{solveExample.m} function, with the \emph{'sedumi'} solver, excluding
problems $k\_exclude=[36,45,46,54,70,71,88,92]$. For those $k$ I catch
exceptions like:
\begin{small}
\begin{verbatim}
   Caught exception at k=36!
   ## '2' is not defined in the line of 'Variables'.
   ## Should check the line of the objective function in 'Babel.gms'.
   warning: Called readGMS>getObjPoly at line 1306
   warning: Called readGMS at line 341
   warning: Called sparsePOP at line 324
   warning: Called solveExample at line 263
   warning: Called solveExample_test at line 27
\end{verbatim}
\end{small}

I run \emph{sparsePOP} with \emph{param.mex=0}. The \emph{mexconv1} mex-file
occasionally causes a \emph{valgrind} warning when \emph{make\_mexdata}
incorrectly calculates the size of \emph{objPoly.supports}. For example, when
running the SparsePOP \emph{solveExample} function with \emph{valgrind}: 
\begin{small}
\begin{verbatim}
85: randomwithEQ(20,2,4,4,3201)

SparsePOP 3.03
by H.Waki, S.Kim, M.Kojima, M.Muramatsu,
   H.Sugimoto and M.Yamashita, September 2018

==66559== Invalid read of size 8
==66559==    at 0xC346D21: mexFunction (mexconv1.cpp:180)
\end{verbatim}
\end{small}

\pdfbookmark[1]{SDPT3}{sdpt3}
\subsection*{SDPT3}
\emph{SDPT3}~\cite{TohTutuncuTodd_SDPT3,TohToddTutuncu_SDPT3,
  TutuncuTohTodd_SDPT3} is a MATLAB software for semidefinite-quadratic-linear
programming. The version used in this project is a fork of the ``unofficial''
GitHub repository~\cite{Unofficial_SDPT3}.

\subsubsection*{Problems with SDPT3}
The \emph{sdpt3.patch} file shows a modification that suppresses a
divide-by-zero warning when running the \emph{maxcut} example from
\emph{sqlpdemo} with a feasible initial solution. 

\pdfbookmark[1]{YALMIP}{yalmip}
\subsection*{YALMIP}\
\emph{YALMIP}~\cite{Lofberg_YALMIP,Lofberg2004} is a toolbox for modelling and
optimisation in MATLAB and Octave. \emph{YALMIP} calls semi-definite programming
(SDP) solvers such as \emph{SeDuMi} and \emph{SDPT3}. 

\pdfbookmark[1]{LMIRank}{lmirank}
\subsection*{LMIRank}\
\emph{LMIRank}~\cite{Orsi_LMIRank,Orsi_NewtonLikeLMIRankConstrained} is a
toolbox for solving rank constrained LMI problems:
\begin{align*}
  F\left(x\right) & \succeq 0 \\
  G\left(x\right) & \succeq 0 \\
  \mathrank G\left(x\right) & \le r 
\end{align*}
The Octave file \emph{lmirank.m} contains the \texttt{lmirank} and
\texttt{trheuristic} functions. The Octave test script \emph{lmirank\_test.m}
contains the \texttt{lmiranktest2} function. \texttt{lmirank} calls the
\emph{SeDuMi} SDP solver. \emph{YALMIP} has an interface to \texttt{lmirank}.

\pdfbookmark[1]{gloptipoly3}{gloptipoly3}
\subsection*{gloptipoly3}\
\emph{gloptipoly3}~\cite{Henrion_gloptipoly3,
Henrion_gloptipoly3MomentsOptimizationSemiDefiniteProg,
Lasserre_SemidefiniteProgrammingGeneralizedProblemMoments,
Lasserre_IntroductionPolySemiAlgOptim} is ``intended to solve, or at least
approximate, the Generalized Problem of Moments (GPM), an infinite-dimensional
optimization problem which can be viewed as an extension of the classical
problem of moments''.

\pdfbookmark[1]{SCS}{SCS}
\subsection*{SCS}
The \emph{Splitting Conic Solver}
(SCS)~\cite{Bodonoghue_SCS,BODonoghueAbbott_Matlab_SCS,BODonoghueChuParikhBoyd_SCS}
is software for solving semidefinite-quadratic-linear programming problems.
There are two varieties of SCS, a \emph{direct} LMI solver and an
\emph{indirect} conjugate-gradient solver\footnote{YALMIP supports the
\emph{"scs"}, \emph{"scs-direct"} and \emph{"scs-indirect"} SCS solver names.}.

\subsubsection*{Compiling SCS with \texttt{\_\_float128} floating-point numbers}
The \emph{build-octave.sh} script installs SCS with patches to enable
compilation with \texttt{\_\_float128} floating-point numbers by setting
\texttt{dfloat=true} in \emph{make\_scs.m}, compiling \emph{scs\_qprintf.c},
and linking with the \emph{libquadmath.so}, \emph{libqblas.a} and
\emph{libqlapack.a} libraries. I found that with \texttt{\_\_float128}
floating-point numbers SCS was $1$ to $2$ orders of magnitude slower than
with \texttt{double} floating-point numbers.

\subsubsection*{Problems with SCS}
The documentation is confusing. In many cases SeDuMi and SDPT3 find a better
solution.

\pdfbookmark[1]{PIQP}{PIQP}
\subsection*{PIQP}
The \emph{Proximal Interior-Point Quadratic Programming} (PIQP) 
solver~\cite{Schwan_PIQP2023} solves, as the name
suggests, quadratic programming problems with equality and inequality
constraints . It is written in C++ template header files and is based on the
Eigen C++ template header library~\cite{EigenWeb}. It is available as an
Octave-Forge package~\cite{OctaveForge_PIQPPackage}.
\subsubsection*{Problems with PIQP}
The documentation is incomplete. In general, the design of IIR filters is a
non-convex problem that is unsuited to quadratic programming optimisation.

\begin{comment}

\pdfbookmark[1]{SDPA}{SDPA}
\subsection*{SDPA}
\emph{SDPA}~\cite{YamashitaFujisawa_SoftwarePackageSemidefiniteProgramsSDPA7,
  Fujisawa_SemidefiniteProgrammingMATLAB} is software for
semidefinite-quadratic-linear programming. The shell script
\emph{install-sdpa.sh} downloads, patches and installs \emph{SDPA} with the
\emph{mex}-file interface to Octave. The Fedora MUMPS and MUMPS-devel packages
are prerequisites.
\subsubsection*{Problems with SDPA}
When I run \emph{SDPA} as a solver in the Octave and YALMIP test script
\emph{yalmip\_complex\_test.m} I get messages like:
\begin{small}
\begin{verbatim}
Strange behavior : primal < dual :: line 158 in sdpa_solve.cpp
\end{verbatim}
\end{small}
Nonetheless the results for these small examples appear correct. I suspect that
there is a problem in the conversion from the YALMIP internal format to the SDPA
format.

\pdfbookmark[1]{BMIsolver}{bmisolver}
\subsection*{BMIsolver}
\emph{BMIsolver}~\cite{BMIsolver,Dinh_BMIsolver} is a MATLAB package for solving
optimisation problems with BMI (bilinear matrix inequality) constraints. The
current version requires \emph{YALMIP} as a modeling language. \emph{BMIsolver}
runs under Octave with the minor modification shown in
\emph{BMIsolver\_2013.patch}.

\pdfbookmark[1]{MPSolve}{mpsolve}
\section*{MPSolve}
The \emph{MPSolve}~\cite{BiniFiorentinoRobol_mpsolve} is a high precsion
root-finder with an oct-file implementation. Examples of using
the built-in Octave \emph{roots}, the quad-float implementation in \emph{qroots}
and \emph{mps\_roots}:
\begin{small}
\begin{verbatim}
octave-cli --eval 'norm(roots(bincoeff(20,0:20))+1)'
ans =  1.4835

octave-cli -p src --eval 'norm(qroots(bincoeff(20,0:20))+1)'
ans =  0.19206

octave-cli --eval 'pkg load mpsolve;norm(mps_roots(bincoeff(20,0:20))+1)'
ans =    1.0819e-13
\end{verbatim}
\end{small}

\subsubsection*{Problems with MPSolve}
\emph{MPSolve} does not return repeatable answers:
\begin{small}
\begin{verbatim}
octave-cli --eval 'pkg load mpsolve;norm(mps_roots(bincoeff(20,0:20))+1)'
ans =    1.0819e-13

octave-cli --eval 'pkg load mpsolve;norm(mps_roots(bincoeff(20,0:20))+1)'
ans =    1.1108e-13

octave-cli --eval 'pkg load mpsolve;norm(mps_roots(bincoeff(20,0:20))+1)'
ans =    1.0910e-13
\end{verbatim}
\end{small}
and it can return strange answers:
\begin{small}
\begin{verbatim}
octave:1> pkg load mpsolve 
octave:2> pkg list mpsolve
Package Name  | Version | Installation directory
--------------+---------+-----------------------
     mpsolve *|   3.1.7 | .../octave-5.2.0/share/octave/packages/mpsolve-3.1.7
octave:3> mps_roots([1 0 0 0 0 0 0],'u')
ans =

   1.1840e-316 +  0.0000e+00i
    2.1322e-81 + 2.8664e+161i
   1.9253e+161 + 7.3681e+228i
    3.4546e-86 +  3.5641e-57i
   4.5663e+257 + 2.1335e+233i
   3.6247e+233 +  6.2591e-85i
\end{verbatim}
\end{small}
With \emph{mpsolve-3.2.1} this example seg-faults.
\pdfbookmark[1]{COMPleib}{compleib}
\subsection*{COMPLeib}
\emph{COMPleib}~\cite{Leibfritz_COMPleib,LeibfritzLipinski_COMPleibManual,
  Leibfritz_COMPleibPaper} is a collection of non-linear 
semi-definite test examples referenced by \emph{BMIsolver}. The \emph{COMPleib}
function runs under Octave with the minor modifications shown in
\emph{COMPlib\_r1\_1.patch}.

\end{comment}

\pdfbookmark[0]{QEMU emulation}{qemu}
\section*{QEMU emulation}
I endeavour to ensure that the Octave scripts required to build this document
run successfully under the QEMU emulation of an Intel Nehalem CPU. The following
is a general indication of how to set up QEMU emulation to achieve this.

\subsection*{QEMU user-mode emulation}
To run an Octave script with the QEMU user-mode emulation, run, for example:
\begin{small}
\begin{verbatim}
qemu-x86_64 -cpu Nehalem `which octave` --no-gui -p src src/test/butt3NS_test.m
\end{verbatim}
\end{small}
This runs the \texttt{octave-cli} binary and associated dynamic linker in the
QEMU x86\_64 user-mode emulation of an Intel Nehalem CPU.

To build this document with the QEMU user-mode emulation of Octave, run:
\begin{small}
\begin{verbatim}
make OCTAVE="qemu-x86_64 -cpu Nehalem `which octave` --no-gui"
\end{verbatim}
\end{small}
\subsection*{QEMU virtual machine emulation}
Unfortunately, user-mode QEMU emulation only uses one thread and is is not
completely portable. I build \texttt{octave} and the associated linear
algebra libraries with \texttt{-march=nehalem}. The system compiler links 
\texttt{octave} to the system \emph{libm}, \emph{libquadmath} and
\emph{libstdc++} shared libraries from the Fedora \emph{glibc},
\emph{libquadmath} and \emph{libstdc++} packages, respectively.
Running \texttt{gcc -v} shows that the system compiler is itself compiled with
\texttt{-mtune=generic}. I believe that, currently, this is equivalent to
\texttt{-march=nehalem} but it may change in future. QEMU emulation on a
virtual machine allows use of known libraries, multiple CPUs, and builds this
document much more quickly than user-mode emulation. 
\subsubsection*{Create the VM}
\emph{Buettner}~\cite{Buettner_ConfigureQEMU} describes configuration of a
QEMU~\cite{QEMU_website} based virtual machine with the RedHat
\emph{virt-manager} application. In order to be able to shut down the virtual
machines I found it necessary to also install the Fedora \emph{acpid} and
\emph{qemu-guest-agent} packages and enable the associated services on the host. 

I created a QEMU VM from the Fedora 36 Server net install ISO image with 4GB
RAM, 10GB disk, 8 Nehalem CPUs, bridged networking on device \texttt{virbr0},
root password \texttt{password} and SSH root access with password. Following
\emph{Buettner}'s advice I removed the tablet, sound, serial port 1, channel
qemu-ga, channel spice and USB redirector 1 and 2. In the following the IPv4
address will be determined by your network settings and the VM DHCP lease. The
host firewall is set to allow trusted access by the \emph{ssh} service. Recover
the pointer from the \emph{virt-manager} terminal by depressing the
\texttt{left-Ctrl} and \texttt{left-Alt} keys.

If necessary, edit the \emph{user} and \emph{group} in
\texttt{/etc/libvirt/qemu.conf} and add the user to the \emph{qemu}, \emph{kvm}
and \emph{libvirt} groups:
\begin{small}
\begin{verbatim}
sudo usermod -aG qemu ${USER}
sudo usermod -aG kvm ${USER}
sudo usermod -aG libvirt ${USER}
\end{verbatim}
\end{small}
\texttt{virsh} requires that \emph{LIBVIRT\_DEFAULT\_URI} is set in the shell
environment: 
\begin{small}
\begin{verbatim}
export LIBVIRT_DEFAULT_URI=qemu:///system
\end{verbatim}
\end{small}
Log out and log back in to effect these changes.

\subsubsection*{Rename the VM}
To change the name of a VM:
\begin{small}
\begin{verbatim}
virsh shutdown foo
virsh domrename foo bar
virsh start bar
\end{verbatim}
\end{small}

\subsubsection*{Set up the VM}
I did not attempt to set up a shared directory or file server. I communicate
with the VM through \texttt{ssh} and transfer files with \texttt{scp}. A vertical
ellipsis indicates discarded output.

\begin{small}
\begin{verbatim}
$ virsh start Fedora36Server
Domain 'Fedora36Server' started

$ virsh net-list
Name      State    Autostart   Persistent
--------------------------------------------
 default   active   yes         yes

$ virsh net-dhcp-leases default
.
.
$ ssh root@192.168.122.100
.
.
[root@localhost ~]# uname -rs
Linux 5.19.10-200.fc36.x86_64
[root@localhost ~] dnf install wget readline-devel lzip sharutils gcc gcc-c++ \
gcc-gfortran gmp-devel mpfr-devel make cmake gnuplot-latex m4 gperf bison flex \
openblas-devel patch texinfo texinfo-tex icoutils librsvg2-tools librsvg2 \
dia epstool autoconf automake libtool pcre pcre-devel freetype freetype-devel \
dia epstool texlive-algorithmicx texlive-appendix texlive-boondox \
texlive-calculator texlive-chngcntr texlive-dvipng texlive-environ \
texlive-epstopdf texlive-esint texlive-esint-type1 texlive-fontaxes \
texlive-fouriernc texlive-fourier texlive-framed texlive-gsftopk \
texlive-kpfonts texlive-latex-base-dev texlive-latex-bin-dev \
texlive-latex-graphics-dev texlive-ly1 texlive-mathdesign texlive-multirow \
texlive-nag texlive-needspace texlive-newpx texlive-newtx \
texlive-pdfcrop texlive-powerdot texlive-pst-blur texlive-pst-pdf \
texlive-pst-slpe texlive-rotfloat texlive-scheme-basic \
texlive-threeparttable texlive-tocbibind texlive-trimspaces \
texlive-type1cm texlive-upquote texlive-wrapfig texlive-dvisvgm \
hdf5 hdf5-devel qt qscintilla-qt5 qscintilla-qt5-devel \
qhull qhull-devel portaudio portaudio-devel libsndfile libsndfile-devel \
GraphicsMagick-c++ GraphicsMagick-c++-devel libcurl libcurl-devel \
gl2ps gl2ps-devel fontconfig-devel mesa-libGLU mesa-libGLU-devel \
qt5-qttools qt5-qttools-common qt5-qttools-devel rapidjson-devel python3-sympy \
maxima
.
.
[root@localhost ~]# wget https://github.com/robertgj/DesignOfIIRFilters/archive/master.zip
[root@localhost ~]# unzip master.zip
[root@localhost ~]# mkdir -p /usr/local/src/octave
[root@localhost ~]# cp DesignOfIIRFilters-master/build-octave.sh /usr/local/src/octave
[root@localhost ~]# cd /usr/local/src/octave
[root@localhost octave]# wget https://ftp.gnu.org/gnu/gnu-keyring.gpg
.
.
[root@localhost octave]# gpg2 --import gnu-keyring.gpg
.
.
[root@localhost octave]# sh ./build-octave.sh 
.
.
[root@localhost ~]# cd
[root@localhost ~]# echo "export PATH=$PATH:/usr/local/octave-7.2.0/bin" >> .bashrc 
[root@localhost ~]# shutdown -h now
Connection to 192.168.122.100 closed by remote host.
Connection to 192.168.122.100 closed.
$
\end{verbatim}
\end{small}
This edited example session shows:
\begin{itemize}
\item starting the VM with \emph{virsh}
\item logging into the VM with \emph{ssh}
\item system update with \emph{dnf}
\item installation of the Fedora packages required to build this document
\item download of the source for this document from \emph{GitHub}
\item building a local version of Octave with the \emph{build-octave.sh} script
\end{itemize}

\subsubsection*{Build this document on the VM}

Octave will only use the \emph{qt} graphics toolkit if it finds an X
display. Otherwise it uses the \emph{gnuplot} graphics toolkit. Use
\emph{virt-manager} to set the display to \emph{Type} 'VNC server',
\emph{Listen type} 'Address' and \emph{Address} 'All interfaces'.
The \emph{-Y} option to \texttt{ssh} enables trusted X11 forwarding.
\begin{small}
\begin{verbatim}
$ virsh start Fedora36Server
$ ssh -Y root@192.168.122.100
[root@localhost ~]# dnf install xorg-x11-xauth xorg-x11-xinit \
xorg-x11-drv-qxl xorg-x11-xinit-session xrdb xmodmap 
[root@localhost ~]# echo "X11Forwarding yes" >>/etc/ssh/sshd_config
[root@localhost ~]# echo "X11UseLocalhost no" >>/etc/ssh/sshd_config
[root@localhost ~]# echo "AddressFamily inet" >>/etc/ssh/sshd_config
[root@localhost ~]# systemctl restart sshd.service
[root@localhost ~]# octave --no-gui --eval "available_graphics_toolkits"
ans =
{
  [1,1] = gnuplot
  [1,2] = qt
}
[root@localhost ~]# cd DesignOfIIRFilters-master
[root@localhost DesignOfIIRFilters-master]# make -k -O -j 8 
\end{verbatim}
\end{small}

\subsubsection*{Copy a file to  the VM}
\begin{small}
\begin{verbatim}
$ virsh start Fedora36Server
$ scp Makefile scp://root@192.168.122.100//root/Makefile
\end{verbatim}
\end{small}

\subsubsection*{Copy this document from the VM}
\begin{small}
\begin{verbatim}
$ virsh start Fedora36Server
$ scp root@192.168.122.100:/root/DesignOfIIRFilters-master/DesignOfIIRFilters.pdf \
  DesignOfIIRFilters.pdf
\end{verbatim}
\end{small}


\subsubsection*{Run the test scripts on the VM}
\begin{small}
\begin{verbatim}
$ virsh start Fedora36Server
$ ssh -Y root@192.168.122.100
[root@localhost ~]# cd DesignOfIIRFilters-master
[root@localhost DesignOfIIRFilters-master]# make batchtest
.
.
.
\end{verbatim}
\end{small}

\subsubsection*{Export the VM to libvirt}
\begin{small}
\begin{verbatim}
$ virsh start Fedora36Server
$ virsh dumpxml Fedora36Server 
\end{verbatim}
\end{small}

\subsubsection*{Remove an existing VM}
\begin{small}
\begin{verbatim}
$ sudo virsh shutdown Fedora36Server
$ sudo virsh undefine Fedora36Server
\end{verbatim}
\end{small}

\subsubsection*{Zero the disk image before compressing it}
Shut down the VM and, on the host, run\footnote{First install the Fedora
\emph{guestfs-tools} package.}:
\begin{small}
\begin{verbatim}
$ sudo virsh shutdown Fedora36Server
$ sudo virt-sparsify -v -x --in-place your-image-file
\end{verbatim}
\end{small}

Alternatively, fill unused VM disc sectors with $0$:
\begin{small}
\begin{verbatim}
$ virsh start Fedora36Server
$ ssh -Y root@192.168.122.100
[root@localhost ~]# cd /boot
[root@localhost ~]# dd if=/dev/zero of=zerofile
[root@localhost ~]# sync
[root@localhost ~]# rm -f zerofile
[root@localhost ~]# cd /
[root@localhost ~]# dd if=/dev/zero of=zerofile
[root@localhost ~]# sync
[root@localhost ~]# rm -f zerofile
[root@localhost ~]# shutdown -h now
\end{verbatim}
\end{small}


\pdfbookmark[0]{Testing}{testing}
\section*{Testing}
The \emph{test} directory contains regression test shell
scripts. The test scripts must be run from the project root directory. The
shell script \emph{batchtest.sh} runs multiple tests in parallel.
Alternatively, run \texttt{make batchtest}.

\pdfbookmark[0]{Aegis}{aegis}
\section*{Aegis}
I use the \emph{aegis} software change management system written by the late
Peter Miller~\cite{Miller_aegis}. To build \emph{aegis} with
the patch provided in this project:
\begin{small}
\begin{verbatim}
tar -xf aegis-4.24.tar.gz
cd aegis-4.24
patch -p1 < ../aegis-4.24.patch
CXXFLAGS=-O2 ./configure 
make && make install
\end{verbatim}
\end{small}
Replacing \emph{Makefile.in} with \emph{Makefile.in.solib} builds binaries
linked to a shared library. The \emph{configure} script may prompt you to
install the \emph{groff}, \emph{file-devel}, \emph{uuid-devel} etc. packages.
The \emph{/usr/local/com/aegis/state} file lists existing Aegis projects.
The \emph{/usr/local/com/aegis/user} directory contains files listing the
per-user state of existing Aegis projects. I use this \emph{.aegisrc}:
\begin{small}
\begin{verbatim} 
default_development_directory = "CHANGES";
default_project_directory = "AEGIS";
\end{verbatim}
\end{small}
and add to \emph{.bashrc}:
\begin{small}
\begin{verbatim}
if [ -f /usr/local/etc/profile.d/aegis.sh ]; then
  . /usr/local/etc/profile.d/aegis.sh
fi
\end{verbatim}
\end{small}

\emph{aegis.conf} configures \emph{aegis} to use the file comparison functions
from Miller's \emph{fhist}~\cite{Miller_fhist} project. \emph{fhist} depends on
the \emph{libexplain}~\cite{Miller_libexplain} library. \emph{fhist}
and \emph{libexplain} are compiled similarly to \emph{aegis} with the patches 
provided in this project. 

\pdfbookmark[0]{Monochrome printing}{monochrome-printing}
\section*{Monochrome printing}
Monochrome printing of this document is supported by:
\begin{itemize}
\item hiding coloured hyperlinks in the \emph{printed} PDF document by compiling
  this document with:
\begin{small}
\begin{verbatim}
pdflatex '\newcommand\DesignOfIIRFiltersMono{}\input{DesignOfIIRFilters}'
\end{verbatim}
\end{small}
The \emph{DesignOfIIRFiltersMono} flag enables the following
\LaTeX code: 
\begin{small}
\begin{verbatim}
\usepackage[hidelinks]{hyperref} 
\end{verbatim}
\end{small}
\item setting the Octave default line palette to all black in
  \emph{src/test\_common.m}: 
\begin{small}
\begin{verbatim}
if getenv("OCTAVE_ENABLE_MONOCHROME")
  set(0,"defaultaxescolororder",zeros(size(get(0,"defaultaxescolororder"))));
endif
\end{verbatim}
\end{small}
\end{itemize}

The following command enables both these changes:
\begin{small}
\begin{verbatim}
make cleanall && OCTAVE_ENABLE_MONOCHROME=1 make -j 6 monochrome
\end{verbatim}
\end{small}

\cleardoublepage
\phantomsection
\addcontentsline{toc}{part}{Bibliography}
\bibliographystyle{plain}
\bibliography{DesignOfIIRFilters}

\end{document}
